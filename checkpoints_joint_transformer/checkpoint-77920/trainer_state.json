{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 77920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003208418891170431,
      "grad_norm": 1.8618873357772827,
      "learning_rate": 4.996855749486653e-05,
      "loss": 0.123,
      "step": 50
    },
    {
      "epoch": 0.006416837782340862,
      "grad_norm": 1.441545009613037,
      "learning_rate": 4.993647330595483e-05,
      "loss": 0.0742,
      "step": 100
    },
    {
      "epoch": 0.009625256673511294,
      "grad_norm": 0.9945878982543945,
      "learning_rate": 4.990438911704312e-05,
      "loss": 0.0505,
      "step": 150
    },
    {
      "epoch": 0.012833675564681724,
      "grad_norm": 0.7490195035934448,
      "learning_rate": 4.987230492813142e-05,
      "loss": 0.0333,
      "step": 200
    },
    {
      "epoch": 0.016042094455852154,
      "grad_norm": 0.5976370573043823,
      "learning_rate": 4.984022073921972e-05,
      "loss": 0.0226,
      "step": 250
    },
    {
      "epoch": 0.019250513347022588,
      "grad_norm": 0.39978665113449097,
      "learning_rate": 4.980813655030801e-05,
      "loss": 0.0159,
      "step": 300
    },
    {
      "epoch": 0.02245893223819302,
      "grad_norm": 0.39327123761177063,
      "learning_rate": 4.9776052361396305e-05,
      "loss": 0.0113,
      "step": 350
    },
    {
      "epoch": 0.02566735112936345,
      "grad_norm": 0.23910671472549438,
      "learning_rate": 4.97439681724846e-05,
      "loss": 0.0086,
      "step": 400
    },
    {
      "epoch": 0.028875770020533882,
      "grad_norm": 0.30874067544937134,
      "learning_rate": 4.97118839835729e-05,
      "loss": 0.0067,
      "step": 450
    },
    {
      "epoch": 0.03208418891170431,
      "grad_norm": 0.319812148809433,
      "learning_rate": 4.9679799794661194e-05,
      "loss": 0.0055,
      "step": 500
    },
    {
      "epoch": 0.03529260780287474,
      "grad_norm": 0.1626594364643097,
      "learning_rate": 4.964771560574949e-05,
      "loss": 0.0044,
      "step": 550
    },
    {
      "epoch": 0.038501026694045176,
      "grad_norm": 0.13181710243225098,
      "learning_rate": 4.961563141683778e-05,
      "loss": 0.0041,
      "step": 600
    },
    {
      "epoch": 0.0417094455852156,
      "grad_norm": 0.07095635682344437,
      "learning_rate": 4.958354722792608e-05,
      "loss": 0.0037,
      "step": 650
    },
    {
      "epoch": 0.04491786447638604,
      "grad_norm": 0.07307136058807373,
      "learning_rate": 4.955146303901438e-05,
      "loss": 0.0032,
      "step": 700
    },
    {
      "epoch": 0.04812628336755647,
      "grad_norm": 0.07232923060655594,
      "learning_rate": 4.951937885010267e-05,
      "loss": 0.0029,
      "step": 750
    },
    {
      "epoch": 0.0513347022587269,
      "grad_norm": 0.08000003546476364,
      "learning_rate": 4.948729466119097e-05,
      "loss": 0.0028,
      "step": 800
    },
    {
      "epoch": 0.05454312114989733,
      "grad_norm": 0.06012258678674698,
      "learning_rate": 4.945521047227926e-05,
      "loss": 0.0026,
      "step": 850
    },
    {
      "epoch": 0.057751540041067764,
      "grad_norm": 0.11292734742164612,
      "learning_rate": 4.942312628336756e-05,
      "loss": 0.0025,
      "step": 900
    },
    {
      "epoch": 0.06095995893223819,
      "grad_norm": 0.07417883723974228,
      "learning_rate": 4.939104209445585e-05,
      "loss": 0.0024,
      "step": 950
    },
    {
      "epoch": 0.06416837782340862,
      "grad_norm": 0.049293939024209976,
      "learning_rate": 4.935895790554415e-05,
      "loss": 0.0023,
      "step": 1000
    },
    {
      "epoch": 0.06737679671457905,
      "grad_norm": 0.12760330736637115,
      "learning_rate": 4.9326873716632445e-05,
      "loss": 0.0022,
      "step": 1050
    },
    {
      "epoch": 0.07058521560574949,
      "grad_norm": 0.05779903754591942,
      "learning_rate": 4.929478952772074e-05,
      "loss": 0.0022,
      "step": 1100
    },
    {
      "epoch": 0.07379363449691992,
      "grad_norm": 0.0560147799551487,
      "learning_rate": 4.926270533880904e-05,
      "loss": 0.0021,
      "step": 1150
    },
    {
      "epoch": 0.07700205338809035,
      "grad_norm": 0.0767228826880455,
      "learning_rate": 4.9230621149897334e-05,
      "loss": 0.002,
      "step": 1200
    },
    {
      "epoch": 0.08021047227926079,
      "grad_norm": 0.18805907666683197,
      "learning_rate": 4.919853696098563e-05,
      "loss": 0.002,
      "step": 1250
    },
    {
      "epoch": 0.0834188911704312,
      "grad_norm": 0.05436065047979355,
      "learning_rate": 4.9166452772073926e-05,
      "loss": 0.0021,
      "step": 1300
    },
    {
      "epoch": 0.08662731006160164,
      "grad_norm": 0.03340139985084534,
      "learning_rate": 4.913436858316222e-05,
      "loss": 0.0019,
      "step": 1350
    },
    {
      "epoch": 0.08983572895277207,
      "grad_norm": 0.038186974823474884,
      "learning_rate": 4.910228439425051e-05,
      "loss": 0.0019,
      "step": 1400
    },
    {
      "epoch": 0.0930441478439425,
      "grad_norm": 0.0666898861527443,
      "learning_rate": 4.9070200205338815e-05,
      "loss": 0.0019,
      "step": 1450
    },
    {
      "epoch": 0.09625256673511294,
      "grad_norm": 0.07509221881628036,
      "learning_rate": 4.9038116016427104e-05,
      "loss": 0.0018,
      "step": 1500
    },
    {
      "epoch": 0.09946098562628337,
      "grad_norm": 0.07153709977865219,
      "learning_rate": 4.90060318275154e-05,
      "loss": 0.0018,
      "step": 1550
    },
    {
      "epoch": 0.1026694045174538,
      "grad_norm": 0.03817585110664368,
      "learning_rate": 4.89739476386037e-05,
      "loss": 0.0018,
      "step": 1600
    },
    {
      "epoch": 0.10587782340862423,
      "grad_norm": 0.010965713299810886,
      "learning_rate": 4.894186344969199e-05,
      "loss": 0.0018,
      "step": 1650
    },
    {
      "epoch": 0.10908624229979466,
      "grad_norm": 0.06733473390340805,
      "learning_rate": 4.890977926078029e-05,
      "loss": 0.0018,
      "step": 1700
    },
    {
      "epoch": 0.1122946611909651,
      "grad_norm": 0.08355464041233063,
      "learning_rate": 4.8877695071868585e-05,
      "loss": 0.0018,
      "step": 1750
    },
    {
      "epoch": 0.11550308008213553,
      "grad_norm": 0.09481209516525269,
      "learning_rate": 4.884561088295688e-05,
      "loss": 0.0018,
      "step": 1800
    },
    {
      "epoch": 0.11871149897330595,
      "grad_norm": 0.0095345014706254,
      "learning_rate": 4.881352669404518e-05,
      "loss": 0.0017,
      "step": 1850
    },
    {
      "epoch": 0.12191991786447638,
      "grad_norm": 0.1204560250043869,
      "learning_rate": 4.8781442505133473e-05,
      "loss": 0.0017,
      "step": 1900
    },
    {
      "epoch": 0.12512833675564683,
      "grad_norm": 0.13046987354755402,
      "learning_rate": 4.874935831622176e-05,
      "loss": 0.0017,
      "step": 1950
    },
    {
      "epoch": 0.12833675564681724,
      "grad_norm": 0.06653016805648804,
      "learning_rate": 4.8717274127310066e-05,
      "loss": 0.0016,
      "step": 2000
    },
    {
      "epoch": 0.13154517453798767,
      "grad_norm": 0.1286737322807312,
      "learning_rate": 4.868518993839836e-05,
      "loss": 0.0016,
      "step": 2050
    },
    {
      "epoch": 0.1347535934291581,
      "grad_norm": 0.028704093769192696,
      "learning_rate": 4.865310574948666e-05,
      "loss": 0.0016,
      "step": 2100
    },
    {
      "epoch": 0.13796201232032854,
      "grad_norm": 0.1147100105881691,
      "learning_rate": 4.8621021560574954e-05,
      "loss": 0.0017,
      "step": 2150
    },
    {
      "epoch": 0.14117043121149897,
      "grad_norm": 0.1150909885764122,
      "learning_rate": 4.8588937371663244e-05,
      "loss": 0.0016,
      "step": 2200
    },
    {
      "epoch": 0.1443788501026694,
      "grad_norm": 0.13757583498954773,
      "learning_rate": 4.855685318275155e-05,
      "loss": 0.0017,
      "step": 2250
    },
    {
      "epoch": 0.14758726899383984,
      "grad_norm": 0.04533865302801132,
      "learning_rate": 4.8524768993839836e-05,
      "loss": 0.0017,
      "step": 2300
    },
    {
      "epoch": 0.15079568788501027,
      "grad_norm": 0.11126852035522461,
      "learning_rate": 4.849268480492813e-05,
      "loss": 0.0016,
      "step": 2350
    },
    {
      "epoch": 0.1540041067761807,
      "grad_norm": 0.05205458402633667,
      "learning_rate": 4.846060061601643e-05,
      "loss": 0.0016,
      "step": 2400
    },
    {
      "epoch": 0.15721252566735114,
      "grad_norm": 0.05353657901287079,
      "learning_rate": 4.8428516427104725e-05,
      "loss": 0.0017,
      "step": 2450
    },
    {
      "epoch": 0.16042094455852157,
      "grad_norm": 0.04819076508283615,
      "learning_rate": 4.839643223819302e-05,
      "loss": 0.0016,
      "step": 2500
    },
    {
      "epoch": 0.16362936344969198,
      "grad_norm": 0.029744846746325493,
      "learning_rate": 4.836434804928132e-05,
      "loss": 0.0016,
      "step": 2550
    },
    {
      "epoch": 0.1668377823408624,
      "grad_norm": 0.017689870670437813,
      "learning_rate": 4.833226386036961e-05,
      "loss": 0.0016,
      "step": 2600
    },
    {
      "epoch": 0.17004620123203285,
      "grad_norm": 0.0712764710187912,
      "learning_rate": 4.830017967145791e-05,
      "loss": 0.0016,
      "step": 2650
    },
    {
      "epoch": 0.17325462012320328,
      "grad_norm": 0.0782766118645668,
      "learning_rate": 4.8268095482546206e-05,
      "loss": 0.0016,
      "step": 2700
    },
    {
      "epoch": 0.1764630390143737,
      "grad_norm": 0.14212974905967712,
      "learning_rate": 4.8236011293634495e-05,
      "loss": 0.0016,
      "step": 2750
    },
    {
      "epoch": 0.17967145790554415,
      "grad_norm": 0.06703441590070724,
      "learning_rate": 4.82039271047228e-05,
      "loss": 0.0016,
      "step": 2800
    },
    {
      "epoch": 0.18287987679671458,
      "grad_norm": 0.08941950649023056,
      "learning_rate": 4.817184291581109e-05,
      "loss": 0.0016,
      "step": 2850
    },
    {
      "epoch": 0.186088295687885,
      "grad_norm": 0.06821450591087341,
      "learning_rate": 4.8139758726899384e-05,
      "loss": 0.0015,
      "step": 2900
    },
    {
      "epoch": 0.18929671457905545,
      "grad_norm": 0.11723428219556808,
      "learning_rate": 4.810767453798768e-05,
      "loss": 0.0016,
      "step": 2950
    },
    {
      "epoch": 0.19250513347022588,
      "grad_norm": 0.029114576056599617,
      "learning_rate": 4.8075590349075976e-05,
      "loss": 0.0016,
      "step": 3000
    },
    {
      "epoch": 0.19571355236139631,
      "grad_norm": 0.11045718938112259,
      "learning_rate": 4.804350616016427e-05,
      "loss": 0.0015,
      "step": 3050
    },
    {
      "epoch": 0.19892197125256675,
      "grad_norm": 0.07360862195491791,
      "learning_rate": 4.801142197125257e-05,
      "loss": 0.0015,
      "step": 3100
    },
    {
      "epoch": 0.20213039014373715,
      "grad_norm": 0.03246740996837616,
      "learning_rate": 4.7979337782340865e-05,
      "loss": 0.0016,
      "step": 3150
    },
    {
      "epoch": 0.2053388090349076,
      "grad_norm": 0.09699195623397827,
      "learning_rate": 4.794725359342916e-05,
      "loss": 0.0015,
      "step": 3200
    },
    {
      "epoch": 0.20854722792607802,
      "grad_norm": 0.057443272322416306,
      "learning_rate": 4.791516940451746e-05,
      "loss": 0.0015,
      "step": 3250
    },
    {
      "epoch": 0.21175564681724846,
      "grad_norm": 0.02042320929467678,
      "learning_rate": 4.7883085215605746e-05,
      "loss": 0.0015,
      "step": 3300
    },
    {
      "epoch": 0.2149640657084189,
      "grad_norm": 0.07691802084445953,
      "learning_rate": 4.785100102669405e-05,
      "loss": 0.0015,
      "step": 3350
    },
    {
      "epoch": 0.21817248459958932,
      "grad_norm": 0.04550920054316521,
      "learning_rate": 4.781891683778234e-05,
      "loss": 0.0015,
      "step": 3400
    },
    {
      "epoch": 0.22138090349075976,
      "grad_norm": 0.0229314137250185,
      "learning_rate": 4.778683264887064e-05,
      "loss": 0.0015,
      "step": 3450
    },
    {
      "epoch": 0.2245893223819302,
      "grad_norm": 0.036864250898361206,
      "learning_rate": 4.775474845995894e-05,
      "loss": 0.0015,
      "step": 3500
    },
    {
      "epoch": 0.22779774127310062,
      "grad_norm": 0.049065254628658295,
      "learning_rate": 4.772266427104723e-05,
      "loss": 0.0015,
      "step": 3550
    },
    {
      "epoch": 0.23100616016427106,
      "grad_norm": 0.052149657160043716,
      "learning_rate": 4.769058008213553e-05,
      "loss": 0.0015,
      "step": 3600
    },
    {
      "epoch": 0.2342145790554415,
      "grad_norm": 0.02131987176835537,
      "learning_rate": 4.765849589322382e-05,
      "loss": 0.0015,
      "step": 3650
    },
    {
      "epoch": 0.2374229979466119,
      "grad_norm": 0.030872764065861702,
      "learning_rate": 4.7626411704312116e-05,
      "loss": 0.0015,
      "step": 3700
    },
    {
      "epoch": 0.24063141683778233,
      "grad_norm": 0.09684517979621887,
      "learning_rate": 4.759432751540041e-05,
      "loss": 0.0015,
      "step": 3750
    },
    {
      "epoch": 0.24383983572895276,
      "grad_norm": 0.12071435153484344,
      "learning_rate": 4.756224332648871e-05,
      "loss": 0.0015,
      "step": 3800
    },
    {
      "epoch": 0.2470482546201232,
      "grad_norm": 0.0527171716094017,
      "learning_rate": 4.7530159137577004e-05,
      "loss": 0.0015,
      "step": 3850
    },
    {
      "epoch": 0.25025667351129366,
      "grad_norm": 0.19540458917617798,
      "learning_rate": 4.74980749486653e-05,
      "loss": 0.0015,
      "step": 3900
    },
    {
      "epoch": 0.25346509240246407,
      "grad_norm": 0.009443646296858788,
      "learning_rate": 4.74659907597536e-05,
      "loss": 0.0015,
      "step": 3950
    },
    {
      "epoch": 0.25667351129363447,
      "grad_norm": 0.025776037946343422,
      "learning_rate": 4.743390657084189e-05,
      "loss": 0.0015,
      "step": 4000
    },
    {
      "epoch": 0.25988193018480493,
      "grad_norm": 0.01185863371938467,
      "learning_rate": 4.740182238193019e-05,
      "loss": 0.0014,
      "step": 4050
    },
    {
      "epoch": 0.26309034907597534,
      "grad_norm": 0.03817903622984886,
      "learning_rate": 4.736973819301848e-05,
      "loss": 0.0015,
      "step": 4100
    },
    {
      "epoch": 0.2662987679671458,
      "grad_norm": 0.0347752682864666,
      "learning_rate": 4.733765400410678e-05,
      "loss": 0.0015,
      "step": 4150
    },
    {
      "epoch": 0.2695071868583162,
      "grad_norm": 0.022238416597247124,
      "learning_rate": 4.730556981519507e-05,
      "loss": 0.0015,
      "step": 4200
    },
    {
      "epoch": 0.27271560574948667,
      "grad_norm": 0.020946567878127098,
      "learning_rate": 4.727348562628337e-05,
      "loss": 0.0014,
      "step": 4250
    },
    {
      "epoch": 0.2759240246406571,
      "grad_norm": 0.08297334611415863,
      "learning_rate": 4.724140143737166e-05,
      "loss": 0.0015,
      "step": 4300
    },
    {
      "epoch": 0.27913244353182753,
      "grad_norm": 0.08003022521734238,
      "learning_rate": 4.720931724845996e-05,
      "loss": 0.0015,
      "step": 4350
    },
    {
      "epoch": 0.28234086242299794,
      "grad_norm": 0.10969718545675278,
      "learning_rate": 4.717723305954826e-05,
      "loss": 0.0015,
      "step": 4400
    },
    {
      "epoch": 0.2855492813141684,
      "grad_norm": 0.023536713793873787,
      "learning_rate": 4.714514887063655e-05,
      "loss": 0.0015,
      "step": 4450
    },
    {
      "epoch": 0.2887577002053388,
      "grad_norm": 0.04927212372422218,
      "learning_rate": 4.711306468172485e-05,
      "loss": 0.0015,
      "step": 4500
    },
    {
      "epoch": 0.2919661190965092,
      "grad_norm": 0.06943873316049576,
      "learning_rate": 4.7080980492813144e-05,
      "loss": 0.0015,
      "step": 4550
    },
    {
      "epoch": 0.2951745379876797,
      "grad_norm": 0.03206690773367882,
      "learning_rate": 4.704889630390144e-05,
      "loss": 0.0015,
      "step": 4600
    },
    {
      "epoch": 0.2983829568788501,
      "grad_norm": 0.03964413329958916,
      "learning_rate": 4.701681211498974e-05,
      "loss": 0.0015,
      "step": 4650
    },
    {
      "epoch": 0.30159137577002054,
      "grad_norm": 0.08032107353210449,
      "learning_rate": 4.698472792607803e-05,
      "loss": 0.0015,
      "step": 4700
    },
    {
      "epoch": 0.30479979466119095,
      "grad_norm": 0.07239292562007904,
      "learning_rate": 4.695264373716632e-05,
      "loss": 0.0014,
      "step": 4750
    },
    {
      "epoch": 0.3080082135523614,
      "grad_norm": 0.02894393354654312,
      "learning_rate": 4.6920559548254625e-05,
      "loss": 0.0014,
      "step": 4800
    },
    {
      "epoch": 0.3112166324435318,
      "grad_norm": 0.1547781527042389,
      "learning_rate": 4.688847535934292e-05,
      "loss": 0.0014,
      "step": 4850
    },
    {
      "epoch": 0.3144250513347023,
      "grad_norm": 0.027552945539355278,
      "learning_rate": 4.685639117043121e-05,
      "loss": 0.0015,
      "step": 4900
    },
    {
      "epoch": 0.3176334702258727,
      "grad_norm": 0.1204255223274231,
      "learning_rate": 4.6824306981519514e-05,
      "loss": 0.0014,
      "step": 4950
    },
    {
      "epoch": 0.32084188911704314,
      "grad_norm": 0.03672361746430397,
      "learning_rate": 4.67922227926078e-05,
      "loss": 0.0015,
      "step": 5000
    },
    {
      "epoch": 0.32405030800821355,
      "grad_norm": 0.09915529936552048,
      "learning_rate": 4.67601386036961e-05,
      "loss": 0.0014,
      "step": 5050
    },
    {
      "epoch": 0.32725872689938396,
      "grad_norm": 0.04120735451579094,
      "learning_rate": 4.6728054414784396e-05,
      "loss": 0.0015,
      "step": 5100
    },
    {
      "epoch": 0.3304671457905544,
      "grad_norm": 0.03905445709824562,
      "learning_rate": 4.669597022587269e-05,
      "loss": 0.0014,
      "step": 5150
    },
    {
      "epoch": 0.3336755646817248,
      "grad_norm": 0.05294622480869293,
      "learning_rate": 4.666388603696099e-05,
      "loss": 0.0014,
      "step": 5200
    },
    {
      "epoch": 0.3368839835728953,
      "grad_norm": 0.013953479006886482,
      "learning_rate": 4.6631801848049284e-05,
      "loss": 0.0015,
      "step": 5250
    },
    {
      "epoch": 0.3400924024640657,
      "grad_norm": 0.044334884732961655,
      "learning_rate": 4.659971765913758e-05,
      "loss": 0.0014,
      "step": 5300
    },
    {
      "epoch": 0.34330082135523615,
      "grad_norm": 0.024638941511511803,
      "learning_rate": 4.6567633470225877e-05,
      "loss": 0.0014,
      "step": 5350
    },
    {
      "epoch": 0.34650924024640656,
      "grad_norm": 0.049342237412929535,
      "learning_rate": 4.653554928131417e-05,
      "loss": 0.0014,
      "step": 5400
    },
    {
      "epoch": 0.349717659137577,
      "grad_norm": 0.02640196867287159,
      "learning_rate": 4.650346509240246e-05,
      "loss": 0.0014,
      "step": 5450
    },
    {
      "epoch": 0.3529260780287474,
      "grad_norm": 0.12299786508083344,
      "learning_rate": 4.6471380903490765e-05,
      "loss": 0.0015,
      "step": 5500
    },
    {
      "epoch": 0.3561344969199179,
      "grad_norm": 0.08477312326431274,
      "learning_rate": 4.6439296714579055e-05,
      "loss": 0.0014,
      "step": 5550
    },
    {
      "epoch": 0.3593429158110883,
      "grad_norm": 0.03624090179800987,
      "learning_rate": 4.640721252566735e-05,
      "loss": 0.0014,
      "step": 5600
    },
    {
      "epoch": 0.36255133470225875,
      "grad_norm": 0.0157910268753767,
      "learning_rate": 4.637512833675565e-05,
      "loss": 0.0014,
      "step": 5650
    },
    {
      "epoch": 0.36575975359342916,
      "grad_norm": 0.055918239057064056,
      "learning_rate": 4.634304414784394e-05,
      "loss": 0.0014,
      "step": 5700
    },
    {
      "epoch": 0.36896817248459957,
      "grad_norm": 0.026026317849755287,
      "learning_rate": 4.6310959958932246e-05,
      "loss": 0.0014,
      "step": 5750
    },
    {
      "epoch": 0.37217659137577,
      "grad_norm": 0.0593528114259243,
      "learning_rate": 4.6278875770020535e-05,
      "loss": 0.0014,
      "step": 5800
    },
    {
      "epoch": 0.37538501026694043,
      "grad_norm": 0.10529136657714844,
      "learning_rate": 4.624679158110883e-05,
      "loss": 0.0014,
      "step": 5850
    },
    {
      "epoch": 0.3785934291581109,
      "grad_norm": 0.14428099989891052,
      "learning_rate": 4.621470739219713e-05,
      "loss": 0.0014,
      "step": 5900
    },
    {
      "epoch": 0.3818018480492813,
      "grad_norm": 0.10143613070249557,
      "learning_rate": 4.6182623203285424e-05,
      "loss": 0.0014,
      "step": 5950
    },
    {
      "epoch": 0.38501026694045176,
      "grad_norm": 0.020179472863674164,
      "learning_rate": 4.615053901437372e-05,
      "loss": 0.0014,
      "step": 6000
    },
    {
      "epoch": 0.38821868583162217,
      "grad_norm": 0.032172467559576035,
      "learning_rate": 4.6118454825462016e-05,
      "loss": 0.0014,
      "step": 6050
    },
    {
      "epoch": 0.39142710472279263,
      "grad_norm": 0.04516664147377014,
      "learning_rate": 4.6086370636550306e-05,
      "loss": 0.0014,
      "step": 6100
    },
    {
      "epoch": 0.39463552361396304,
      "grad_norm": 0.0228563342243433,
      "learning_rate": 4.605428644763861e-05,
      "loss": 0.0014,
      "step": 6150
    },
    {
      "epoch": 0.3978439425051335,
      "grad_norm": 0.015122642740607262,
      "learning_rate": 4.6022202258726905e-05,
      "loss": 0.0014,
      "step": 6200
    },
    {
      "epoch": 0.4010523613963039,
      "grad_norm": 0.023855095729231834,
      "learning_rate": 4.5990118069815194e-05,
      "loss": 0.0014,
      "step": 6250
    },
    {
      "epoch": 0.4042607802874743,
      "grad_norm": 0.036323681473731995,
      "learning_rate": 4.59580338809035e-05,
      "loss": 0.0014,
      "step": 6300
    },
    {
      "epoch": 0.40746919917864477,
      "grad_norm": 0.02464001439511776,
      "learning_rate": 4.592594969199179e-05,
      "loss": 0.0014,
      "step": 6350
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.1414632499217987,
      "learning_rate": 4.589386550308008e-05,
      "loss": 0.0014,
      "step": 6400
    },
    {
      "epoch": 0.41388603696098564,
      "grad_norm": 0.08282282203435898,
      "learning_rate": 4.586178131416838e-05,
      "loss": 0.0014,
      "step": 6450
    },
    {
      "epoch": 0.41709445585215604,
      "grad_norm": 0.025547590106725693,
      "learning_rate": 4.5829697125256675e-05,
      "loss": 0.0014,
      "step": 6500
    },
    {
      "epoch": 0.4203028747433265,
      "grad_norm": 0.06936997175216675,
      "learning_rate": 4.579761293634497e-05,
      "loss": 0.0014,
      "step": 6550
    },
    {
      "epoch": 0.4235112936344969,
      "grad_norm": 0.03188001736998558,
      "learning_rate": 4.576552874743327e-05,
      "loss": 0.0014,
      "step": 6600
    },
    {
      "epoch": 0.42671971252566737,
      "grad_norm": 0.09902377426624298,
      "learning_rate": 4.5733444558521564e-05,
      "loss": 0.0014,
      "step": 6650
    },
    {
      "epoch": 0.4299281314168378,
      "grad_norm": 0.014487247914075851,
      "learning_rate": 4.570136036960986e-05,
      "loss": 0.0014,
      "step": 6700
    },
    {
      "epoch": 0.43313655030800824,
      "grad_norm": 0.04804503545165062,
      "learning_rate": 4.5669276180698156e-05,
      "loss": 0.0014,
      "step": 6750
    },
    {
      "epoch": 0.43634496919917864,
      "grad_norm": 0.074173703789711,
      "learning_rate": 4.5637191991786446e-05,
      "loss": 0.0014,
      "step": 6800
    },
    {
      "epoch": 0.43955338809034905,
      "grad_norm": 0.08177253603935242,
      "learning_rate": 4.560510780287475e-05,
      "loss": 0.0014,
      "step": 6850
    },
    {
      "epoch": 0.4427618069815195,
      "grad_norm": 0.06068671867251396,
      "learning_rate": 4.557302361396304e-05,
      "loss": 0.0014,
      "step": 6900
    },
    {
      "epoch": 0.4459702258726899,
      "grad_norm": 0.11314015835523605,
      "learning_rate": 4.554093942505134e-05,
      "loss": 0.0014,
      "step": 6950
    },
    {
      "epoch": 0.4491786447638604,
      "grad_norm": 0.053069356828927994,
      "learning_rate": 4.550885523613963e-05,
      "loss": 0.0014,
      "step": 7000
    },
    {
      "epoch": 0.4523870636550308,
      "grad_norm": 0.07987438142299652,
      "learning_rate": 4.547677104722793e-05,
      "loss": 0.0014,
      "step": 7050
    },
    {
      "epoch": 0.45559548254620125,
      "grad_norm": 0.10263164341449738,
      "learning_rate": 4.544468685831623e-05,
      "loss": 0.0014,
      "step": 7100
    },
    {
      "epoch": 0.45880390143737165,
      "grad_norm": 0.04123002663254738,
      "learning_rate": 4.541260266940452e-05,
      "loss": 0.0014,
      "step": 7150
    },
    {
      "epoch": 0.4620123203285421,
      "grad_norm": 0.06486701220273972,
      "learning_rate": 4.5380518480492815e-05,
      "loss": 0.0014,
      "step": 7200
    },
    {
      "epoch": 0.4652207392197125,
      "grad_norm": 0.06371769309043884,
      "learning_rate": 4.534843429158111e-05,
      "loss": 0.0014,
      "step": 7250
    },
    {
      "epoch": 0.468429158110883,
      "grad_norm": 0.08856707811355591,
      "learning_rate": 4.531635010266941e-05,
      "loss": 0.0014,
      "step": 7300
    },
    {
      "epoch": 0.4716375770020534,
      "grad_norm": 0.01577667146921158,
      "learning_rate": 4.5284265913757704e-05,
      "loss": 0.0014,
      "step": 7350
    },
    {
      "epoch": 0.4748459958932238,
      "grad_norm": 0.03791649639606476,
      "learning_rate": 4.5252181724846e-05,
      "loss": 0.0014,
      "step": 7400
    },
    {
      "epoch": 0.47805441478439425,
      "grad_norm": 0.025891728699207306,
      "learning_rate": 4.522009753593429e-05,
      "loss": 0.0014,
      "step": 7450
    },
    {
      "epoch": 0.48126283367556466,
      "grad_norm": 0.019654633477330208,
      "learning_rate": 4.518801334702259e-05,
      "loss": 0.0013,
      "step": 7500
    },
    {
      "epoch": 0.4844712525667351,
      "grad_norm": 0.09632903337478638,
      "learning_rate": 4.515592915811089e-05,
      "loss": 0.0014,
      "step": 7550
    },
    {
      "epoch": 0.48767967145790553,
      "grad_norm": 0.07077724486589432,
      "learning_rate": 4.512384496919918e-05,
      "loss": 0.0014,
      "step": 7600
    },
    {
      "epoch": 0.490888090349076,
      "grad_norm": 0.03857836499810219,
      "learning_rate": 4.509176078028748e-05,
      "loss": 0.0013,
      "step": 7650
    },
    {
      "epoch": 0.4940965092402464,
      "grad_norm": 0.07174096256494522,
      "learning_rate": 4.505967659137577e-05,
      "loss": 0.0014,
      "step": 7700
    },
    {
      "epoch": 0.49730492813141686,
      "grad_norm": 0.01572933793067932,
      "learning_rate": 4.5027592402464066e-05,
      "loss": 0.0014,
      "step": 7750
    },
    {
      "epoch": 0.5005133470225873,
      "grad_norm": 0.03790852054953575,
      "learning_rate": 4.499550821355236e-05,
      "loss": 0.0014,
      "step": 7800
    },
    {
      "epoch": 0.5037217659137577,
      "grad_norm": 0.025784524157643318,
      "learning_rate": 4.496342402464066e-05,
      "loss": 0.0014,
      "step": 7850
    },
    {
      "epoch": 0.5069301848049281,
      "grad_norm": 0.04190418869256973,
      "learning_rate": 4.4931339835728955e-05,
      "loss": 0.0013,
      "step": 7900
    },
    {
      "epoch": 0.5101386036960985,
      "grad_norm": 0.05896963179111481,
      "learning_rate": 4.489925564681725e-05,
      "loss": 0.0013,
      "step": 7950
    },
    {
      "epoch": 0.5133470225872689,
      "grad_norm": 0.060030240565538406,
      "learning_rate": 4.486717145790554e-05,
      "loss": 0.0014,
      "step": 8000
    },
    {
      "epoch": 0.5165554414784395,
      "grad_norm": 0.10569287091493607,
      "learning_rate": 4.4835087268993844e-05,
      "loss": 0.0014,
      "step": 8050
    },
    {
      "epoch": 0.5197638603696099,
      "grad_norm": 0.04777154698967934,
      "learning_rate": 4.480300308008214e-05,
      "loss": 0.0014,
      "step": 8100
    },
    {
      "epoch": 0.5229722792607803,
      "grad_norm": 0.11957470327615738,
      "learning_rate": 4.477091889117043e-05,
      "loss": 0.0014,
      "step": 8150
    },
    {
      "epoch": 0.5261806981519507,
      "grad_norm": 0.04609798640012741,
      "learning_rate": 4.473883470225873e-05,
      "loss": 0.0014,
      "step": 8200
    },
    {
      "epoch": 0.5293891170431212,
      "grad_norm": 0.025018252432346344,
      "learning_rate": 4.470675051334702e-05,
      "loss": 0.0013,
      "step": 8250
    },
    {
      "epoch": 0.5325975359342916,
      "grad_norm": 0.13842199742794037,
      "learning_rate": 4.4674666324435325e-05,
      "loss": 0.0013,
      "step": 8300
    },
    {
      "epoch": 0.535805954825462,
      "grad_norm": 0.01654622331261635,
      "learning_rate": 4.4642582135523614e-05,
      "loss": 0.0014,
      "step": 8350
    },
    {
      "epoch": 0.5390143737166324,
      "grad_norm": 0.11901819705963135,
      "learning_rate": 4.461049794661191e-05,
      "loss": 0.0014,
      "step": 8400
    },
    {
      "epoch": 0.5422227926078029,
      "grad_norm": 0.09489326924085617,
      "learning_rate": 4.4578413757700206e-05,
      "loss": 0.0014,
      "step": 8450
    },
    {
      "epoch": 0.5454312114989733,
      "grad_norm": 0.021875830367207527,
      "learning_rate": 4.45463295687885e-05,
      "loss": 0.0014,
      "step": 8500
    },
    {
      "epoch": 0.5486396303901437,
      "grad_norm": 0.047648947685956955,
      "learning_rate": 4.45142453798768e-05,
      "loss": 0.0014,
      "step": 8550
    },
    {
      "epoch": 0.5518480492813141,
      "grad_norm": 0.06143224984407425,
      "learning_rate": 4.4482161190965095e-05,
      "loss": 0.0014,
      "step": 8600
    },
    {
      "epoch": 0.5550564681724846,
      "grad_norm": 0.07795009016990662,
      "learning_rate": 4.445007700205339e-05,
      "loss": 0.0014,
      "step": 8650
    },
    {
      "epoch": 0.5582648870636551,
      "grad_norm": 0.06144076585769653,
      "learning_rate": 4.441799281314169e-05,
      "loss": 0.0014,
      "step": 8700
    },
    {
      "epoch": 0.5614733059548255,
      "grad_norm": 0.043411824852228165,
      "learning_rate": 4.4385908624229983e-05,
      "loss": 0.0014,
      "step": 8750
    },
    {
      "epoch": 0.5646817248459959,
      "grad_norm": 0.04074299708008766,
      "learning_rate": 4.435382443531827e-05,
      "loss": 0.0013,
      "step": 8800
    },
    {
      "epoch": 0.5678901437371663,
      "grad_norm": 0.05029330030083656,
      "learning_rate": 4.4321740246406576e-05,
      "loss": 0.0014,
      "step": 8850
    },
    {
      "epoch": 0.5710985626283368,
      "grad_norm": 0.041199952363967896,
      "learning_rate": 4.4289656057494865e-05,
      "loss": 0.0013,
      "step": 8900
    },
    {
      "epoch": 0.5743069815195072,
      "grad_norm": 0.021360646933317184,
      "learning_rate": 4.425757186858316e-05,
      "loss": 0.0014,
      "step": 8950
    },
    {
      "epoch": 0.5775154004106776,
      "grad_norm": 0.13503223657608032,
      "learning_rate": 4.4225487679671464e-05,
      "loss": 0.0014,
      "step": 9000
    },
    {
      "epoch": 0.580723819301848,
      "grad_norm": 0.06975001841783524,
      "learning_rate": 4.4193403490759754e-05,
      "loss": 0.0014,
      "step": 9050
    },
    {
      "epoch": 0.5839322381930184,
      "grad_norm": 0.039463356137275696,
      "learning_rate": 4.416131930184805e-05,
      "loss": 0.0014,
      "step": 9100
    },
    {
      "epoch": 0.5871406570841889,
      "grad_norm": 0.019055623561143875,
      "learning_rate": 4.4129235112936346e-05,
      "loss": 0.0014,
      "step": 9150
    },
    {
      "epoch": 0.5903490759753593,
      "grad_norm": 0.04813113063573837,
      "learning_rate": 4.409715092402464e-05,
      "loss": 0.0014,
      "step": 9200
    },
    {
      "epoch": 0.5935574948665298,
      "grad_norm": 0.020034566521644592,
      "learning_rate": 4.406506673511294e-05,
      "loss": 0.0013,
      "step": 9250
    },
    {
      "epoch": 0.5967659137577002,
      "grad_norm": 0.02337157167494297,
      "learning_rate": 4.4032982546201235e-05,
      "loss": 0.0013,
      "step": 9300
    },
    {
      "epoch": 0.5999743326488707,
      "grad_norm": 0.031788334250450134,
      "learning_rate": 4.4000898357289524e-05,
      "loss": 0.0013,
      "step": 9350
    },
    {
      "epoch": 0.6031827515400411,
      "grad_norm": 0.047820691019296646,
      "learning_rate": 4.396881416837783e-05,
      "loss": 0.0013,
      "step": 9400
    },
    {
      "epoch": 0.6063911704312115,
      "grad_norm": 0.17439435422420502,
      "learning_rate": 4.393672997946612e-05,
      "loss": 0.0013,
      "step": 9450
    },
    {
      "epoch": 0.6095995893223819,
      "grad_norm": 0.05848516523838043,
      "learning_rate": 4.390464579055442e-05,
      "loss": 0.0014,
      "step": 9500
    },
    {
      "epoch": 0.6128080082135524,
      "grad_norm": 0.03374827653169632,
      "learning_rate": 4.3872561601642716e-05,
      "loss": 0.0013,
      "step": 9550
    },
    {
      "epoch": 0.6160164271047228,
      "grad_norm": 0.029852401465177536,
      "learning_rate": 4.3840477412731005e-05,
      "loss": 0.0013,
      "step": 9600
    },
    {
      "epoch": 0.6192248459958932,
      "grad_norm": 0.016981691122055054,
      "learning_rate": 4.380839322381931e-05,
      "loss": 0.0013,
      "step": 9650
    },
    {
      "epoch": 0.6224332648870636,
      "grad_norm": 0.052288852632045746,
      "learning_rate": 4.37763090349076e-05,
      "loss": 0.0013,
      "step": 9700
    },
    {
      "epoch": 0.625641683778234,
      "grad_norm": 0.09080112725496292,
      "learning_rate": 4.3744224845995894e-05,
      "loss": 0.0013,
      "step": 9750
    },
    {
      "epoch": 0.6288501026694046,
      "grad_norm": 0.03633345663547516,
      "learning_rate": 4.371214065708419e-05,
      "loss": 0.0013,
      "step": 9800
    },
    {
      "epoch": 0.632058521560575,
      "grad_norm": 0.0990397185087204,
      "learning_rate": 4.3680056468172486e-05,
      "loss": 0.0013,
      "step": 9850
    },
    {
      "epoch": 0.6352669404517454,
      "grad_norm": 0.12433712929487228,
      "learning_rate": 4.364797227926078e-05,
      "loss": 0.0013,
      "step": 9900
    },
    {
      "epoch": 0.6384753593429158,
      "grad_norm": 0.09626727551221848,
      "learning_rate": 4.361588809034908e-05,
      "loss": 0.0014,
      "step": 9950
    },
    {
      "epoch": 0.6416837782340863,
      "grad_norm": 0.07804600894451141,
      "learning_rate": 4.3583803901437375e-05,
      "loss": 0.0013,
      "step": 10000
    },
    {
      "epoch": 0.6448921971252567,
      "grad_norm": 0.022539107128977776,
      "learning_rate": 4.355171971252567e-05,
      "loss": 0.0013,
      "step": 10050
    },
    {
      "epoch": 0.6481006160164271,
      "grad_norm": 0.06740175187587738,
      "learning_rate": 4.351963552361397e-05,
      "loss": 0.0013,
      "step": 10100
    },
    {
      "epoch": 0.6513090349075975,
      "grad_norm": 0.05320107191801071,
      "learning_rate": 4.3487551334702256e-05,
      "loss": 0.0013,
      "step": 10150
    },
    {
      "epoch": 0.6545174537987679,
      "grad_norm": 0.03553905338048935,
      "learning_rate": 4.345546714579056e-05,
      "loss": 0.0013,
      "step": 10200
    },
    {
      "epoch": 0.6577258726899384,
      "grad_norm": 0.047324664890766144,
      "learning_rate": 4.342338295687885e-05,
      "loss": 0.0013,
      "step": 10250
    },
    {
      "epoch": 0.6609342915811088,
      "grad_norm": 0.04925056919455528,
      "learning_rate": 4.3391298767967145e-05,
      "loss": 0.0014,
      "step": 10300
    },
    {
      "epoch": 0.6641427104722792,
      "grad_norm": 0.04155232012271881,
      "learning_rate": 4.335921457905545e-05,
      "loss": 0.0013,
      "step": 10350
    },
    {
      "epoch": 0.6673511293634496,
      "grad_norm": 0.05145280063152313,
      "learning_rate": 4.332713039014374e-05,
      "loss": 0.0013,
      "step": 10400
    },
    {
      "epoch": 0.6705595482546202,
      "grad_norm": 0.0592690072953701,
      "learning_rate": 4.3295046201232034e-05,
      "loss": 0.0013,
      "step": 10450
    },
    {
      "epoch": 0.6737679671457906,
      "grad_norm": 0.05307771638035774,
      "learning_rate": 4.326296201232033e-05,
      "loss": 0.0013,
      "step": 10500
    },
    {
      "epoch": 0.676976386036961,
      "grad_norm": 0.041005976498126984,
      "learning_rate": 4.3230877823408626e-05,
      "loss": 0.0013,
      "step": 10550
    },
    {
      "epoch": 0.6801848049281314,
      "grad_norm": 0.08525539189577103,
      "learning_rate": 4.319879363449692e-05,
      "loss": 0.0013,
      "step": 10600
    },
    {
      "epoch": 0.6833932238193019,
      "grad_norm": 0.1737043410539627,
      "learning_rate": 4.316670944558522e-05,
      "loss": 0.0013,
      "step": 10650
    },
    {
      "epoch": 0.6866016427104723,
      "grad_norm": 0.021732740104198456,
      "learning_rate": 4.313462525667351e-05,
      "loss": 0.0013,
      "step": 10700
    },
    {
      "epoch": 0.6898100616016427,
      "grad_norm": 0.04194492846727371,
      "learning_rate": 4.310254106776181e-05,
      "loss": 0.0013,
      "step": 10750
    },
    {
      "epoch": 0.6930184804928131,
      "grad_norm": 0.06095017492771149,
      "learning_rate": 4.307045687885011e-05,
      "loss": 0.0013,
      "step": 10800
    },
    {
      "epoch": 0.6962268993839835,
      "grad_norm": 0.059713274240493774,
      "learning_rate": 4.30383726899384e-05,
      "loss": 0.0013,
      "step": 10850
    },
    {
      "epoch": 0.699435318275154,
      "grad_norm": 0.026080919429659843,
      "learning_rate": 4.30062885010267e-05,
      "loss": 0.0013,
      "step": 10900
    },
    {
      "epoch": 0.7026437371663244,
      "grad_norm": 0.030839379876852036,
      "learning_rate": 4.297420431211499e-05,
      "loss": 0.0013,
      "step": 10950
    },
    {
      "epoch": 0.7058521560574949,
      "grad_norm": 0.02517014555633068,
      "learning_rate": 4.294212012320329e-05,
      "loss": 0.0013,
      "step": 11000
    },
    {
      "epoch": 0.7090605749486653,
      "grad_norm": 0.026660650968551636,
      "learning_rate": 4.291003593429158e-05,
      "loss": 0.0013,
      "step": 11050
    },
    {
      "epoch": 0.7122689938398358,
      "grad_norm": 0.12756890058517456,
      "learning_rate": 4.287795174537988e-05,
      "loss": 0.0013,
      "step": 11100
    },
    {
      "epoch": 0.7154774127310062,
      "grad_norm": 0.06528909504413605,
      "learning_rate": 4.2845867556468173e-05,
      "loss": 0.0013,
      "step": 11150
    },
    {
      "epoch": 0.7186858316221766,
      "grad_norm": 0.13221991062164307,
      "learning_rate": 4.281378336755647e-05,
      "loss": 0.0013,
      "step": 11200
    },
    {
      "epoch": 0.721894250513347,
      "grad_norm": 0.01718071475625038,
      "learning_rate": 4.2781699178644766e-05,
      "loss": 0.0013,
      "step": 11250
    },
    {
      "epoch": 0.7251026694045175,
      "grad_norm": 0.04817386344075203,
      "learning_rate": 4.274961498973306e-05,
      "loss": 0.0013,
      "step": 11300
    },
    {
      "epoch": 0.7283110882956879,
      "grad_norm": 0.0396796315908432,
      "learning_rate": 4.271753080082136e-05,
      "loss": 0.0013,
      "step": 11350
    },
    {
      "epoch": 0.7315195071868583,
      "grad_norm": 0.08713427186012268,
      "learning_rate": 4.2685446611909654e-05,
      "loss": 0.0013,
      "step": 11400
    },
    {
      "epoch": 0.7347279260780287,
      "grad_norm": 0.022682655602693558,
      "learning_rate": 4.265336242299795e-05,
      "loss": 0.0013,
      "step": 11450
    },
    {
      "epoch": 0.7379363449691991,
      "grad_norm": 0.042213357985019684,
      "learning_rate": 4.262127823408624e-05,
      "loss": 0.0012,
      "step": 11500
    },
    {
      "epoch": 0.7411447638603696,
      "grad_norm": 0.04178436100482941,
      "learning_rate": 4.258919404517454e-05,
      "loss": 0.0013,
      "step": 11550
    },
    {
      "epoch": 0.74435318275154,
      "grad_norm": 0.03794625401496887,
      "learning_rate": 4.255710985626283e-05,
      "loss": 0.0012,
      "step": 11600
    },
    {
      "epoch": 0.7475616016427105,
      "grad_norm": 0.02703651785850525,
      "learning_rate": 4.252502566735113e-05,
      "loss": 0.0012,
      "step": 11650
    },
    {
      "epoch": 0.7507700205338809,
      "grad_norm": 0.032715924084186554,
      "learning_rate": 4.249294147843943e-05,
      "loss": 0.0012,
      "step": 11700
    },
    {
      "epoch": 0.7539784394250514,
      "grad_norm": 0.043515339493751526,
      "learning_rate": 4.246085728952772e-05,
      "loss": 0.0012,
      "step": 11750
    },
    {
      "epoch": 0.7571868583162218,
      "grad_norm": 0.03076687827706337,
      "learning_rate": 4.2428773100616024e-05,
      "loss": 0.0012,
      "step": 11800
    },
    {
      "epoch": 0.7603952772073922,
      "grad_norm": 0.02452101930975914,
      "learning_rate": 4.239668891170431e-05,
      "loss": 0.0012,
      "step": 11850
    },
    {
      "epoch": 0.7636036960985626,
      "grad_norm": 0.04641549289226532,
      "learning_rate": 4.236460472279261e-05,
      "loss": 0.0012,
      "step": 11900
    },
    {
      "epoch": 0.766812114989733,
      "grad_norm": 0.07839664816856384,
      "learning_rate": 4.2332520533880906e-05,
      "loss": 0.0012,
      "step": 11950
    },
    {
      "epoch": 0.7700205338809035,
      "grad_norm": 0.04991001635789871,
      "learning_rate": 4.23004363449692e-05,
      "loss": 0.0012,
      "step": 12000
    },
    {
      "epoch": 0.7732289527720739,
      "grad_norm": 0.014806254766881466,
      "learning_rate": 4.22683521560575e-05,
      "loss": 0.0012,
      "step": 12050
    },
    {
      "epoch": 0.7764373716632443,
      "grad_norm": 0.03431886434555054,
      "learning_rate": 4.2236267967145794e-05,
      "loss": 0.0012,
      "step": 12100
    },
    {
      "epoch": 0.7796457905544147,
      "grad_norm": 0.01534039806574583,
      "learning_rate": 4.220418377823409e-05,
      "loss": 0.0012,
      "step": 12150
    },
    {
      "epoch": 0.7828542094455853,
      "grad_norm": 0.06097523868083954,
      "learning_rate": 4.2172099589322387e-05,
      "loss": 0.0012,
      "step": 12200
    },
    {
      "epoch": 0.7860626283367557,
      "grad_norm": 0.1133621484041214,
      "learning_rate": 4.214001540041068e-05,
      "loss": 0.0012,
      "step": 12250
    },
    {
      "epoch": 0.7892710472279261,
      "grad_norm": 0.051041942089796066,
      "learning_rate": 4.210793121149897e-05,
      "loss": 0.0012,
      "step": 12300
    },
    {
      "epoch": 0.7924794661190965,
      "grad_norm": 0.04188051447272301,
      "learning_rate": 4.2075847022587275e-05,
      "loss": 0.0012,
      "step": 12350
    },
    {
      "epoch": 0.795687885010267,
      "grad_norm": 0.11956363916397095,
      "learning_rate": 4.2043762833675565e-05,
      "loss": 0.0012,
      "step": 12400
    },
    {
      "epoch": 0.7988963039014374,
      "grad_norm": 0.017614543437957764,
      "learning_rate": 4.201167864476386e-05,
      "loss": 0.0012,
      "step": 12450
    },
    {
      "epoch": 0.8021047227926078,
      "grad_norm": 0.08952194452285767,
      "learning_rate": 4.197959445585216e-05,
      "loss": 0.0012,
      "step": 12500
    },
    {
      "epoch": 0.8053131416837782,
      "grad_norm": 0.03172571584582329,
      "learning_rate": 4.194751026694045e-05,
      "loss": 0.0012,
      "step": 12550
    },
    {
      "epoch": 0.8085215605749486,
      "grad_norm": 0.06858188658952713,
      "learning_rate": 4.191542607802875e-05,
      "loss": 0.0012,
      "step": 12600
    },
    {
      "epoch": 0.8117299794661191,
      "grad_norm": 0.13769112527370453,
      "learning_rate": 4.1883341889117045e-05,
      "loss": 0.0012,
      "step": 12650
    },
    {
      "epoch": 0.8149383983572895,
      "grad_norm": 0.03559759259223938,
      "learning_rate": 4.185125770020534e-05,
      "loss": 0.0012,
      "step": 12700
    },
    {
      "epoch": 0.81814681724846,
      "grad_norm": 0.06385491788387299,
      "learning_rate": 4.181917351129364e-05,
      "loss": 0.0012,
      "step": 12750
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.020670589059591293,
      "learning_rate": 4.1787089322381934e-05,
      "loss": 0.0012,
      "step": 12800
    },
    {
      "epoch": 0.8245636550308009,
      "grad_norm": 0.028200583532452583,
      "learning_rate": 4.1755005133470223e-05,
      "loss": 0.0012,
      "step": 12850
    },
    {
      "epoch": 0.8277720739219713,
      "grad_norm": 0.09028496593236923,
      "learning_rate": 4.1722920944558526e-05,
      "loss": 0.0012,
      "step": 12900
    },
    {
      "epoch": 0.8309804928131417,
      "grad_norm": 0.0365229956805706,
      "learning_rate": 4.1690836755646816e-05,
      "loss": 0.0012,
      "step": 12950
    },
    {
      "epoch": 0.8341889117043121,
      "grad_norm": 0.10907528549432755,
      "learning_rate": 4.165875256673511e-05,
      "loss": 0.0012,
      "step": 13000
    },
    {
      "epoch": 0.8373973305954825,
      "grad_norm": 0.026733126491308212,
      "learning_rate": 4.162666837782341e-05,
      "loss": 0.0012,
      "step": 13050
    },
    {
      "epoch": 0.840605749486653,
      "grad_norm": 0.03844752535223961,
      "learning_rate": 4.1594584188911704e-05,
      "loss": 0.0012,
      "step": 13100
    },
    {
      "epoch": 0.8438141683778234,
      "grad_norm": 0.018478145822882652,
      "learning_rate": 4.156250000000001e-05,
      "loss": 0.0012,
      "step": 13150
    },
    {
      "epoch": 0.8470225872689938,
      "grad_norm": 0.04466957971453667,
      "learning_rate": 4.15304158110883e-05,
      "loss": 0.0012,
      "step": 13200
    },
    {
      "epoch": 0.8502310061601642,
      "grad_norm": 0.041834477335214615,
      "learning_rate": 4.149833162217659e-05,
      "loss": 0.0012,
      "step": 13250
    },
    {
      "epoch": 0.8534394250513347,
      "grad_norm": 0.055049870163202286,
      "learning_rate": 4.146624743326489e-05,
      "loss": 0.0011,
      "step": 13300
    },
    {
      "epoch": 0.8566478439425051,
      "grad_norm": 0.09869872033596039,
      "learning_rate": 4.1434163244353185e-05,
      "loss": 0.0011,
      "step": 13350
    },
    {
      "epoch": 0.8598562628336756,
      "grad_norm": 0.0536666177213192,
      "learning_rate": 4.140207905544148e-05,
      "loss": 0.0011,
      "step": 13400
    },
    {
      "epoch": 0.863064681724846,
      "grad_norm": 0.06525545567274094,
      "learning_rate": 4.136999486652978e-05,
      "loss": 0.0011,
      "step": 13450
    },
    {
      "epoch": 0.8662731006160165,
      "grad_norm": 0.0236363485455513,
      "learning_rate": 4.133791067761807e-05,
      "loss": 0.0012,
      "step": 13500
    },
    {
      "epoch": 0.8694815195071869,
      "grad_norm": 0.12222899496555328,
      "learning_rate": 4.130582648870637e-05,
      "loss": 0.0012,
      "step": 13550
    },
    {
      "epoch": 0.8726899383983573,
      "grad_norm": 0.020534034818410873,
      "learning_rate": 4.1273742299794666e-05,
      "loss": 0.0011,
      "step": 13600
    },
    {
      "epoch": 0.8758983572895277,
      "grad_norm": 0.045034583657979965,
      "learning_rate": 4.1241658110882956e-05,
      "loss": 0.0012,
      "step": 13650
    },
    {
      "epoch": 0.8791067761806981,
      "grad_norm": 0.03230883926153183,
      "learning_rate": 4.120957392197126e-05,
      "loss": 0.0011,
      "step": 13700
    },
    {
      "epoch": 0.8823151950718686,
      "grad_norm": 0.0503169409930706,
      "learning_rate": 4.117748973305955e-05,
      "loss": 0.0012,
      "step": 13750
    },
    {
      "epoch": 0.885523613963039,
      "grad_norm": 0.057373881340026855,
      "learning_rate": 4.1145405544147844e-05,
      "loss": 0.0012,
      "step": 13800
    },
    {
      "epoch": 0.8887320328542094,
      "grad_norm": 0.12192647904157639,
      "learning_rate": 4.111332135523614e-05,
      "loss": 0.0011,
      "step": 13850
    },
    {
      "epoch": 0.8919404517453798,
      "grad_norm": 0.0459744818508625,
      "learning_rate": 4.108123716632444e-05,
      "loss": 0.0011,
      "step": 13900
    },
    {
      "epoch": 0.8951488706365504,
      "grad_norm": 0.0542738176882267,
      "learning_rate": 4.104915297741273e-05,
      "loss": 0.0011,
      "step": 13950
    },
    {
      "epoch": 0.8983572895277208,
      "grad_norm": 0.017556974664330482,
      "learning_rate": 4.101706878850103e-05,
      "loss": 0.0011,
      "step": 14000
    },
    {
      "epoch": 0.9015657084188912,
      "grad_norm": 0.08850595355033875,
      "learning_rate": 4.0984984599589325e-05,
      "loss": 0.0011,
      "step": 14050
    },
    {
      "epoch": 0.9047741273100616,
      "grad_norm": 0.04907291382551193,
      "learning_rate": 4.095290041067762e-05,
      "loss": 0.0011,
      "step": 14100
    },
    {
      "epoch": 0.9079825462012321,
      "grad_norm": 0.03671153634786606,
      "learning_rate": 4.092081622176592e-05,
      "loss": 0.0011,
      "step": 14150
    },
    {
      "epoch": 0.9111909650924025,
      "grad_norm": 0.05609135702252388,
      "learning_rate": 4.088873203285421e-05,
      "loss": 0.0011,
      "step": 14200
    },
    {
      "epoch": 0.9143993839835729,
      "grad_norm": 0.13841906189918518,
      "learning_rate": 4.085664784394251e-05,
      "loss": 0.0011,
      "step": 14250
    },
    {
      "epoch": 0.9176078028747433,
      "grad_norm": 0.06583283096551895,
      "learning_rate": 4.08245636550308e-05,
      "loss": 0.0011,
      "step": 14300
    },
    {
      "epoch": 0.9208162217659137,
      "grad_norm": 0.03635463863611221,
      "learning_rate": 4.07924794661191e-05,
      "loss": 0.0011,
      "step": 14350
    },
    {
      "epoch": 0.9240246406570842,
      "grad_norm": 0.0702434703707695,
      "learning_rate": 4.076039527720739e-05,
      "loss": 0.0011,
      "step": 14400
    },
    {
      "epoch": 0.9272330595482546,
      "grad_norm": 0.06526247411966324,
      "learning_rate": 4.072831108829569e-05,
      "loss": 0.0011,
      "step": 14450
    },
    {
      "epoch": 0.930441478439425,
      "grad_norm": 0.15593738853931427,
      "learning_rate": 4.069622689938399e-05,
      "loss": 0.0011,
      "step": 14500
    },
    {
      "epoch": 0.9336498973305954,
      "grad_norm": 0.0843171626329422,
      "learning_rate": 4.066414271047228e-05,
      "loss": 0.0011,
      "step": 14550
    },
    {
      "epoch": 0.936858316221766,
      "grad_norm": 0.1317060887813568,
      "learning_rate": 4.0632058521560576e-05,
      "loss": 0.0011,
      "step": 14600
    },
    {
      "epoch": 0.9400667351129364,
      "grad_norm": 0.13186527788639069,
      "learning_rate": 4.059997433264887e-05,
      "loss": 0.0011,
      "step": 14650
    },
    {
      "epoch": 0.9432751540041068,
      "grad_norm": 0.06555019319057465,
      "learning_rate": 4.056789014373717e-05,
      "loss": 0.0012,
      "step": 14700
    },
    {
      "epoch": 0.9464835728952772,
      "grad_norm": 0.019897904247045517,
      "learning_rate": 4.0535805954825465e-05,
      "loss": 0.0011,
      "step": 14750
    },
    {
      "epoch": 0.9496919917864476,
      "grad_norm": 0.07128149271011353,
      "learning_rate": 4.050372176591376e-05,
      "loss": 0.0011,
      "step": 14800
    },
    {
      "epoch": 0.9529004106776181,
      "grad_norm": 0.044025979936122894,
      "learning_rate": 4.047163757700205e-05,
      "loss": 0.0011,
      "step": 14850
    },
    {
      "epoch": 0.9561088295687885,
      "grad_norm": 0.07157762348651886,
      "learning_rate": 4.0439553388090354e-05,
      "loss": 0.0011,
      "step": 14900
    },
    {
      "epoch": 0.9593172484599589,
      "grad_norm": 0.038956284523010254,
      "learning_rate": 4.040746919917865e-05,
      "loss": 0.0011,
      "step": 14950
    },
    {
      "epoch": 0.9625256673511293,
      "grad_norm": 0.02136063762009144,
      "learning_rate": 4.037538501026694e-05,
      "loss": 0.0011,
      "step": 15000
    },
    {
      "epoch": 0.9657340862422998,
      "grad_norm": 0.07578456401824951,
      "learning_rate": 4.034330082135524e-05,
      "loss": 0.0011,
      "step": 15050
    },
    {
      "epoch": 0.9689425051334702,
      "grad_norm": 0.06463778018951416,
      "learning_rate": 4.031121663244353e-05,
      "loss": 0.0011,
      "step": 15100
    },
    {
      "epoch": 0.9721509240246407,
      "grad_norm": 0.06896155327558517,
      "learning_rate": 4.027913244353183e-05,
      "loss": 0.0011,
      "step": 15150
    },
    {
      "epoch": 0.9753593429158111,
      "grad_norm": 0.05751371383666992,
      "learning_rate": 4.0247048254620124e-05,
      "loss": 0.0011,
      "step": 15200
    },
    {
      "epoch": 0.9785677618069816,
      "grad_norm": 0.08062159270048141,
      "learning_rate": 4.021496406570842e-05,
      "loss": 0.0011,
      "step": 15250
    },
    {
      "epoch": 0.981776180698152,
      "grad_norm": 0.021689195185899734,
      "learning_rate": 4.0182879876796716e-05,
      "loss": 0.0011,
      "step": 15300
    },
    {
      "epoch": 0.9849845995893224,
      "grad_norm": 0.034361738711595535,
      "learning_rate": 4.015079568788501e-05,
      "loss": 0.0011,
      "step": 15350
    },
    {
      "epoch": 0.9881930184804928,
      "grad_norm": 0.06712980568408966,
      "learning_rate": 4.011871149897331e-05,
      "loss": 0.0011,
      "step": 15400
    },
    {
      "epoch": 0.9914014373716632,
      "grad_norm": 0.01978243514895439,
      "learning_rate": 4.0086627310061605e-05,
      "loss": 0.0011,
      "step": 15450
    },
    {
      "epoch": 0.9946098562628337,
      "grad_norm": 0.0768446996808052,
      "learning_rate": 4.00545431211499e-05,
      "loss": 0.0011,
      "step": 15500
    },
    {
      "epoch": 0.9978182751540041,
      "grad_norm": 0.10042749345302582,
      "learning_rate": 4.002245893223819e-05,
      "loss": 0.0011,
      "step": 15550
    },
    {
      "epoch": 1.0010266940451746,
      "grad_norm": 0.05155231058597565,
      "learning_rate": 3.9990374743326493e-05,
      "loss": 0.0011,
      "step": 15600
    },
    {
      "epoch": 1.004235112936345,
      "grad_norm": 0.02140951342880726,
      "learning_rate": 3.995829055441478e-05,
      "loss": 0.0011,
      "step": 15650
    },
    {
      "epoch": 1.0074435318275154,
      "grad_norm": 0.030637599527835846,
      "learning_rate": 3.9926206365503086e-05,
      "loss": 0.0011,
      "step": 15700
    },
    {
      "epoch": 1.0106519507186857,
      "grad_norm": 0.009648543782532215,
      "learning_rate": 3.9894122176591375e-05,
      "loss": 0.0011,
      "step": 15750
    },
    {
      "epoch": 1.0138603696098563,
      "grad_norm": 0.02074972167611122,
      "learning_rate": 3.986203798767967e-05,
      "loss": 0.0011,
      "step": 15800
    },
    {
      "epoch": 1.0170687885010268,
      "grad_norm": 0.03178529441356659,
      "learning_rate": 3.9829953798767974e-05,
      "loss": 0.0011,
      "step": 15850
    },
    {
      "epoch": 1.020277207392197,
      "grad_norm": 0.0652398094534874,
      "learning_rate": 3.9797869609856264e-05,
      "loss": 0.0011,
      "step": 15900
    },
    {
      "epoch": 1.0234856262833676,
      "grad_norm": 0.035268958657979965,
      "learning_rate": 3.976578542094456e-05,
      "loss": 0.0011,
      "step": 15950
    },
    {
      "epoch": 1.0266940451745379,
      "grad_norm": 0.016153255477547646,
      "learning_rate": 3.9733701232032856e-05,
      "loss": 0.0011,
      "step": 16000
    },
    {
      "epoch": 1.0299024640657084,
      "grad_norm": 0.04349707067012787,
      "learning_rate": 3.970161704312115e-05,
      "loss": 0.0011,
      "step": 16050
    },
    {
      "epoch": 1.033110882956879,
      "grad_norm": 0.07039134949445724,
      "learning_rate": 3.966953285420945e-05,
      "loss": 0.0011,
      "step": 16100
    },
    {
      "epoch": 1.0363193018480492,
      "grad_norm": 0.060076694935560226,
      "learning_rate": 3.9637448665297745e-05,
      "loss": 0.0011,
      "step": 16150
    },
    {
      "epoch": 1.0395277207392197,
      "grad_norm": 0.030413085594773293,
      "learning_rate": 3.9605364476386034e-05,
      "loss": 0.0011,
      "step": 16200
    },
    {
      "epoch": 1.0427361396303902,
      "grad_norm": 0.0471501350402832,
      "learning_rate": 3.957328028747434e-05,
      "loss": 0.0011,
      "step": 16250
    },
    {
      "epoch": 1.0459445585215605,
      "grad_norm": 0.029605956748127937,
      "learning_rate": 3.954119609856263e-05,
      "loss": 0.0011,
      "step": 16300
    },
    {
      "epoch": 1.049152977412731,
      "grad_norm": 0.08591856807470322,
      "learning_rate": 3.950911190965092e-05,
      "loss": 0.0011,
      "step": 16350
    },
    {
      "epoch": 1.0523613963039014,
      "grad_norm": 0.026115117594599724,
      "learning_rate": 3.9477027720739226e-05,
      "loss": 0.0011,
      "step": 16400
    },
    {
      "epoch": 1.0555698151950719,
      "grad_norm": 0.0482497401535511,
      "learning_rate": 3.9444943531827515e-05,
      "loss": 0.0011,
      "step": 16450
    },
    {
      "epoch": 1.0587782340862424,
      "grad_norm": 0.08367465436458588,
      "learning_rate": 3.941285934291581e-05,
      "loss": 0.0011,
      "step": 16500
    },
    {
      "epoch": 1.0619866529774127,
      "grad_norm": 0.09603665769100189,
      "learning_rate": 3.938077515400411e-05,
      "loss": 0.0011,
      "step": 16550
    },
    {
      "epoch": 1.0651950718685832,
      "grad_norm": 0.047992072999477386,
      "learning_rate": 3.9348690965092404e-05,
      "loss": 0.0011,
      "step": 16600
    },
    {
      "epoch": 1.0684034907597535,
      "grad_norm": 0.03774379566311836,
      "learning_rate": 3.93166067761807e-05,
      "loss": 0.0011,
      "step": 16650
    },
    {
      "epoch": 1.071611909650924,
      "grad_norm": 0.04483205825090408,
      "learning_rate": 3.9284522587268996e-05,
      "loss": 0.0011,
      "step": 16700
    },
    {
      "epoch": 1.0748203285420945,
      "grad_norm": 0.09537917375564575,
      "learning_rate": 3.925243839835729e-05,
      "loss": 0.0011,
      "step": 16750
    },
    {
      "epoch": 1.0780287474332648,
      "grad_norm": 0.015187223441898823,
      "learning_rate": 3.922035420944559e-05,
      "loss": 0.0011,
      "step": 16800
    },
    {
      "epoch": 1.0812371663244353,
      "grad_norm": 0.012336880899965763,
      "learning_rate": 3.9188270020533885e-05,
      "loss": 0.0011,
      "step": 16850
    },
    {
      "epoch": 1.0844455852156059,
      "grad_norm": 0.03774676471948624,
      "learning_rate": 3.915618583162218e-05,
      "loss": 0.0011,
      "step": 16900
    },
    {
      "epoch": 1.0876540041067762,
      "grad_norm": 0.033570460975170135,
      "learning_rate": 3.912410164271048e-05,
      "loss": 0.0011,
      "step": 16950
    },
    {
      "epoch": 1.0908624229979467,
      "grad_norm": 0.040872808545827866,
      "learning_rate": 3.9092017453798766e-05,
      "loss": 0.0011,
      "step": 17000
    },
    {
      "epoch": 1.094070841889117,
      "grad_norm": 0.04218720272183418,
      "learning_rate": 3.905993326488707e-05,
      "loss": 0.0011,
      "step": 17050
    },
    {
      "epoch": 1.0972792607802875,
      "grad_norm": 0.03630414232611656,
      "learning_rate": 3.902784907597536e-05,
      "loss": 0.0011,
      "step": 17100
    },
    {
      "epoch": 1.100487679671458,
      "grad_norm": 0.0597698949277401,
      "learning_rate": 3.8995764887063655e-05,
      "loss": 0.0011,
      "step": 17150
    },
    {
      "epoch": 1.1036960985626283,
      "grad_norm": 0.029342791065573692,
      "learning_rate": 3.896368069815196e-05,
      "loss": 0.0011,
      "step": 17200
    },
    {
      "epoch": 1.1069045174537988,
      "grad_norm": 0.07068806886672974,
      "learning_rate": 3.893159650924025e-05,
      "loss": 0.0011,
      "step": 17250
    },
    {
      "epoch": 1.110112936344969,
      "grad_norm": 0.13778910040855408,
      "learning_rate": 3.8899512320328544e-05,
      "loss": 0.0011,
      "step": 17300
    },
    {
      "epoch": 1.1133213552361396,
      "grad_norm": 0.15330198407173157,
      "learning_rate": 3.886742813141684e-05,
      "loss": 0.0011,
      "step": 17350
    },
    {
      "epoch": 1.1165297741273101,
      "grad_norm": 0.04900128021836281,
      "learning_rate": 3.8835343942505136e-05,
      "loss": 0.0011,
      "step": 17400
    },
    {
      "epoch": 1.1197381930184804,
      "grad_norm": 0.06753404438495636,
      "learning_rate": 3.880325975359343e-05,
      "loss": 0.0011,
      "step": 17450
    },
    {
      "epoch": 1.122946611909651,
      "grad_norm": 0.06337915360927582,
      "learning_rate": 3.877117556468173e-05,
      "loss": 0.0011,
      "step": 17500
    },
    {
      "epoch": 1.1261550308008212,
      "grad_norm": 0.06438849866390228,
      "learning_rate": 3.873909137577002e-05,
      "loss": 0.0011,
      "step": 17550
    },
    {
      "epoch": 1.1293634496919918,
      "grad_norm": 0.025952456519007683,
      "learning_rate": 3.870700718685832e-05,
      "loss": 0.0011,
      "step": 17600
    },
    {
      "epoch": 1.1325718685831623,
      "grad_norm": 0.030040204524993896,
      "learning_rate": 3.867492299794661e-05,
      "loss": 0.0011,
      "step": 17650
    },
    {
      "epoch": 1.1357802874743326,
      "grad_norm": 0.05271584168076515,
      "learning_rate": 3.8642838809034906e-05,
      "loss": 0.0011,
      "step": 17700
    },
    {
      "epoch": 1.138988706365503,
      "grad_norm": 0.046671003103256226,
      "learning_rate": 3.861075462012321e-05,
      "loss": 0.0011,
      "step": 17750
    },
    {
      "epoch": 1.1421971252566736,
      "grad_norm": 0.012565558776259422,
      "learning_rate": 3.85786704312115e-05,
      "loss": 0.0011,
      "step": 17800
    },
    {
      "epoch": 1.145405544147844,
      "grad_norm": 0.032808199524879456,
      "learning_rate": 3.8546586242299795e-05,
      "loss": 0.0011,
      "step": 17850
    },
    {
      "epoch": 1.1486139630390144,
      "grad_norm": 0.03164586052298546,
      "learning_rate": 3.851450205338809e-05,
      "loss": 0.0011,
      "step": 17900
    },
    {
      "epoch": 1.1518223819301847,
      "grad_norm": 0.021005498245358467,
      "learning_rate": 3.848241786447639e-05,
      "loss": 0.0011,
      "step": 17950
    },
    {
      "epoch": 1.1550308008213552,
      "grad_norm": 0.058445774018764496,
      "learning_rate": 3.8450333675564683e-05,
      "loss": 0.0011,
      "step": 18000
    },
    {
      "epoch": 1.1582392197125257,
      "grad_norm": 0.060040902346372604,
      "learning_rate": 3.841824948665298e-05,
      "loss": 0.0011,
      "step": 18050
    },
    {
      "epoch": 1.161447638603696,
      "grad_norm": 0.04103507846593857,
      "learning_rate": 3.838616529774127e-05,
      "loss": 0.0011,
      "step": 18100
    },
    {
      "epoch": 1.1646560574948666,
      "grad_norm": 0.033660903573036194,
      "learning_rate": 3.835408110882957e-05,
      "loss": 0.001,
      "step": 18150
    },
    {
      "epoch": 1.167864476386037,
      "grad_norm": 0.05919133499264717,
      "learning_rate": 3.832199691991787e-05,
      "loss": 0.0011,
      "step": 18200
    },
    {
      "epoch": 1.1710728952772074,
      "grad_norm": 0.04401356726884842,
      "learning_rate": 3.8289912731006164e-05,
      "loss": 0.0011,
      "step": 18250
    },
    {
      "epoch": 1.1742813141683779,
      "grad_norm": 0.033656101673841476,
      "learning_rate": 3.825782854209446e-05,
      "loss": 0.001,
      "step": 18300
    },
    {
      "epoch": 1.1774897330595482,
      "grad_norm": 0.053168885409832,
      "learning_rate": 3.822574435318275e-05,
      "loss": 0.0011,
      "step": 18350
    },
    {
      "epoch": 1.1806981519507187,
      "grad_norm": 0.022629596292972565,
      "learning_rate": 3.819366016427105e-05,
      "loss": 0.0011,
      "step": 18400
    },
    {
      "epoch": 1.1839065708418892,
      "grad_norm": 0.099309042096138,
      "learning_rate": 3.816157597535934e-05,
      "loss": 0.001,
      "step": 18450
    },
    {
      "epoch": 1.1871149897330595,
      "grad_norm": 0.08802305161952972,
      "learning_rate": 3.812949178644764e-05,
      "loss": 0.0011,
      "step": 18500
    },
    {
      "epoch": 1.19032340862423,
      "grad_norm": 0.038590967655181885,
      "learning_rate": 3.8097407597535935e-05,
      "loss": 0.001,
      "step": 18550
    },
    {
      "epoch": 1.1935318275154003,
      "grad_norm": 0.09731482714414597,
      "learning_rate": 3.806532340862423e-05,
      "loss": 0.0011,
      "step": 18600
    },
    {
      "epoch": 1.1967402464065708,
      "grad_norm": 0.032707761973142624,
      "learning_rate": 3.803323921971253e-05,
      "loss": 0.0011,
      "step": 18650
    },
    {
      "epoch": 1.1999486652977414,
      "grad_norm": 0.046148981899023056,
      "learning_rate": 3.800115503080082e-05,
      "loss": 0.0011,
      "step": 18700
    },
    {
      "epoch": 1.2031570841889117,
      "grad_norm": 0.06572544574737549,
      "learning_rate": 3.796907084188912e-05,
      "loss": 0.0011,
      "step": 18750
    },
    {
      "epoch": 1.2063655030800822,
      "grad_norm": 0.05291469395160675,
      "learning_rate": 3.7936986652977416e-05,
      "loss": 0.0011,
      "step": 18800
    },
    {
      "epoch": 1.2095739219712525,
      "grad_norm": 0.02443665824830532,
      "learning_rate": 3.790490246406571e-05,
      "loss": 0.001,
      "step": 18850
    },
    {
      "epoch": 1.212782340862423,
      "grad_norm": 0.08976687490940094,
      "learning_rate": 3.7872818275154e-05,
      "loss": 0.001,
      "step": 18900
    },
    {
      "epoch": 1.2159907597535935,
      "grad_norm": 0.04550010710954666,
      "learning_rate": 3.7840734086242304e-05,
      "loss": 0.0011,
      "step": 18950
    },
    {
      "epoch": 1.2191991786447638,
      "grad_norm": 0.04316117614507675,
      "learning_rate": 3.7808649897330594e-05,
      "loss": 0.0011,
      "step": 19000
    },
    {
      "epoch": 1.2224075975359343,
      "grad_norm": 0.09106644988059998,
      "learning_rate": 3.777656570841889e-05,
      "loss": 0.0011,
      "step": 19050
    },
    {
      "epoch": 1.2256160164271046,
      "grad_norm": 0.09023275226354599,
      "learning_rate": 3.774448151950719e-05,
      "loss": 0.0011,
      "step": 19100
    },
    {
      "epoch": 1.2288244353182751,
      "grad_norm": 0.04507322609424591,
      "learning_rate": 3.771239733059548e-05,
      "loss": 0.0011,
      "step": 19150
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.09688086062669754,
      "learning_rate": 3.7680313141683785e-05,
      "loss": 0.0011,
      "step": 19200
    },
    {
      "epoch": 1.235241273100616,
      "grad_norm": 0.02361646108329296,
      "learning_rate": 3.7648228952772075e-05,
      "loss": 0.0011,
      "step": 19250
    },
    {
      "epoch": 1.2384496919917864,
      "grad_norm": 0.036250416189432144,
      "learning_rate": 3.761614476386037e-05,
      "loss": 0.0011,
      "step": 19300
    },
    {
      "epoch": 1.241658110882957,
      "grad_norm": 0.05321168527007103,
      "learning_rate": 3.758406057494867e-05,
      "loss": 0.0011,
      "step": 19350
    },
    {
      "epoch": 1.2448665297741273,
      "grad_norm": 0.10216822475194931,
      "learning_rate": 3.755197638603696e-05,
      "loss": 0.0011,
      "step": 19400
    },
    {
      "epoch": 1.2480749486652978,
      "grad_norm": 0.12213185429573059,
      "learning_rate": 3.751989219712526e-05,
      "loss": 0.001,
      "step": 19450
    },
    {
      "epoch": 1.2512833675564683,
      "grad_norm": 0.05819927528500557,
      "learning_rate": 3.7487808008213556e-05,
      "loss": 0.0011,
      "step": 19500
    },
    {
      "epoch": 1.2544917864476386,
      "grad_norm": 0.03923110291361809,
      "learning_rate": 3.745572381930185e-05,
      "loss": 0.0011,
      "step": 19550
    },
    {
      "epoch": 1.257700205338809,
      "grad_norm": 0.021446919068694115,
      "learning_rate": 3.742363963039015e-05,
      "loss": 0.0011,
      "step": 19600
    },
    {
      "epoch": 1.2609086242299794,
      "grad_norm": 0.04750959202647209,
      "learning_rate": 3.7391555441478444e-05,
      "loss": 0.001,
      "step": 19650
    },
    {
      "epoch": 1.26411704312115,
      "grad_norm": 0.05494676157832146,
      "learning_rate": 3.7359471252566733e-05,
      "loss": 0.001,
      "step": 19700
    },
    {
      "epoch": 1.2673254620123204,
      "grad_norm": 0.03714187070727348,
      "learning_rate": 3.7327387063655036e-05,
      "loss": 0.0011,
      "step": 19750
    },
    {
      "epoch": 1.2705338809034907,
      "grad_norm": 0.0866231843829155,
      "learning_rate": 3.7295302874743326e-05,
      "loss": 0.001,
      "step": 19800
    },
    {
      "epoch": 1.2737422997946612,
      "grad_norm": 0.022846315056085587,
      "learning_rate": 3.726321868583162e-05,
      "loss": 0.0011,
      "step": 19850
    },
    {
      "epoch": 1.2769507186858315,
      "grad_norm": 0.06680992245674133,
      "learning_rate": 3.723113449691992e-05,
      "loss": 0.001,
      "step": 19900
    },
    {
      "epoch": 1.280159137577002,
      "grad_norm": 0.03678305074572563,
      "learning_rate": 3.7199050308008214e-05,
      "loss": 0.001,
      "step": 19950
    },
    {
      "epoch": 1.2833675564681726,
      "grad_norm": 0.05869271606206894,
      "learning_rate": 3.716696611909651e-05,
      "loss": 0.001,
      "step": 20000
    },
    {
      "epoch": 1.2865759753593429,
      "grad_norm": 0.07335061579942703,
      "learning_rate": 3.713488193018481e-05,
      "loss": 0.0011,
      "step": 20050
    },
    {
      "epoch": 1.2897843942505134,
      "grad_norm": 0.07010391354560852,
      "learning_rate": 3.71027977412731e-05,
      "loss": 0.001,
      "step": 20100
    },
    {
      "epoch": 1.2929928131416837,
      "grad_norm": 0.11876567453145981,
      "learning_rate": 3.70707135523614e-05,
      "loss": 0.001,
      "step": 20150
    },
    {
      "epoch": 1.2962012320328542,
      "grad_norm": 0.07630135864019394,
      "learning_rate": 3.7038629363449695e-05,
      "loss": 0.001,
      "step": 20200
    },
    {
      "epoch": 1.2994096509240247,
      "grad_norm": 0.04724431410431862,
      "learning_rate": 3.7006545174537985e-05,
      "loss": 0.0011,
      "step": 20250
    },
    {
      "epoch": 1.302618069815195,
      "grad_norm": 0.03990776836872101,
      "learning_rate": 3.697446098562629e-05,
      "loss": 0.0011,
      "step": 20300
    },
    {
      "epoch": 1.3058264887063655,
      "grad_norm": 0.03711399435997009,
      "learning_rate": 3.694237679671458e-05,
      "loss": 0.001,
      "step": 20350
    },
    {
      "epoch": 1.3090349075975358,
      "grad_norm": 0.022349273785948753,
      "learning_rate": 3.691029260780287e-05,
      "loss": 0.001,
      "step": 20400
    },
    {
      "epoch": 1.3122433264887063,
      "grad_norm": 0.041836969554424286,
      "learning_rate": 3.6878208418891176e-05,
      "loss": 0.001,
      "step": 20450
    },
    {
      "epoch": 1.3154517453798769,
      "grad_norm": 0.08230699598789215,
      "learning_rate": 3.6846124229979466e-05,
      "loss": 0.0011,
      "step": 20500
    },
    {
      "epoch": 1.3186601642710472,
      "grad_norm": 0.026855668053030968,
      "learning_rate": 3.681404004106777e-05,
      "loss": 0.001,
      "step": 20550
    },
    {
      "epoch": 1.3218685831622177,
      "grad_norm": 0.04581192508339882,
      "learning_rate": 3.678195585215606e-05,
      "loss": 0.001,
      "step": 20600
    },
    {
      "epoch": 1.325077002053388,
      "grad_norm": 0.16595298051834106,
      "learning_rate": 3.6749871663244354e-05,
      "loss": 0.0011,
      "step": 20650
    },
    {
      "epoch": 1.3282854209445585,
      "grad_norm": 0.030162548646330833,
      "learning_rate": 3.671778747433265e-05,
      "loss": 0.001,
      "step": 20700
    },
    {
      "epoch": 1.331493839835729,
      "grad_norm": 0.05803018435835838,
      "learning_rate": 3.668570328542095e-05,
      "loss": 0.001,
      "step": 20750
    },
    {
      "epoch": 1.3347022587268995,
      "grad_norm": 0.06271444261074066,
      "learning_rate": 3.665361909650924e-05,
      "loss": 0.001,
      "step": 20800
    },
    {
      "epoch": 1.3379106776180698,
      "grad_norm": 0.05620609223842621,
      "learning_rate": 3.662153490759754e-05,
      "loss": 0.0011,
      "step": 20850
    },
    {
      "epoch": 1.3411190965092403,
      "grad_norm": 0.0642424076795578,
      "learning_rate": 3.6589450718685835e-05,
      "loss": 0.001,
      "step": 20900
    },
    {
      "epoch": 1.3443275154004106,
      "grad_norm": 0.08025661110877991,
      "learning_rate": 3.655736652977413e-05,
      "loss": 0.001,
      "step": 20950
    },
    {
      "epoch": 1.3475359342915811,
      "grad_norm": 0.02795545384287834,
      "learning_rate": 3.652528234086243e-05,
      "loss": 0.001,
      "step": 21000
    },
    {
      "epoch": 1.3507443531827517,
      "grad_norm": 0.047757338732481,
      "learning_rate": 3.649319815195072e-05,
      "loss": 0.001,
      "step": 21050
    },
    {
      "epoch": 1.353952772073922,
      "grad_norm": 0.18030385673046112,
      "learning_rate": 3.646111396303902e-05,
      "loss": 0.001,
      "step": 21100
    },
    {
      "epoch": 1.3571611909650925,
      "grad_norm": 0.07465680688619614,
      "learning_rate": 3.642902977412731e-05,
      "loss": 0.0011,
      "step": 21150
    },
    {
      "epoch": 1.3603696098562628,
      "grad_norm": 0.06952746212482452,
      "learning_rate": 3.6396945585215606e-05,
      "loss": 0.001,
      "step": 21200
    },
    {
      "epoch": 1.3635780287474333,
      "grad_norm": 0.0837249681353569,
      "learning_rate": 3.63648613963039e-05,
      "loss": 0.001,
      "step": 21250
    },
    {
      "epoch": 1.3667864476386038,
      "grad_norm": 0.07041031867265701,
      "learning_rate": 3.63327772073922e-05,
      "loss": 0.001,
      "step": 21300
    },
    {
      "epoch": 1.369994866529774,
      "grad_norm": 0.04573749378323555,
      "learning_rate": 3.6300693018480494e-05,
      "loss": 0.0011,
      "step": 21350
    },
    {
      "epoch": 1.3732032854209446,
      "grad_norm": 0.07394980639219284,
      "learning_rate": 3.626860882956879e-05,
      "loss": 0.001,
      "step": 21400
    },
    {
      "epoch": 1.376411704312115,
      "grad_norm": 0.06346414238214493,
      "learning_rate": 3.6236524640657087e-05,
      "loss": 0.001,
      "step": 21450
    },
    {
      "epoch": 1.3796201232032854,
      "grad_norm": 0.02911703661084175,
      "learning_rate": 3.620444045174538e-05,
      "loss": 0.001,
      "step": 21500
    },
    {
      "epoch": 1.382828542094456,
      "grad_norm": 0.06786498427391052,
      "learning_rate": 3.617235626283368e-05,
      "loss": 0.001,
      "step": 21550
    },
    {
      "epoch": 1.3860369609856262,
      "grad_norm": 0.018230777233839035,
      "learning_rate": 3.614027207392197e-05,
      "loss": 0.001,
      "step": 21600
    },
    {
      "epoch": 1.3892453798767967,
      "grad_norm": 0.028646958991885185,
      "learning_rate": 3.610818788501027e-05,
      "loss": 0.001,
      "step": 21650
    },
    {
      "epoch": 1.392453798767967,
      "grad_norm": 0.0929781123995781,
      "learning_rate": 3.607610369609856e-05,
      "loss": 0.001,
      "step": 21700
    },
    {
      "epoch": 1.3956622176591376,
      "grad_norm": 0.09136905521154404,
      "learning_rate": 3.6044019507186864e-05,
      "loss": 0.001,
      "step": 21750
    },
    {
      "epoch": 1.398870636550308,
      "grad_norm": 0.030298838391900063,
      "learning_rate": 3.601193531827516e-05,
      "loss": 0.001,
      "step": 21800
    },
    {
      "epoch": 1.4020790554414784,
      "grad_norm": 0.09993262588977814,
      "learning_rate": 3.597985112936345e-05,
      "loss": 0.001,
      "step": 21850
    },
    {
      "epoch": 1.405287474332649,
      "grad_norm": 0.029120350256562233,
      "learning_rate": 3.594776694045175e-05,
      "loss": 0.001,
      "step": 21900
    },
    {
      "epoch": 1.4084958932238192,
      "grad_norm": 0.06481776386499405,
      "learning_rate": 3.591568275154004e-05,
      "loss": 0.001,
      "step": 21950
    },
    {
      "epoch": 1.4117043121149897,
      "grad_norm": 0.09274648129940033,
      "learning_rate": 3.588359856262834e-05,
      "loss": 0.001,
      "step": 22000
    },
    {
      "epoch": 1.4149127310061602,
      "grad_norm": 0.09342891722917557,
      "learning_rate": 3.5851514373716634e-05,
      "loss": 0.001,
      "step": 22050
    },
    {
      "epoch": 1.4181211498973305,
      "grad_norm": 0.0695040374994278,
      "learning_rate": 3.581943018480493e-05,
      "loss": 0.0011,
      "step": 22100
    },
    {
      "epoch": 1.421329568788501,
      "grad_norm": 0.03951401636004448,
      "learning_rate": 3.5787345995893226e-05,
      "loss": 0.001,
      "step": 22150
    },
    {
      "epoch": 1.4245379876796713,
      "grad_norm": 0.04081675410270691,
      "learning_rate": 3.575526180698152e-05,
      "loss": 0.001,
      "step": 22200
    },
    {
      "epoch": 1.4277464065708418,
      "grad_norm": 0.035165105015039444,
      "learning_rate": 3.572317761806982e-05,
      "loss": 0.001,
      "step": 22250
    },
    {
      "epoch": 1.4309548254620124,
      "grad_norm": 0.04558858275413513,
      "learning_rate": 3.5691093429158115e-05,
      "loss": 0.001,
      "step": 22300
    },
    {
      "epoch": 1.4341632443531829,
      "grad_norm": 0.08187539875507355,
      "learning_rate": 3.565900924024641e-05,
      "loss": 0.001,
      "step": 22350
    },
    {
      "epoch": 1.4373716632443532,
      "grad_norm": 0.06570085883140564,
      "learning_rate": 3.56269250513347e-05,
      "loss": 0.001,
      "step": 22400
    },
    {
      "epoch": 1.4405800821355237,
      "grad_norm": 0.061367593705654144,
      "learning_rate": 3.5594840862423003e-05,
      "loss": 0.001,
      "step": 22450
    },
    {
      "epoch": 1.443788501026694,
      "grad_norm": 0.05942219868302345,
      "learning_rate": 3.556275667351129e-05,
      "loss": 0.001,
      "step": 22500
    },
    {
      "epoch": 1.4469969199178645,
      "grad_norm": 0.07902152836322784,
      "learning_rate": 3.553067248459959e-05,
      "loss": 0.001,
      "step": 22550
    },
    {
      "epoch": 1.450205338809035,
      "grad_norm": 0.05105754733085632,
      "learning_rate": 3.5498588295687885e-05,
      "loss": 0.001,
      "step": 22600
    },
    {
      "epoch": 1.4534137577002053,
      "grad_norm": 0.012422065250575542,
      "learning_rate": 3.546650410677618e-05,
      "loss": 0.001,
      "step": 22650
    },
    {
      "epoch": 1.4566221765913758,
      "grad_norm": 0.03621068224310875,
      "learning_rate": 3.543441991786448e-05,
      "loss": 0.001,
      "step": 22700
    },
    {
      "epoch": 1.4598305954825461,
      "grad_norm": 0.01746225915849209,
      "learning_rate": 3.5402335728952774e-05,
      "loss": 0.001,
      "step": 22750
    },
    {
      "epoch": 1.4630390143737166,
      "grad_norm": 0.03830289468169212,
      "learning_rate": 3.537025154004107e-05,
      "loss": 0.001,
      "step": 22800
    },
    {
      "epoch": 1.4662474332648872,
      "grad_norm": 0.07514505088329315,
      "learning_rate": 3.5338167351129366e-05,
      "loss": 0.001,
      "step": 22850
    },
    {
      "epoch": 1.4694558521560575,
      "grad_norm": 0.025442354381084442,
      "learning_rate": 3.530608316221766e-05,
      "loss": 0.001,
      "step": 22900
    },
    {
      "epoch": 1.472664271047228,
      "grad_norm": 0.019491424784064293,
      "learning_rate": 3.527399897330595e-05,
      "loss": 0.001,
      "step": 22950
    },
    {
      "epoch": 1.4758726899383983,
      "grad_norm": 0.05034104362130165,
      "learning_rate": 3.5241914784394255e-05,
      "loss": 0.001,
      "step": 23000
    },
    {
      "epoch": 1.4790811088295688,
      "grad_norm": 0.045507218688726425,
      "learning_rate": 3.5209830595482544e-05,
      "loss": 0.001,
      "step": 23050
    },
    {
      "epoch": 1.4822895277207393,
      "grad_norm": 0.027271023020148277,
      "learning_rate": 3.517774640657085e-05,
      "loss": 0.001,
      "step": 23100
    },
    {
      "epoch": 1.4854979466119096,
      "grad_norm": 0.0849720761179924,
      "learning_rate": 3.5145662217659137e-05,
      "loss": 0.001,
      "step": 23150
    },
    {
      "epoch": 1.48870636550308,
      "grad_norm": 0.03520001843571663,
      "learning_rate": 3.511357802874743e-05,
      "loss": 0.001,
      "step": 23200
    },
    {
      "epoch": 1.4919147843942504,
      "grad_norm": 0.12706679105758667,
      "learning_rate": 3.5081493839835736e-05,
      "loss": 0.001,
      "step": 23250
    },
    {
      "epoch": 1.495123203285421,
      "grad_norm": 0.07218334823846817,
      "learning_rate": 3.5049409650924025e-05,
      "loss": 0.001,
      "step": 23300
    },
    {
      "epoch": 1.4983316221765914,
      "grad_norm": 0.03861307352781296,
      "learning_rate": 3.501732546201232e-05,
      "loss": 0.001,
      "step": 23350
    },
    {
      "epoch": 1.501540041067762,
      "grad_norm": 0.09384164959192276,
      "learning_rate": 3.498524127310062e-05,
      "loss": 0.001,
      "step": 23400
    },
    {
      "epoch": 1.5047484599589322,
      "grad_norm": 0.094231978058815,
      "learning_rate": 3.4953157084188914e-05,
      "loss": 0.001,
      "step": 23450
    },
    {
      "epoch": 1.5079568788501025,
      "grad_norm": 0.10946597903966904,
      "learning_rate": 3.492107289527721e-05,
      "loss": 0.001,
      "step": 23500
    },
    {
      "epoch": 1.511165297741273,
      "grad_norm": 0.01874011568725109,
      "learning_rate": 3.4888988706365506e-05,
      "loss": 0.001,
      "step": 23550
    },
    {
      "epoch": 1.5143737166324436,
      "grad_norm": 0.035752031952142715,
      "learning_rate": 3.4856904517453795e-05,
      "loss": 0.001,
      "step": 23600
    },
    {
      "epoch": 1.517582135523614,
      "grad_norm": 0.08994411677122116,
      "learning_rate": 3.48248203285421e-05,
      "loss": 0.001,
      "step": 23650
    },
    {
      "epoch": 1.5207905544147844,
      "grad_norm": 0.015161426737904549,
      "learning_rate": 3.4792736139630395e-05,
      "loss": 0.001,
      "step": 23700
    },
    {
      "epoch": 1.5239989733059547,
      "grad_norm": 0.036956749856472015,
      "learning_rate": 3.4760651950718684e-05,
      "loss": 0.001,
      "step": 23750
    },
    {
      "epoch": 1.5272073921971252,
      "grad_norm": 0.04168296605348587,
      "learning_rate": 3.472856776180699e-05,
      "loss": 0.001,
      "step": 23800
    },
    {
      "epoch": 1.5304158110882957,
      "grad_norm": 0.060652002692222595,
      "learning_rate": 3.4696483572895276e-05,
      "loss": 0.001,
      "step": 23850
    },
    {
      "epoch": 1.5336242299794662,
      "grad_norm": 0.039223767817020416,
      "learning_rate": 3.466439938398357e-05,
      "loss": 0.001,
      "step": 23900
    },
    {
      "epoch": 1.5368326488706365,
      "grad_norm": 0.020630404353141785,
      "learning_rate": 3.463231519507187e-05,
      "loss": 0.001,
      "step": 23950
    },
    {
      "epoch": 1.5400410677618068,
      "grad_norm": 0.04933486133813858,
      "learning_rate": 3.4600231006160165e-05,
      "loss": 0.001,
      "step": 24000
    },
    {
      "epoch": 1.5432494866529773,
      "grad_norm": 0.08278122544288635,
      "learning_rate": 3.456814681724846e-05,
      "loss": 0.001,
      "step": 24050
    },
    {
      "epoch": 1.5464579055441479,
      "grad_norm": 0.08942437171936035,
      "learning_rate": 3.453606262833676e-05,
      "loss": 0.001,
      "step": 24100
    },
    {
      "epoch": 1.5496663244353184,
      "grad_norm": 0.05871259421110153,
      "learning_rate": 3.4503978439425054e-05,
      "loss": 0.001,
      "step": 24150
    },
    {
      "epoch": 1.5528747433264887,
      "grad_norm": 0.07652433216571808,
      "learning_rate": 3.447189425051335e-05,
      "loss": 0.001,
      "step": 24200
    },
    {
      "epoch": 1.5560831622176592,
      "grad_norm": 0.012615304440259933,
      "learning_rate": 3.4439810061601646e-05,
      "loss": 0.001,
      "step": 24250
    },
    {
      "epoch": 1.5592915811088295,
      "grad_norm": 0.07210228592157364,
      "learning_rate": 3.440772587268994e-05,
      "loss": 0.001,
      "step": 24300
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.07213079929351807,
      "learning_rate": 3.437564168377824e-05,
      "loss": 0.001,
      "step": 24350
    },
    {
      "epoch": 1.5657084188911705,
      "grad_norm": 0.05486731231212616,
      "learning_rate": 3.434355749486653e-05,
      "loss": 0.001,
      "step": 24400
    },
    {
      "epoch": 1.5689168377823408,
      "grad_norm": 0.10595924407243729,
      "learning_rate": 3.431147330595483e-05,
      "loss": 0.001,
      "step": 24450
    },
    {
      "epoch": 1.5721252566735113,
      "grad_norm": 0.03260321542620659,
      "learning_rate": 3.427938911704312e-05,
      "loss": 0.001,
      "step": 24500
    },
    {
      "epoch": 1.5753336755646816,
      "grad_norm": 0.12998127937316895,
      "learning_rate": 3.4247304928131416e-05,
      "loss": 0.001,
      "step": 24550
    },
    {
      "epoch": 1.5785420944558521,
      "grad_norm": 0.021889012306928635,
      "learning_rate": 3.421522073921972e-05,
      "loss": 0.001,
      "step": 24600
    },
    {
      "epoch": 1.5817505133470227,
      "grad_norm": 0.055944010615348816,
      "learning_rate": 3.418313655030801e-05,
      "loss": 0.001,
      "step": 24650
    },
    {
      "epoch": 1.5849589322381932,
      "grad_norm": 0.0965777188539505,
      "learning_rate": 3.4151052361396305e-05,
      "loss": 0.001,
      "step": 24700
    },
    {
      "epoch": 1.5881673511293635,
      "grad_norm": 0.10406681895256042,
      "learning_rate": 3.41189681724846e-05,
      "loss": 0.001,
      "step": 24750
    },
    {
      "epoch": 1.5913757700205338,
      "grad_norm": 0.0732072964310646,
      "learning_rate": 3.40868839835729e-05,
      "loss": 0.001,
      "step": 24800
    },
    {
      "epoch": 1.5945841889117043,
      "grad_norm": 0.028134886175394058,
      "learning_rate": 3.4054799794661193e-05,
      "loss": 0.001,
      "step": 24850
    },
    {
      "epoch": 1.5977926078028748,
      "grad_norm": 0.062165517359972,
      "learning_rate": 3.402271560574949e-05,
      "loss": 0.001,
      "step": 24900
    },
    {
      "epoch": 1.6010010266940453,
      "grad_norm": 0.08931764960289001,
      "learning_rate": 3.399063141683778e-05,
      "loss": 0.001,
      "step": 24950
    },
    {
      "epoch": 1.6042094455852156,
      "grad_norm": 0.09068271517753601,
      "learning_rate": 3.395854722792608e-05,
      "loss": 0.001,
      "step": 25000
    },
    {
      "epoch": 1.607417864476386,
      "grad_norm": 0.025049030780792236,
      "learning_rate": 3.392646303901438e-05,
      "loss": 0.001,
      "step": 25050
    },
    {
      "epoch": 1.6106262833675564,
      "grad_norm": 0.02978562004864216,
      "learning_rate": 3.389437885010267e-05,
      "loss": 0.001,
      "step": 25100
    },
    {
      "epoch": 1.613834702258727,
      "grad_norm": 0.02675257809460163,
      "learning_rate": 3.386229466119097e-05,
      "loss": 0.001,
      "step": 25150
    },
    {
      "epoch": 1.6170431211498975,
      "grad_norm": 0.05031607672572136,
      "learning_rate": 3.383021047227926e-05,
      "loss": 0.001,
      "step": 25200
    },
    {
      "epoch": 1.6202515400410678,
      "grad_norm": 0.06957051903009415,
      "learning_rate": 3.3798126283367556e-05,
      "loss": 0.001,
      "step": 25250
    },
    {
      "epoch": 1.623459958932238,
      "grad_norm": 0.11996334791183472,
      "learning_rate": 3.376604209445585e-05,
      "loss": 0.001,
      "step": 25300
    },
    {
      "epoch": 1.6266683778234086,
      "grad_norm": 0.10085614770650864,
      "learning_rate": 3.373395790554415e-05,
      "loss": 0.001,
      "step": 25350
    },
    {
      "epoch": 1.629876796714579,
      "grad_norm": 0.018321795389056206,
      "learning_rate": 3.3701873716632445e-05,
      "loss": 0.001,
      "step": 25400
    },
    {
      "epoch": 1.6330852156057496,
      "grad_norm": 0.031042838469147682,
      "learning_rate": 3.366978952772074e-05,
      "loss": 0.001,
      "step": 25450
    },
    {
      "epoch": 1.63629363449692,
      "grad_norm": 0.09532655775547028,
      "learning_rate": 3.363770533880904e-05,
      "loss": 0.001,
      "step": 25500
    },
    {
      "epoch": 1.6395020533880902,
      "grad_norm": 0.027432184666395187,
      "learning_rate": 3.360562114989733e-05,
      "loss": 0.001,
      "step": 25550
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.06284135580062866,
      "learning_rate": 3.357353696098563e-05,
      "loss": 0.001,
      "step": 25600
    },
    {
      "epoch": 1.6459188911704312,
      "grad_norm": 0.037123873829841614,
      "learning_rate": 3.3541452772073926e-05,
      "loss": 0.001,
      "step": 25650
    },
    {
      "epoch": 1.6491273100616017,
      "grad_norm": 0.07408849895000458,
      "learning_rate": 3.350936858316222e-05,
      "loss": 0.001,
      "step": 25700
    },
    {
      "epoch": 1.652335728952772,
      "grad_norm": 0.05323977768421173,
      "learning_rate": 3.347728439425051e-05,
      "loss": 0.001,
      "step": 25750
    },
    {
      "epoch": 1.6555441478439425,
      "grad_norm": 0.057816799730062485,
      "learning_rate": 3.3445200205338814e-05,
      "loss": 0.001,
      "step": 25800
    },
    {
      "epoch": 1.6587525667351128,
      "grad_norm": 0.04787134379148483,
      "learning_rate": 3.3413116016427104e-05,
      "loss": 0.001,
      "step": 25850
    },
    {
      "epoch": 1.6619609856262834,
      "grad_norm": 0.03618433699011803,
      "learning_rate": 3.33810318275154e-05,
      "loss": 0.001,
      "step": 25900
    },
    {
      "epoch": 1.6651694045174539,
      "grad_norm": 0.029026949778199196,
      "learning_rate": 3.33489476386037e-05,
      "loss": 0.001,
      "step": 25950
    },
    {
      "epoch": 1.6683778234086244,
      "grad_norm": 0.07861756533384323,
      "learning_rate": 3.331686344969199e-05,
      "loss": 0.001,
      "step": 26000
    },
    {
      "epoch": 1.6715862422997947,
      "grad_norm": 0.0220635998994112,
      "learning_rate": 3.328477926078029e-05,
      "loss": 0.001,
      "step": 26050
    },
    {
      "epoch": 1.674794661190965,
      "grad_norm": 0.12887954711914062,
      "learning_rate": 3.3252695071868585e-05,
      "loss": 0.001,
      "step": 26100
    },
    {
      "epoch": 1.6780030800821355,
      "grad_norm": 0.032949939370155334,
      "learning_rate": 3.322061088295688e-05,
      "loss": 0.001,
      "step": 26150
    },
    {
      "epoch": 1.681211498973306,
      "grad_norm": 0.04290109500288963,
      "learning_rate": 3.318852669404518e-05,
      "loss": 0.001,
      "step": 26200
    },
    {
      "epoch": 1.6844199178644765,
      "grad_norm": 0.1596328616142273,
      "learning_rate": 3.315644250513347e-05,
      "loss": 0.001,
      "step": 26250
    },
    {
      "epoch": 1.6876283367556468,
      "grad_norm": 0.02047341875731945,
      "learning_rate": 3.312435831622176e-05,
      "loss": 0.001,
      "step": 26300
    },
    {
      "epoch": 1.6908367556468171,
      "grad_norm": 0.05754196271300316,
      "learning_rate": 3.3092274127310066e-05,
      "loss": 0.001,
      "step": 26350
    },
    {
      "epoch": 1.6940451745379876,
      "grad_norm": 0.051687244325876236,
      "learning_rate": 3.306018993839836e-05,
      "loss": 0.001,
      "step": 26400
    },
    {
      "epoch": 1.6972535934291582,
      "grad_norm": 0.06106703355908394,
      "learning_rate": 3.302810574948665e-05,
      "loss": 0.001,
      "step": 26450
    },
    {
      "epoch": 1.7004620123203287,
      "grad_norm": 0.03604229912161827,
      "learning_rate": 3.2996021560574954e-05,
      "loss": 0.001,
      "step": 26500
    },
    {
      "epoch": 1.703670431211499,
      "grad_norm": 0.08619111031293869,
      "learning_rate": 3.2963937371663243e-05,
      "loss": 0.001,
      "step": 26550
    },
    {
      "epoch": 1.7068788501026693,
      "grad_norm": 0.06304963678121567,
      "learning_rate": 3.2931853182751546e-05,
      "loss": 0.001,
      "step": 26600
    },
    {
      "epoch": 1.7100872689938398,
      "grad_norm": 0.13614164292812347,
      "learning_rate": 3.2899768993839836e-05,
      "loss": 0.001,
      "step": 26650
    },
    {
      "epoch": 1.7132956878850103,
      "grad_norm": 0.04757142439484596,
      "learning_rate": 3.286768480492813e-05,
      "loss": 0.001,
      "step": 26700
    },
    {
      "epoch": 1.7165041067761808,
      "grad_norm": 0.037482962012290955,
      "learning_rate": 3.283560061601643e-05,
      "loss": 0.001,
      "step": 26750
    },
    {
      "epoch": 1.719712525667351,
      "grad_norm": 0.04686657339334488,
      "learning_rate": 3.2803516427104724e-05,
      "loss": 0.001,
      "step": 26800
    },
    {
      "epoch": 1.7229209445585214,
      "grad_norm": 0.06507802754640579,
      "learning_rate": 3.277143223819302e-05,
      "loss": 0.001,
      "step": 26850
    },
    {
      "epoch": 1.726129363449692,
      "grad_norm": 0.06171011924743652,
      "learning_rate": 3.273934804928132e-05,
      "loss": 0.001,
      "step": 26900
    },
    {
      "epoch": 1.7293377823408624,
      "grad_norm": 0.03813321888446808,
      "learning_rate": 3.270726386036961e-05,
      "loss": 0.001,
      "step": 26950
    },
    {
      "epoch": 1.732546201232033,
      "grad_norm": 0.07458041608333588,
      "learning_rate": 3.267517967145791e-05,
      "loss": 0.001,
      "step": 27000
    },
    {
      "epoch": 1.7357546201232033,
      "grad_norm": 0.06707707047462463,
      "learning_rate": 3.2643095482546205e-05,
      "loss": 0.001,
      "step": 27050
    },
    {
      "epoch": 1.7389630390143738,
      "grad_norm": 0.023270882666110992,
      "learning_rate": 3.2611011293634495e-05,
      "loss": 0.001,
      "step": 27100
    },
    {
      "epoch": 1.742171457905544,
      "grad_norm": 0.06336379051208496,
      "learning_rate": 3.25789271047228e-05,
      "loss": 0.001,
      "step": 27150
    },
    {
      "epoch": 1.7453798767967146,
      "grad_norm": 0.11123054474592209,
      "learning_rate": 3.254684291581109e-05,
      "loss": 0.001,
      "step": 27200
    },
    {
      "epoch": 1.748588295687885,
      "grad_norm": 0.040475841611623764,
      "learning_rate": 3.251475872689938e-05,
      "loss": 0.001,
      "step": 27250
    },
    {
      "epoch": 1.7517967145790554,
      "grad_norm": 0.06993335485458374,
      "learning_rate": 3.248267453798768e-05,
      "loss": 0.001,
      "step": 27300
    },
    {
      "epoch": 1.755005133470226,
      "grad_norm": 0.02483062632381916,
      "learning_rate": 3.2450590349075976e-05,
      "loss": 0.001,
      "step": 27350
    },
    {
      "epoch": 1.7582135523613962,
      "grad_norm": 0.05780801549553871,
      "learning_rate": 3.241850616016427e-05,
      "loss": 0.001,
      "step": 27400
    },
    {
      "epoch": 1.7614219712525667,
      "grad_norm": 0.07603541761636734,
      "learning_rate": 3.238642197125257e-05,
      "loss": 0.001,
      "step": 27450
    },
    {
      "epoch": 1.7646303901437372,
      "grad_norm": 0.05347084254026413,
      "learning_rate": 3.2354337782340864e-05,
      "loss": 0.001,
      "step": 27500
    },
    {
      "epoch": 1.7678388090349078,
      "grad_norm": 0.10238112509250641,
      "learning_rate": 3.232225359342916e-05,
      "loss": 0.001,
      "step": 27550
    },
    {
      "epoch": 1.771047227926078,
      "grad_norm": 0.055389199405908585,
      "learning_rate": 3.229016940451746e-05,
      "loss": 0.001,
      "step": 27600
    },
    {
      "epoch": 1.7742556468172483,
      "grad_norm": 0.10729014128446579,
      "learning_rate": 3.2258085215605746e-05,
      "loss": 0.001,
      "step": 27650
    },
    {
      "epoch": 1.7774640657084189,
      "grad_norm": 0.06353657692670822,
      "learning_rate": 3.222600102669405e-05,
      "loss": 0.001,
      "step": 27700
    },
    {
      "epoch": 1.7806724845995894,
      "grad_norm": 0.012902593240141869,
      "learning_rate": 3.219391683778234e-05,
      "loss": 0.0009,
      "step": 27750
    },
    {
      "epoch": 1.78388090349076,
      "grad_norm": 0.07613840699195862,
      "learning_rate": 3.2161832648870635e-05,
      "loss": 0.001,
      "step": 27800
    },
    {
      "epoch": 1.7870893223819302,
      "grad_norm": 0.03706982359290123,
      "learning_rate": 3.212974845995894e-05,
      "loss": 0.001,
      "step": 27850
    },
    {
      "epoch": 1.7902977412731005,
      "grad_norm": 0.016441931948065758,
      "learning_rate": 3.209766427104723e-05,
      "loss": 0.001,
      "step": 27900
    },
    {
      "epoch": 1.793506160164271,
      "grad_norm": 0.1696624755859375,
      "learning_rate": 3.206558008213553e-05,
      "loss": 0.001,
      "step": 27950
    },
    {
      "epoch": 1.7967145790554415,
      "grad_norm": 0.024296727031469345,
      "learning_rate": 3.203349589322382e-05,
      "loss": 0.001,
      "step": 28000
    },
    {
      "epoch": 1.799922997946612,
      "grad_norm": 0.042957235127687454,
      "learning_rate": 3.2001411704312116e-05,
      "loss": 0.001,
      "step": 28050
    },
    {
      "epoch": 1.8031314168377823,
      "grad_norm": 0.07664816081523895,
      "learning_rate": 3.196932751540041e-05,
      "loss": 0.001,
      "step": 28100
    },
    {
      "epoch": 1.8063398357289526,
      "grad_norm": 0.026806380599737167,
      "learning_rate": 3.193724332648871e-05,
      "loss": 0.001,
      "step": 28150
    },
    {
      "epoch": 1.8095482546201231,
      "grad_norm": 0.07126279920339584,
      "learning_rate": 3.1905159137577004e-05,
      "loss": 0.001,
      "step": 28200
    },
    {
      "epoch": 1.8127566735112937,
      "grad_norm": 0.025154557079076767,
      "learning_rate": 3.18730749486653e-05,
      "loss": 0.001,
      "step": 28250
    },
    {
      "epoch": 1.8159650924024642,
      "grad_norm": 0.01218130998313427,
      "learning_rate": 3.1840990759753597e-05,
      "loss": 0.001,
      "step": 28300
    },
    {
      "epoch": 1.8191735112936345,
      "grad_norm": 0.02449451945722103,
      "learning_rate": 3.180890657084189e-05,
      "loss": 0.001,
      "step": 28350
    },
    {
      "epoch": 1.8223819301848048,
      "grad_norm": 0.025627631694078445,
      "learning_rate": 3.177682238193019e-05,
      "loss": 0.001,
      "step": 28400
    },
    {
      "epoch": 1.8255903490759753,
      "grad_norm": 0.06428689509630203,
      "learning_rate": 3.174473819301848e-05,
      "loss": 0.001,
      "step": 28450
    },
    {
      "epoch": 1.8287987679671458,
      "grad_norm": 0.06858256459236145,
      "learning_rate": 3.171265400410678e-05,
      "loss": 0.001,
      "step": 28500
    },
    {
      "epoch": 1.8320071868583163,
      "grad_norm": 0.06666730344295502,
      "learning_rate": 3.168056981519507e-05,
      "loss": 0.001,
      "step": 28550
    },
    {
      "epoch": 1.8352156057494866,
      "grad_norm": 0.05847125127911568,
      "learning_rate": 3.164848562628337e-05,
      "loss": 0.001,
      "step": 28600
    },
    {
      "epoch": 1.8384240246406571,
      "grad_norm": 0.06025949865579605,
      "learning_rate": 3.161640143737166e-05,
      "loss": 0.001,
      "step": 28650
    },
    {
      "epoch": 1.8416324435318274,
      "grad_norm": 0.04371284320950508,
      "learning_rate": 3.158431724845996e-05,
      "loss": 0.001,
      "step": 28700
    },
    {
      "epoch": 1.844840862422998,
      "grad_norm": 0.09219270199537277,
      "learning_rate": 3.1552233059548255e-05,
      "loss": 0.001,
      "step": 28750
    },
    {
      "epoch": 1.8480492813141685,
      "grad_norm": 0.09113507717847824,
      "learning_rate": 3.152014887063655e-05,
      "loss": 0.001,
      "step": 28800
    },
    {
      "epoch": 1.851257700205339,
      "grad_norm": 0.028023388236761093,
      "learning_rate": 3.148806468172485e-05,
      "loss": 0.001,
      "step": 28850
    },
    {
      "epoch": 1.8544661190965093,
      "grad_norm": 0.03035699762403965,
      "learning_rate": 3.1455980492813144e-05,
      "loss": 0.001,
      "step": 28900
    },
    {
      "epoch": 1.8576745379876796,
      "grad_norm": 0.06869247555732727,
      "learning_rate": 3.142389630390144e-05,
      "loss": 0.001,
      "step": 28950
    },
    {
      "epoch": 1.86088295687885,
      "grad_norm": 0.11016707122325897,
      "learning_rate": 3.139181211498973e-05,
      "loss": 0.001,
      "step": 29000
    },
    {
      "epoch": 1.8640913757700206,
      "grad_norm": 0.0746736079454422,
      "learning_rate": 3.135972792607803e-05,
      "loss": 0.001,
      "step": 29050
    },
    {
      "epoch": 1.8672997946611911,
      "grad_norm": 0.08445713669061661,
      "learning_rate": 3.132764373716632e-05,
      "loss": 0.001,
      "step": 29100
    },
    {
      "epoch": 1.8705082135523614,
      "grad_norm": 0.06957373023033142,
      "learning_rate": 3.129555954825462e-05,
      "loss": 0.001,
      "step": 29150
    },
    {
      "epoch": 1.8737166324435317,
      "grad_norm": 0.0581425316631794,
      "learning_rate": 3.126347535934292e-05,
      "loss": 0.001,
      "step": 29200
    },
    {
      "epoch": 1.8769250513347022,
      "grad_norm": 0.07294911891222,
      "learning_rate": 3.123139117043121e-05,
      "loss": 0.001,
      "step": 29250
    },
    {
      "epoch": 1.8801334702258727,
      "grad_norm": 0.07954715192317963,
      "learning_rate": 3.1199306981519514e-05,
      "loss": 0.001,
      "step": 29300
    },
    {
      "epoch": 1.8833418891170433,
      "grad_norm": 0.07826050370931625,
      "learning_rate": 3.11672227926078e-05,
      "loss": 0.001,
      "step": 29350
    },
    {
      "epoch": 1.8865503080082136,
      "grad_norm": 0.03158272057771683,
      "learning_rate": 3.11351386036961e-05,
      "loss": 0.001,
      "step": 29400
    },
    {
      "epoch": 1.8897587268993838,
      "grad_norm": 0.022347310557961464,
      "learning_rate": 3.1103054414784395e-05,
      "loss": 0.001,
      "step": 29450
    },
    {
      "epoch": 1.8929671457905544,
      "grad_norm": 0.06823211163282394,
      "learning_rate": 3.107097022587269e-05,
      "loss": 0.0009,
      "step": 29500
    },
    {
      "epoch": 1.8961755646817249,
      "grad_norm": 0.039205025881528854,
      "learning_rate": 3.103888603696099e-05,
      "loss": 0.001,
      "step": 29550
    },
    {
      "epoch": 1.8993839835728954,
      "grad_norm": 0.08694188296794891,
      "learning_rate": 3.1006801848049284e-05,
      "loss": 0.001,
      "step": 29600
    },
    {
      "epoch": 1.9025924024640657,
      "grad_norm": 0.04034470021724701,
      "learning_rate": 3.097471765913758e-05,
      "loss": 0.001,
      "step": 29650
    },
    {
      "epoch": 1.905800821355236,
      "grad_norm": 0.11747529357671738,
      "learning_rate": 3.0942633470225876e-05,
      "loss": 0.001,
      "step": 29700
    },
    {
      "epoch": 1.9090092402464065,
      "grad_norm": 0.0883309543132782,
      "learning_rate": 3.091054928131417e-05,
      "loss": 0.001,
      "step": 29750
    },
    {
      "epoch": 1.912217659137577,
      "grad_norm": 0.05149751156568527,
      "learning_rate": 3.087846509240246e-05,
      "loss": 0.001,
      "step": 29800
    },
    {
      "epoch": 1.9154260780287475,
      "grad_norm": 0.08356598019599915,
      "learning_rate": 3.0846380903490765e-05,
      "loss": 0.0009,
      "step": 29850
    },
    {
      "epoch": 1.9186344969199178,
      "grad_norm": 0.018419362604618073,
      "learning_rate": 3.0814296714579054e-05,
      "loss": 0.001,
      "step": 29900
    },
    {
      "epoch": 1.9218429158110883,
      "grad_norm": 0.14136448502540588,
      "learning_rate": 3.078221252566735e-05,
      "loss": 0.001,
      "step": 29950
    },
    {
      "epoch": 1.9250513347022586,
      "grad_norm": 0.1162310466170311,
      "learning_rate": 3.0750128336755647e-05,
      "loss": 0.001,
      "step": 30000
    },
    {
      "epoch": 1.9282597535934292,
      "grad_norm": 0.09956324845552444,
      "learning_rate": 3.071804414784394e-05,
      "loss": 0.001,
      "step": 30050
    },
    {
      "epoch": 1.9314681724845997,
      "grad_norm": 0.011710301972925663,
      "learning_rate": 3.068595995893224e-05,
      "loss": 0.001,
      "step": 30100
    },
    {
      "epoch": 1.93467659137577,
      "grad_norm": 0.08707669377326965,
      "learning_rate": 3.0653875770020535e-05,
      "loss": 0.001,
      "step": 30150
    },
    {
      "epoch": 1.9378850102669405,
      "grad_norm": 0.07736247032880783,
      "learning_rate": 3.062179158110883e-05,
      "loss": 0.001,
      "step": 30200
    },
    {
      "epoch": 1.9410934291581108,
      "grad_norm": 0.033363230526447296,
      "learning_rate": 3.058970739219713e-05,
      "loss": 0.001,
      "step": 30250
    },
    {
      "epoch": 1.9443018480492813,
      "grad_norm": 0.07957726716995239,
      "learning_rate": 3.0557623203285424e-05,
      "loss": 0.001,
      "step": 30300
    },
    {
      "epoch": 1.9475102669404518,
      "grad_norm": 0.06666285544633865,
      "learning_rate": 3.052553901437371e-05,
      "loss": 0.0009,
      "step": 30350
    },
    {
      "epoch": 1.9507186858316223,
      "grad_norm": 0.058414749801158905,
      "learning_rate": 3.0493454825462016e-05,
      "loss": 0.001,
      "step": 30400
    },
    {
      "epoch": 1.9539271047227926,
      "grad_norm": 0.0962882861495018,
      "learning_rate": 3.0461370636550306e-05,
      "loss": 0.001,
      "step": 30450
    },
    {
      "epoch": 1.957135523613963,
      "grad_norm": 0.11785399168729782,
      "learning_rate": 3.0429286447638605e-05,
      "loss": 0.001,
      "step": 30500
    },
    {
      "epoch": 1.9603439425051334,
      "grad_norm": 0.11453147977590561,
      "learning_rate": 3.0397202258726905e-05,
      "loss": 0.001,
      "step": 30550
    },
    {
      "epoch": 1.963552361396304,
      "grad_norm": 0.04658818989992142,
      "learning_rate": 3.0365118069815197e-05,
      "loss": 0.001,
      "step": 30600
    },
    {
      "epoch": 1.9667607802874745,
      "grad_norm": 0.06649644672870636,
      "learning_rate": 3.0333033880903494e-05,
      "loss": 0.001,
      "step": 30650
    },
    {
      "epoch": 1.9699691991786448,
      "grad_norm": 0.05570448189973831,
      "learning_rate": 3.0300949691991786e-05,
      "loss": 0.0009,
      "step": 30700
    },
    {
      "epoch": 1.973177618069815,
      "grad_norm": 0.049178797751665115,
      "learning_rate": 3.0268865503080086e-05,
      "loss": 0.001,
      "step": 30750
    },
    {
      "epoch": 1.9763860369609856,
      "grad_norm": 0.06647941470146179,
      "learning_rate": 3.023678131416838e-05,
      "loss": 0.0009,
      "step": 30800
    },
    {
      "epoch": 1.979594455852156,
      "grad_norm": 0.08744920790195465,
      "learning_rate": 3.0204697125256675e-05,
      "loss": 0.001,
      "step": 30850
    },
    {
      "epoch": 1.9828028747433266,
      "grad_norm": 0.07226063311100006,
      "learning_rate": 3.0172612936344968e-05,
      "loss": 0.001,
      "step": 30900
    },
    {
      "epoch": 1.986011293634497,
      "grad_norm": 0.06655079871416092,
      "learning_rate": 3.0140528747433267e-05,
      "loss": 0.001,
      "step": 30950
    },
    {
      "epoch": 1.9892197125256672,
      "grad_norm": 0.07873069494962692,
      "learning_rate": 3.0108444558521564e-05,
      "loss": 0.001,
      "step": 31000
    },
    {
      "epoch": 1.9924281314168377,
      "grad_norm": 0.17893338203430176,
      "learning_rate": 3.0076360369609856e-05,
      "loss": 0.001,
      "step": 31050
    },
    {
      "epoch": 1.9956365503080082,
      "grad_norm": 0.08413966000080109,
      "learning_rate": 3.0044276180698156e-05,
      "loss": 0.001,
      "step": 31100
    },
    {
      "epoch": 1.9988449691991788,
      "grad_norm": 0.08801018446683884,
      "learning_rate": 3.001219199178645e-05,
      "loss": 0.001,
      "step": 31150
    },
    {
      "epoch": 2.0020533880903493,
      "grad_norm": 0.06744624674320221,
      "learning_rate": 2.9980107802874745e-05,
      "loss": 0.001,
      "step": 31200
    },
    {
      "epoch": 2.0052618069815193,
      "grad_norm": 0.09085667133331299,
      "learning_rate": 2.9948023613963038e-05,
      "loss": 0.0009,
      "step": 31250
    },
    {
      "epoch": 2.00847022587269,
      "grad_norm": 0.048221565783023834,
      "learning_rate": 2.9915939425051337e-05,
      "loss": 0.001,
      "step": 31300
    },
    {
      "epoch": 2.0116786447638604,
      "grad_norm": 0.0833830013871193,
      "learning_rate": 2.988385523613963e-05,
      "loss": 0.0009,
      "step": 31350
    },
    {
      "epoch": 2.014887063655031,
      "grad_norm": 0.0437396764755249,
      "learning_rate": 2.9851771047227926e-05,
      "loss": 0.001,
      "step": 31400
    },
    {
      "epoch": 2.0180954825462014,
      "grad_norm": 0.03907576948404312,
      "learning_rate": 2.9819686858316226e-05,
      "loss": 0.001,
      "step": 31450
    },
    {
      "epoch": 2.0213039014373715,
      "grad_norm": 0.058848828077316284,
      "learning_rate": 2.978760266940452e-05,
      "loss": 0.0009,
      "step": 31500
    },
    {
      "epoch": 2.024512320328542,
      "grad_norm": 0.0784100592136383,
      "learning_rate": 2.9755518480492818e-05,
      "loss": 0.001,
      "step": 31550
    },
    {
      "epoch": 2.0277207392197125,
      "grad_norm": 0.07999289035797119,
      "learning_rate": 2.9723434291581108e-05,
      "loss": 0.0009,
      "step": 31600
    },
    {
      "epoch": 2.030929158110883,
      "grad_norm": 0.09686575084924698,
      "learning_rate": 2.9691350102669407e-05,
      "loss": 0.001,
      "step": 31650
    },
    {
      "epoch": 2.0341375770020536,
      "grad_norm": 0.09159467369318008,
      "learning_rate": 2.96592659137577e-05,
      "loss": 0.0009,
      "step": 31700
    },
    {
      "epoch": 2.0373459958932236,
      "grad_norm": 0.07214858382940292,
      "learning_rate": 2.9627181724846e-05,
      "loss": 0.001,
      "step": 31750
    },
    {
      "epoch": 2.040554414784394,
      "grad_norm": 0.07744768261909485,
      "learning_rate": 2.9595097535934292e-05,
      "loss": 0.0009,
      "step": 31800
    },
    {
      "epoch": 2.0437628336755647,
      "grad_norm": 0.04844456538558006,
      "learning_rate": 2.956301334702259e-05,
      "loss": 0.001,
      "step": 31850
    },
    {
      "epoch": 2.046971252566735,
      "grad_norm": 0.06793437153100967,
      "learning_rate": 2.9530929158110888e-05,
      "loss": 0.0009,
      "step": 31900
    },
    {
      "epoch": 2.0501796714579057,
      "grad_norm": 0.05317976325750351,
      "learning_rate": 2.949884496919918e-05,
      "loss": 0.001,
      "step": 31950
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.06968607008457184,
      "learning_rate": 2.9466760780287477e-05,
      "loss": 0.0009,
      "step": 32000
    },
    {
      "epoch": 2.0565965092402463,
      "grad_norm": 0.0396876223385334,
      "learning_rate": 2.943467659137577e-05,
      "loss": 0.0009,
      "step": 32050
    },
    {
      "epoch": 2.059804928131417,
      "grad_norm": 0.04941742122173309,
      "learning_rate": 2.940259240246407e-05,
      "loss": 0.0009,
      "step": 32100
    },
    {
      "epoch": 2.0630133470225873,
      "grad_norm": 0.028262866660952568,
      "learning_rate": 2.9370508213552362e-05,
      "loss": 0.001,
      "step": 32150
    },
    {
      "epoch": 2.066221765913758,
      "grad_norm": 0.03619487211108208,
      "learning_rate": 2.933842402464066e-05,
      "loss": 0.001,
      "step": 32200
    },
    {
      "epoch": 2.0694301848049284,
      "grad_norm": 0.0740414634346962,
      "learning_rate": 2.930633983572895e-05,
      "loss": 0.0009,
      "step": 32250
    },
    {
      "epoch": 2.0726386036960984,
      "grad_norm": 0.04513897746801376,
      "learning_rate": 2.927425564681725e-05,
      "loss": 0.0009,
      "step": 32300
    },
    {
      "epoch": 2.075847022587269,
      "grad_norm": 0.03465629741549492,
      "learning_rate": 2.9242171457905544e-05,
      "loss": 0.0009,
      "step": 32350
    },
    {
      "epoch": 2.0790554414784395,
      "grad_norm": 0.08703688532114029,
      "learning_rate": 2.921008726899384e-05,
      "loss": 0.0009,
      "step": 32400
    },
    {
      "epoch": 2.08226386036961,
      "grad_norm": 0.07845687121152878,
      "learning_rate": 2.917800308008214e-05,
      "loss": 0.001,
      "step": 32450
    },
    {
      "epoch": 2.0854722792607805,
      "grad_norm": 0.06400103121995926,
      "learning_rate": 2.9145918891170432e-05,
      "loss": 0.0009,
      "step": 32500
    },
    {
      "epoch": 2.0886806981519506,
      "grad_norm": 0.11482470482587814,
      "learning_rate": 2.911383470225873e-05,
      "loss": 0.0009,
      "step": 32550
    },
    {
      "epoch": 2.091889117043121,
      "grad_norm": 0.08751938492059708,
      "learning_rate": 2.908175051334702e-05,
      "loss": 0.001,
      "step": 32600
    },
    {
      "epoch": 2.0950975359342916,
      "grad_norm": 0.1118311658501625,
      "learning_rate": 2.904966632443532e-05,
      "loss": 0.001,
      "step": 32650
    },
    {
      "epoch": 2.098305954825462,
      "grad_norm": 0.08565057069063187,
      "learning_rate": 2.9017582135523614e-05,
      "loss": 0.001,
      "step": 32700
    },
    {
      "epoch": 2.1015143737166326,
      "grad_norm": 0.06042976677417755,
      "learning_rate": 2.898549794661191e-05,
      "loss": 0.001,
      "step": 32750
    },
    {
      "epoch": 2.1047227926078027,
      "grad_norm": 0.04217511788010597,
      "learning_rate": 2.8953413757700203e-05,
      "loss": 0.001,
      "step": 32800
    },
    {
      "epoch": 2.1079312114989732,
      "grad_norm": 0.04190075397491455,
      "learning_rate": 2.8921329568788502e-05,
      "loss": 0.0009,
      "step": 32850
    },
    {
      "epoch": 2.1111396303901437,
      "grad_norm": 0.07216319441795349,
      "learning_rate": 2.8889245379876802e-05,
      "loss": 0.0009,
      "step": 32900
    },
    {
      "epoch": 2.1143480492813143,
      "grad_norm": 0.03252659738063812,
      "learning_rate": 2.8857161190965095e-05,
      "loss": 0.0009,
      "step": 32950
    },
    {
      "epoch": 2.1175564681724848,
      "grad_norm": 0.13750287890434265,
      "learning_rate": 2.882507700205339e-05,
      "loss": 0.0009,
      "step": 33000
    },
    {
      "epoch": 2.120764887063655,
      "grad_norm": 0.10621257871389389,
      "learning_rate": 2.8792992813141684e-05,
      "loss": 0.001,
      "step": 33050
    },
    {
      "epoch": 2.1239733059548254,
      "grad_norm": 0.03961408510804176,
      "learning_rate": 2.8760908624229983e-05,
      "loss": 0.0009,
      "step": 33100
    },
    {
      "epoch": 2.127181724845996,
      "grad_norm": 0.08273852616548538,
      "learning_rate": 2.8728824435318276e-05,
      "loss": 0.0009,
      "step": 33150
    },
    {
      "epoch": 2.1303901437371664,
      "grad_norm": 0.024575451388955116,
      "learning_rate": 2.8696740246406572e-05,
      "loss": 0.001,
      "step": 33200
    },
    {
      "epoch": 2.133598562628337,
      "grad_norm": 0.045004427433013916,
      "learning_rate": 2.8664656057494865e-05,
      "loss": 0.001,
      "step": 33250
    },
    {
      "epoch": 2.136806981519507,
      "grad_norm": 0.053048279136419296,
      "learning_rate": 2.8632571868583165e-05,
      "loss": 0.0009,
      "step": 33300
    },
    {
      "epoch": 2.1400154004106775,
      "grad_norm": 0.045234594494104385,
      "learning_rate": 2.860048767967146e-05,
      "loss": 0.0009,
      "step": 33350
    },
    {
      "epoch": 2.143223819301848,
      "grad_norm": 0.04953674226999283,
      "learning_rate": 2.8568403490759753e-05,
      "loss": 0.0009,
      "step": 33400
    },
    {
      "epoch": 2.1464322381930185,
      "grad_norm": 0.1345072090625763,
      "learning_rate": 2.8536319301848053e-05,
      "loss": 0.001,
      "step": 33450
    },
    {
      "epoch": 2.149640657084189,
      "grad_norm": 0.12846125662326813,
      "learning_rate": 2.8504235112936346e-05,
      "loss": 0.0009,
      "step": 33500
    },
    {
      "epoch": 2.152849075975359,
      "grad_norm": 0.03525083139538765,
      "learning_rate": 2.8472150924024642e-05,
      "loss": 0.0009,
      "step": 33550
    },
    {
      "epoch": 2.1560574948665296,
      "grad_norm": 0.13806243240833282,
      "learning_rate": 2.8440066735112935e-05,
      "loss": 0.0009,
      "step": 33600
    },
    {
      "epoch": 2.1592659137577,
      "grad_norm": 0.09237361699342728,
      "learning_rate": 2.8407982546201234e-05,
      "loss": 0.0009,
      "step": 33650
    },
    {
      "epoch": 2.1624743326488707,
      "grad_norm": 0.04662373289465904,
      "learning_rate": 2.8375898357289527e-05,
      "loss": 0.001,
      "step": 33700
    },
    {
      "epoch": 2.165682751540041,
      "grad_norm": 0.11646339297294617,
      "learning_rate": 2.8343814168377823e-05,
      "loss": 0.0009,
      "step": 33750
    },
    {
      "epoch": 2.1688911704312117,
      "grad_norm": 0.08158472925424576,
      "learning_rate": 2.8311729979466123e-05,
      "loss": 0.001,
      "step": 33800
    },
    {
      "epoch": 2.172099589322382,
      "grad_norm": 0.08660360425710678,
      "learning_rate": 2.8279645790554416e-05,
      "loss": 0.0009,
      "step": 33850
    },
    {
      "epoch": 2.1753080082135523,
      "grad_norm": 0.057501547038555145,
      "learning_rate": 2.8247561601642712e-05,
      "loss": 0.0009,
      "step": 33900
    },
    {
      "epoch": 2.178516427104723,
      "grad_norm": 0.02394012175500393,
      "learning_rate": 2.8215477412731005e-05,
      "loss": 0.0009,
      "step": 33950
    },
    {
      "epoch": 2.1817248459958933,
      "grad_norm": 0.06460560113191605,
      "learning_rate": 2.8183393223819304e-05,
      "loss": 0.0009,
      "step": 34000
    },
    {
      "epoch": 2.184933264887064,
      "grad_norm": 0.03160617873072624,
      "learning_rate": 2.8151309034907597e-05,
      "loss": 0.0009,
      "step": 34050
    },
    {
      "epoch": 2.188141683778234,
      "grad_norm": 0.047213636338710785,
      "learning_rate": 2.8119224845995897e-05,
      "loss": 0.0009,
      "step": 34100
    },
    {
      "epoch": 2.1913501026694044,
      "grad_norm": 0.08462164551019669,
      "learning_rate": 2.8087140657084186e-05,
      "loss": 0.0009,
      "step": 34150
    },
    {
      "epoch": 2.194558521560575,
      "grad_norm": 0.036686550825834274,
      "learning_rate": 2.8055056468172486e-05,
      "loss": 0.001,
      "step": 34200
    },
    {
      "epoch": 2.1977669404517455,
      "grad_norm": 0.07914804667234421,
      "learning_rate": 2.8022972279260785e-05,
      "loss": 0.001,
      "step": 34250
    },
    {
      "epoch": 2.200975359342916,
      "grad_norm": 0.1637951284646988,
      "learning_rate": 2.7990888090349078e-05,
      "loss": 0.0009,
      "step": 34300
    },
    {
      "epoch": 2.204183778234086,
      "grad_norm": 0.11906325817108154,
      "learning_rate": 2.7958803901437374e-05,
      "loss": 0.001,
      "step": 34350
    },
    {
      "epoch": 2.2073921971252566,
      "grad_norm": 0.1248137503862381,
      "learning_rate": 2.7926719712525667e-05,
      "loss": 0.0009,
      "step": 34400
    },
    {
      "epoch": 2.210600616016427,
      "grad_norm": 0.02617071196436882,
      "learning_rate": 2.7894635523613967e-05,
      "loss": 0.001,
      "step": 34450
    },
    {
      "epoch": 2.2138090349075976,
      "grad_norm": 0.07404931634664536,
      "learning_rate": 2.786255133470226e-05,
      "loss": 0.001,
      "step": 34500
    },
    {
      "epoch": 2.217017453798768,
      "grad_norm": 0.08703331649303436,
      "learning_rate": 2.7830467145790556e-05,
      "loss": 0.0009,
      "step": 34550
    },
    {
      "epoch": 2.220225872689938,
      "grad_norm": 0.0790417268872261,
      "learning_rate": 2.779838295687885e-05,
      "loss": 0.0009,
      "step": 34600
    },
    {
      "epoch": 2.2234342915811087,
      "grad_norm": 0.08948605507612228,
      "learning_rate": 2.7766298767967148e-05,
      "loss": 0.001,
      "step": 34650
    },
    {
      "epoch": 2.2266427104722792,
      "grad_norm": 0.044709302484989166,
      "learning_rate": 2.7734214579055444e-05,
      "loss": 0.0009,
      "step": 34700
    },
    {
      "epoch": 2.2298511293634498,
      "grad_norm": 0.10542989522218704,
      "learning_rate": 2.7702130390143737e-05,
      "loss": 0.0009,
      "step": 34750
    },
    {
      "epoch": 2.2330595482546203,
      "grad_norm": 0.11317093670368195,
      "learning_rate": 2.7670046201232037e-05,
      "loss": 0.0009,
      "step": 34800
    },
    {
      "epoch": 2.2362679671457903,
      "grad_norm": 0.083757683634758,
      "learning_rate": 2.763796201232033e-05,
      "loss": 0.001,
      "step": 34850
    },
    {
      "epoch": 2.239476386036961,
      "grad_norm": 0.041681159287691116,
      "learning_rate": 2.7605877823408626e-05,
      "loss": 0.0009,
      "step": 34900
    },
    {
      "epoch": 2.2426848049281314,
      "grad_norm": 0.04169785603880882,
      "learning_rate": 2.757379363449692e-05,
      "loss": 0.0009,
      "step": 34950
    },
    {
      "epoch": 2.245893223819302,
      "grad_norm": 0.08097048848867416,
      "learning_rate": 2.7541709445585218e-05,
      "loss": 0.0009,
      "step": 35000
    },
    {
      "epoch": 2.2491016427104724,
      "grad_norm": 0.038124796003103256,
      "learning_rate": 2.750962525667351e-05,
      "loss": 0.0009,
      "step": 35050
    },
    {
      "epoch": 2.2523100616016425,
      "grad_norm": 0.12286055088043213,
      "learning_rate": 2.7477541067761807e-05,
      "loss": 0.001,
      "step": 35100
    },
    {
      "epoch": 2.255518480492813,
      "grad_norm": 0.0818171352148056,
      "learning_rate": 2.7445456878850107e-05,
      "loss": 0.0009,
      "step": 35150
    },
    {
      "epoch": 2.2587268993839835,
      "grad_norm": 0.04123341292142868,
      "learning_rate": 2.74133726899384e-05,
      "loss": 0.001,
      "step": 35200
    },
    {
      "epoch": 2.261935318275154,
      "grad_norm": 0.07320521771907806,
      "learning_rate": 2.73812885010267e-05,
      "loss": 0.0009,
      "step": 35250
    },
    {
      "epoch": 2.2651437371663246,
      "grad_norm": 0.06613344699144363,
      "learning_rate": 2.734920431211499e-05,
      "loss": 0.0009,
      "step": 35300
    },
    {
      "epoch": 2.268352156057495,
      "grad_norm": 0.05955025926232338,
      "learning_rate": 2.7317120123203288e-05,
      "loss": 0.0009,
      "step": 35350
    },
    {
      "epoch": 2.271560574948665,
      "grad_norm": 0.1005823016166687,
      "learning_rate": 2.728503593429158e-05,
      "loss": 0.0009,
      "step": 35400
    },
    {
      "epoch": 2.2747689938398357,
      "grad_norm": 0.11754447966814041,
      "learning_rate": 2.725295174537988e-05,
      "loss": 0.0009,
      "step": 35450
    },
    {
      "epoch": 2.277977412731006,
      "grad_norm": 0.04774200916290283,
      "learning_rate": 2.7220867556468173e-05,
      "loss": 0.0009,
      "step": 35500
    },
    {
      "epoch": 2.2811858316221767,
      "grad_norm": 0.13628113269805908,
      "learning_rate": 2.718878336755647e-05,
      "loss": 0.001,
      "step": 35550
    },
    {
      "epoch": 2.284394250513347,
      "grad_norm": 0.023171113803982735,
      "learning_rate": 2.715669917864477e-05,
      "loss": 0.0009,
      "step": 35600
    },
    {
      "epoch": 2.2876026694045173,
      "grad_norm": 0.013542582280933857,
      "learning_rate": 2.712461498973306e-05,
      "loss": 0.0009,
      "step": 35650
    },
    {
      "epoch": 2.290811088295688,
      "grad_norm": 0.12943758070468903,
      "learning_rate": 2.7092530800821358e-05,
      "loss": 0.0009,
      "step": 35700
    },
    {
      "epoch": 2.2940195071868583,
      "grad_norm": 0.08822484314441681,
      "learning_rate": 2.706044661190965e-05,
      "loss": 0.0009,
      "step": 35750
    },
    {
      "epoch": 2.297227926078029,
      "grad_norm": 0.04485367611050606,
      "learning_rate": 2.702836242299795e-05,
      "loss": 0.0009,
      "step": 35800
    },
    {
      "epoch": 2.3004363449691994,
      "grad_norm": 0.06191490218043327,
      "learning_rate": 2.6996278234086243e-05,
      "loss": 0.001,
      "step": 35850
    },
    {
      "epoch": 2.3036447638603694,
      "grad_norm": 0.06422478705644608,
      "learning_rate": 2.696419404517454e-05,
      "loss": 0.0009,
      "step": 35900
    },
    {
      "epoch": 2.30685318275154,
      "grad_norm": 0.06529486924409866,
      "learning_rate": 2.6932109856262832e-05,
      "loss": 0.0009,
      "step": 35950
    },
    {
      "epoch": 2.3100616016427105,
      "grad_norm": 0.025672756135463715,
      "learning_rate": 2.690002566735113e-05,
      "loss": 0.0009,
      "step": 36000
    },
    {
      "epoch": 2.313270020533881,
      "grad_norm": 0.03813798353075981,
      "learning_rate": 2.6867941478439428e-05,
      "loss": 0.0009,
      "step": 36050
    },
    {
      "epoch": 2.3164784394250515,
      "grad_norm": 0.012461565434932709,
      "learning_rate": 2.683585728952772e-05,
      "loss": 0.0009,
      "step": 36100
    },
    {
      "epoch": 2.3196868583162216,
      "grad_norm": 0.028857406228780746,
      "learning_rate": 2.680377310061602e-05,
      "loss": 0.001,
      "step": 36150
    },
    {
      "epoch": 2.322895277207392,
      "grad_norm": 0.0866895541548729,
      "learning_rate": 2.6771688911704313e-05,
      "loss": 0.0009,
      "step": 36200
    },
    {
      "epoch": 2.3261036960985626,
      "grad_norm": 0.03843720257282257,
      "learning_rate": 2.673960472279261e-05,
      "loss": 0.001,
      "step": 36250
    },
    {
      "epoch": 2.329312114989733,
      "grad_norm": 0.08324768394231796,
      "learning_rate": 2.6707520533880902e-05,
      "loss": 0.0009,
      "step": 36300
    },
    {
      "epoch": 2.3325205338809036,
      "grad_norm": 0.023989718407392502,
      "learning_rate": 2.66754363449692e-05,
      "loss": 0.0009,
      "step": 36350
    },
    {
      "epoch": 2.335728952772074,
      "grad_norm": 0.030572758987545967,
      "learning_rate": 2.6643352156057494e-05,
      "loss": 0.0009,
      "step": 36400
    },
    {
      "epoch": 2.3389373716632442,
      "grad_norm": 0.057621605694293976,
      "learning_rate": 2.661126796714579e-05,
      "loss": 0.0009,
      "step": 36450
    },
    {
      "epoch": 2.3421457905544147,
      "grad_norm": 0.1106317788362503,
      "learning_rate": 2.657918377823409e-05,
      "loss": 0.0009,
      "step": 36500
    },
    {
      "epoch": 2.3453542094455853,
      "grad_norm": 0.03137015551328659,
      "learning_rate": 2.6547099589322383e-05,
      "loss": 0.0009,
      "step": 36550
    },
    {
      "epoch": 2.3485626283367558,
      "grad_norm": 0.08140770345926285,
      "learning_rate": 2.6515015400410682e-05,
      "loss": 0.0009,
      "step": 36600
    },
    {
      "epoch": 2.351771047227926,
      "grad_norm": 0.045440204441547394,
      "learning_rate": 2.6482931211498975e-05,
      "loss": 0.0009,
      "step": 36650
    },
    {
      "epoch": 2.3549794661190964,
      "grad_norm": 0.05881787836551666,
      "learning_rate": 2.645084702258727e-05,
      "loss": 0.0009,
      "step": 36700
    },
    {
      "epoch": 2.358187885010267,
      "grad_norm": 0.08150637149810791,
      "learning_rate": 2.6418762833675564e-05,
      "loss": 0.001,
      "step": 36750
    },
    {
      "epoch": 2.3613963039014374,
      "grad_norm": 0.022936202585697174,
      "learning_rate": 2.6386678644763864e-05,
      "loss": 0.0009,
      "step": 36800
    },
    {
      "epoch": 2.364604722792608,
      "grad_norm": 0.06841915100812912,
      "learning_rate": 2.6354594455852157e-05,
      "loss": 0.0009,
      "step": 36850
    },
    {
      "epoch": 2.3678131416837784,
      "grad_norm": 0.11879424005746841,
      "learning_rate": 2.6322510266940453e-05,
      "loss": 0.0009,
      "step": 36900
    },
    {
      "epoch": 2.3710215605749485,
      "grad_norm": 0.05219737067818642,
      "learning_rate": 2.6290426078028752e-05,
      "loss": 0.0009,
      "step": 36950
    },
    {
      "epoch": 2.374229979466119,
      "grad_norm": 0.021399566903710365,
      "learning_rate": 2.6258341889117045e-05,
      "loss": 0.0009,
      "step": 37000
    },
    {
      "epoch": 2.3774383983572895,
      "grad_norm": 0.06981383264064789,
      "learning_rate": 2.622625770020534e-05,
      "loss": 0.0009,
      "step": 37050
    },
    {
      "epoch": 2.38064681724846,
      "grad_norm": 0.07811881601810455,
      "learning_rate": 2.6194173511293634e-05,
      "loss": 0.0009,
      "step": 37100
    },
    {
      "epoch": 2.3838552361396306,
      "grad_norm": 0.0250419769436121,
      "learning_rate": 2.6162089322381934e-05,
      "loss": 0.001,
      "step": 37150
    },
    {
      "epoch": 2.3870636550308006,
      "grad_norm": 0.11497806012630463,
      "learning_rate": 2.6130005133470227e-05,
      "loss": 0.0009,
      "step": 37200
    },
    {
      "epoch": 2.390272073921971,
      "grad_norm": 0.05186355859041214,
      "learning_rate": 2.6097920944558523e-05,
      "loss": 0.0009,
      "step": 37250
    },
    {
      "epoch": 2.3934804928131417,
      "grad_norm": 0.13832971453666687,
      "learning_rate": 2.6065836755646816e-05,
      "loss": 0.0009,
      "step": 37300
    },
    {
      "epoch": 2.396688911704312,
      "grad_norm": 0.03466662019491196,
      "learning_rate": 2.6033752566735115e-05,
      "loss": 0.0009,
      "step": 37350
    },
    {
      "epoch": 2.3998973305954827,
      "grad_norm": 0.043304458260536194,
      "learning_rate": 2.6001668377823408e-05,
      "loss": 0.0009,
      "step": 37400
    },
    {
      "epoch": 2.403105749486653,
      "grad_norm": 0.07650872319936752,
      "learning_rate": 2.5969584188911704e-05,
      "loss": 0.0009,
      "step": 37450
    },
    {
      "epoch": 2.4063141683778233,
      "grad_norm": 0.044494546949863434,
      "learning_rate": 2.5937500000000004e-05,
      "loss": 0.0009,
      "step": 37500
    },
    {
      "epoch": 2.409522587268994,
      "grad_norm": 0.07573822885751724,
      "learning_rate": 2.5905415811088296e-05,
      "loss": 0.0009,
      "step": 37550
    },
    {
      "epoch": 2.4127310061601643,
      "grad_norm": 0.03629891946911812,
      "learning_rate": 2.5873331622176593e-05,
      "loss": 0.0009,
      "step": 37600
    },
    {
      "epoch": 2.415939425051335,
      "grad_norm": 0.0640764832496643,
      "learning_rate": 2.5841247433264885e-05,
      "loss": 0.0009,
      "step": 37650
    },
    {
      "epoch": 2.419147843942505,
      "grad_norm": 0.07556869089603424,
      "learning_rate": 2.5809163244353185e-05,
      "loss": 0.0009,
      "step": 37700
    },
    {
      "epoch": 2.4223562628336754,
      "grad_norm": 0.11393433064222336,
      "learning_rate": 2.5777079055441478e-05,
      "loss": 0.0009,
      "step": 37750
    },
    {
      "epoch": 2.425564681724846,
      "grad_norm": 0.13391095399856567,
      "learning_rate": 2.5744994866529777e-05,
      "loss": 0.0009,
      "step": 37800
    },
    {
      "epoch": 2.4287731006160165,
      "grad_norm": 0.06634584069252014,
      "learning_rate": 2.5712910677618067e-05,
      "loss": 0.0009,
      "step": 37850
    },
    {
      "epoch": 2.431981519507187,
      "grad_norm": 0.07280123233795166,
      "learning_rate": 2.5680826488706366e-05,
      "loss": 0.0009,
      "step": 37900
    },
    {
      "epoch": 2.4351899383983575,
      "grad_norm": 0.0586373507976532,
      "learning_rate": 2.5648742299794666e-05,
      "loss": 0.0009,
      "step": 37950
    },
    {
      "epoch": 2.4383983572895276,
      "grad_norm": 0.08636360615491867,
      "learning_rate": 2.561665811088296e-05,
      "loss": 0.0009,
      "step": 38000
    },
    {
      "epoch": 2.441606776180698,
      "grad_norm": 0.04785788804292679,
      "learning_rate": 2.5584573921971255e-05,
      "loss": 0.0009,
      "step": 38050
    },
    {
      "epoch": 2.4448151950718686,
      "grad_norm": 0.05593344196677208,
      "learning_rate": 2.5552489733059548e-05,
      "loss": 0.0009,
      "step": 38100
    },
    {
      "epoch": 2.448023613963039,
      "grad_norm": 0.09882433712482452,
      "learning_rate": 2.5520405544147847e-05,
      "loss": 0.0009,
      "step": 38150
    },
    {
      "epoch": 2.451232032854209,
      "grad_norm": 0.034315332770347595,
      "learning_rate": 2.548832135523614e-05,
      "loss": 0.0009,
      "step": 38200
    },
    {
      "epoch": 2.4544404517453797,
      "grad_norm": 0.05931740626692772,
      "learning_rate": 2.5456237166324436e-05,
      "loss": 0.0009,
      "step": 38250
    },
    {
      "epoch": 2.4576488706365502,
      "grad_norm": 0.08853869140148163,
      "learning_rate": 2.542415297741273e-05,
      "loss": 0.0009,
      "step": 38300
    },
    {
      "epoch": 2.4608572895277208,
      "grad_norm": 0.06529378890991211,
      "learning_rate": 2.539206878850103e-05,
      "loss": 0.0009,
      "step": 38350
    },
    {
      "epoch": 2.4640657084188913,
      "grad_norm": 0.10534553229808807,
      "learning_rate": 2.5359984599589325e-05,
      "loss": 0.0009,
      "step": 38400
    },
    {
      "epoch": 2.467274127310062,
      "grad_norm": 0.10519200563430786,
      "learning_rate": 2.5327900410677618e-05,
      "loss": 0.0009,
      "step": 38450
    },
    {
      "epoch": 2.470482546201232,
      "grad_norm": 0.0814283937215805,
      "learning_rate": 2.5295816221765917e-05,
      "loss": 0.0009,
      "step": 38500
    },
    {
      "epoch": 2.4736909650924024,
      "grad_norm": 0.10020610690116882,
      "learning_rate": 2.526373203285421e-05,
      "loss": 0.0009,
      "step": 38550
    },
    {
      "epoch": 2.476899383983573,
      "grad_norm": 0.07390487194061279,
      "learning_rate": 2.5231647843942506e-05,
      "loss": 0.0009,
      "step": 38600
    },
    {
      "epoch": 2.4801078028747434,
      "grad_norm": 0.06141439825296402,
      "learning_rate": 2.51995636550308e-05,
      "loss": 0.0009,
      "step": 38650
    },
    {
      "epoch": 2.483316221765914,
      "grad_norm": 0.04969970881938934,
      "learning_rate": 2.51674794661191e-05,
      "loss": 0.0009,
      "step": 38700
    },
    {
      "epoch": 2.486524640657084,
      "grad_norm": 0.04501871392130852,
      "learning_rate": 2.513539527720739e-05,
      "loss": 0.0009,
      "step": 38750
    },
    {
      "epoch": 2.4897330595482545,
      "grad_norm": 0.03724281117320061,
      "learning_rate": 2.5103311088295688e-05,
      "loss": 0.0009,
      "step": 38800
    },
    {
      "epoch": 2.492941478439425,
      "grad_norm": 0.04285622015595436,
      "learning_rate": 2.5071226899383987e-05,
      "loss": 0.0009,
      "step": 38850
    },
    {
      "epoch": 2.4961498973305956,
      "grad_norm": 0.08167967200279236,
      "learning_rate": 2.503914271047228e-05,
      "loss": 0.001,
      "step": 38900
    },
    {
      "epoch": 2.499358316221766,
      "grad_norm": 0.12101960927248001,
      "learning_rate": 2.500705852156058e-05,
      "loss": 0.0009,
      "step": 38950
    },
    {
      "epoch": 2.5025667351129366,
      "grad_norm": 0.09944168478250504,
      "learning_rate": 2.497497433264887e-05,
      "loss": 0.0009,
      "step": 39000
    },
    {
      "epoch": 2.5057751540041067,
      "grad_norm": 0.09616735577583313,
      "learning_rate": 2.494289014373717e-05,
      "loss": 0.0009,
      "step": 39050
    },
    {
      "epoch": 2.508983572895277,
      "grad_norm": 0.022667119279503822,
      "learning_rate": 2.4910805954825465e-05,
      "loss": 0.0009,
      "step": 39100
    },
    {
      "epoch": 2.5121919917864477,
      "grad_norm": 0.046068210154771805,
      "learning_rate": 2.487872176591376e-05,
      "loss": 0.0009,
      "step": 39150
    },
    {
      "epoch": 2.515400410677618,
      "grad_norm": 0.06600017100572586,
      "learning_rate": 2.4846637577002054e-05,
      "loss": 0.0009,
      "step": 39200
    },
    {
      "epoch": 2.5186088295687883,
      "grad_norm": 0.0908154770731926,
      "learning_rate": 2.481455338809035e-05,
      "loss": 0.0009,
      "step": 39250
    },
    {
      "epoch": 2.521817248459959,
      "grad_norm": 0.05025726184248924,
      "learning_rate": 2.4782469199178646e-05,
      "loss": 0.0009,
      "step": 39300
    },
    {
      "epoch": 2.5250256673511293,
      "grad_norm": 0.09772619605064392,
      "learning_rate": 2.4750385010266942e-05,
      "loss": 0.0009,
      "step": 39350
    },
    {
      "epoch": 2.5282340862423,
      "grad_norm": 0.04766126722097397,
      "learning_rate": 2.4718300821355235e-05,
      "loss": 0.0009,
      "step": 39400
    },
    {
      "epoch": 2.5314425051334704,
      "grad_norm": 0.031345434486866,
      "learning_rate": 2.468621663244353e-05,
      "loss": 0.0009,
      "step": 39450
    },
    {
      "epoch": 2.534650924024641,
      "grad_norm": 0.11566410213708878,
      "learning_rate": 2.465413244353183e-05,
      "loss": 0.0009,
      "step": 39500
    },
    {
      "epoch": 2.537859342915811,
      "grad_norm": 0.039117537438869476,
      "learning_rate": 2.4622048254620124e-05,
      "loss": 0.0009,
      "step": 39550
    },
    {
      "epoch": 2.5410677618069815,
      "grad_norm": 0.10266437381505966,
      "learning_rate": 2.458996406570842e-05,
      "loss": 0.0009,
      "step": 39600
    },
    {
      "epoch": 2.544276180698152,
      "grad_norm": 0.07356993854045868,
      "learning_rate": 2.4557879876796716e-05,
      "loss": 0.0009,
      "step": 39650
    },
    {
      "epoch": 2.5474845995893225,
      "grad_norm": 0.03318957984447479,
      "learning_rate": 2.4525795687885012e-05,
      "loss": 0.0009,
      "step": 39700
    },
    {
      "epoch": 2.5506930184804926,
      "grad_norm": 0.12164606899023056,
      "learning_rate": 2.449371149897331e-05,
      "loss": 0.0009,
      "step": 39750
    },
    {
      "epoch": 2.553901437371663,
      "grad_norm": 0.040908459573984146,
      "learning_rate": 2.44616273100616e-05,
      "loss": 0.0009,
      "step": 39800
    },
    {
      "epoch": 2.5571098562628336,
      "grad_norm": 0.0362248457968235,
      "learning_rate": 2.4429543121149897e-05,
      "loss": 0.0009,
      "step": 39850
    },
    {
      "epoch": 2.560318275154004,
      "grad_norm": 0.03448145091533661,
      "learning_rate": 2.4397458932238194e-05,
      "loss": 0.0009,
      "step": 39900
    },
    {
      "epoch": 2.5635266940451746,
      "grad_norm": 0.031835902482271194,
      "learning_rate": 2.436537474332649e-05,
      "loss": 0.0009,
      "step": 39950
    },
    {
      "epoch": 2.566735112936345,
      "grad_norm": 0.04929116368293762,
      "learning_rate": 2.4333290554414786e-05,
      "loss": 0.0009,
      "step": 40000
    },
    {
      "epoch": 2.5699435318275157,
      "grad_norm": 0.08658131957054138,
      "learning_rate": 2.4301206365503082e-05,
      "loss": 0.0009,
      "step": 40050
    },
    {
      "epoch": 2.5731519507186857,
      "grad_norm": 0.06387851387262344,
      "learning_rate": 2.426912217659138e-05,
      "loss": 0.0009,
      "step": 40100
    },
    {
      "epoch": 2.5763603696098563,
      "grad_norm": 0.07923609763383865,
      "learning_rate": 2.423703798767967e-05,
      "loss": 0.0009,
      "step": 40150
    },
    {
      "epoch": 2.5795687885010268,
      "grad_norm": 0.06378103047609329,
      "learning_rate": 2.4204953798767967e-05,
      "loss": 0.0009,
      "step": 40200
    },
    {
      "epoch": 2.582777207392197,
      "grad_norm": 0.05161350965499878,
      "learning_rate": 2.4172869609856264e-05,
      "loss": 0.0009,
      "step": 40250
    },
    {
      "epoch": 2.5859856262833674,
      "grad_norm": 0.10682045668363571,
      "learning_rate": 2.414078542094456e-05,
      "loss": 0.0009,
      "step": 40300
    },
    {
      "epoch": 2.589194045174538,
      "grad_norm": 0.032691486179828644,
      "learning_rate": 2.4108701232032856e-05,
      "loss": 0.0009,
      "step": 40350
    },
    {
      "epoch": 2.5924024640657084,
      "grad_norm": 0.07276654243469238,
      "learning_rate": 2.4076617043121152e-05,
      "loss": 0.0009,
      "step": 40400
    },
    {
      "epoch": 2.595610882956879,
      "grad_norm": 0.0930527001619339,
      "learning_rate": 2.4044532854209448e-05,
      "loss": 0.0009,
      "step": 40450
    },
    {
      "epoch": 2.5988193018480494,
      "grad_norm": 0.07360624521970749,
      "learning_rate": 2.4012448665297744e-05,
      "loss": 0.0009,
      "step": 40500
    },
    {
      "epoch": 2.60202772073922,
      "grad_norm": 0.030777957290410995,
      "learning_rate": 2.3980364476386037e-05,
      "loss": 0.0009,
      "step": 40550
    },
    {
      "epoch": 2.60523613963039,
      "grad_norm": 0.09277636557817459,
      "learning_rate": 2.3948280287474333e-05,
      "loss": 0.0009,
      "step": 40600
    },
    {
      "epoch": 2.6084445585215605,
      "grad_norm": 0.04470011591911316,
      "learning_rate": 2.391619609856263e-05,
      "loss": 0.0009,
      "step": 40650
    },
    {
      "epoch": 2.611652977412731,
      "grad_norm": 0.020305152982473373,
      "learning_rate": 2.3884111909650926e-05,
      "loss": 0.0009,
      "step": 40700
    },
    {
      "epoch": 2.6148613963039016,
      "grad_norm": 0.016191497445106506,
      "learning_rate": 2.385202772073922e-05,
      "loss": 0.0009,
      "step": 40750
    },
    {
      "epoch": 2.6180698151950716,
      "grad_norm": 0.02924431674182415,
      "learning_rate": 2.3819943531827515e-05,
      "loss": 0.0009,
      "step": 40800
    },
    {
      "epoch": 2.621278234086242,
      "grad_norm": 0.10903187841176987,
      "learning_rate": 2.378785934291581e-05,
      "loss": 0.0009,
      "step": 40850
    },
    {
      "epoch": 2.6244866529774127,
      "grad_norm": 0.03713017702102661,
      "learning_rate": 2.375577515400411e-05,
      "loss": 0.0009,
      "step": 40900
    },
    {
      "epoch": 2.627695071868583,
      "grad_norm": 0.018118422478437424,
      "learning_rate": 2.3723690965092403e-05,
      "loss": 0.0009,
      "step": 40950
    },
    {
      "epoch": 2.6309034907597537,
      "grad_norm": 0.0281079038977623,
      "learning_rate": 2.36916067761807e-05,
      "loss": 0.0009,
      "step": 41000
    },
    {
      "epoch": 2.6341119096509242,
      "grad_norm": 0.07224228233098984,
      "learning_rate": 2.3659522587268996e-05,
      "loss": 0.0009,
      "step": 41050
    },
    {
      "epoch": 2.6373203285420943,
      "grad_norm": 0.07221095263957977,
      "learning_rate": 2.3627438398357292e-05,
      "loss": 0.0009,
      "step": 41100
    },
    {
      "epoch": 2.640528747433265,
      "grad_norm": 0.03994189202785492,
      "learning_rate": 2.3595354209445585e-05,
      "loss": 0.0009,
      "step": 41150
    },
    {
      "epoch": 2.6437371663244353,
      "grad_norm": 0.02564827911555767,
      "learning_rate": 2.356327002053388e-05,
      "loss": 0.0009,
      "step": 41200
    },
    {
      "epoch": 2.646945585215606,
      "grad_norm": 0.046308718621730804,
      "learning_rate": 2.3531185831622177e-05,
      "loss": 0.0009,
      "step": 41250
    },
    {
      "epoch": 2.650154004106776,
      "grad_norm": 0.07001965492963791,
      "learning_rate": 2.3499101642710473e-05,
      "loss": 0.0009,
      "step": 41300
    },
    {
      "epoch": 2.6533624229979464,
      "grad_norm": 0.04219163954257965,
      "learning_rate": 2.346701745379877e-05,
      "loss": 0.0009,
      "step": 41350
    },
    {
      "epoch": 2.656570841889117,
      "grad_norm": 0.08360666781663895,
      "learning_rate": 2.3434933264887066e-05,
      "loss": 0.0009,
      "step": 41400
    },
    {
      "epoch": 2.6597792607802875,
      "grad_norm": 0.09521681070327759,
      "learning_rate": 2.3402849075975362e-05,
      "loss": 0.0009,
      "step": 41450
    },
    {
      "epoch": 2.662987679671458,
      "grad_norm": 0.009036567062139511,
      "learning_rate": 2.3370764887063658e-05,
      "loss": 0.0009,
      "step": 41500
    },
    {
      "epoch": 2.6661960985626285,
      "grad_norm": 0.09660454839468002,
      "learning_rate": 2.333868069815195e-05,
      "loss": 0.0009,
      "step": 41550
    },
    {
      "epoch": 2.669404517453799,
      "grad_norm": 0.10294130444526672,
      "learning_rate": 2.3306596509240247e-05,
      "loss": 0.0009,
      "step": 41600
    },
    {
      "epoch": 2.672612936344969,
      "grad_norm": 0.03815614432096481,
      "learning_rate": 2.3274512320328543e-05,
      "loss": 0.0009,
      "step": 41650
    },
    {
      "epoch": 2.6758213552361396,
      "grad_norm": 0.09297539293766022,
      "learning_rate": 2.324242813141684e-05,
      "loss": 0.0009,
      "step": 41700
    },
    {
      "epoch": 2.67902977412731,
      "grad_norm": 0.042758792638778687,
      "learning_rate": 2.3210343942505132e-05,
      "loss": 0.0009,
      "step": 41750
    },
    {
      "epoch": 2.6822381930184807,
      "grad_norm": 0.06302428990602493,
      "learning_rate": 2.3178259753593432e-05,
      "loss": 0.0009,
      "step": 41800
    },
    {
      "epoch": 2.6854466119096507,
      "grad_norm": 0.07590635865926743,
      "learning_rate": 2.3146175564681728e-05,
      "loss": 0.0009,
      "step": 41850
    },
    {
      "epoch": 2.6886550308008212,
      "grad_norm": 0.029881000518798828,
      "learning_rate": 2.311409137577002e-05,
      "loss": 0.0009,
      "step": 41900
    },
    {
      "epoch": 2.6918634496919918,
      "grad_norm": 0.03253621608018875,
      "learning_rate": 2.3082007186858317e-05,
      "loss": 0.0009,
      "step": 41950
    },
    {
      "epoch": 2.6950718685831623,
      "grad_norm": 0.06022987514734268,
      "learning_rate": 2.3049922997946613e-05,
      "loss": 0.0009,
      "step": 42000
    },
    {
      "epoch": 2.698280287474333,
      "grad_norm": 0.07788808643817902,
      "learning_rate": 2.301783880903491e-05,
      "loss": 0.0009,
      "step": 42050
    },
    {
      "epoch": 2.7014887063655033,
      "grad_norm": 0.04816928133368492,
      "learning_rate": 2.2985754620123202e-05,
      "loss": 0.0009,
      "step": 42100
    },
    {
      "epoch": 2.7046971252566734,
      "grad_norm": 0.06489770859479904,
      "learning_rate": 2.29536704312115e-05,
      "loss": 0.0009,
      "step": 42150
    },
    {
      "epoch": 2.707905544147844,
      "grad_norm": 0.13202665746212006,
      "learning_rate": 2.2921586242299795e-05,
      "loss": 0.0009,
      "step": 42200
    },
    {
      "epoch": 2.7111139630390144,
      "grad_norm": 0.10011109709739685,
      "learning_rate": 2.2889502053388094e-05,
      "loss": 0.0009,
      "step": 42250
    },
    {
      "epoch": 2.714322381930185,
      "grad_norm": 0.15219473838806152,
      "learning_rate": 2.2857417864476387e-05,
      "loss": 0.0009,
      "step": 42300
    },
    {
      "epoch": 2.717530800821355,
      "grad_norm": 0.03183925151824951,
      "learning_rate": 2.2825333675564683e-05,
      "loss": 0.0009,
      "step": 42350
    },
    {
      "epoch": 2.7207392197125255,
      "grad_norm": 0.01990925520658493,
      "learning_rate": 2.279324948665298e-05,
      "loss": 0.0009,
      "step": 42400
    },
    {
      "epoch": 2.723947638603696,
      "grad_norm": 0.030010757967829704,
      "learning_rate": 2.2761165297741275e-05,
      "loss": 0.0009,
      "step": 42450
    },
    {
      "epoch": 2.7271560574948666,
      "grad_norm": 0.02867395058274269,
      "learning_rate": 2.2729081108829568e-05,
      "loss": 0.0009,
      "step": 42500
    },
    {
      "epoch": 2.730364476386037,
      "grad_norm": 0.07600335031747818,
      "learning_rate": 2.2696996919917864e-05,
      "loss": 0.0009,
      "step": 42550
    },
    {
      "epoch": 2.7335728952772076,
      "grad_norm": 0.055737849324941635,
      "learning_rate": 2.266491273100616e-05,
      "loss": 0.0009,
      "step": 42600
    },
    {
      "epoch": 2.7367813141683777,
      "grad_norm": 0.04179960861802101,
      "learning_rate": 2.2632828542094457e-05,
      "loss": 0.0009,
      "step": 42650
    },
    {
      "epoch": 2.739989733059548,
      "grad_norm": 0.05973958596587181,
      "learning_rate": 2.2600744353182753e-05,
      "loss": 0.0009,
      "step": 42700
    },
    {
      "epoch": 2.7431981519507187,
      "grad_norm": 0.06965889781713486,
      "learning_rate": 2.256866016427105e-05,
      "loss": 0.0009,
      "step": 42750
    },
    {
      "epoch": 2.746406570841889,
      "grad_norm": 0.06251253932714462,
      "learning_rate": 2.2536575975359345e-05,
      "loss": 0.0009,
      "step": 42800
    },
    {
      "epoch": 2.7496149897330593,
      "grad_norm": 0.1331261694431305,
      "learning_rate": 2.250449178644764e-05,
      "loss": 0.0009,
      "step": 42850
    },
    {
      "epoch": 2.75282340862423,
      "grad_norm": 0.06273537874221802,
      "learning_rate": 2.2472407597535934e-05,
      "loss": 0.0009,
      "step": 42900
    },
    {
      "epoch": 2.7560318275154003,
      "grad_norm": 0.05468937009572983,
      "learning_rate": 2.244032340862423e-05,
      "loss": 0.0009,
      "step": 42950
    },
    {
      "epoch": 2.759240246406571,
      "grad_norm": 0.026447053998708725,
      "learning_rate": 2.2408239219712527e-05,
      "loss": 0.0009,
      "step": 43000
    },
    {
      "epoch": 2.7624486652977414,
      "grad_norm": 0.04321771487593651,
      "learning_rate": 2.2376155030800823e-05,
      "loss": 0.0009,
      "step": 43050
    },
    {
      "epoch": 2.765657084188912,
      "grad_norm": 0.15389597415924072,
      "learning_rate": 2.2344070841889116e-05,
      "loss": 0.0009,
      "step": 43100
    },
    {
      "epoch": 2.7688655030800824,
      "grad_norm": 0.052137795835733414,
      "learning_rate": 2.2311986652977412e-05,
      "loss": 0.0009,
      "step": 43150
    },
    {
      "epoch": 2.7720739219712525,
      "grad_norm": 0.0769868716597557,
      "learning_rate": 2.227990246406571e-05,
      "loss": 0.0009,
      "step": 43200
    },
    {
      "epoch": 2.775282340862423,
      "grad_norm": 0.12256210297346115,
      "learning_rate": 2.2247818275154004e-05,
      "loss": 0.0009,
      "step": 43250
    },
    {
      "epoch": 2.7784907597535935,
      "grad_norm": 0.04994862899184227,
      "learning_rate": 2.22157340862423e-05,
      "loss": 0.0009,
      "step": 43300
    },
    {
      "epoch": 2.781699178644764,
      "grad_norm": 0.09016033262014389,
      "learning_rate": 2.2183649897330597e-05,
      "loss": 0.0009,
      "step": 43350
    },
    {
      "epoch": 2.784907597535934,
      "grad_norm": 0.04834204912185669,
      "learning_rate": 2.2151565708418893e-05,
      "loss": 0.0009,
      "step": 43400
    },
    {
      "epoch": 2.7881160164271046,
      "grad_norm": 0.11119243502616882,
      "learning_rate": 2.211948151950719e-05,
      "loss": 0.0009,
      "step": 43450
    },
    {
      "epoch": 2.791324435318275,
      "grad_norm": 0.031299419701099396,
      "learning_rate": 2.2087397330595482e-05,
      "loss": 0.0009,
      "step": 43500
    },
    {
      "epoch": 2.7945328542094456,
      "grad_norm": 0.11867103725671768,
      "learning_rate": 2.2055313141683778e-05,
      "loss": 0.0009,
      "step": 43550
    },
    {
      "epoch": 2.797741273100616,
      "grad_norm": 0.029057802632451057,
      "learning_rate": 2.2023228952772074e-05,
      "loss": 0.0009,
      "step": 43600
    },
    {
      "epoch": 2.8009496919917867,
      "grad_norm": 0.04462973400950432,
      "learning_rate": 2.199114476386037e-05,
      "loss": 0.0009,
      "step": 43650
    },
    {
      "epoch": 2.8041581108829567,
      "grad_norm": 0.06413118541240692,
      "learning_rate": 2.1959060574948667e-05,
      "loss": 0.0009,
      "step": 43700
    },
    {
      "epoch": 2.8073665297741273,
      "grad_norm": 0.03305621072649956,
      "learning_rate": 2.1926976386036963e-05,
      "loss": 0.0009,
      "step": 43750
    },
    {
      "epoch": 2.810574948665298,
      "grad_norm": 0.034625738859176636,
      "learning_rate": 2.189489219712526e-05,
      "loss": 0.0009,
      "step": 43800
    },
    {
      "epoch": 2.8137833675564683,
      "grad_norm": 0.01765342988073826,
      "learning_rate": 2.1862808008213552e-05,
      "loss": 0.0009,
      "step": 43850
    },
    {
      "epoch": 2.8169917864476384,
      "grad_norm": 0.060173001140356064,
      "learning_rate": 2.1830723819301848e-05,
      "loss": 0.0009,
      "step": 43900
    },
    {
      "epoch": 2.820200205338809,
      "grad_norm": 0.06533315777778625,
      "learning_rate": 2.1798639630390144e-05,
      "loss": 0.0009,
      "step": 43950
    },
    {
      "epoch": 2.8234086242299794,
      "grad_norm": 0.05231977626681328,
      "learning_rate": 2.176655544147844e-05,
      "loss": 0.0009,
      "step": 44000
    },
    {
      "epoch": 2.82661704312115,
      "grad_norm": 0.06927871704101562,
      "learning_rate": 2.1734471252566737e-05,
      "loss": 0.0009,
      "step": 44050
    },
    {
      "epoch": 2.8298254620123204,
      "grad_norm": 0.17840375006198883,
      "learning_rate": 2.1702387063655033e-05,
      "loss": 0.0009,
      "step": 44100
    },
    {
      "epoch": 2.833033880903491,
      "grad_norm": 0.021725894883275032,
      "learning_rate": 2.167030287474333e-05,
      "loss": 0.0009,
      "step": 44150
    },
    {
      "epoch": 2.836242299794661,
      "grad_norm": 0.11873765289783478,
      "learning_rate": 2.1638218685831625e-05,
      "loss": 0.0009,
      "step": 44200
    },
    {
      "epoch": 2.8394507186858315,
      "grad_norm": 0.065583735704422,
      "learning_rate": 2.1606134496919918e-05,
      "loss": 0.0009,
      "step": 44250
    },
    {
      "epoch": 2.842659137577002,
      "grad_norm": 0.05908234789967537,
      "learning_rate": 2.1574050308008214e-05,
      "loss": 0.0009,
      "step": 44300
    },
    {
      "epoch": 2.8458675564681726,
      "grad_norm": 0.024816378951072693,
      "learning_rate": 2.154196611909651e-05,
      "loss": 0.0009,
      "step": 44350
    },
    {
      "epoch": 2.8490759753593426,
      "grad_norm": 0.05993859842419624,
      "learning_rate": 2.1509881930184806e-05,
      "loss": 0.0009,
      "step": 44400
    },
    {
      "epoch": 2.852284394250513,
      "grad_norm": 0.0399426631629467,
      "learning_rate": 2.14777977412731e-05,
      "loss": 0.0009,
      "step": 44450
    },
    {
      "epoch": 2.8554928131416837,
      "grad_norm": 0.07468732446432114,
      "learning_rate": 2.1445713552361395e-05,
      "loss": 0.0009,
      "step": 44500
    },
    {
      "epoch": 2.858701232032854,
      "grad_norm": 0.09192996472120285,
      "learning_rate": 2.1413629363449695e-05,
      "loss": 0.0009,
      "step": 44550
    },
    {
      "epoch": 2.8619096509240247,
      "grad_norm": 0.0495128408074379,
      "learning_rate": 2.138154517453799e-05,
      "loss": 0.0009,
      "step": 44600
    },
    {
      "epoch": 2.8651180698151952,
      "grad_norm": 0.06337232887744904,
      "learning_rate": 2.1349460985626284e-05,
      "loss": 0.0009,
      "step": 44650
    },
    {
      "epoch": 2.8683264887063658,
      "grad_norm": 0.05981282517313957,
      "learning_rate": 2.131737679671458e-05,
      "loss": 0.0009,
      "step": 44700
    },
    {
      "epoch": 2.871534907597536,
      "grad_norm": 0.03887997940182686,
      "learning_rate": 2.1285292607802876e-05,
      "loss": 0.0009,
      "step": 44750
    },
    {
      "epoch": 2.8747433264887063,
      "grad_norm": 0.016085008159279823,
      "learning_rate": 2.1253208418891173e-05,
      "loss": 0.0009,
      "step": 44800
    },
    {
      "epoch": 2.877951745379877,
      "grad_norm": 0.03912540525197983,
      "learning_rate": 2.1221124229979465e-05,
      "loss": 0.0009,
      "step": 44850
    },
    {
      "epoch": 2.8811601642710474,
      "grad_norm": 0.11207683384418488,
      "learning_rate": 2.118904004106776e-05,
      "loss": 0.0009,
      "step": 44900
    },
    {
      "epoch": 2.8843685831622174,
      "grad_norm": 0.04128711298108101,
      "learning_rate": 2.1156955852156058e-05,
      "loss": 0.0009,
      "step": 44950
    },
    {
      "epoch": 2.887577002053388,
      "grad_norm": 0.0683392584323883,
      "learning_rate": 2.1124871663244354e-05,
      "loss": 0.0009,
      "step": 45000
    },
    {
      "epoch": 2.8907854209445585,
      "grad_norm": 0.06593579798936844,
      "learning_rate": 2.109278747433265e-05,
      "loss": 0.0009,
      "step": 45050
    },
    {
      "epoch": 2.893993839835729,
      "grad_norm": 0.06153196096420288,
      "learning_rate": 2.1060703285420946e-05,
      "loss": 0.0009,
      "step": 45100
    },
    {
      "epoch": 2.8972022587268995,
      "grad_norm": 0.12436388432979584,
      "learning_rate": 2.1028619096509243e-05,
      "loss": 0.0009,
      "step": 45150
    },
    {
      "epoch": 2.90041067761807,
      "grad_norm": 0.0843643993139267,
      "learning_rate": 2.099653490759754e-05,
      "loss": 0.0009,
      "step": 45200
    },
    {
      "epoch": 2.90361909650924,
      "grad_norm": 0.06813978403806686,
      "learning_rate": 2.096445071868583e-05,
      "loss": 0.0009,
      "step": 45250
    },
    {
      "epoch": 2.9068275154004106,
      "grad_norm": 0.039602600038051605,
      "learning_rate": 2.0932366529774128e-05,
      "loss": 0.0009,
      "step": 45300
    },
    {
      "epoch": 2.910035934291581,
      "grad_norm": 0.15353290736675262,
      "learning_rate": 2.0900282340862424e-05,
      "loss": 0.0009,
      "step": 45350
    },
    {
      "epoch": 2.9132443531827517,
      "grad_norm": 0.05118761956691742,
      "learning_rate": 2.086819815195072e-05,
      "loss": 0.0009,
      "step": 45400
    },
    {
      "epoch": 2.9164527720739217,
      "grad_norm": 0.060128748416900635,
      "learning_rate": 2.0836113963039016e-05,
      "loss": 0.0009,
      "step": 45450
    },
    {
      "epoch": 2.9196611909650922,
      "grad_norm": 0.041850946843624115,
      "learning_rate": 2.0804029774127312e-05,
      "loss": 0.0009,
      "step": 45500
    },
    {
      "epoch": 2.9228696098562628,
      "grad_norm": 0.036358803510665894,
      "learning_rate": 2.077194558521561e-05,
      "loss": 0.0009,
      "step": 45550
    },
    {
      "epoch": 2.9260780287474333,
      "grad_norm": 0.021358484402298927,
      "learning_rate": 2.07398613963039e-05,
      "loss": 0.0009,
      "step": 45600
    },
    {
      "epoch": 2.929286447638604,
      "grad_norm": 0.05953555926680565,
      "learning_rate": 2.0707777207392198e-05,
      "loss": 0.0009,
      "step": 45650
    },
    {
      "epoch": 2.9324948665297743,
      "grad_norm": 0.06058638542890549,
      "learning_rate": 2.0675693018480494e-05,
      "loss": 0.0009,
      "step": 45700
    },
    {
      "epoch": 2.935703285420945,
      "grad_norm": 0.032201945781707764,
      "learning_rate": 2.064360882956879e-05,
      "loss": 0.0009,
      "step": 45750
    },
    {
      "epoch": 2.938911704312115,
      "grad_norm": 0.15369060635566711,
      "learning_rate": 2.0611524640657083e-05,
      "loss": 0.0009,
      "step": 45800
    },
    {
      "epoch": 2.9421201232032854,
      "grad_norm": 0.07086700946092606,
      "learning_rate": 2.057944045174538e-05,
      "loss": 0.0009,
      "step": 45850
    },
    {
      "epoch": 2.945328542094456,
      "grad_norm": 0.06143349036574364,
      "learning_rate": 2.0547356262833675e-05,
      "loss": 0.0009,
      "step": 45900
    },
    {
      "epoch": 2.948536960985626,
      "grad_norm": 0.11614472419023514,
      "learning_rate": 2.0515272073921975e-05,
      "loss": 0.0009,
      "step": 45950
    },
    {
      "epoch": 2.9517453798767965,
      "grad_norm": 0.04707827791571617,
      "learning_rate": 2.0483187885010268e-05,
      "loss": 0.0009,
      "step": 46000
    },
    {
      "epoch": 2.954953798767967,
      "grad_norm": 0.0659523457288742,
      "learning_rate": 2.0451103696098564e-05,
      "loss": 0.0009,
      "step": 46050
    },
    {
      "epoch": 2.9581622176591376,
      "grad_norm": 0.06154642254114151,
      "learning_rate": 2.041901950718686e-05,
      "loss": 0.0009,
      "step": 46100
    },
    {
      "epoch": 2.961370636550308,
      "grad_norm": 0.09579675644636154,
      "learning_rate": 2.0386935318275156e-05,
      "loss": 0.0009,
      "step": 46150
    },
    {
      "epoch": 2.9645790554414786,
      "grad_norm": 0.029192648828029633,
      "learning_rate": 2.035485112936345e-05,
      "loss": 0.0009,
      "step": 46200
    },
    {
      "epoch": 2.967787474332649,
      "grad_norm": 0.0973321944475174,
      "learning_rate": 2.0322766940451745e-05,
      "loss": 0.0009,
      "step": 46250
    },
    {
      "epoch": 2.970995893223819,
      "grad_norm": 0.05093850567936897,
      "learning_rate": 2.029068275154004e-05,
      "loss": 0.0009,
      "step": 46300
    },
    {
      "epoch": 2.9742043121149897,
      "grad_norm": 0.10523131489753723,
      "learning_rate": 2.0258598562628337e-05,
      "loss": 0.0009,
      "step": 46350
    },
    {
      "epoch": 2.97741273100616,
      "grad_norm": 0.056694090366363525,
      "learning_rate": 2.0226514373716634e-05,
      "loss": 0.0009,
      "step": 46400
    },
    {
      "epoch": 2.9806211498973307,
      "grad_norm": 0.028984280303120613,
      "learning_rate": 2.019443018480493e-05,
      "loss": 0.0009,
      "step": 46450
    },
    {
      "epoch": 2.983829568788501,
      "grad_norm": 0.05195407196879387,
      "learning_rate": 2.0162345995893226e-05,
      "loss": 0.0009,
      "step": 46500
    },
    {
      "epoch": 2.9870379876796713,
      "grad_norm": 0.056861672550439835,
      "learning_rate": 2.0130261806981522e-05,
      "loss": 0.0009,
      "step": 46550
    },
    {
      "epoch": 2.990246406570842,
      "grad_norm": 0.039776623249053955,
      "learning_rate": 2.0098177618069815e-05,
      "loss": 0.0009,
      "step": 46600
    },
    {
      "epoch": 2.9934548254620124,
      "grad_norm": 0.06936187297105789,
      "learning_rate": 2.006609342915811e-05,
      "loss": 0.0009,
      "step": 46650
    },
    {
      "epoch": 2.996663244353183,
      "grad_norm": 0.06708262860774994,
      "learning_rate": 2.0034009240246407e-05,
      "loss": 0.0009,
      "step": 46700
    },
    {
      "epoch": 2.9998716632443534,
      "grad_norm": 0.07553769648075104,
      "learning_rate": 2.0001925051334704e-05,
      "loss": 0.0009,
      "step": 46750
    },
    {
      "epoch": 3.0030800821355235,
      "grad_norm": 0.059333547949790955,
      "learning_rate": 1.9969840862422996e-05,
      "loss": 0.0009,
      "step": 46800
    },
    {
      "epoch": 3.006288501026694,
      "grad_norm": 0.04977685958147049,
      "learning_rate": 1.9937756673511296e-05,
      "loss": 0.0009,
      "step": 46850
    },
    {
      "epoch": 3.0094969199178645,
      "grad_norm": 0.02985767461359501,
      "learning_rate": 1.9905672484599592e-05,
      "loss": 0.0009,
      "step": 46900
    },
    {
      "epoch": 3.012705338809035,
      "grad_norm": 0.11292660981416702,
      "learning_rate": 1.9873588295687885e-05,
      "loss": 0.0009,
      "step": 46950
    },
    {
      "epoch": 3.0159137577002055,
      "grad_norm": 0.1156749278306961,
      "learning_rate": 1.984150410677618e-05,
      "loss": 0.0009,
      "step": 47000
    },
    {
      "epoch": 3.0191221765913756,
      "grad_norm": 0.0836356058716774,
      "learning_rate": 1.9809419917864477e-05,
      "loss": 0.0009,
      "step": 47050
    },
    {
      "epoch": 3.022330595482546,
      "grad_norm": 0.07168709486722946,
      "learning_rate": 1.9777335728952774e-05,
      "loss": 0.0009,
      "step": 47100
    },
    {
      "epoch": 3.0255390143737166,
      "grad_norm": 0.058681685477495193,
      "learning_rate": 1.974525154004107e-05,
      "loss": 0.0009,
      "step": 47150
    },
    {
      "epoch": 3.028747433264887,
      "grad_norm": 0.024963464587926865,
      "learning_rate": 1.9713167351129363e-05,
      "loss": 0.0009,
      "step": 47200
    },
    {
      "epoch": 3.0319558521560577,
      "grad_norm": 0.11316728591918945,
      "learning_rate": 1.968108316221766e-05,
      "loss": 0.0009,
      "step": 47250
    },
    {
      "epoch": 3.0351642710472277,
      "grad_norm": 0.02788504958152771,
      "learning_rate": 1.9648998973305958e-05,
      "loss": 0.0009,
      "step": 47300
    },
    {
      "epoch": 3.0383726899383983,
      "grad_norm": 0.018160060048103333,
      "learning_rate": 1.961691478439425e-05,
      "loss": 0.0009,
      "step": 47350
    },
    {
      "epoch": 3.041581108829569,
      "grad_norm": 0.05591355264186859,
      "learning_rate": 1.9584830595482547e-05,
      "loss": 0.0009,
      "step": 47400
    },
    {
      "epoch": 3.0447895277207393,
      "grad_norm": 0.07462455332279205,
      "learning_rate": 1.9552746406570843e-05,
      "loss": 0.0009,
      "step": 47450
    },
    {
      "epoch": 3.04799794661191,
      "grad_norm": 0.05288577079772949,
      "learning_rate": 1.952066221765914e-05,
      "loss": 0.0009,
      "step": 47500
    },
    {
      "epoch": 3.05120636550308,
      "grad_norm": 0.07330557703971863,
      "learning_rate": 1.9488578028747432e-05,
      "loss": 0.0009,
      "step": 47550
    },
    {
      "epoch": 3.0544147843942504,
      "grad_norm": 0.07032199949026108,
      "learning_rate": 1.945649383983573e-05,
      "loss": 0.0009,
      "step": 47600
    },
    {
      "epoch": 3.057623203285421,
      "grad_norm": 0.07714729756116867,
      "learning_rate": 1.9424409650924025e-05,
      "loss": 0.0009,
      "step": 47650
    },
    {
      "epoch": 3.0608316221765914,
      "grad_norm": 0.08997556567192078,
      "learning_rate": 1.939232546201232e-05,
      "loss": 0.0009,
      "step": 47700
    },
    {
      "epoch": 3.064040041067762,
      "grad_norm": 0.09194708615541458,
      "learning_rate": 1.9360241273100617e-05,
      "loss": 0.0009,
      "step": 47750
    },
    {
      "epoch": 3.067248459958932,
      "grad_norm": 0.01796880178153515,
      "learning_rate": 1.9328157084188913e-05,
      "loss": 0.0009,
      "step": 47800
    },
    {
      "epoch": 3.0704568788501025,
      "grad_norm": 0.045139241963624954,
      "learning_rate": 1.929607289527721e-05,
      "loss": 0.0009,
      "step": 47850
    },
    {
      "epoch": 3.073665297741273,
      "grad_norm": 0.1197684183716774,
      "learning_rate": 1.9263988706365506e-05,
      "loss": 0.0009,
      "step": 47900
    },
    {
      "epoch": 3.0768737166324436,
      "grad_norm": 0.03698764741420746,
      "learning_rate": 1.92319045174538e-05,
      "loss": 0.0009,
      "step": 47950
    },
    {
      "epoch": 3.080082135523614,
      "grad_norm": 0.11116249859333038,
      "learning_rate": 1.9199820328542095e-05,
      "loss": 0.0009,
      "step": 48000
    },
    {
      "epoch": 3.083290554414784,
      "grad_norm": 0.046100813895463943,
      "learning_rate": 1.916773613963039e-05,
      "loss": 0.0009,
      "step": 48050
    },
    {
      "epoch": 3.0864989733059547,
      "grad_norm": 0.11911222338676453,
      "learning_rate": 1.9135651950718687e-05,
      "loss": 0.0009,
      "step": 48100
    },
    {
      "epoch": 3.089707392197125,
      "grad_norm": 0.07473761588335037,
      "learning_rate": 1.910356776180698e-05,
      "loss": 0.0009,
      "step": 48150
    },
    {
      "epoch": 3.0929158110882957,
      "grad_norm": 0.06837710738182068,
      "learning_rate": 1.9071483572895276e-05,
      "loss": 0.0009,
      "step": 48200
    },
    {
      "epoch": 3.0961242299794662,
      "grad_norm": 0.09935543686151505,
      "learning_rate": 1.9039399383983576e-05,
      "loss": 0.0009,
      "step": 48250
    },
    {
      "epoch": 3.0993326488706368,
      "grad_norm": 0.07685201615095139,
      "learning_rate": 1.9007315195071872e-05,
      "loss": 0.0009,
      "step": 48300
    },
    {
      "epoch": 3.102541067761807,
      "grad_norm": 0.09091180562973022,
      "learning_rate": 1.8975231006160165e-05,
      "loss": 0.0009,
      "step": 48350
    },
    {
      "epoch": 3.1057494866529773,
      "grad_norm": 0.06467148661613464,
      "learning_rate": 1.894314681724846e-05,
      "loss": 0.0009,
      "step": 48400
    },
    {
      "epoch": 3.108957905544148,
      "grad_norm": 0.07406829297542572,
      "learning_rate": 1.8911062628336757e-05,
      "loss": 0.0009,
      "step": 48450
    },
    {
      "epoch": 3.1121663244353184,
      "grad_norm": 0.0799722820520401,
      "learning_rate": 1.8878978439425053e-05,
      "loss": 0.0009,
      "step": 48500
    },
    {
      "epoch": 3.115374743326489,
      "grad_norm": 0.10054382681846619,
      "learning_rate": 1.8846894250513346e-05,
      "loss": 0.0009,
      "step": 48550
    },
    {
      "epoch": 3.118583162217659,
      "grad_norm": 0.09711073338985443,
      "learning_rate": 1.8814810061601642e-05,
      "loss": 0.0009,
      "step": 48600
    },
    {
      "epoch": 3.1217915811088295,
      "grad_norm": 0.056216221302747726,
      "learning_rate": 1.878272587268994e-05,
      "loss": 0.0009,
      "step": 48650
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.03291408717632294,
      "learning_rate": 1.8750641683778235e-05,
      "loss": 0.0009,
      "step": 48700
    },
    {
      "epoch": 3.1282084188911705,
      "grad_norm": 0.15277180075645447,
      "learning_rate": 1.871855749486653e-05,
      "loss": 0.0009,
      "step": 48750
    },
    {
      "epoch": 3.131416837782341,
      "grad_norm": 0.08052012324333191,
      "learning_rate": 1.8686473305954827e-05,
      "loss": 0.0009,
      "step": 48800
    },
    {
      "epoch": 3.134625256673511,
      "grad_norm": 0.07316149771213531,
      "learning_rate": 1.8654389117043123e-05,
      "loss": 0.0009,
      "step": 48850
    },
    {
      "epoch": 3.1378336755646816,
      "grad_norm": 0.06213928759098053,
      "learning_rate": 1.862230492813142e-05,
      "loss": 0.0009,
      "step": 48900
    },
    {
      "epoch": 3.141042094455852,
      "grad_norm": 0.030103355646133423,
      "learning_rate": 1.8590220739219712e-05,
      "loss": 0.0009,
      "step": 48950
    },
    {
      "epoch": 3.1442505133470227,
      "grad_norm": 0.08556237071752548,
      "learning_rate": 1.855813655030801e-05,
      "loss": 0.0009,
      "step": 49000
    },
    {
      "epoch": 3.147458932238193,
      "grad_norm": 0.09883196651935577,
      "learning_rate": 1.8526052361396305e-05,
      "loss": 0.0009,
      "step": 49050
    },
    {
      "epoch": 3.1506673511293632,
      "grad_norm": 0.05950339511036873,
      "learning_rate": 1.84939681724846e-05,
      "loss": 0.0009,
      "step": 49100
    },
    {
      "epoch": 3.1538757700205338,
      "grad_norm": 0.03608943521976471,
      "learning_rate": 1.8461883983572897e-05,
      "loss": 0.0009,
      "step": 49150
    },
    {
      "epoch": 3.1570841889117043,
      "grad_norm": 0.08761255443096161,
      "learning_rate": 1.8429799794661193e-05,
      "loss": 0.0009,
      "step": 49200
    },
    {
      "epoch": 3.160292607802875,
      "grad_norm": 0.04799361526966095,
      "learning_rate": 1.839771560574949e-05,
      "loss": 0.0009,
      "step": 49250
    },
    {
      "epoch": 3.1635010266940453,
      "grad_norm": 0.08295787870883942,
      "learning_rate": 1.8365631416837782e-05,
      "loss": 0.0009,
      "step": 49300
    },
    {
      "epoch": 3.166709445585216,
      "grad_norm": 0.03610463812947273,
      "learning_rate": 1.8333547227926078e-05,
      "loss": 0.0009,
      "step": 49350
    },
    {
      "epoch": 3.169917864476386,
      "grad_norm": 0.1040501669049263,
      "learning_rate": 1.8301463039014374e-05,
      "loss": 0.0009,
      "step": 49400
    },
    {
      "epoch": 3.1731262833675564,
      "grad_norm": 0.12795905768871307,
      "learning_rate": 1.826937885010267e-05,
      "loss": 0.0009,
      "step": 49450
    },
    {
      "epoch": 3.176334702258727,
      "grad_norm": 0.0967249795794487,
      "learning_rate": 1.8237294661190963e-05,
      "loss": 0.0009,
      "step": 49500
    },
    {
      "epoch": 3.1795431211498975,
      "grad_norm": 0.019880112260580063,
      "learning_rate": 1.820521047227926e-05,
      "loss": 0.0009,
      "step": 49550
    },
    {
      "epoch": 3.1827515400410675,
      "grad_norm": 0.06905496120452881,
      "learning_rate": 1.817312628336756e-05,
      "loss": 0.0009,
      "step": 49600
    },
    {
      "epoch": 3.185959958932238,
      "grad_norm": 0.13547465205192566,
      "learning_rate": 1.8141042094455855e-05,
      "loss": 0.0009,
      "step": 49650
    },
    {
      "epoch": 3.1891683778234086,
      "grad_norm": 0.04508931189775467,
      "learning_rate": 1.8108957905544148e-05,
      "loss": 0.0009,
      "step": 49700
    },
    {
      "epoch": 3.192376796714579,
      "grad_norm": 0.09997386485338211,
      "learning_rate": 1.8076873716632444e-05,
      "loss": 0.0009,
      "step": 49750
    },
    {
      "epoch": 3.1955852156057496,
      "grad_norm": 0.08084855228662491,
      "learning_rate": 1.804478952772074e-05,
      "loss": 0.0009,
      "step": 49800
    },
    {
      "epoch": 3.19879363449692,
      "grad_norm": 0.04952253773808479,
      "learning_rate": 1.8012705338809037e-05,
      "loss": 0.0009,
      "step": 49850
    },
    {
      "epoch": 3.20200205338809,
      "grad_norm": 0.026947923004627228,
      "learning_rate": 1.798062114989733e-05,
      "loss": 0.0009,
      "step": 49900
    },
    {
      "epoch": 3.2052104722792607,
      "grad_norm": 0.050812479108572006,
      "learning_rate": 1.7948536960985626e-05,
      "loss": 0.0009,
      "step": 49950
    },
    {
      "epoch": 3.208418891170431,
      "grad_norm": 0.07066168636083603,
      "learning_rate": 1.7916452772073922e-05,
      "loss": 0.0009,
      "step": 50000
    },
    {
      "epoch": 3.2116273100616017,
      "grad_norm": 0.1296011507511139,
      "learning_rate": 1.788436858316222e-05,
      "loss": 0.0009,
      "step": 50050
    },
    {
      "epoch": 3.2148357289527723,
      "grad_norm": 0.03444261476397514,
      "learning_rate": 1.7852284394250514e-05,
      "loss": 0.0009,
      "step": 50100
    },
    {
      "epoch": 3.2180441478439423,
      "grad_norm": 0.02171863429248333,
      "learning_rate": 1.782020020533881e-05,
      "loss": 0.0009,
      "step": 50150
    },
    {
      "epoch": 3.221252566735113,
      "grad_norm": 0.043907638639211655,
      "learning_rate": 1.7788116016427107e-05,
      "loss": 0.0009,
      "step": 50200
    },
    {
      "epoch": 3.2244609856262834,
      "grad_norm": 0.08255407959222794,
      "learning_rate": 1.7756031827515403e-05,
      "loss": 0.0009,
      "step": 50250
    },
    {
      "epoch": 3.227669404517454,
      "grad_norm": 0.04736008495092392,
      "learning_rate": 1.7723947638603696e-05,
      "loss": 0.0009,
      "step": 50300
    },
    {
      "epoch": 3.2308778234086244,
      "grad_norm": 0.06376498192548752,
      "learning_rate": 1.7691863449691992e-05,
      "loss": 0.0009,
      "step": 50350
    },
    {
      "epoch": 3.2340862422997945,
      "grad_norm": 0.09652246534824371,
      "learning_rate": 1.7659779260780288e-05,
      "loss": 0.0009,
      "step": 50400
    },
    {
      "epoch": 3.237294661190965,
      "grad_norm": 0.05864141881465912,
      "learning_rate": 1.7627695071868584e-05,
      "loss": 0.0009,
      "step": 50450
    },
    {
      "epoch": 3.2405030800821355,
      "grad_norm": 0.03973937779664993,
      "learning_rate": 1.7595610882956877e-05,
      "loss": 0.0009,
      "step": 50500
    },
    {
      "epoch": 3.243711498973306,
      "grad_norm": 0.0141930365934968,
      "learning_rate": 1.7563526694045177e-05,
      "loss": 0.0009,
      "step": 50550
    },
    {
      "epoch": 3.2469199178644765,
      "grad_norm": 0.11729606240987778,
      "learning_rate": 1.7531442505133473e-05,
      "loss": 0.0009,
      "step": 50600
    },
    {
      "epoch": 3.2501283367556466,
      "grad_norm": 0.06262978911399841,
      "learning_rate": 1.7499358316221766e-05,
      "loss": 0.0009,
      "step": 50650
    },
    {
      "epoch": 3.253336755646817,
      "grad_norm": 0.0664566308259964,
      "learning_rate": 1.7467274127310062e-05,
      "loss": 0.0009,
      "step": 50700
    },
    {
      "epoch": 3.2565451745379876,
      "grad_norm": 0.08971668779850006,
      "learning_rate": 1.7435189938398358e-05,
      "loss": 0.0009,
      "step": 50750
    },
    {
      "epoch": 3.259753593429158,
      "grad_norm": 0.13882699608802795,
      "learning_rate": 1.7403105749486654e-05,
      "loss": 0.0009,
      "step": 50800
    },
    {
      "epoch": 3.2629620123203287,
      "grad_norm": 0.12174118310213089,
      "learning_rate": 1.737102156057495e-05,
      "loss": 0.0009,
      "step": 50850
    },
    {
      "epoch": 3.266170431211499,
      "grad_norm": 0.10449782758951187,
      "learning_rate": 1.7338937371663243e-05,
      "loss": 0.0009,
      "step": 50900
    },
    {
      "epoch": 3.2693788501026693,
      "grad_norm": 0.08474890887737274,
      "learning_rate": 1.730685318275154e-05,
      "loss": 0.0009,
      "step": 50950
    },
    {
      "epoch": 3.27258726899384,
      "grad_norm": 0.10994161665439606,
      "learning_rate": 1.727476899383984e-05,
      "loss": 0.0009,
      "step": 51000
    },
    {
      "epoch": 3.2757956878850103,
      "grad_norm": 0.04993736743927002,
      "learning_rate": 1.7242684804928132e-05,
      "loss": 0.0009,
      "step": 51050
    },
    {
      "epoch": 3.279004106776181,
      "grad_norm": 0.06772873550653458,
      "learning_rate": 1.7210600616016428e-05,
      "loss": 0.0009,
      "step": 51100
    },
    {
      "epoch": 3.282212525667351,
      "grad_norm": 0.016828665509819984,
      "learning_rate": 1.7178516427104724e-05,
      "loss": 0.0009,
      "step": 51150
    },
    {
      "epoch": 3.2854209445585214,
      "grad_norm": 0.05028149485588074,
      "learning_rate": 1.714643223819302e-05,
      "loss": 0.0009,
      "step": 51200
    },
    {
      "epoch": 3.288629363449692,
      "grad_norm": 0.016622981056571007,
      "learning_rate": 1.7114348049281313e-05,
      "loss": 0.0009,
      "step": 51250
    },
    {
      "epoch": 3.2918377823408624,
      "grad_norm": 0.13327676057815552,
      "learning_rate": 1.708226386036961e-05,
      "loss": 0.0009,
      "step": 51300
    },
    {
      "epoch": 3.295046201232033,
      "grad_norm": 0.01477021723985672,
      "learning_rate": 1.7050179671457905e-05,
      "loss": 0.0009,
      "step": 51350
    },
    {
      "epoch": 3.2982546201232035,
      "grad_norm": 0.1221487745642662,
      "learning_rate": 1.70180954825462e-05,
      "loss": 0.0009,
      "step": 51400
    },
    {
      "epoch": 3.3014630390143735,
      "grad_norm": 0.07326678186655045,
      "learning_rate": 1.6986011293634498e-05,
      "loss": 0.0009,
      "step": 51450
    },
    {
      "epoch": 3.304671457905544,
      "grad_norm": 0.04556672275066376,
      "learning_rate": 1.6953927104722794e-05,
      "loss": 0.0009,
      "step": 51500
    },
    {
      "epoch": 3.3078798767967146,
      "grad_norm": 0.07498420774936676,
      "learning_rate": 1.692184291581109e-05,
      "loss": 0.0009,
      "step": 51550
    },
    {
      "epoch": 3.311088295687885,
      "grad_norm": 0.05104030668735504,
      "learning_rate": 1.6889758726899386e-05,
      "loss": 0.0009,
      "step": 51600
    },
    {
      "epoch": 3.3142967145790556,
      "grad_norm": 0.06264255940914154,
      "learning_rate": 1.685767453798768e-05,
      "loss": 0.0009,
      "step": 51650
    },
    {
      "epoch": 3.3175051334702257,
      "grad_norm": 0.05104592815041542,
      "learning_rate": 1.6825590349075975e-05,
      "loss": 0.0009,
      "step": 51700
    },
    {
      "epoch": 3.320713552361396,
      "grad_norm": 0.04668296128511429,
      "learning_rate": 1.679350616016427e-05,
      "loss": 0.0009,
      "step": 51750
    },
    {
      "epoch": 3.3239219712525667,
      "grad_norm": 0.06657188385725021,
      "learning_rate": 1.6761421971252568e-05,
      "loss": 0.0009,
      "step": 51800
    },
    {
      "epoch": 3.3271303901437372,
      "grad_norm": 0.062709741294384,
      "learning_rate": 1.672933778234086e-05,
      "loss": 0.0009,
      "step": 51850
    },
    {
      "epoch": 3.3303388090349078,
      "grad_norm": 0.054283346980810165,
      "learning_rate": 1.669725359342916e-05,
      "loss": 0.0009,
      "step": 51900
    },
    {
      "epoch": 3.3335472279260783,
      "grad_norm": 0.01748560555279255,
      "learning_rate": 1.6665169404517456e-05,
      "loss": 0.0008,
      "step": 51950
    },
    {
      "epoch": 3.3367556468172483,
      "grad_norm": 0.10272722691297531,
      "learning_rate": 1.6633085215605753e-05,
      "loss": 0.0009,
      "step": 52000
    },
    {
      "epoch": 3.339964065708419,
      "grad_norm": 0.06670422852039337,
      "learning_rate": 1.6601001026694045e-05,
      "loss": 0.0009,
      "step": 52050
    },
    {
      "epoch": 3.3431724845995894,
      "grad_norm": 0.06763625144958496,
      "learning_rate": 1.656891683778234e-05,
      "loss": 0.0009,
      "step": 52100
    },
    {
      "epoch": 3.34638090349076,
      "grad_norm": 0.17321817576885223,
      "learning_rate": 1.6536832648870638e-05,
      "loss": 0.0009,
      "step": 52150
    },
    {
      "epoch": 3.34958932238193,
      "grad_norm": 0.03268975019454956,
      "learning_rate": 1.6504748459958934e-05,
      "loss": 0.0009,
      "step": 52200
    },
    {
      "epoch": 3.3527977412731005,
      "grad_norm": 0.01637907512485981,
      "learning_rate": 1.6472664271047227e-05,
      "loss": 0.0009,
      "step": 52250
    },
    {
      "epoch": 3.356006160164271,
      "grad_norm": 0.08989310264587402,
      "learning_rate": 1.6440580082135523e-05,
      "loss": 0.0009,
      "step": 52300
    },
    {
      "epoch": 3.3592145790554415,
      "grad_norm": 0.11420261859893799,
      "learning_rate": 1.6408495893223822e-05,
      "loss": 0.0009,
      "step": 52350
    },
    {
      "epoch": 3.362422997946612,
      "grad_norm": 0.1298639476299286,
      "learning_rate": 1.6376411704312115e-05,
      "loss": 0.0009,
      "step": 52400
    },
    {
      "epoch": 3.3656314168377826,
      "grad_norm": 0.07762472331523895,
      "learning_rate": 1.634432751540041e-05,
      "loss": 0.0009,
      "step": 52450
    },
    {
      "epoch": 3.3688398357289526,
      "grad_norm": 0.1395859271287918,
      "learning_rate": 1.6312243326488708e-05,
      "loss": 0.0009,
      "step": 52500
    },
    {
      "epoch": 3.372048254620123,
      "grad_norm": 0.03375543653964996,
      "learning_rate": 1.6280159137577004e-05,
      "loss": 0.0009,
      "step": 52550
    },
    {
      "epoch": 3.3752566735112937,
      "grad_norm": 0.09487732499837875,
      "learning_rate": 1.62480749486653e-05,
      "loss": 0.0009,
      "step": 52600
    },
    {
      "epoch": 3.378465092402464,
      "grad_norm": 0.06645137816667557,
      "learning_rate": 1.6215990759753593e-05,
      "loss": 0.0009,
      "step": 52650
    },
    {
      "epoch": 3.3816735112936342,
      "grad_norm": 0.1189090684056282,
      "learning_rate": 1.618390657084189e-05,
      "loss": 0.0009,
      "step": 52700
    },
    {
      "epoch": 3.3848819301848048,
      "grad_norm": 0.057264573872089386,
      "learning_rate": 1.6151822381930185e-05,
      "loss": 0.0009,
      "step": 52750
    },
    {
      "epoch": 3.3880903490759753,
      "grad_norm": 0.05339662358164787,
      "learning_rate": 1.611973819301848e-05,
      "loss": 0.0009,
      "step": 52800
    },
    {
      "epoch": 3.391298767967146,
      "grad_norm": 0.10991238057613373,
      "learning_rate": 1.6087654004106778e-05,
      "loss": 0.0009,
      "step": 52850
    },
    {
      "epoch": 3.3945071868583163,
      "grad_norm": 0.10703340917825699,
      "learning_rate": 1.6055569815195074e-05,
      "loss": 0.0008,
      "step": 52900
    },
    {
      "epoch": 3.397715605749487,
      "grad_norm": 0.062246888875961304,
      "learning_rate": 1.602348562628337e-05,
      "loss": 0.0009,
      "step": 52950
    },
    {
      "epoch": 3.400924024640657,
      "grad_norm": 0.08573870360851288,
      "learning_rate": 1.5991401437371663e-05,
      "loss": 0.0009,
      "step": 53000
    },
    {
      "epoch": 3.4041324435318274,
      "grad_norm": 0.055830057710409164,
      "learning_rate": 1.595931724845996e-05,
      "loss": 0.0009,
      "step": 53050
    },
    {
      "epoch": 3.407340862422998,
      "grad_norm": 0.08290299028158188,
      "learning_rate": 1.5927233059548255e-05,
      "loss": 0.0009,
      "step": 53100
    },
    {
      "epoch": 3.4105492813141685,
      "grad_norm": 0.10992427915334702,
      "learning_rate": 1.589514887063655e-05,
      "loss": 0.0009,
      "step": 53150
    },
    {
      "epoch": 3.413757700205339,
      "grad_norm": 0.09379592537879944,
      "learning_rate": 1.5863064681724844e-05,
      "loss": 0.0009,
      "step": 53200
    },
    {
      "epoch": 3.416966119096509,
      "grad_norm": 0.061189986765384674,
      "learning_rate": 1.583098049281314e-05,
      "loss": 0.0009,
      "step": 53250
    },
    {
      "epoch": 3.4201745379876796,
      "grad_norm": 0.07534630596637726,
      "learning_rate": 1.579889630390144e-05,
      "loss": 0.0009,
      "step": 53300
    },
    {
      "epoch": 3.42338295687885,
      "grad_norm": 0.07190075516700745,
      "learning_rate": 1.5766812114989736e-05,
      "loss": 0.0009,
      "step": 53350
    },
    {
      "epoch": 3.4265913757700206,
      "grad_norm": 0.06377220898866653,
      "learning_rate": 1.573472792607803e-05,
      "loss": 0.0009,
      "step": 53400
    },
    {
      "epoch": 3.429799794661191,
      "grad_norm": 0.06262393295764923,
      "learning_rate": 1.5702643737166325e-05,
      "loss": 0.0009,
      "step": 53450
    },
    {
      "epoch": 3.4330082135523616,
      "grad_norm": 0.04015044495463371,
      "learning_rate": 1.567055954825462e-05,
      "loss": 0.0009,
      "step": 53500
    },
    {
      "epoch": 3.4362166324435317,
      "grad_norm": 0.03374934941530228,
      "learning_rate": 1.5638475359342917e-05,
      "loss": 0.0009,
      "step": 53550
    },
    {
      "epoch": 3.439425051334702,
      "grad_norm": 0.05573475733399391,
      "learning_rate": 1.560639117043121e-05,
      "loss": 0.0009,
      "step": 53600
    },
    {
      "epoch": 3.4426334702258727,
      "grad_norm": 0.13523218035697937,
      "learning_rate": 1.5574306981519506e-05,
      "loss": 0.0009,
      "step": 53650
    },
    {
      "epoch": 3.4458418891170433,
      "grad_norm": 0.016635829582810402,
      "learning_rate": 1.5542222792607803e-05,
      "loss": 0.0009,
      "step": 53700
    },
    {
      "epoch": 3.4490503080082133,
      "grad_norm": 0.0734403133392334,
      "learning_rate": 1.5510138603696102e-05,
      "loss": 0.0009,
      "step": 53750
    },
    {
      "epoch": 3.452258726899384,
      "grad_norm": 0.04566189646720886,
      "learning_rate": 1.5478054414784395e-05,
      "loss": 0.0009,
      "step": 53800
    },
    {
      "epoch": 3.4554671457905544,
      "grad_norm": 0.09855011105537415,
      "learning_rate": 1.544597022587269e-05,
      "loss": 0.0009,
      "step": 53850
    },
    {
      "epoch": 3.458675564681725,
      "grad_norm": 0.08906547725200653,
      "learning_rate": 1.5413886036960987e-05,
      "loss": 0.0009,
      "step": 53900
    },
    {
      "epoch": 3.4618839835728954,
      "grad_norm": 0.04329809173941612,
      "learning_rate": 1.5381801848049284e-05,
      "loss": 0.0009,
      "step": 53950
    },
    {
      "epoch": 3.465092402464066,
      "grad_norm": 0.07976328581571579,
      "learning_rate": 1.5349717659137576e-05,
      "loss": 0.0009,
      "step": 54000
    },
    {
      "epoch": 3.468300821355236,
      "grad_norm": 0.055130649358034134,
      "learning_rate": 1.5317633470225873e-05,
      "loss": 0.0009,
      "step": 54050
    },
    {
      "epoch": 3.4715092402464065,
      "grad_norm": 0.03852393105626106,
      "learning_rate": 1.528554928131417e-05,
      "loss": 0.0009,
      "step": 54100
    },
    {
      "epoch": 3.474717659137577,
      "grad_norm": 0.1004912406206131,
      "learning_rate": 1.5253465092402463e-05,
      "loss": 0.0009,
      "step": 54150
    },
    {
      "epoch": 3.4779260780287475,
      "grad_norm": 0.07691044360399246,
      "learning_rate": 1.5221380903490761e-05,
      "loss": 0.0009,
      "step": 54200
    },
    {
      "epoch": 3.481134496919918,
      "grad_norm": 0.05723316967487335,
      "learning_rate": 1.5189296714579057e-05,
      "loss": 0.0009,
      "step": 54250
    },
    {
      "epoch": 3.484342915811088,
      "grad_norm": 0.06751161068677902,
      "learning_rate": 1.5157212525667352e-05,
      "loss": 0.0009,
      "step": 54300
    },
    {
      "epoch": 3.4875513347022586,
      "grad_norm": 0.07669195532798767,
      "learning_rate": 1.5125128336755648e-05,
      "loss": 0.0008,
      "step": 54350
    },
    {
      "epoch": 3.490759753593429,
      "grad_norm": 0.09124170243740082,
      "learning_rate": 1.5093044147843942e-05,
      "loss": 0.0008,
      "step": 54400
    },
    {
      "epoch": 3.4939681724845997,
      "grad_norm": 0.05614851787686348,
      "learning_rate": 1.5060959958932239e-05,
      "loss": 0.0009,
      "step": 54450
    },
    {
      "epoch": 3.49717659137577,
      "grad_norm": 0.04271785914897919,
      "learning_rate": 1.5028875770020535e-05,
      "loss": 0.0009,
      "step": 54500
    },
    {
      "epoch": 3.5003850102669407,
      "grad_norm": 0.048165518790483475,
      "learning_rate": 1.499679158110883e-05,
      "loss": 0.0009,
      "step": 54550
    },
    {
      "epoch": 3.503593429158111,
      "grad_norm": 0.04886623099446297,
      "learning_rate": 1.4964707392197126e-05,
      "loss": 0.0009,
      "step": 54600
    },
    {
      "epoch": 3.5068018480492813,
      "grad_norm": 0.1680699735879898,
      "learning_rate": 1.4932623203285423e-05,
      "loss": 0.0009,
      "step": 54650
    },
    {
      "epoch": 3.510010266940452,
      "grad_norm": 0.1455729901790619,
      "learning_rate": 1.4900539014373718e-05,
      "loss": 0.0009,
      "step": 54700
    },
    {
      "epoch": 3.5132186858316223,
      "grad_norm": 0.04962843284010887,
      "learning_rate": 1.4868454825462014e-05,
      "loss": 0.0009,
      "step": 54750
    },
    {
      "epoch": 3.5164271047227924,
      "grad_norm": 0.08276021480560303,
      "learning_rate": 1.4836370636550309e-05,
      "loss": 0.0009,
      "step": 54800
    },
    {
      "epoch": 3.519635523613963,
      "grad_norm": 0.1096661165356636,
      "learning_rate": 1.4804286447638605e-05,
      "loss": 0.0009,
      "step": 54850
    },
    {
      "epoch": 3.5228439425051334,
      "grad_norm": 0.08649729937314987,
      "learning_rate": 1.47722022587269e-05,
      "loss": 0.0009,
      "step": 54900
    },
    {
      "epoch": 3.526052361396304,
      "grad_norm": 0.1259470134973526,
      "learning_rate": 1.4740118069815195e-05,
      "loss": 0.0009,
      "step": 54950
    },
    {
      "epoch": 3.5292607802874745,
      "grad_norm": 0.0758628249168396,
      "learning_rate": 1.470803388090349e-05,
      "loss": 0.0009,
      "step": 55000
    },
    {
      "epoch": 3.532469199178645,
      "grad_norm": 0.07364535331726074,
      "learning_rate": 1.4675949691991786e-05,
      "loss": 0.0009,
      "step": 55050
    },
    {
      "epoch": 3.535677618069815,
      "grad_norm": 0.08430761098861694,
      "learning_rate": 1.4643865503080084e-05,
      "loss": 0.0009,
      "step": 55100
    },
    {
      "epoch": 3.5388860369609856,
      "grad_norm": 0.08297847956418991,
      "learning_rate": 1.461178131416838e-05,
      "loss": 0.0009,
      "step": 55150
    },
    {
      "epoch": 3.542094455852156,
      "grad_norm": 0.10775445401668549,
      "learning_rate": 1.4579697125256675e-05,
      "loss": 0.0009,
      "step": 55200
    },
    {
      "epoch": 3.5453028747433266,
      "grad_norm": 0.06381157040596008,
      "learning_rate": 1.4547612936344971e-05,
      "loss": 0.0009,
      "step": 55250
    },
    {
      "epoch": 3.5485112936344967,
      "grad_norm": 0.06994086503982544,
      "learning_rate": 1.4515528747433265e-05,
      "loss": 0.0009,
      "step": 55300
    },
    {
      "epoch": 3.551719712525667,
      "grad_norm": 0.0387442372739315,
      "learning_rate": 1.4483444558521562e-05,
      "loss": 0.0009,
      "step": 55350
    },
    {
      "epoch": 3.5549281314168377,
      "grad_norm": 0.058875635266304016,
      "learning_rate": 1.4451360369609856e-05,
      "loss": 0.0009,
      "step": 55400
    },
    {
      "epoch": 3.5581365503080082,
      "grad_norm": 0.05794211104512215,
      "learning_rate": 1.4419276180698152e-05,
      "loss": 0.0009,
      "step": 55450
    },
    {
      "epoch": 3.5613449691991788,
      "grad_norm": 0.04462643712759018,
      "learning_rate": 1.4387191991786447e-05,
      "loss": 0.0009,
      "step": 55500
    },
    {
      "epoch": 3.5645533880903493,
      "grad_norm": 0.026132602244615555,
      "learning_rate": 1.4355107802874743e-05,
      "loss": 0.0008,
      "step": 55550
    },
    {
      "epoch": 3.5677618069815193,
      "grad_norm": 0.0821199044585228,
      "learning_rate": 1.432302361396304e-05,
      "loss": 0.0008,
      "step": 55600
    },
    {
      "epoch": 3.57097022587269,
      "grad_norm": 0.017794430255889893,
      "learning_rate": 1.4290939425051337e-05,
      "loss": 0.0009,
      "step": 55650
    },
    {
      "epoch": 3.5741786447638604,
      "grad_norm": 0.04683299735188484,
      "learning_rate": 1.4258855236139631e-05,
      "loss": 0.0009,
      "step": 55700
    },
    {
      "epoch": 3.577387063655031,
      "grad_norm": 0.10519661754369736,
      "learning_rate": 1.4226771047227928e-05,
      "loss": 0.0009,
      "step": 55750
    },
    {
      "epoch": 3.580595482546201,
      "grad_norm": 0.05101309344172478,
      "learning_rate": 1.4194686858316222e-05,
      "loss": 0.0008,
      "step": 55800
    },
    {
      "epoch": 3.5838039014373715,
      "grad_norm": 0.064082570374012,
      "learning_rate": 1.4162602669404518e-05,
      "loss": 0.0009,
      "step": 55850
    },
    {
      "epoch": 3.587012320328542,
      "grad_norm": 0.03462354838848114,
      "learning_rate": 1.4130518480492813e-05,
      "loss": 0.0008,
      "step": 55900
    },
    {
      "epoch": 3.5902207392197125,
      "grad_norm": 0.054173823446035385,
      "learning_rate": 1.4098434291581109e-05,
      "loss": 0.0009,
      "step": 55950
    },
    {
      "epoch": 3.593429158110883,
      "grad_norm": 0.029282448813319206,
      "learning_rate": 1.4066350102669404e-05,
      "loss": 0.0009,
      "step": 56000
    },
    {
      "epoch": 3.5966375770020536,
      "grad_norm": 0.09356016665697098,
      "learning_rate": 1.4034265913757701e-05,
      "loss": 0.0008,
      "step": 56050
    },
    {
      "epoch": 3.599845995893224,
      "grad_norm": 0.028454376384615898,
      "learning_rate": 1.4002181724845998e-05,
      "loss": 0.0009,
      "step": 56100
    },
    {
      "epoch": 3.603054414784394,
      "grad_norm": 0.01645651087164879,
      "learning_rate": 1.3970097535934292e-05,
      "loss": 0.0009,
      "step": 56150
    },
    {
      "epoch": 3.6062628336755647,
      "grad_norm": 0.030338412150740623,
      "learning_rate": 1.3938013347022588e-05,
      "loss": 0.0009,
      "step": 56200
    },
    {
      "epoch": 3.609471252566735,
      "grad_norm": 0.03777420520782471,
      "learning_rate": 1.3905929158110883e-05,
      "loss": 0.0009,
      "step": 56250
    },
    {
      "epoch": 3.6126796714579057,
      "grad_norm": 0.04151248559355736,
      "learning_rate": 1.3873844969199179e-05,
      "loss": 0.0008,
      "step": 56300
    },
    {
      "epoch": 3.6158880903490758,
      "grad_norm": 0.10729505866765976,
      "learning_rate": 1.3841760780287475e-05,
      "loss": 0.0009,
      "step": 56350
    },
    {
      "epoch": 3.6190965092402463,
      "grad_norm": 0.09362118691205978,
      "learning_rate": 1.380967659137577e-05,
      "loss": 0.0009,
      "step": 56400
    },
    {
      "epoch": 3.622304928131417,
      "grad_norm": 0.09480917453765869,
      "learning_rate": 1.3777592402464066e-05,
      "loss": 0.0009,
      "step": 56450
    },
    {
      "epoch": 3.6255133470225873,
      "grad_norm": 0.02977258339524269,
      "learning_rate": 1.3745508213552364e-05,
      "loss": 0.0009,
      "step": 56500
    },
    {
      "epoch": 3.628721765913758,
      "grad_norm": 0.08806363493204117,
      "learning_rate": 1.3713424024640658e-05,
      "loss": 0.0009,
      "step": 56550
    },
    {
      "epoch": 3.6319301848049284,
      "grad_norm": 0.03783890977501869,
      "learning_rate": 1.3681339835728954e-05,
      "loss": 0.0009,
      "step": 56600
    },
    {
      "epoch": 3.6351386036960984,
      "grad_norm": 0.027143104001879692,
      "learning_rate": 1.3649255646817249e-05,
      "loss": 0.0009,
      "step": 56650
    },
    {
      "epoch": 3.638347022587269,
      "grad_norm": 0.0220625139772892,
      "learning_rate": 1.3617171457905545e-05,
      "loss": 0.0008,
      "step": 56700
    },
    {
      "epoch": 3.6415554414784395,
      "grad_norm": 0.04951060563325882,
      "learning_rate": 1.358508726899384e-05,
      "loss": 0.0009,
      "step": 56750
    },
    {
      "epoch": 3.64476386036961,
      "grad_norm": 0.05566338822245598,
      "learning_rate": 1.3553003080082136e-05,
      "loss": 0.0009,
      "step": 56800
    },
    {
      "epoch": 3.64797227926078,
      "grad_norm": 0.08787272870540619,
      "learning_rate": 1.352091889117043e-05,
      "loss": 0.0009,
      "step": 56850
    },
    {
      "epoch": 3.6511806981519506,
      "grad_norm": 0.03065936081111431,
      "learning_rate": 1.3488834702258726e-05,
      "loss": 0.0009,
      "step": 56900
    },
    {
      "epoch": 3.654389117043121,
      "grad_norm": 0.07817739993333817,
      "learning_rate": 1.3456750513347024e-05,
      "loss": 0.0009,
      "step": 56950
    },
    {
      "epoch": 3.6575975359342916,
      "grad_norm": 0.1222890093922615,
      "learning_rate": 1.342466632443532e-05,
      "loss": 0.0008,
      "step": 57000
    },
    {
      "epoch": 3.660805954825462,
      "grad_norm": 0.11004593223333359,
      "learning_rate": 1.3392582135523615e-05,
      "loss": 0.0008,
      "step": 57050
    },
    {
      "epoch": 3.6640143737166326,
      "grad_norm": 0.1282636672258377,
      "learning_rate": 1.3360497946611911e-05,
      "loss": 0.0009,
      "step": 57100
    },
    {
      "epoch": 3.667222792607803,
      "grad_norm": 0.032643262296915054,
      "learning_rate": 1.3328413757700206e-05,
      "loss": 0.0009,
      "step": 57150
    },
    {
      "epoch": 3.6704312114989732,
      "grad_norm": 0.08551950007677078,
      "learning_rate": 1.3296329568788502e-05,
      "loss": 0.0009,
      "step": 57200
    },
    {
      "epoch": 3.6736396303901437,
      "grad_norm": 0.1409664750099182,
      "learning_rate": 1.3264245379876796e-05,
      "loss": 0.0008,
      "step": 57250
    },
    {
      "epoch": 3.6768480492813143,
      "grad_norm": 0.06409475952386856,
      "learning_rate": 1.3232161190965093e-05,
      "loss": 0.0009,
      "step": 57300
    },
    {
      "epoch": 3.6800564681724843,
      "grad_norm": 0.013011828996241093,
      "learning_rate": 1.3200077002053387e-05,
      "loss": 0.0009,
      "step": 57350
    },
    {
      "epoch": 3.683264887063655,
      "grad_norm": 0.13900429010391235,
      "learning_rate": 1.3167992813141685e-05,
      "loss": 0.0009,
      "step": 57400
    },
    {
      "epoch": 3.6864733059548254,
      "grad_norm": 0.09300688654184341,
      "learning_rate": 1.3135908624229981e-05,
      "loss": 0.0009,
      "step": 57450
    },
    {
      "epoch": 3.689681724845996,
      "grad_norm": 0.12282203882932663,
      "learning_rate": 1.3103824435318277e-05,
      "loss": 0.0009,
      "step": 57500
    },
    {
      "epoch": 3.6928901437371664,
      "grad_norm": 0.037812717258930206,
      "learning_rate": 1.3071740246406572e-05,
      "loss": 0.0009,
      "step": 57550
    },
    {
      "epoch": 3.696098562628337,
      "grad_norm": 0.04570113122463226,
      "learning_rate": 1.3039656057494868e-05,
      "loss": 0.0009,
      "step": 57600
    },
    {
      "epoch": 3.6993069815195074,
      "grad_norm": 0.03951976075768471,
      "learning_rate": 1.3007571868583162e-05,
      "loss": 0.0009,
      "step": 57650
    },
    {
      "epoch": 3.7025154004106775,
      "grad_norm": 0.10865374654531479,
      "learning_rate": 1.2975487679671459e-05,
      "loss": 0.0009,
      "step": 57700
    },
    {
      "epoch": 3.705723819301848,
      "grad_norm": 0.03760499507188797,
      "learning_rate": 1.2943403490759753e-05,
      "loss": 0.0008,
      "step": 57750
    },
    {
      "epoch": 3.7089322381930185,
      "grad_norm": 0.10591451078653336,
      "learning_rate": 1.291131930184805e-05,
      "loss": 0.0009,
      "step": 57800
    },
    {
      "epoch": 3.712140657084189,
      "grad_norm": 0.11993444710969925,
      "learning_rate": 1.2879235112936344e-05,
      "loss": 0.0008,
      "step": 57850
    },
    {
      "epoch": 3.715349075975359,
      "grad_norm": 0.06584642827510834,
      "learning_rate": 1.2847150924024642e-05,
      "loss": 0.0009,
      "step": 57900
    },
    {
      "epoch": 3.7185574948665296,
      "grad_norm": 0.09190285205841064,
      "learning_rate": 1.2815066735112938e-05,
      "loss": 0.0009,
      "step": 57950
    },
    {
      "epoch": 3.7217659137577,
      "grad_norm": 0.022793885320425034,
      "learning_rate": 1.2782982546201232e-05,
      "loss": 0.0009,
      "step": 58000
    },
    {
      "epoch": 3.7249743326488707,
      "grad_norm": 0.10390202701091766,
      "learning_rate": 1.2750898357289529e-05,
      "loss": 0.0008,
      "step": 58050
    },
    {
      "epoch": 3.728182751540041,
      "grad_norm": 0.06285284459590912,
      "learning_rate": 1.2718814168377823e-05,
      "loss": 0.0009,
      "step": 58100
    },
    {
      "epoch": 3.7313911704312117,
      "grad_norm": 0.06928195059299469,
      "learning_rate": 1.268672997946612e-05,
      "loss": 0.0008,
      "step": 58150
    },
    {
      "epoch": 3.734599589322382,
      "grad_norm": 0.12932346761226654,
      "learning_rate": 1.2654645790554415e-05,
      "loss": 0.0008,
      "step": 58200
    },
    {
      "epoch": 3.7378080082135523,
      "grad_norm": 0.09615160524845123,
      "learning_rate": 1.262256160164271e-05,
      "loss": 0.0009,
      "step": 58250
    },
    {
      "epoch": 3.741016427104723,
      "grad_norm": 0.08879519253969193,
      "learning_rate": 1.2590477412731006e-05,
      "loss": 0.0008,
      "step": 58300
    },
    {
      "epoch": 3.7442248459958933,
      "grad_norm": 0.13521535694599152,
      "learning_rate": 1.2558393223819304e-05,
      "loss": 0.0009,
      "step": 58350
    },
    {
      "epoch": 3.7474332648870634,
      "grad_norm": 0.04667181521654129,
      "learning_rate": 1.2526309034907599e-05,
      "loss": 0.0008,
      "step": 58400
    },
    {
      "epoch": 3.750641683778234,
      "grad_norm": 0.03698411211371422,
      "learning_rate": 1.2494224845995895e-05,
      "loss": 0.0008,
      "step": 58450
    },
    {
      "epoch": 3.7538501026694044,
      "grad_norm": 0.08583741635084152,
      "learning_rate": 1.246214065708419e-05,
      "loss": 0.0009,
      "step": 58500
    },
    {
      "epoch": 3.757058521560575,
      "grad_norm": 0.09490209072828293,
      "learning_rate": 1.2430056468172485e-05,
      "loss": 0.0009,
      "step": 58550
    },
    {
      "epoch": 3.7602669404517455,
      "grad_norm": 0.10414290428161621,
      "learning_rate": 1.239797227926078e-05,
      "loss": 0.0008,
      "step": 58600
    },
    {
      "epoch": 3.763475359342916,
      "grad_norm": 0.029900727793574333,
      "learning_rate": 1.2365888090349076e-05,
      "loss": 0.0008,
      "step": 58650
    },
    {
      "epoch": 3.7666837782340865,
      "grad_norm": 0.0528922975063324,
      "learning_rate": 1.2333803901437372e-05,
      "loss": 0.0009,
      "step": 58700
    },
    {
      "epoch": 3.7698921971252566,
      "grad_norm": 0.054829876869916916,
      "learning_rate": 1.2301719712525668e-05,
      "loss": 0.0008,
      "step": 58750
    },
    {
      "epoch": 3.773100616016427,
      "grad_norm": 0.04000115767121315,
      "learning_rate": 1.2269635523613963e-05,
      "loss": 0.0009,
      "step": 58800
    },
    {
      "epoch": 3.7763090349075976,
      "grad_norm": 0.11963551491498947,
      "learning_rate": 1.2237551334702259e-05,
      "loss": 0.0009,
      "step": 58850
    },
    {
      "epoch": 3.7795174537987677,
      "grad_norm": 0.07977555692195892,
      "learning_rate": 1.2205467145790555e-05,
      "loss": 0.0008,
      "step": 58900
    },
    {
      "epoch": 3.782725872689938,
      "grad_norm": 0.0850650817155838,
      "learning_rate": 1.2173382956878852e-05,
      "loss": 0.0009,
      "step": 58950
    },
    {
      "epoch": 3.7859342915811087,
      "grad_norm": 0.04945987090468407,
      "learning_rate": 1.2141298767967146e-05,
      "loss": 0.0008,
      "step": 59000
    },
    {
      "epoch": 3.7891427104722792,
      "grad_norm": 0.07863064855337143,
      "learning_rate": 1.2109214579055442e-05,
      "loss": 0.0009,
      "step": 59050
    },
    {
      "epoch": 3.7923511293634498,
      "grad_norm": 0.06308003515005112,
      "learning_rate": 1.2077130390143737e-05,
      "loss": 0.0008,
      "step": 59100
    },
    {
      "epoch": 3.7955595482546203,
      "grad_norm": 0.13250882923603058,
      "learning_rate": 1.2045046201232035e-05,
      "loss": 0.0008,
      "step": 59150
    },
    {
      "epoch": 3.798767967145791,
      "grad_norm": 0.07831065356731415,
      "learning_rate": 1.2012962012320329e-05,
      "loss": 0.0008,
      "step": 59200
    },
    {
      "epoch": 3.801976386036961,
      "grad_norm": 0.05551309511065483,
      "learning_rate": 1.1980877823408625e-05,
      "loss": 0.0009,
      "step": 59250
    },
    {
      "epoch": 3.8051848049281314,
      "grad_norm": 0.09045447409152985,
      "learning_rate": 1.194879363449692e-05,
      "loss": 0.0008,
      "step": 59300
    },
    {
      "epoch": 3.808393223819302,
      "grad_norm": 0.06832988560199738,
      "learning_rate": 1.1916709445585218e-05,
      "loss": 0.0008,
      "step": 59350
    },
    {
      "epoch": 3.8116016427104724,
      "grad_norm": 0.08957444131374359,
      "learning_rate": 1.1884625256673512e-05,
      "loss": 0.0009,
      "step": 59400
    },
    {
      "epoch": 3.8148100616016425,
      "grad_norm": 0.11260846257209778,
      "learning_rate": 1.1852541067761808e-05,
      "loss": 0.0009,
      "step": 59450
    },
    {
      "epoch": 3.818018480492813,
      "grad_norm": 0.10326172411441803,
      "learning_rate": 1.1820456878850103e-05,
      "loss": 0.0008,
      "step": 59500
    },
    {
      "epoch": 3.8212268993839835,
      "grad_norm": 0.1087462306022644,
      "learning_rate": 1.1788372689938399e-05,
      "loss": 0.0009,
      "step": 59550
    },
    {
      "epoch": 3.824435318275154,
      "grad_norm": 0.05679472163319588,
      "learning_rate": 1.1756288501026695e-05,
      "loss": 0.0008,
      "step": 59600
    },
    {
      "epoch": 3.8276437371663246,
      "grad_norm": 0.07534494251012802,
      "learning_rate": 1.1724204312114991e-05,
      "loss": 0.0008,
      "step": 59650
    },
    {
      "epoch": 3.830852156057495,
      "grad_norm": 0.052589595317840576,
      "learning_rate": 1.1692120123203286e-05,
      "loss": 0.0008,
      "step": 59700
    },
    {
      "epoch": 3.834060574948665,
      "grad_norm": 0.047232672572135925,
      "learning_rate": 1.1660035934291582e-05,
      "loss": 0.0008,
      "step": 59750
    },
    {
      "epoch": 3.8372689938398357,
      "grad_norm": 0.07014761865139008,
      "learning_rate": 1.1627951745379877e-05,
      "loss": 0.0009,
      "step": 59800
    },
    {
      "epoch": 3.840477412731006,
      "grad_norm": 0.07947774231433868,
      "learning_rate": 1.1595867556468173e-05,
      "loss": 0.0008,
      "step": 59850
    },
    {
      "epoch": 3.8436858316221767,
      "grad_norm": 0.06715839356184006,
      "learning_rate": 1.1563783367556469e-05,
      "loss": 0.0009,
      "step": 59900
    },
    {
      "epoch": 3.8468942505133468,
      "grad_norm": 0.028434965759515762,
      "learning_rate": 1.1531699178644763e-05,
      "loss": 0.0008,
      "step": 59950
    },
    {
      "epoch": 3.8501026694045173,
      "grad_norm": 0.07518263906240463,
      "learning_rate": 1.149961498973306e-05,
      "loss": 0.0009,
      "step": 60000
    },
    {
      "epoch": 3.853311088295688,
      "grad_norm": 0.10392250865697861,
      "learning_rate": 1.1467530800821356e-05,
      "loss": 0.0009,
      "step": 60050
    },
    {
      "epoch": 3.8565195071868583,
      "grad_norm": 0.046348877251148224,
      "learning_rate": 1.1435446611909652e-05,
      "loss": 0.0009,
      "step": 60100
    },
    {
      "epoch": 3.859727926078029,
      "grad_norm": 0.060376450419425964,
      "learning_rate": 1.1403362422997946e-05,
      "loss": 0.0008,
      "step": 60150
    },
    {
      "epoch": 3.8629363449691994,
      "grad_norm": 0.05485290288925171,
      "learning_rate": 1.1371278234086243e-05,
      "loss": 0.0009,
      "step": 60200
    },
    {
      "epoch": 3.86614476386037,
      "grad_norm": 0.09732937812805176,
      "learning_rate": 1.1339194045174537e-05,
      "loss": 0.0008,
      "step": 60250
    },
    {
      "epoch": 3.86935318275154,
      "grad_norm": 0.07434561103582382,
      "learning_rate": 1.1307109856262835e-05,
      "loss": 0.0009,
      "step": 60300
    },
    {
      "epoch": 3.8725616016427105,
      "grad_norm": 0.06860944628715515,
      "learning_rate": 1.127502566735113e-05,
      "loss": 0.0008,
      "step": 60350
    },
    {
      "epoch": 3.875770020533881,
      "grad_norm": 0.04486973583698273,
      "learning_rate": 1.1242941478439426e-05,
      "loss": 0.0008,
      "step": 60400
    },
    {
      "epoch": 3.8789784394250515,
      "grad_norm": 0.10476942360401154,
      "learning_rate": 1.121085728952772e-05,
      "loss": 0.0009,
      "step": 60450
    },
    {
      "epoch": 3.8821868583162216,
      "grad_norm": 0.02124197781085968,
      "learning_rate": 1.1178773100616018e-05,
      "loss": 0.0009,
      "step": 60500
    },
    {
      "epoch": 3.885395277207392,
      "grad_norm": 0.024844294413924217,
      "learning_rate": 1.1146688911704313e-05,
      "loss": 0.0009,
      "step": 60550
    },
    {
      "epoch": 3.8886036960985626,
      "grad_norm": 0.03225015476346016,
      "learning_rate": 1.1114604722792609e-05,
      "loss": 0.0009,
      "step": 60600
    },
    {
      "epoch": 3.891812114989733,
      "grad_norm": 0.05804447829723358,
      "learning_rate": 1.1082520533880903e-05,
      "loss": 0.0009,
      "step": 60650
    },
    {
      "epoch": 3.8950205338809036,
      "grad_norm": 0.06888220459222794,
      "learning_rate": 1.10504363449692e-05,
      "loss": 0.0008,
      "step": 60700
    },
    {
      "epoch": 3.898228952772074,
      "grad_norm": 0.05488356575369835,
      "learning_rate": 1.1018352156057496e-05,
      "loss": 0.0008,
      "step": 60750
    },
    {
      "epoch": 3.9014373716632442,
      "grad_norm": 0.15024612843990326,
      "learning_rate": 1.0986267967145792e-05,
      "loss": 0.0008,
      "step": 60800
    },
    {
      "epoch": 3.9046457905544147,
      "grad_norm": 0.027017982676625252,
      "learning_rate": 1.0954183778234086e-05,
      "loss": 0.0008,
      "step": 60850
    },
    {
      "epoch": 3.9078542094455853,
      "grad_norm": 0.06806939840316772,
      "learning_rate": 1.0922099589322383e-05,
      "loss": 0.0008,
      "step": 60900
    },
    {
      "epoch": 3.9110626283367558,
      "grad_norm": 0.06207839772105217,
      "learning_rate": 1.0890015400410677e-05,
      "loss": 0.0008,
      "step": 60950
    },
    {
      "epoch": 3.914271047227926,
      "grad_norm": 0.014891531318426132,
      "learning_rate": 1.0857931211498975e-05,
      "loss": 0.0008,
      "step": 61000
    },
    {
      "epoch": 3.9174794661190964,
      "grad_norm": 0.049549300223588943,
      "learning_rate": 1.082584702258727e-05,
      "loss": 0.0009,
      "step": 61050
    },
    {
      "epoch": 3.920687885010267,
      "grad_norm": 0.05092345178127289,
      "learning_rate": 1.0793762833675566e-05,
      "loss": 0.0008,
      "step": 61100
    },
    {
      "epoch": 3.9238963039014374,
      "grad_norm": 0.10639654099941254,
      "learning_rate": 1.076167864476386e-05,
      "loss": 0.0008,
      "step": 61150
    },
    {
      "epoch": 3.927104722792608,
      "grad_norm": 0.06991773098707199,
      "learning_rate": 1.0729594455852158e-05,
      "loss": 0.0008,
      "step": 61200
    },
    {
      "epoch": 3.9303131416837784,
      "grad_norm": 0.028485221788287163,
      "learning_rate": 1.0697510266940452e-05,
      "loss": 0.0009,
      "step": 61250
    },
    {
      "epoch": 3.9335215605749485,
      "grad_norm": 0.08441741019487381,
      "learning_rate": 1.0665426078028749e-05,
      "loss": 0.0009,
      "step": 61300
    },
    {
      "epoch": 3.936729979466119,
      "grad_norm": 0.10791055858135223,
      "learning_rate": 1.0633341889117043e-05,
      "loss": 0.0008,
      "step": 61350
    },
    {
      "epoch": 3.9399383983572895,
      "grad_norm": 0.03921264037489891,
      "learning_rate": 1.060125770020534e-05,
      "loss": 0.0008,
      "step": 61400
    },
    {
      "epoch": 3.94314681724846,
      "grad_norm": 0.07337675988674164,
      "learning_rate": 1.0569173511293636e-05,
      "loss": 0.0008,
      "step": 61450
    },
    {
      "epoch": 3.94635523613963,
      "grad_norm": 0.07428831607103348,
      "learning_rate": 1.053708932238193e-05,
      "loss": 0.0008,
      "step": 61500
    },
    {
      "epoch": 3.9495636550308006,
      "grad_norm": 0.1231226921081543,
      "learning_rate": 1.0505005133470226e-05,
      "loss": 0.0009,
      "step": 61550
    },
    {
      "epoch": 3.952772073921971,
      "grad_norm": 0.060533493757247925,
      "learning_rate": 1.0472920944558522e-05,
      "loss": 0.0008,
      "step": 61600
    },
    {
      "epoch": 3.9559804928131417,
      "grad_norm": 0.05120943486690521,
      "learning_rate": 1.0440836755646819e-05,
      "loss": 0.0008,
      "step": 61650
    },
    {
      "epoch": 3.959188911704312,
      "grad_norm": 0.1378123015165329,
      "learning_rate": 1.0408752566735113e-05,
      "loss": 0.0008,
      "step": 61700
    },
    {
      "epoch": 3.9623973305954827,
      "grad_norm": 0.09173516184091568,
      "learning_rate": 1.037666837782341e-05,
      "loss": 0.0008,
      "step": 61750
    },
    {
      "epoch": 3.9656057494866532,
      "grad_norm": 0.04267200455069542,
      "learning_rate": 1.0344584188911704e-05,
      "loss": 0.0009,
      "step": 61800
    },
    {
      "epoch": 3.9688141683778233,
      "grad_norm": 0.06091804802417755,
      "learning_rate": 1.03125e-05,
      "loss": 0.0008,
      "step": 61850
    },
    {
      "epoch": 3.972022587268994,
      "grad_norm": 0.09883508086204529,
      "learning_rate": 1.0280415811088296e-05,
      "loss": 0.0008,
      "step": 61900
    },
    {
      "epoch": 3.9752310061601643,
      "grad_norm": 0.04591485857963562,
      "learning_rate": 1.0248331622176592e-05,
      "loss": 0.0008,
      "step": 61950
    },
    {
      "epoch": 3.978439425051335,
      "grad_norm": 0.051857851445674896,
      "learning_rate": 1.0216247433264887e-05,
      "loss": 0.0008,
      "step": 62000
    },
    {
      "epoch": 3.981647843942505,
      "grad_norm": 0.06425599008798599,
      "learning_rate": 1.0184163244353183e-05,
      "loss": 0.0008,
      "step": 62050
    },
    {
      "epoch": 3.9848562628336754,
      "grad_norm": 0.02705252170562744,
      "learning_rate": 1.0152079055441477e-05,
      "loss": 0.0008,
      "step": 62100
    },
    {
      "epoch": 3.988064681724846,
      "grad_norm": 0.04546366259455681,
      "learning_rate": 1.0119994866529775e-05,
      "loss": 0.0008,
      "step": 62150
    },
    {
      "epoch": 3.9912731006160165,
      "grad_norm": 0.030098633840680122,
      "learning_rate": 1.008791067761807e-05,
      "loss": 0.0008,
      "step": 62200
    },
    {
      "epoch": 3.994481519507187,
      "grad_norm": 0.08344104886054993,
      "learning_rate": 1.0055826488706366e-05,
      "loss": 0.0008,
      "step": 62250
    },
    {
      "epoch": 3.9976899383983575,
      "grad_norm": 0.05406738817691803,
      "learning_rate": 1.002374229979466e-05,
      "loss": 0.0008,
      "step": 62300
    },
    {
      "epoch": 4.000898357289528,
      "grad_norm": 0.07939627766609192,
      "learning_rate": 9.991658110882958e-06,
      "loss": 0.0008,
      "step": 62350
    },
    {
      "epoch": 4.0041067761806985,
      "grad_norm": 0.021302873268723488,
      "learning_rate": 9.959573921971253e-06,
      "loss": 0.0008,
      "step": 62400
    },
    {
      "epoch": 4.007315195071868,
      "grad_norm": 0.04215859994292259,
      "learning_rate": 9.927489733059549e-06,
      "loss": 0.0008,
      "step": 62450
    },
    {
      "epoch": 4.010523613963039,
      "grad_norm": 0.05217667296528816,
      "learning_rate": 9.895405544147844e-06,
      "loss": 0.0008,
      "step": 62500
    },
    {
      "epoch": 4.013732032854209,
      "grad_norm": 0.04439941421151161,
      "learning_rate": 9.86332135523614e-06,
      "loss": 0.0008,
      "step": 62550
    },
    {
      "epoch": 4.01694045174538,
      "grad_norm": 0.0795782208442688,
      "learning_rate": 9.831237166324436e-06,
      "loss": 0.0008,
      "step": 62600
    },
    {
      "epoch": 4.02014887063655,
      "grad_norm": 0.019493402913212776,
      "learning_rate": 9.799152977412732e-06,
      "loss": 0.0008,
      "step": 62650
    },
    {
      "epoch": 4.023357289527721,
      "grad_norm": 0.13297730684280396,
      "learning_rate": 9.767068788501027e-06,
      "loss": 0.0008,
      "step": 62700
    },
    {
      "epoch": 4.026565708418891,
      "grad_norm": 0.1491203010082245,
      "learning_rate": 9.734984599589323e-06,
      "loss": 0.0009,
      "step": 62750
    },
    {
      "epoch": 4.029774127310062,
      "grad_norm": 0.06082943454384804,
      "learning_rate": 9.702900410677619e-06,
      "loss": 0.0008,
      "step": 62800
    },
    {
      "epoch": 4.032982546201232,
      "grad_norm": 0.1138136014342308,
      "learning_rate": 9.670816221765915e-06,
      "loss": 0.0009,
      "step": 62850
    },
    {
      "epoch": 4.036190965092403,
      "grad_norm": 0.044296689331531525,
      "learning_rate": 9.63873203285421e-06,
      "loss": 0.0008,
      "step": 62900
    },
    {
      "epoch": 4.0393993839835725,
      "grad_norm": 0.029991289600729942,
      "learning_rate": 9.606647843942506e-06,
      "loss": 0.0008,
      "step": 62950
    },
    {
      "epoch": 4.042607802874743,
      "grad_norm": 0.11574723571538925,
      "learning_rate": 9.5745636550308e-06,
      "loss": 0.0008,
      "step": 63000
    },
    {
      "epoch": 4.0458162217659135,
      "grad_norm": 0.06401173025369644,
      "learning_rate": 9.542479466119098e-06,
      "loss": 0.0008,
      "step": 63050
    },
    {
      "epoch": 4.049024640657084,
      "grad_norm": 0.05362032726407051,
      "learning_rate": 9.510395277207393e-06,
      "loss": 0.0008,
      "step": 63100
    },
    {
      "epoch": 4.0522330595482545,
      "grad_norm": 0.12791967391967773,
      "learning_rate": 9.478311088295689e-06,
      "loss": 0.0008,
      "step": 63150
    },
    {
      "epoch": 4.055441478439425,
      "grad_norm": 0.08312946557998657,
      "learning_rate": 9.446226899383983e-06,
      "loss": 0.0008,
      "step": 63200
    },
    {
      "epoch": 4.058649897330596,
      "grad_norm": 0.0676550343632698,
      "learning_rate": 9.41414271047228e-06,
      "loss": 0.0008,
      "step": 63250
    },
    {
      "epoch": 4.061858316221766,
      "grad_norm": 0.06592757254838943,
      "learning_rate": 9.382058521560576e-06,
      "loss": 0.0008,
      "step": 63300
    },
    {
      "epoch": 4.065066735112937,
      "grad_norm": 0.052250154316425323,
      "learning_rate": 9.34997433264887e-06,
      "loss": 0.0008,
      "step": 63350
    },
    {
      "epoch": 4.068275154004107,
      "grad_norm": 0.02904587611556053,
      "learning_rate": 9.317890143737167e-06,
      "loss": 0.0008,
      "step": 63400
    },
    {
      "epoch": 4.071483572895278,
      "grad_norm": 0.1495562046766281,
      "learning_rate": 9.285805954825463e-06,
      "loss": 0.0008,
      "step": 63450
    },
    {
      "epoch": 4.074691991786447,
      "grad_norm": 0.015742452815175056,
      "learning_rate": 9.253721765913759e-06,
      "loss": 0.0008,
      "step": 63500
    },
    {
      "epoch": 4.077900410677618,
      "grad_norm": 0.06550528854131699,
      "learning_rate": 9.221637577002053e-06,
      "loss": 0.0008,
      "step": 63550
    },
    {
      "epoch": 4.081108829568788,
      "grad_norm": 0.04704950377345085,
      "learning_rate": 9.18955338809035e-06,
      "loss": 0.0008,
      "step": 63600
    },
    {
      "epoch": 4.084317248459959,
      "grad_norm": 0.06308431923389435,
      "learning_rate": 9.157469199178644e-06,
      "loss": 0.0008,
      "step": 63650
    },
    {
      "epoch": 4.087525667351129,
      "grad_norm": 0.06858543306589127,
      "learning_rate": 9.12538501026694e-06,
      "loss": 0.0008,
      "step": 63700
    },
    {
      "epoch": 4.0907340862423,
      "grad_norm": 0.07022622227668762,
      "learning_rate": 9.093300821355236e-06,
      "loss": 0.0008,
      "step": 63750
    },
    {
      "epoch": 4.09394250513347,
      "grad_norm": 0.06848927587270737,
      "learning_rate": 9.061216632443533e-06,
      "loss": 0.0008,
      "step": 63800
    },
    {
      "epoch": 4.097150924024641,
      "grad_norm": 0.04227512329816818,
      "learning_rate": 9.029132443531827e-06,
      "loss": 0.0008,
      "step": 63850
    },
    {
      "epoch": 4.100359342915811,
      "grad_norm": 0.05883003771305084,
      "learning_rate": 8.997048254620123e-06,
      "loss": 0.0008,
      "step": 63900
    },
    {
      "epoch": 4.103567761806982,
      "grad_norm": 0.03691905364394188,
      "learning_rate": 8.96496406570842e-06,
      "loss": 0.0008,
      "step": 63950
    },
    {
      "epoch": 4.1067761806981515,
      "grad_norm": 0.04831087216734886,
      "learning_rate": 8.932879876796716e-06,
      "loss": 0.0008,
      "step": 64000
    },
    {
      "epoch": 4.109984599589322,
      "grad_norm": 0.05360722169280052,
      "learning_rate": 8.90079568788501e-06,
      "loss": 0.0008,
      "step": 64050
    },
    {
      "epoch": 4.113193018480493,
      "grad_norm": 0.046813301742076874,
      "learning_rate": 8.868711498973306e-06,
      "loss": 0.0008,
      "step": 64100
    },
    {
      "epoch": 4.116401437371663,
      "grad_norm": 0.019755296409130096,
      "learning_rate": 8.836627310061601e-06,
      "loss": 0.0008,
      "step": 64150
    },
    {
      "epoch": 4.119609856262834,
      "grad_norm": 0.03860253840684891,
      "learning_rate": 8.804543121149899e-06,
      "loss": 0.0008,
      "step": 64200
    },
    {
      "epoch": 4.122818275154004,
      "grad_norm": 0.12595130503177643,
      "learning_rate": 8.772458932238193e-06,
      "loss": 0.0008,
      "step": 64250
    },
    {
      "epoch": 4.126026694045175,
      "grad_norm": 0.038856085389852524,
      "learning_rate": 8.74037474332649e-06,
      "loss": 0.0008,
      "step": 64300
    },
    {
      "epoch": 4.129235112936345,
      "grad_norm": 0.03238331899046898,
      "learning_rate": 8.708290554414784e-06,
      "loss": 0.0008,
      "step": 64350
    },
    {
      "epoch": 4.132443531827516,
      "grad_norm": 0.03059632144868374,
      "learning_rate": 8.676206365503082e-06,
      "loss": 0.0008,
      "step": 64400
    },
    {
      "epoch": 4.135651950718686,
      "grad_norm": 0.05718692019581795,
      "learning_rate": 8.644122176591376e-06,
      "loss": 0.0008,
      "step": 64450
    },
    {
      "epoch": 4.138860369609857,
      "grad_norm": 0.08331944793462753,
      "learning_rate": 8.612037987679673e-06,
      "loss": 0.0008,
      "step": 64500
    },
    {
      "epoch": 4.142068788501026,
      "grad_norm": 0.10712829977273941,
      "learning_rate": 8.579953798767967e-06,
      "loss": 0.0008,
      "step": 64550
    },
    {
      "epoch": 4.145277207392197,
      "grad_norm": 0.04401343688368797,
      "learning_rate": 8.547869609856263e-06,
      "loss": 0.0008,
      "step": 64600
    },
    {
      "epoch": 4.148485626283367,
      "grad_norm": 0.12121530622243881,
      "learning_rate": 8.51578542094456e-06,
      "loss": 0.0008,
      "step": 64650
    },
    {
      "epoch": 4.151694045174538,
      "grad_norm": 0.09963814169168472,
      "learning_rate": 8.483701232032856e-06,
      "loss": 0.0008,
      "step": 64700
    },
    {
      "epoch": 4.154902464065708,
      "grad_norm": 0.024746118113398552,
      "learning_rate": 8.45161704312115e-06,
      "loss": 0.0008,
      "step": 64750
    },
    {
      "epoch": 4.158110882956879,
      "grad_norm": 0.06062495708465576,
      "learning_rate": 8.419532854209446e-06,
      "loss": 0.0008,
      "step": 64800
    },
    {
      "epoch": 4.161319301848049,
      "grad_norm": 0.11168163269758224,
      "learning_rate": 8.38744866529774e-06,
      "loss": 0.0008,
      "step": 64850
    },
    {
      "epoch": 4.16452772073922,
      "grad_norm": 0.09685870260000229,
      "learning_rate": 8.355364476386039e-06,
      "loss": 0.0008,
      "step": 64900
    },
    {
      "epoch": 4.1677361396303905,
      "grad_norm": 0.04293064400553703,
      "learning_rate": 8.323280287474333e-06,
      "loss": 0.0008,
      "step": 64950
    },
    {
      "epoch": 4.170944558521561,
      "grad_norm": 0.06951943784952164,
      "learning_rate": 8.29119609856263e-06,
      "loss": 0.0008,
      "step": 65000
    },
    {
      "epoch": 4.174152977412731,
      "grad_norm": 0.05245884135365486,
      "learning_rate": 8.259111909650924e-06,
      "loss": 0.0008,
      "step": 65050
    },
    {
      "epoch": 4.177361396303901,
      "grad_norm": 0.02075710892677307,
      "learning_rate": 8.22702772073922e-06,
      "loss": 0.0008,
      "step": 65100
    },
    {
      "epoch": 4.180569815195072,
      "grad_norm": 0.055186837911605835,
      "learning_rate": 8.194943531827516e-06,
      "loss": 0.0008,
      "step": 65150
    },
    {
      "epoch": 4.183778234086242,
      "grad_norm": 0.037967853248119354,
      "learning_rate": 8.16285934291581e-06,
      "loss": 0.0008,
      "step": 65200
    },
    {
      "epoch": 4.186986652977413,
      "grad_norm": 0.07467187196016312,
      "learning_rate": 8.130775154004107e-06,
      "loss": 0.0009,
      "step": 65250
    },
    {
      "epoch": 4.190195071868583,
      "grad_norm": 0.05147552117705345,
      "learning_rate": 8.098690965092403e-06,
      "loss": 0.0008,
      "step": 65300
    },
    {
      "epoch": 4.193403490759754,
      "grad_norm": 0.029009131714701653,
      "learning_rate": 8.0666067761807e-06,
      "loss": 0.0008,
      "step": 65350
    },
    {
      "epoch": 4.196611909650924,
      "grad_norm": 0.07520772516727448,
      "learning_rate": 8.034522587268994e-06,
      "loss": 0.0008,
      "step": 65400
    },
    {
      "epoch": 4.199820328542095,
      "grad_norm": 0.04894349351525307,
      "learning_rate": 8.00243839835729e-06,
      "loss": 0.0008,
      "step": 65450
    },
    {
      "epoch": 4.203028747433265,
      "grad_norm": 0.03739264979958534,
      "learning_rate": 7.970354209445584e-06,
      "loss": 0.0008,
      "step": 65500
    },
    {
      "epoch": 4.206237166324435,
      "grad_norm": 0.048905763775110245,
      "learning_rate": 7.938270020533882e-06,
      "loss": 0.0008,
      "step": 65550
    },
    {
      "epoch": 4.209445585215605,
      "grad_norm": 0.05107412859797478,
      "learning_rate": 7.906185831622177e-06,
      "loss": 0.0008,
      "step": 65600
    },
    {
      "epoch": 4.212654004106776,
      "grad_norm": 0.06691903620958328,
      "learning_rate": 7.874101642710473e-06,
      "loss": 0.0008,
      "step": 65650
    },
    {
      "epoch": 4.2158624229979464,
      "grad_norm": 0.09112159162759781,
      "learning_rate": 7.842017453798767e-06,
      "loss": 0.0008,
      "step": 65700
    },
    {
      "epoch": 4.219070841889117,
      "grad_norm": 0.03200085088610649,
      "learning_rate": 7.809933264887064e-06,
      "loss": 0.0008,
      "step": 65750
    },
    {
      "epoch": 4.2222792607802875,
      "grad_norm": 0.06572477519512177,
      "learning_rate": 7.77784907597536e-06,
      "loss": 0.0008,
      "step": 65800
    },
    {
      "epoch": 4.225487679671458,
      "grad_norm": 0.1495998501777649,
      "learning_rate": 7.745764887063656e-06,
      "loss": 0.0008,
      "step": 65850
    },
    {
      "epoch": 4.2286960985626285,
      "grad_norm": 0.12933625280857086,
      "learning_rate": 7.71368069815195e-06,
      "loss": 0.0009,
      "step": 65900
    },
    {
      "epoch": 4.231904517453799,
      "grad_norm": 0.11832653731107712,
      "learning_rate": 7.681596509240247e-06,
      "loss": 0.0008,
      "step": 65950
    },
    {
      "epoch": 4.2351129363449695,
      "grad_norm": 0.05193443223834038,
      "learning_rate": 7.649512320328541e-06,
      "loss": 0.0008,
      "step": 66000
    },
    {
      "epoch": 4.23832135523614,
      "grad_norm": 0.13402917981147766,
      "learning_rate": 7.617428131416838e-06,
      "loss": 0.0009,
      "step": 66050
    },
    {
      "epoch": 4.24152977412731,
      "grad_norm": 0.057130325585603714,
      "learning_rate": 7.585343942505134e-06,
      "loss": 0.0008,
      "step": 66100
    },
    {
      "epoch": 4.24473819301848,
      "grad_norm": 0.09705296903848648,
      "learning_rate": 7.55325975359343e-06,
      "loss": 0.0008,
      "step": 66150
    },
    {
      "epoch": 4.247946611909651,
      "grad_norm": 0.04362183436751366,
      "learning_rate": 7.521175564681725e-06,
      "loss": 0.0008,
      "step": 66200
    },
    {
      "epoch": 4.251155030800821,
      "grad_norm": 0.030320199206471443,
      "learning_rate": 7.489091375770021e-06,
      "loss": 0.0008,
      "step": 66250
    },
    {
      "epoch": 4.254363449691992,
      "grad_norm": 0.02341199293732643,
      "learning_rate": 7.457007186858317e-06,
      "loss": 0.0008,
      "step": 66300
    },
    {
      "epoch": 4.257571868583162,
      "grad_norm": 0.08012474328279495,
      "learning_rate": 7.424922997946612e-06,
      "loss": 0.0008,
      "step": 66350
    },
    {
      "epoch": 4.260780287474333,
      "grad_norm": 0.024972351267933846,
      "learning_rate": 7.392838809034907e-06,
      "loss": 0.0008,
      "step": 66400
    },
    {
      "epoch": 4.263988706365503,
      "grad_norm": 0.04487193003296852,
      "learning_rate": 7.360754620123203e-06,
      "loss": 0.0008,
      "step": 66450
    },
    {
      "epoch": 4.267197125256674,
      "grad_norm": 0.1752110868692398,
      "learning_rate": 7.3286704312115e-06,
      "loss": 0.0008,
      "step": 66500
    },
    {
      "epoch": 4.270405544147844,
      "grad_norm": 0.08204095810651779,
      "learning_rate": 7.296586242299795e-06,
      "loss": 0.0008,
      "step": 66550
    },
    {
      "epoch": 4.273613963039014,
      "grad_norm": 0.02995627000927925,
      "learning_rate": 7.26450205338809e-06,
      "loss": 0.0008,
      "step": 66600
    },
    {
      "epoch": 4.2768223819301845,
      "grad_norm": 0.04880526289343834,
      "learning_rate": 7.232417864476386e-06,
      "loss": 0.0008,
      "step": 66650
    },
    {
      "epoch": 4.280030800821355,
      "grad_norm": 0.09955572336912155,
      "learning_rate": 7.200333675564683e-06,
      "loss": 0.0008,
      "step": 66700
    },
    {
      "epoch": 4.2832392197125255,
      "grad_norm": 0.06132153794169426,
      "learning_rate": 7.168249486652978e-06,
      "loss": 0.0008,
      "step": 66750
    },
    {
      "epoch": 4.286447638603696,
      "grad_norm": 0.11073917150497437,
      "learning_rate": 7.1361652977412734e-06,
      "loss": 0.0008,
      "step": 66800
    },
    {
      "epoch": 4.289656057494867,
      "grad_norm": 0.09828080236911774,
      "learning_rate": 7.104081108829569e-06,
      "loss": 0.0009,
      "step": 66850
    },
    {
      "epoch": 4.292864476386037,
      "grad_norm": 0.09550988674163818,
      "learning_rate": 7.071996919917864e-06,
      "loss": 0.0008,
      "step": 66900
    },
    {
      "epoch": 4.296072895277208,
      "grad_norm": 0.11209523677825928,
      "learning_rate": 7.039912731006161e-06,
      "loss": 0.0008,
      "step": 66950
    },
    {
      "epoch": 4.299281314168378,
      "grad_norm": 0.03646034747362137,
      "learning_rate": 7.0078285420944565e-06,
      "loss": 0.0008,
      "step": 67000
    },
    {
      "epoch": 4.302489733059549,
      "grad_norm": 0.03864361718297005,
      "learning_rate": 6.975744353182752e-06,
      "loss": 0.0008,
      "step": 67050
    },
    {
      "epoch": 4.305698151950718,
      "grad_norm": 0.11000748723745346,
      "learning_rate": 6.943660164271047e-06,
      "loss": 0.0008,
      "step": 67100
    },
    {
      "epoch": 4.308906570841889,
      "grad_norm": 0.07927615195512772,
      "learning_rate": 6.9115759753593425e-06,
      "loss": 0.0008,
      "step": 67150
    },
    {
      "epoch": 4.312114989733059,
      "grad_norm": 0.040388330817222595,
      "learning_rate": 6.8794917864476396e-06,
      "loss": 0.0008,
      "step": 67200
    },
    {
      "epoch": 4.31532340862423,
      "grad_norm": 0.12964656949043274,
      "learning_rate": 6.847407597535935e-06,
      "loss": 0.0008,
      "step": 67250
    },
    {
      "epoch": 4.3185318275154,
      "grad_norm": 0.02841239422559738,
      "learning_rate": 6.81532340862423e-06,
      "loss": 0.0008,
      "step": 67300
    },
    {
      "epoch": 4.321740246406571,
      "grad_norm": 0.1042371466755867,
      "learning_rate": 6.783239219712526e-06,
      "loss": 0.0008,
      "step": 67350
    },
    {
      "epoch": 4.324948665297741,
      "grad_norm": 0.03576728329062462,
      "learning_rate": 6.751155030800823e-06,
      "loss": 0.0008,
      "step": 67400
    },
    {
      "epoch": 4.328157084188912,
      "grad_norm": 0.0486450269818306,
      "learning_rate": 6.719070841889118e-06,
      "loss": 0.0008,
      "step": 67450
    },
    {
      "epoch": 4.331365503080082,
      "grad_norm": 0.09483544528484344,
      "learning_rate": 6.686986652977413e-06,
      "loss": 0.0008,
      "step": 67500
    },
    {
      "epoch": 4.334573921971253,
      "grad_norm": 0.0564199760556221,
      "learning_rate": 6.654902464065709e-06,
      "loss": 0.0008,
      "step": 67550
    },
    {
      "epoch": 4.337782340862423,
      "grad_norm": 0.12570826709270477,
      "learning_rate": 6.622818275154004e-06,
      "loss": 0.0008,
      "step": 67600
    },
    {
      "epoch": 4.340990759753593,
      "grad_norm": 0.01975664310157299,
      "learning_rate": 6.590734086242301e-06,
      "loss": 0.0008,
      "step": 67650
    },
    {
      "epoch": 4.344199178644764,
      "grad_norm": 0.06710817664861679,
      "learning_rate": 6.558649897330596e-06,
      "loss": 0.0008,
      "step": 67700
    },
    {
      "epoch": 4.347407597535934,
      "grad_norm": 0.08618036657571793,
      "learning_rate": 6.526565708418892e-06,
      "loss": 0.0008,
      "step": 67750
    },
    {
      "epoch": 4.350616016427105,
      "grad_norm": 0.09629451483488083,
      "learning_rate": 6.494481519507187e-06,
      "loss": 0.0008,
      "step": 67800
    },
    {
      "epoch": 4.353824435318275,
      "grad_norm": 0.030506446957588196,
      "learning_rate": 6.462397330595483e-06,
      "loss": 0.0008,
      "step": 67850
    },
    {
      "epoch": 4.357032854209446,
      "grad_norm": 0.09749477356672287,
      "learning_rate": 6.4303131416837786e-06,
      "loss": 0.0008,
      "step": 67900
    },
    {
      "epoch": 4.360241273100616,
      "grad_norm": 0.09621650725603104,
      "learning_rate": 6.398228952772074e-06,
      "loss": 0.0008,
      "step": 67950
    },
    {
      "epoch": 4.363449691991787,
      "grad_norm": 0.04524003714323044,
      "learning_rate": 6.36614476386037e-06,
      "loss": 0.0008,
      "step": 68000
    },
    {
      "epoch": 4.366658110882957,
      "grad_norm": 0.13733774423599243,
      "learning_rate": 6.3340605749486654e-06,
      "loss": 0.0008,
      "step": 68050
    },
    {
      "epoch": 4.369866529774128,
      "grad_norm": 0.04619870334863663,
      "learning_rate": 6.301976386036962e-06,
      "loss": 0.0008,
      "step": 68100
    },
    {
      "epoch": 4.373074948665297,
      "grad_norm": 0.021840820088982582,
      "learning_rate": 6.269892197125257e-06,
      "loss": 0.0008,
      "step": 68150
    },
    {
      "epoch": 4.376283367556468,
      "grad_norm": 0.08750026673078537,
      "learning_rate": 6.237808008213552e-06,
      "loss": 0.0008,
      "step": 68200
    },
    {
      "epoch": 4.379491786447638,
      "grad_norm": 0.09205156564712524,
      "learning_rate": 6.2057238193018485e-06,
      "loss": 0.0008,
      "step": 68250
    },
    {
      "epoch": 4.382700205338809,
      "grad_norm": 0.043002497404813766,
      "learning_rate": 6.173639630390144e-06,
      "loss": 0.0008,
      "step": 68300
    },
    {
      "epoch": 4.385908624229979,
      "grad_norm": 0.0652446374297142,
      "learning_rate": 6.141555441478439e-06,
      "loss": 0.0008,
      "step": 68350
    },
    {
      "epoch": 4.38911704312115,
      "grad_norm": 0.02976992353796959,
      "learning_rate": 6.109471252566735e-06,
      "loss": 0.0008,
      "step": 68400
    },
    {
      "epoch": 4.39232546201232,
      "grad_norm": 0.025540269911289215,
      "learning_rate": 6.077387063655031e-06,
      "loss": 0.0008,
      "step": 68450
    },
    {
      "epoch": 4.395533880903491,
      "grad_norm": 0.153174489736557,
      "learning_rate": 6.045302874743327e-06,
      "loss": 0.0008,
      "step": 68500
    },
    {
      "epoch": 4.3987422997946615,
      "grad_norm": 0.02165900729596615,
      "learning_rate": 6.013218685831622e-06,
      "loss": 0.0009,
      "step": 68550
    },
    {
      "epoch": 4.401950718685832,
      "grad_norm": 0.046911243349313736,
      "learning_rate": 5.9811344969199184e-06,
      "loss": 0.0008,
      "step": 68600
    },
    {
      "epoch": 4.405159137577002,
      "grad_norm": 0.08104237169027328,
      "learning_rate": 5.949050308008214e-06,
      "loss": 0.0008,
      "step": 68650
    },
    {
      "epoch": 4.408367556468172,
      "grad_norm": 0.10180795937776566,
      "learning_rate": 5.916966119096509e-06,
      "loss": 0.0008,
      "step": 68700
    },
    {
      "epoch": 4.411575975359343,
      "grad_norm": 0.044593192636966705,
      "learning_rate": 5.884881930184805e-06,
      "loss": 0.0008,
      "step": 68750
    },
    {
      "epoch": 4.414784394250513,
      "grad_norm": 0.12307663261890411,
      "learning_rate": 5.852797741273101e-06,
      "loss": 0.0008,
      "step": 68800
    },
    {
      "epoch": 4.417992813141684,
      "grad_norm": 0.11239205300807953,
      "learning_rate": 5.820713552361397e-06,
      "loss": 0.0008,
      "step": 68850
    },
    {
      "epoch": 4.421201232032854,
      "grad_norm": 0.12645983695983887,
      "learning_rate": 5.788629363449692e-06,
      "loss": 0.0008,
      "step": 68900
    },
    {
      "epoch": 4.424409650924025,
      "grad_norm": 0.017184626311063766,
      "learning_rate": 5.756545174537988e-06,
      "loss": 0.0008,
      "step": 68950
    },
    {
      "epoch": 4.427618069815195,
      "grad_norm": 0.05628456175327301,
      "learning_rate": 5.724460985626284e-06,
      "loss": 0.0008,
      "step": 69000
    },
    {
      "epoch": 4.430826488706366,
      "grad_norm": 0.05878378078341484,
      "learning_rate": 5.692376796714579e-06,
      "loss": 0.0008,
      "step": 69050
    },
    {
      "epoch": 4.434034907597536,
      "grad_norm": 0.06024207919836044,
      "learning_rate": 5.660292607802875e-06,
      "loss": 0.0008,
      "step": 69100
    },
    {
      "epoch": 4.437243326488707,
      "grad_norm": 0.026089515537023544,
      "learning_rate": 5.6282084188911706e-06,
      "loss": 0.0008,
      "step": 69150
    },
    {
      "epoch": 4.440451745379876,
      "grad_norm": 0.05541927367448807,
      "learning_rate": 5.596124229979467e-06,
      "loss": 0.0008,
      "step": 69200
    },
    {
      "epoch": 4.443660164271047,
      "grad_norm": 0.08504440635442734,
      "learning_rate": 5.564040041067762e-06,
      "loss": 0.0008,
      "step": 69250
    },
    {
      "epoch": 4.4468685831622174,
      "grad_norm": 0.1067541316151619,
      "learning_rate": 5.531955852156058e-06,
      "loss": 0.0008,
      "step": 69300
    },
    {
      "epoch": 4.450077002053388,
      "grad_norm": 0.07149607688188553,
      "learning_rate": 5.499871663244354e-06,
      "loss": 0.0008,
      "step": 69350
    },
    {
      "epoch": 4.4532854209445585,
      "grad_norm": 0.1104925349354744,
      "learning_rate": 5.46778747433265e-06,
      "loss": 0.0008,
      "step": 69400
    },
    {
      "epoch": 4.456493839835729,
      "grad_norm": 0.08709146082401276,
      "learning_rate": 5.435703285420945e-06,
      "loss": 0.0008,
      "step": 69450
    },
    {
      "epoch": 4.4597022587268995,
      "grad_norm": 0.16690123081207275,
      "learning_rate": 5.4036190965092405e-06,
      "loss": 0.0008,
      "step": 69500
    },
    {
      "epoch": 4.46291067761807,
      "grad_norm": 0.07800566405057907,
      "learning_rate": 5.371534907597537e-06,
      "loss": 0.0008,
      "step": 69550
    },
    {
      "epoch": 4.4661190965092405,
      "grad_norm": 0.06953910738229752,
      "learning_rate": 5.339450718685832e-06,
      "loss": 0.0008,
      "step": 69600
    },
    {
      "epoch": 4.469327515400411,
      "grad_norm": 0.06988538056612015,
      "learning_rate": 5.307366529774127e-06,
      "loss": 0.0008,
      "step": 69650
    },
    {
      "epoch": 4.472535934291581,
      "grad_norm": 0.021459123119711876,
      "learning_rate": 5.2752823408624236e-06,
      "loss": 0.0008,
      "step": 69700
    },
    {
      "epoch": 4.475744353182751,
      "grad_norm": 0.0764225497841835,
      "learning_rate": 5.243198151950719e-06,
      "loss": 0.0008,
      "step": 69750
    },
    {
      "epoch": 4.478952772073922,
      "grad_norm": 0.11133342236280441,
      "learning_rate": 5.211113963039014e-06,
      "loss": 0.0008,
      "step": 69800
    },
    {
      "epoch": 4.482161190965092,
      "grad_norm": 0.10216323286294937,
      "learning_rate": 5.17902977412731e-06,
      "loss": 0.0008,
      "step": 69850
    },
    {
      "epoch": 4.485369609856263,
      "grad_norm": 0.0878148227930069,
      "learning_rate": 5.146945585215606e-06,
      "loss": 0.0008,
      "step": 69900
    },
    {
      "epoch": 4.488578028747433,
      "grad_norm": 0.025157133117318153,
      "learning_rate": 5.114861396303901e-06,
      "loss": 0.0008,
      "step": 69950
    },
    {
      "epoch": 4.491786447638604,
      "grad_norm": 0.05180885270237923,
      "learning_rate": 5.082777207392197e-06,
      "loss": 0.0008,
      "step": 70000
    },
    {
      "epoch": 4.494994866529774,
      "grad_norm": 0.16402758657932281,
      "learning_rate": 5.050693018480493e-06,
      "loss": 0.0008,
      "step": 70050
    },
    {
      "epoch": 4.498203285420945,
      "grad_norm": 0.033780310302972794,
      "learning_rate": 5.018608829568789e-06,
      "loss": 0.0008,
      "step": 70100
    },
    {
      "epoch": 4.501411704312115,
      "grad_norm": 0.021913131698966026,
      "learning_rate": 4.986524640657084e-06,
      "loss": 0.0008,
      "step": 70150
    },
    {
      "epoch": 4.504620123203285,
      "grad_norm": 0.042328204959630966,
      "learning_rate": 4.9544404517453795e-06,
      "loss": 0.0008,
      "step": 70200
    },
    {
      "epoch": 4.5078285420944555,
      "grad_norm": 0.09128446131944656,
      "learning_rate": 4.922356262833676e-06,
      "loss": 0.0008,
      "step": 70250
    },
    {
      "epoch": 4.511036960985626,
      "grad_norm": 0.047771014273166656,
      "learning_rate": 4.890272073921971e-06,
      "loss": 0.0008,
      "step": 70300
    },
    {
      "epoch": 4.5142453798767965,
      "grad_norm": 0.047801073640584946,
      "learning_rate": 4.858187885010267e-06,
      "loss": 0.0008,
      "step": 70350
    },
    {
      "epoch": 4.517453798767967,
      "grad_norm": 0.10367394983768463,
      "learning_rate": 4.8261036960985626e-06,
      "loss": 0.0008,
      "step": 70400
    },
    {
      "epoch": 4.520662217659138,
      "grad_norm": 0.06359661370515823,
      "learning_rate": 4.794019507186859e-06,
      "loss": 0.0008,
      "step": 70450
    },
    {
      "epoch": 4.523870636550308,
      "grad_norm": 0.07276332378387451,
      "learning_rate": 4.761935318275154e-06,
      "loss": 0.0008,
      "step": 70500
    },
    {
      "epoch": 4.527079055441479,
      "grad_norm": 0.032470494508743286,
      "learning_rate": 4.72985112936345e-06,
      "loss": 0.0008,
      "step": 70550
    },
    {
      "epoch": 4.530287474332649,
      "grad_norm": 0.041322968900203705,
      "learning_rate": 4.697766940451746e-06,
      "loss": 0.0008,
      "step": 70600
    },
    {
      "epoch": 4.53349589322382,
      "grad_norm": 0.04020768404006958,
      "learning_rate": 4.665682751540041e-06,
      "loss": 0.0008,
      "step": 70650
    },
    {
      "epoch": 4.53670431211499,
      "grad_norm": 0.039488762617111206,
      "learning_rate": 4.633598562628337e-06,
      "loss": 0.0008,
      "step": 70700
    },
    {
      "epoch": 4.53991273100616,
      "grad_norm": 0.054269127547740936,
      "learning_rate": 4.6015143737166325e-06,
      "loss": 0.0008,
      "step": 70750
    },
    {
      "epoch": 4.54312114989733,
      "grad_norm": 0.087346151471138,
      "learning_rate": 4.569430184804929e-06,
      "loss": 0.0008,
      "step": 70800
    },
    {
      "epoch": 4.546329568788501,
      "grad_norm": 0.026839544996619225,
      "learning_rate": 4.537345995893224e-06,
      "loss": 0.0008,
      "step": 70850
    },
    {
      "epoch": 4.549537987679671,
      "grad_norm": 0.1007123738527298,
      "learning_rate": 4.50526180698152e-06,
      "loss": 0.0008,
      "step": 70900
    },
    {
      "epoch": 4.552746406570842,
      "grad_norm": 0.06270897388458252,
      "learning_rate": 4.4731776180698156e-06,
      "loss": 0.0008,
      "step": 70950
    },
    {
      "epoch": 4.555954825462012,
      "grad_norm": 0.07409001886844635,
      "learning_rate": 4.441093429158111e-06,
      "loss": 0.0008,
      "step": 71000
    },
    {
      "epoch": 4.559163244353183,
      "grad_norm": 0.0759572982788086,
      "learning_rate": 4.409009240246407e-06,
      "loss": 0.0008,
      "step": 71050
    },
    {
      "epoch": 4.562371663244353,
      "grad_norm": 0.0651032030582428,
      "learning_rate": 4.376925051334702e-06,
      "loss": 0.0008,
      "step": 71100
    },
    {
      "epoch": 4.565580082135524,
      "grad_norm": 0.10003601759672165,
      "learning_rate": 4.344840862422999e-06,
      "loss": 0.0008,
      "step": 71150
    },
    {
      "epoch": 4.568788501026694,
      "grad_norm": 0.05325401946902275,
      "learning_rate": 4.312756673511294e-06,
      "loss": 0.0008,
      "step": 71200
    },
    {
      "epoch": 4.571996919917865,
      "grad_norm": 0.03243890404701233,
      "learning_rate": 4.28067248459959e-06,
      "loss": 0.0008,
      "step": 71250
    },
    {
      "epoch": 4.575205338809035,
      "grad_norm": 0.06093502417206764,
      "learning_rate": 4.2485882956878855e-06,
      "loss": 0.0008,
      "step": 71300
    },
    {
      "epoch": 4.578413757700205,
      "grad_norm": 0.018901130184531212,
      "learning_rate": 4.216504106776181e-06,
      "loss": 0.0008,
      "step": 71350
    },
    {
      "epoch": 4.581622176591376,
      "grad_norm": 0.09837940335273743,
      "learning_rate": 4.184419917864477e-06,
      "loss": 0.0008,
      "step": 71400
    },
    {
      "epoch": 4.584830595482546,
      "grad_norm": 0.04248761385679245,
      "learning_rate": 4.152335728952772e-06,
      "loss": 0.0008,
      "step": 71450
    },
    {
      "epoch": 4.588039014373717,
      "grad_norm": 0.08447445183992386,
      "learning_rate": 4.120251540041068e-06,
      "loss": 0.0008,
      "step": 71500
    },
    {
      "epoch": 4.591247433264887,
      "grad_norm": 0.07604562491178513,
      "learning_rate": 4.088167351129364e-06,
      "loss": 0.0008,
      "step": 71550
    },
    {
      "epoch": 4.594455852156058,
      "grad_norm": 0.06407102197408676,
      "learning_rate": 4.056083162217659e-06,
      "loss": 0.0008,
      "step": 71600
    },
    {
      "epoch": 4.597664271047228,
      "grad_norm": 0.03302459791302681,
      "learning_rate": 4.0239989733059546e-06,
      "loss": 0.0008,
      "step": 71650
    },
    {
      "epoch": 4.600872689938399,
      "grad_norm": 0.16934409737586975,
      "learning_rate": 3.991914784394251e-06,
      "loss": 0.0008,
      "step": 71700
    },
    {
      "epoch": 4.604081108829568,
      "grad_norm": 0.019870249554514885,
      "learning_rate": 3.959830595482546e-06,
      "loss": 0.0008,
      "step": 71750
    },
    {
      "epoch": 4.607289527720739,
      "grad_norm": 0.11063496023416519,
      "learning_rate": 3.9277464065708414e-06,
      "loss": 0.0008,
      "step": 71800
    },
    {
      "epoch": 4.610497946611909,
      "grad_norm": 0.10380612313747406,
      "learning_rate": 3.895662217659138e-06,
      "loss": 0.0008,
      "step": 71850
    },
    {
      "epoch": 4.61370636550308,
      "grad_norm": 0.1219426766037941,
      "learning_rate": 3.863578028747433e-06,
      "loss": 0.0008,
      "step": 71900
    },
    {
      "epoch": 4.61691478439425,
      "grad_norm": 0.13954567909240723,
      "learning_rate": 3.831493839835729e-06,
      "loss": 0.0008,
      "step": 71950
    },
    {
      "epoch": 4.620123203285421,
      "grad_norm": 0.02865729108452797,
      "learning_rate": 3.799409650924025e-06,
      "loss": 0.0008,
      "step": 72000
    },
    {
      "epoch": 4.623331622176591,
      "grad_norm": 0.15241526067256927,
      "learning_rate": 3.7673254620123207e-06,
      "loss": 0.0008,
      "step": 72050
    },
    {
      "epoch": 4.626540041067762,
      "grad_norm": 0.0342104509472847,
      "learning_rate": 3.735241273100616e-06,
      "loss": 0.0008,
      "step": 72100
    },
    {
      "epoch": 4.6297484599589325,
      "grad_norm": 0.08582538366317749,
      "learning_rate": 3.7031570841889114e-06,
      "loss": 0.0008,
      "step": 72150
    },
    {
      "epoch": 4.632956878850103,
      "grad_norm": 0.04443618282675743,
      "learning_rate": 3.6710728952772075e-06,
      "loss": 0.0008,
      "step": 72200
    },
    {
      "epoch": 4.6361652977412735,
      "grad_norm": 0.13266639411449432,
      "learning_rate": 3.638988706365503e-06,
      "loss": 0.0008,
      "step": 72250
    },
    {
      "epoch": 4.639373716632443,
      "grad_norm": 0.046034954488277435,
      "learning_rate": 3.606904517453799e-06,
      "loss": 0.0008,
      "step": 72300
    },
    {
      "epoch": 4.642582135523614,
      "grad_norm": 0.08932917565107346,
      "learning_rate": 3.5748203285420944e-06,
      "loss": 0.0008,
      "step": 72350
    },
    {
      "epoch": 4.645790554414784,
      "grad_norm": 0.14647193253040314,
      "learning_rate": 3.5427361396303906e-06,
      "loss": 0.0008,
      "step": 72400
    },
    {
      "epoch": 4.648998973305955,
      "grad_norm": 0.06667256355285645,
      "learning_rate": 3.510651950718686e-06,
      "loss": 0.0008,
      "step": 72450
    },
    {
      "epoch": 4.652207392197125,
      "grad_norm": 0.027103515341877937,
      "learning_rate": 3.478567761806982e-06,
      "loss": 0.0008,
      "step": 72500
    },
    {
      "epoch": 4.655415811088296,
      "grad_norm": 0.08271631598472595,
      "learning_rate": 3.4464835728952775e-06,
      "loss": 0.0008,
      "step": 72550
    },
    {
      "epoch": 4.658624229979466,
      "grad_norm": 0.05540239065885544,
      "learning_rate": 3.414399383983573e-06,
      "loss": 0.0008,
      "step": 72600
    },
    {
      "epoch": 4.661832648870637,
      "grad_norm": 0.10409912467002869,
      "learning_rate": 3.382315195071869e-06,
      "loss": 0.0008,
      "step": 72650
    },
    {
      "epoch": 4.665041067761807,
      "grad_norm": 0.08650852739810944,
      "learning_rate": 3.3502310061601643e-06,
      "loss": 0.0008,
      "step": 72700
    },
    {
      "epoch": 4.668249486652978,
      "grad_norm": 0.02452963963150978,
      "learning_rate": 3.3181468172484605e-06,
      "loss": 0.0008,
      "step": 72750
    },
    {
      "epoch": 4.671457905544148,
      "grad_norm": 0.044671252369880676,
      "learning_rate": 3.286062628336756e-06,
      "loss": 0.0008,
      "step": 72800
    },
    {
      "epoch": 4.674666324435318,
      "grad_norm": 0.10198534280061722,
      "learning_rate": 3.2539784394250516e-06,
      "loss": 0.0008,
      "step": 72850
    },
    {
      "epoch": 4.6778747433264884,
      "grad_norm": 0.03304597735404968,
      "learning_rate": 3.221894250513347e-06,
      "loss": 0.0008,
      "step": 72900
    },
    {
      "epoch": 4.681083162217659,
      "grad_norm": 0.03408210724592209,
      "learning_rate": 3.1898100616016427e-06,
      "loss": 0.0008,
      "step": 72950
    },
    {
      "epoch": 4.6842915811088295,
      "grad_norm": 0.06742310523986816,
      "learning_rate": 3.1577258726899385e-06,
      "loss": 0.0008,
      "step": 73000
    },
    {
      "epoch": 4.6875,
      "grad_norm": 0.07766224443912506,
      "learning_rate": 3.125641683778234e-06,
      "loss": 0.0008,
      "step": 73050
    },
    {
      "epoch": 4.6907084188911705,
      "grad_norm": 0.07949809730052948,
      "learning_rate": 3.0935574948665296e-06,
      "loss": 0.0008,
      "step": 73100
    },
    {
      "epoch": 4.693916837782341,
      "grad_norm": 0.036318711936473846,
      "learning_rate": 3.0614733059548254e-06,
      "loss": 0.0008,
      "step": 73150
    },
    {
      "epoch": 4.6971252566735116,
      "grad_norm": 0.033209867775440216,
      "learning_rate": 3.029389117043121e-06,
      "loss": 0.0008,
      "step": 73200
    },
    {
      "epoch": 4.700333675564682,
      "grad_norm": 0.02555716410279274,
      "learning_rate": 2.997304928131417e-06,
      "loss": 0.0008,
      "step": 73250
    },
    {
      "epoch": 4.703542094455852,
      "grad_norm": 0.05154389515519142,
      "learning_rate": 2.9652207392197127e-06,
      "loss": 0.0008,
      "step": 73300
    },
    {
      "epoch": 4.706750513347022,
      "grad_norm": 0.093866266310215,
      "learning_rate": 2.9331365503080084e-06,
      "loss": 0.0008,
      "step": 73350
    },
    {
      "epoch": 4.709958932238193,
      "grad_norm": 0.06221243739128113,
      "learning_rate": 2.901052361396304e-06,
      "loss": 0.0008,
      "step": 73400
    },
    {
      "epoch": 4.713167351129363,
      "grad_norm": 0.03989337384700775,
      "learning_rate": 2.8689681724846e-06,
      "loss": 0.0008,
      "step": 73450
    },
    {
      "epoch": 4.716375770020534,
      "grad_norm": 0.07131966948509216,
      "learning_rate": 2.8368839835728953e-06,
      "loss": 0.0008,
      "step": 73500
    },
    {
      "epoch": 4.719584188911704,
      "grad_norm": 0.06748032569885254,
      "learning_rate": 2.804799794661191e-06,
      "loss": 0.0008,
      "step": 73550
    },
    {
      "epoch": 4.722792607802875,
      "grad_norm": 0.06264851242303848,
      "learning_rate": 2.772715605749487e-06,
      "loss": 0.0008,
      "step": 73600
    },
    {
      "epoch": 4.726001026694045,
      "grad_norm": 0.06370384991168976,
      "learning_rate": 2.7406314168377826e-06,
      "loss": 0.0008,
      "step": 73650
    },
    {
      "epoch": 4.729209445585216,
      "grad_norm": 0.07170400023460388,
      "learning_rate": 2.7085472279260784e-06,
      "loss": 0.0008,
      "step": 73700
    },
    {
      "epoch": 4.732417864476386,
      "grad_norm": 0.07772137224674225,
      "learning_rate": 2.6764630390143737e-06,
      "loss": 0.0008,
      "step": 73750
    },
    {
      "epoch": 4.735626283367557,
      "grad_norm": 0.14714415371418,
      "learning_rate": 2.6443788501026695e-06,
      "loss": 0.0008,
      "step": 73800
    },
    {
      "epoch": 4.7388347022587265,
      "grad_norm": 0.06366399675607681,
      "learning_rate": 2.6122946611909652e-06,
      "loss": 0.0008,
      "step": 73850
    },
    {
      "epoch": 4.742043121149897,
      "grad_norm": 0.04569711536169052,
      "learning_rate": 2.5802104722792606e-06,
      "loss": 0.0008,
      "step": 73900
    },
    {
      "epoch": 4.7452515400410675,
      "grad_norm": 0.14389799535274506,
      "learning_rate": 2.5481262833675563e-06,
      "loss": 0.0008,
      "step": 73950
    },
    {
      "epoch": 4.748459958932238,
      "grad_norm": 0.05106278881430626,
      "learning_rate": 2.516042094455852e-06,
      "loss": 0.0008,
      "step": 74000
    },
    {
      "epoch": 4.751668377823409,
      "grad_norm": 0.0855826810002327,
      "learning_rate": 2.483957905544148e-06,
      "loss": 0.0008,
      "step": 74050
    },
    {
      "epoch": 4.754876796714579,
      "grad_norm": 0.06828649342060089,
      "learning_rate": 2.4518737166324436e-06,
      "loss": 0.0008,
      "step": 74100
    },
    {
      "epoch": 4.75808521560575,
      "grad_norm": 0.09480410814285278,
      "learning_rate": 2.4197895277207394e-06,
      "loss": 0.0008,
      "step": 74150
    },
    {
      "epoch": 4.76129363449692,
      "grad_norm": 0.02155286818742752,
      "learning_rate": 2.387705338809035e-06,
      "loss": 0.0008,
      "step": 74200
    },
    {
      "epoch": 4.764502053388091,
      "grad_norm": 0.12070314586162567,
      "learning_rate": 2.355621149897331e-06,
      "loss": 0.0008,
      "step": 74250
    },
    {
      "epoch": 4.767710472279261,
      "grad_norm": 0.06299138814210892,
      "learning_rate": 2.3235369609856263e-06,
      "loss": 0.0008,
      "step": 74300
    },
    {
      "epoch": 4.770918891170432,
      "grad_norm": 0.07445128262042999,
      "learning_rate": 2.291452772073922e-06,
      "loss": 0.0008,
      "step": 74350
    },
    {
      "epoch": 4.774127310061601,
      "grad_norm": 0.03921150416135788,
      "learning_rate": 2.259368583162218e-06,
      "loss": 0.0008,
      "step": 74400
    },
    {
      "epoch": 4.777335728952772,
      "grad_norm": 0.05424781143665314,
      "learning_rate": 2.2272843942505136e-06,
      "loss": 0.0008,
      "step": 74450
    },
    {
      "epoch": 4.780544147843942,
      "grad_norm": 0.02982318215072155,
      "learning_rate": 2.1952002053388093e-06,
      "loss": 0.0008,
      "step": 74500
    },
    {
      "epoch": 4.783752566735113,
      "grad_norm": 0.05658135935664177,
      "learning_rate": 2.163116016427105e-06,
      "loss": 0.0008,
      "step": 74550
    },
    {
      "epoch": 4.786960985626283,
      "grad_norm": 0.058075904846191406,
      "learning_rate": 2.1310318275154004e-06,
      "loss": 0.0008,
      "step": 74600
    },
    {
      "epoch": 4.790169404517454,
      "grad_norm": 0.03875766694545746,
      "learning_rate": 2.098947638603696e-06,
      "loss": 0.0008,
      "step": 74650
    },
    {
      "epoch": 4.793377823408624,
      "grad_norm": 0.0718909502029419,
      "learning_rate": 2.066863449691992e-06,
      "loss": 0.0008,
      "step": 74700
    },
    {
      "epoch": 4.796586242299795,
      "grad_norm": 0.030909325927495956,
      "learning_rate": 2.0347792607802873e-06,
      "loss": 0.0008,
      "step": 74750
    },
    {
      "epoch": 4.799794661190965,
      "grad_norm": 0.05442618206143379,
      "learning_rate": 2.002695071868583e-06,
      "loss": 0.0008,
      "step": 74800
    },
    {
      "epoch": 4.803003080082135,
      "grad_norm": 0.030746418982744217,
      "learning_rate": 1.970610882956879e-06,
      "loss": 0.0008,
      "step": 74850
    },
    {
      "epoch": 4.806211498973306,
      "grad_norm": 0.06009889021515846,
      "learning_rate": 1.9385266940451746e-06,
      "loss": 0.0008,
      "step": 74900
    },
    {
      "epoch": 4.809419917864476,
      "grad_norm": 0.0775076299905777,
      "learning_rate": 1.9064425051334704e-06,
      "loss": 0.0008,
      "step": 74950
    },
    {
      "epoch": 4.812628336755647,
      "grad_norm": 0.046512577682733536,
      "learning_rate": 1.8743583162217661e-06,
      "loss": 0.0008,
      "step": 75000
    },
    {
      "epoch": 4.815836755646817,
      "grad_norm": 0.058894649147987366,
      "learning_rate": 1.8422741273100615e-06,
      "loss": 0.0008,
      "step": 75050
    },
    {
      "epoch": 4.819045174537988,
      "grad_norm": 0.08660829812288284,
      "learning_rate": 1.8101899383983572e-06,
      "loss": 0.0008,
      "step": 75100
    },
    {
      "epoch": 4.822253593429158,
      "grad_norm": 0.029147645458579063,
      "learning_rate": 1.778105749486653e-06,
      "loss": 0.0008,
      "step": 75150
    },
    {
      "epoch": 4.825462012320329,
      "grad_norm": 0.03602487966418266,
      "learning_rate": 1.7460215605749488e-06,
      "loss": 0.0008,
      "step": 75200
    },
    {
      "epoch": 4.828670431211499,
      "grad_norm": 0.07858964055776596,
      "learning_rate": 1.7139373716632445e-06,
      "loss": 0.0008,
      "step": 75250
    },
    {
      "epoch": 4.83187885010267,
      "grad_norm": 0.03562859073281288,
      "learning_rate": 1.6818531827515403e-06,
      "loss": 0.0008,
      "step": 75300
    },
    {
      "epoch": 4.83508726899384,
      "grad_norm": 0.041064146906137466,
      "learning_rate": 1.6497689938398358e-06,
      "loss": 0.0008,
      "step": 75350
    },
    {
      "epoch": 4.83829568788501,
      "grad_norm": 0.057330094277858734,
      "learning_rate": 1.6176848049281316e-06,
      "loss": 0.0008,
      "step": 75400
    },
    {
      "epoch": 4.84150410677618,
      "grad_norm": 0.04043598845601082,
      "learning_rate": 1.585600616016427e-06,
      "loss": 0.0008,
      "step": 75450
    },
    {
      "epoch": 4.844712525667351,
      "grad_norm": 0.03755831718444824,
      "learning_rate": 1.553516427104723e-06,
      "loss": 0.0008,
      "step": 75500
    },
    {
      "epoch": 4.847920944558521,
      "grad_norm": 0.035943299531936646,
      "learning_rate": 1.5214322381930185e-06,
      "loss": 0.0008,
      "step": 75550
    },
    {
      "epoch": 4.851129363449692,
      "grad_norm": 0.07686313986778259,
      "learning_rate": 1.4893480492813142e-06,
      "loss": 0.0008,
      "step": 75600
    },
    {
      "epoch": 4.854337782340862,
      "grad_norm": 0.044186268001794815,
      "learning_rate": 1.45726386036961e-06,
      "loss": 0.0008,
      "step": 75650
    },
    {
      "epoch": 4.857546201232033,
      "grad_norm": 0.045582398772239685,
      "learning_rate": 1.4251796714579058e-06,
      "loss": 0.0008,
      "step": 75700
    },
    {
      "epoch": 4.8607546201232035,
      "grad_norm": 0.1007373034954071,
      "learning_rate": 1.3930954825462013e-06,
      "loss": 0.0008,
      "step": 75750
    },
    {
      "epoch": 4.863963039014374,
      "grad_norm": 0.05620312690734863,
      "learning_rate": 1.3610112936344969e-06,
      "loss": 0.0008,
      "step": 75800
    },
    {
      "epoch": 4.8671714579055445,
      "grad_norm": 0.049539871513843536,
      "learning_rate": 1.3289271047227926e-06,
      "loss": 0.0008,
      "step": 75850
    },
    {
      "epoch": 4.870379876796715,
      "grad_norm": 0.06469807028770447,
      "learning_rate": 1.2968429158110882e-06,
      "loss": 0.0008,
      "step": 75900
    },
    {
      "epoch": 4.873588295687885,
      "grad_norm": 0.02492816559970379,
      "learning_rate": 1.264758726899384e-06,
      "loss": 0.0008,
      "step": 75950
    },
    {
      "epoch": 4.876796714579055,
      "grad_norm": 0.06583835929632187,
      "learning_rate": 1.2326745379876797e-06,
      "loss": 0.0008,
      "step": 76000
    },
    {
      "epoch": 4.880005133470226,
      "grad_norm": 0.038830265402793884,
      "learning_rate": 1.2005903490759755e-06,
      "loss": 0.0008,
      "step": 76050
    },
    {
      "epoch": 4.883213552361396,
      "grad_norm": 0.0352741964161396,
      "learning_rate": 1.168506160164271e-06,
      "loss": 0.0008,
      "step": 76100
    },
    {
      "epoch": 4.886421971252567,
      "grad_norm": 0.04849354177713394,
      "learning_rate": 1.1364219712525668e-06,
      "loss": 0.0008,
      "step": 76150
    },
    {
      "epoch": 4.889630390143737,
      "grad_norm": 0.0500907376408577,
      "learning_rate": 1.1043377823408626e-06,
      "loss": 0.0008,
      "step": 76200
    },
    {
      "epoch": 4.892838809034908,
      "grad_norm": 0.05403885245323181,
      "learning_rate": 1.0722535934291581e-06,
      "loss": 0.0008,
      "step": 76250
    },
    {
      "epoch": 4.896047227926078,
      "grad_norm": 0.05931615084409714,
      "learning_rate": 1.0401694045174537e-06,
      "loss": 0.0008,
      "step": 76300
    },
    {
      "epoch": 4.899255646817249,
      "grad_norm": 0.023239675909280777,
      "learning_rate": 1.0080852156057494e-06,
      "loss": 0.0008,
      "step": 76350
    },
    {
      "epoch": 4.902464065708418,
      "grad_norm": 0.0831897109746933,
      "learning_rate": 9.760010266940452e-07,
      "loss": 0.0008,
      "step": 76400
    },
    {
      "epoch": 4.905672484599589,
      "grad_norm": 0.07050984352827072,
      "learning_rate": 9.43916837782341e-07,
      "loss": 0.0008,
      "step": 76450
    },
    {
      "epoch": 4.9088809034907595,
      "grad_norm": 0.02683371491730213,
      "learning_rate": 9.118326488706365e-07,
      "loss": 0.0008,
      "step": 76500
    },
    {
      "epoch": 4.91208932238193,
      "grad_norm": 0.04909583553671837,
      "learning_rate": 8.797484599589323e-07,
      "loss": 0.0008,
      "step": 76550
    },
    {
      "epoch": 4.9152977412731005,
      "grad_norm": 0.042964205145835876,
      "learning_rate": 8.47664271047228e-07,
      "loss": 0.0008,
      "step": 76600
    },
    {
      "epoch": 4.918506160164271,
      "grad_norm": 0.05422236770391464,
      "learning_rate": 8.155800821355237e-07,
      "loss": 0.0008,
      "step": 76650
    },
    {
      "epoch": 4.9217145790554415,
      "grad_norm": 0.0630863755941391,
      "learning_rate": 7.834958932238193e-07,
      "loss": 0.0008,
      "step": 76700
    },
    {
      "epoch": 4.924922997946612,
      "grad_norm": 0.09327995032072067,
      "learning_rate": 7.51411704312115e-07,
      "loss": 0.0008,
      "step": 76750
    },
    {
      "epoch": 4.9281314168377826,
      "grad_norm": 0.023983005434274673,
      "learning_rate": 7.193275154004107e-07,
      "loss": 0.0008,
      "step": 76800
    },
    {
      "epoch": 4.931339835728953,
      "grad_norm": 0.05012696236371994,
      "learning_rate": 6.872433264887064e-07,
      "loss": 0.0008,
      "step": 76850
    },
    {
      "epoch": 4.934548254620124,
      "grad_norm": 0.054498832672834396,
      "learning_rate": 6.551591375770021e-07,
      "loss": 0.0008,
      "step": 76900
    },
    {
      "epoch": 4.937756673511293,
      "grad_norm": 0.07301165163516998,
      "learning_rate": 6.230749486652978e-07,
      "loss": 0.0008,
      "step": 76950
    },
    {
      "epoch": 4.940965092402464,
      "grad_norm": 0.02002512477338314,
      "learning_rate": 5.909907597535935e-07,
      "loss": 0.0008,
      "step": 77000
    },
    {
      "epoch": 4.944173511293634,
      "grad_norm": 0.04133657366037369,
      "learning_rate": 5.589065708418891e-07,
      "loss": 0.0008,
      "step": 77050
    },
    {
      "epoch": 4.947381930184805,
      "grad_norm": 0.049741607159376144,
      "learning_rate": 5.268223819301849e-07,
      "loss": 0.0008,
      "step": 77100
    },
    {
      "epoch": 4.950590349075975,
      "grad_norm": 0.023632101714611053,
      "learning_rate": 4.947381930184805e-07,
      "loss": 0.0008,
      "step": 77150
    },
    {
      "epoch": 4.953798767967146,
      "grad_norm": 0.037924643605947495,
      "learning_rate": 4.6265400410677623e-07,
      "loss": 0.0008,
      "step": 77200
    },
    {
      "epoch": 4.957007186858316,
      "grad_norm": 0.07968669384717941,
      "learning_rate": 4.305698151950719e-07,
      "loss": 0.0008,
      "step": 77250
    },
    {
      "epoch": 4.960215605749487,
      "grad_norm": 0.04272712022066116,
      "learning_rate": 3.984856262833676e-07,
      "loss": 0.0008,
      "step": 77300
    },
    {
      "epoch": 4.963424024640657,
      "grad_norm": 0.02348465286195278,
      "learning_rate": 3.6640143737166326e-07,
      "loss": 0.0008,
      "step": 77350
    },
    {
      "epoch": 4.966632443531828,
      "grad_norm": 0.06510993838310242,
      "learning_rate": 3.3431724845995897e-07,
      "loss": 0.0008,
      "step": 77400
    },
    {
      "epoch": 4.969840862422998,
      "grad_norm": 0.048147834837436676,
      "learning_rate": 3.0223305954825463e-07,
      "loss": 0.0008,
      "step": 77450
    },
    {
      "epoch": 4.973049281314168,
      "grad_norm": 0.02891669049859047,
      "learning_rate": 2.7014887063655034e-07,
      "loss": 0.0008,
      "step": 77500
    },
    {
      "epoch": 4.9762577002053385,
      "grad_norm": 0.04315986484289169,
      "learning_rate": 2.3806468172484602e-07,
      "loss": 0.0008,
      "step": 77550
    },
    {
      "epoch": 4.979466119096509,
      "grad_norm": 0.043404366821050644,
      "learning_rate": 2.059804928131417e-07,
      "loss": 0.0008,
      "step": 77600
    },
    {
      "epoch": 4.98267453798768,
      "grad_norm": 0.056987397372722626,
      "learning_rate": 1.738963039014374e-07,
      "loss": 0.0008,
      "step": 77650
    },
    {
      "epoch": 4.98588295687885,
      "grad_norm": 0.023881854489445686,
      "learning_rate": 1.4181211498973305e-07,
      "loss": 0.0008,
      "step": 77700
    },
    {
      "epoch": 4.989091375770021,
      "grad_norm": 0.06106800213456154,
      "learning_rate": 1.0972792607802874e-07,
      "loss": 0.0008,
      "step": 77750
    },
    {
      "epoch": 4.992299794661191,
      "grad_norm": 0.07873821258544922,
      "learning_rate": 7.764373716632444e-08,
      "loss": 0.0008,
      "step": 77800
    },
    {
      "epoch": 4.995508213552362,
      "grad_norm": 0.02786729298532009,
      "learning_rate": 4.555954825462012e-08,
      "loss": 0.0008,
      "step": 77850
    },
    {
      "epoch": 4.998716632443532,
      "grad_norm": 0.04926557093858719,
      "learning_rate": 1.3475359342915813e-08,
      "loss": 0.0008,
      "step": 77900
    }
  ],
  "logging_steps": 50,
  "max_steps": 77920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
