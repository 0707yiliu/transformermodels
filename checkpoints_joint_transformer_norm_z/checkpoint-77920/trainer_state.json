{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 77920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003208418891170431,
      "grad_norm": 1.9451888799667358,
      "learning_rate": 4.996855749486653e-05,
      "loss": 0.2437,
      "step": 50
    },
    {
      "epoch": 0.006416837782340862,
      "grad_norm": 1.8367291688919067,
      "learning_rate": 4.993647330595483e-05,
      "loss": 0.1908,
      "step": 100
    },
    {
      "epoch": 0.009625256673511294,
      "grad_norm": 1.4752833843231201,
      "learning_rate": 4.990438911704312e-05,
      "loss": 0.1495,
      "step": 150
    },
    {
      "epoch": 0.012833675564681724,
      "grad_norm": 1.1806871891021729,
      "learning_rate": 4.987230492813142e-05,
      "loss": 0.1135,
      "step": 200
    },
    {
      "epoch": 0.016042094455852154,
      "grad_norm": 0.9129260182380676,
      "learning_rate": 4.984022073921972e-05,
      "loss": 0.0846,
      "step": 250
    },
    {
      "epoch": 0.019250513347022588,
      "grad_norm": 0.6705549955368042,
      "learning_rate": 4.980813655030801e-05,
      "loss": 0.0641,
      "step": 300
    },
    {
      "epoch": 0.02245893223819302,
      "grad_norm": 0.627768337726593,
      "learning_rate": 4.9776052361396305e-05,
      "loss": 0.0503,
      "step": 350
    },
    {
      "epoch": 0.02566735112936345,
      "grad_norm": 0.49981924891471863,
      "learning_rate": 4.97439681724846e-05,
      "loss": 0.0408,
      "step": 400
    },
    {
      "epoch": 0.028875770020533882,
      "grad_norm": 0.4156479835510254,
      "learning_rate": 4.97118839835729e-05,
      "loss": 0.0339,
      "step": 450
    },
    {
      "epoch": 0.03208418891170431,
      "grad_norm": 0.3514445424079895,
      "learning_rate": 4.9679799794661194e-05,
      "loss": 0.0287,
      "step": 500
    },
    {
      "epoch": 0.03529260780287474,
      "grad_norm": 0.30903947353363037,
      "learning_rate": 4.964771560574949e-05,
      "loss": 0.0244,
      "step": 550
    },
    {
      "epoch": 0.038501026694045176,
      "grad_norm": 0.2508213222026825,
      "learning_rate": 4.961563141683778e-05,
      "loss": 0.0218,
      "step": 600
    },
    {
      "epoch": 0.0417094455852156,
      "grad_norm": 0.20685094594955444,
      "learning_rate": 4.958354722792608e-05,
      "loss": 0.0192,
      "step": 650
    },
    {
      "epoch": 0.04491786447638604,
      "grad_norm": 0.21605491638183594,
      "learning_rate": 4.955146303901438e-05,
      "loss": 0.0171,
      "step": 700
    },
    {
      "epoch": 0.04812628336755647,
      "grad_norm": 0.20450158417224884,
      "learning_rate": 4.951937885010267e-05,
      "loss": 0.0152,
      "step": 750
    },
    {
      "epoch": 0.0513347022587269,
      "grad_norm": 0.2978499233722687,
      "learning_rate": 4.948729466119097e-05,
      "loss": 0.0141,
      "step": 800
    },
    {
      "epoch": 0.05454312114989733,
      "grad_norm": 0.1409349888563156,
      "learning_rate": 4.945521047227926e-05,
      "loss": 0.0127,
      "step": 850
    },
    {
      "epoch": 0.057751540041067764,
      "grad_norm": 0.13947494328022003,
      "learning_rate": 4.942312628336756e-05,
      "loss": 0.0115,
      "step": 900
    },
    {
      "epoch": 0.06095995893223819,
      "grad_norm": 0.1790686547756195,
      "learning_rate": 4.939104209445585e-05,
      "loss": 0.0107,
      "step": 950
    },
    {
      "epoch": 0.06416837782340862,
      "grad_norm": 0.1078735888004303,
      "learning_rate": 4.935895790554415e-05,
      "loss": 0.0099,
      "step": 1000
    },
    {
      "epoch": 0.06737679671457905,
      "grad_norm": 0.13851600885391235,
      "learning_rate": 4.9326873716632445e-05,
      "loss": 0.0091,
      "step": 1050
    },
    {
      "epoch": 0.07058521560574949,
      "grad_norm": 0.10022669285535812,
      "learning_rate": 4.929478952772074e-05,
      "loss": 0.0086,
      "step": 1100
    },
    {
      "epoch": 0.07379363449691992,
      "grad_norm": 0.10778780281543732,
      "learning_rate": 4.926270533880904e-05,
      "loss": 0.0081,
      "step": 1150
    },
    {
      "epoch": 0.07700205338809035,
      "grad_norm": 0.1048462763428688,
      "learning_rate": 4.9230621149897334e-05,
      "loss": 0.0074,
      "step": 1200
    },
    {
      "epoch": 0.08021047227926079,
      "grad_norm": 0.15650606155395508,
      "learning_rate": 4.919853696098563e-05,
      "loss": 0.0072,
      "step": 1250
    },
    {
      "epoch": 0.0834188911704312,
      "grad_norm": 0.10051559656858444,
      "learning_rate": 4.9166452772073926e-05,
      "loss": 0.0069,
      "step": 1300
    },
    {
      "epoch": 0.08662731006160164,
      "grad_norm": 0.09016157686710358,
      "learning_rate": 4.913436858316222e-05,
      "loss": 0.0064,
      "step": 1350
    },
    {
      "epoch": 0.08983572895277207,
      "grad_norm": 0.08001280575990677,
      "learning_rate": 4.910228439425051e-05,
      "loss": 0.0061,
      "step": 1400
    },
    {
      "epoch": 0.0930441478439425,
      "grad_norm": 0.12060026824474335,
      "learning_rate": 4.9070200205338815e-05,
      "loss": 0.0059,
      "step": 1450
    },
    {
      "epoch": 0.09625256673511294,
      "grad_norm": 0.0635940283536911,
      "learning_rate": 4.9038116016427104e-05,
      "loss": 0.0057,
      "step": 1500
    },
    {
      "epoch": 0.09946098562628337,
      "grad_norm": 0.059037186205387115,
      "learning_rate": 4.90060318275154e-05,
      "loss": 0.0055,
      "step": 1550
    },
    {
      "epoch": 0.1026694045174538,
      "grad_norm": 0.09566392749547958,
      "learning_rate": 4.89739476386037e-05,
      "loss": 0.0054,
      "step": 1600
    },
    {
      "epoch": 0.10587782340862423,
      "grad_norm": 0.12560099363327026,
      "learning_rate": 4.894186344969199e-05,
      "loss": 0.0053,
      "step": 1650
    },
    {
      "epoch": 0.10908624229979466,
      "grad_norm": 0.03344934806227684,
      "learning_rate": 4.890977926078029e-05,
      "loss": 0.0052,
      "step": 1700
    },
    {
      "epoch": 0.1122946611909651,
      "grad_norm": 0.1147867888212204,
      "learning_rate": 4.8877695071868585e-05,
      "loss": 0.005,
      "step": 1750
    },
    {
      "epoch": 0.11550308008213553,
      "grad_norm": 0.058669231832027435,
      "learning_rate": 4.884561088295688e-05,
      "loss": 0.0049,
      "step": 1800
    },
    {
      "epoch": 0.11871149897330595,
      "grad_norm": 0.08756492286920547,
      "learning_rate": 4.881352669404518e-05,
      "loss": 0.0049,
      "step": 1850
    },
    {
      "epoch": 0.12191991786447638,
      "grad_norm": 0.040411327034235,
      "learning_rate": 4.8781442505133473e-05,
      "loss": 0.0048,
      "step": 1900
    },
    {
      "epoch": 0.12512833675564683,
      "grad_norm": 0.11750821024179459,
      "learning_rate": 4.874935831622176e-05,
      "loss": 0.0047,
      "step": 1950
    },
    {
      "epoch": 0.12833675564681724,
      "grad_norm": 0.10084658116102219,
      "learning_rate": 4.8717274127310066e-05,
      "loss": 0.0047,
      "step": 2000
    },
    {
      "epoch": 0.13154517453798767,
      "grad_norm": 0.19766373932361603,
      "learning_rate": 4.868518993839836e-05,
      "loss": 0.0046,
      "step": 2050
    },
    {
      "epoch": 0.1347535934291581,
      "grad_norm": 0.07650025188922882,
      "learning_rate": 4.865310574948666e-05,
      "loss": 0.0046,
      "step": 2100
    },
    {
      "epoch": 0.13796201232032854,
      "grad_norm": 0.1083998903632164,
      "learning_rate": 4.8621021560574954e-05,
      "loss": 0.0046,
      "step": 2150
    },
    {
      "epoch": 0.14117043121149897,
      "grad_norm": 0.02510077878832817,
      "learning_rate": 4.8588937371663244e-05,
      "loss": 0.0045,
      "step": 2200
    },
    {
      "epoch": 0.1443788501026694,
      "grad_norm": 0.03650059923529625,
      "learning_rate": 4.855685318275155e-05,
      "loss": 0.0045,
      "step": 2250
    },
    {
      "epoch": 0.14758726899383984,
      "grad_norm": 0.1100461483001709,
      "learning_rate": 4.8524768993839836e-05,
      "loss": 0.0045,
      "step": 2300
    },
    {
      "epoch": 0.15079568788501027,
      "grad_norm": 0.06642954796552658,
      "learning_rate": 4.849268480492813e-05,
      "loss": 0.0045,
      "step": 2350
    },
    {
      "epoch": 0.1540041067761807,
      "grad_norm": 0.049583762884140015,
      "learning_rate": 4.846060061601643e-05,
      "loss": 0.0045,
      "step": 2400
    },
    {
      "epoch": 0.15721252566735114,
      "grad_norm": 0.08484753966331482,
      "learning_rate": 4.8428516427104725e-05,
      "loss": 0.0045,
      "step": 2450
    },
    {
      "epoch": 0.16042094455852157,
      "grad_norm": 0.09990417212247849,
      "learning_rate": 4.839643223819302e-05,
      "loss": 0.0045,
      "step": 2500
    },
    {
      "epoch": 0.16362936344969198,
      "grad_norm": 0.09501530975103378,
      "learning_rate": 4.836434804928132e-05,
      "loss": 0.0045,
      "step": 2550
    },
    {
      "epoch": 0.1668377823408624,
      "grad_norm": 0.055441536009311676,
      "learning_rate": 4.833226386036961e-05,
      "loss": 0.0045,
      "step": 2600
    },
    {
      "epoch": 0.17004620123203285,
      "grad_norm": 0.1733892410993576,
      "learning_rate": 4.830017967145791e-05,
      "loss": 0.0044,
      "step": 2650
    },
    {
      "epoch": 0.17325462012320328,
      "grad_norm": 0.03225787356495857,
      "learning_rate": 4.8268095482546206e-05,
      "loss": 0.0044,
      "step": 2700
    },
    {
      "epoch": 0.1764630390143737,
      "grad_norm": 0.12250997871160507,
      "learning_rate": 4.8236011293634495e-05,
      "loss": 0.0044,
      "step": 2750
    },
    {
      "epoch": 0.17967145790554415,
      "grad_norm": 0.0791703462600708,
      "learning_rate": 4.82039271047228e-05,
      "loss": 0.0044,
      "step": 2800
    },
    {
      "epoch": 0.18287987679671458,
      "grad_norm": 0.02263312041759491,
      "learning_rate": 4.817184291581109e-05,
      "loss": 0.0044,
      "step": 2850
    },
    {
      "epoch": 0.186088295687885,
      "grad_norm": 0.033245280385017395,
      "learning_rate": 4.8139758726899384e-05,
      "loss": 0.0043,
      "step": 2900
    },
    {
      "epoch": 0.18929671457905545,
      "grad_norm": 0.028124716132879257,
      "learning_rate": 4.810767453798768e-05,
      "loss": 0.0044,
      "step": 2950
    },
    {
      "epoch": 0.19250513347022588,
      "grad_norm": 0.07688651978969574,
      "learning_rate": 4.8075590349075976e-05,
      "loss": 0.0044,
      "step": 3000
    },
    {
      "epoch": 0.19571355236139631,
      "grad_norm": 0.18140803277492523,
      "learning_rate": 4.804350616016427e-05,
      "loss": 0.0044,
      "step": 3050
    },
    {
      "epoch": 0.19892197125256675,
      "grad_norm": 0.03690881282091141,
      "learning_rate": 4.801142197125257e-05,
      "loss": 0.0044,
      "step": 3100
    },
    {
      "epoch": 0.20213039014373715,
      "grad_norm": 0.03366846591234207,
      "learning_rate": 4.7979337782340865e-05,
      "loss": 0.0044,
      "step": 3150
    },
    {
      "epoch": 0.2053388090349076,
      "grad_norm": 0.027727246284484863,
      "learning_rate": 4.794725359342916e-05,
      "loss": 0.0043,
      "step": 3200
    },
    {
      "epoch": 0.20854722792607802,
      "grad_norm": 0.10628437995910645,
      "learning_rate": 4.791516940451746e-05,
      "loss": 0.0044,
      "step": 3250
    },
    {
      "epoch": 0.21175564681724846,
      "grad_norm": 0.036316003650426865,
      "learning_rate": 4.7883085215605746e-05,
      "loss": 0.0043,
      "step": 3300
    },
    {
      "epoch": 0.2149640657084189,
      "grad_norm": 0.04548920318484306,
      "learning_rate": 4.785100102669405e-05,
      "loss": 0.0044,
      "step": 3350
    },
    {
      "epoch": 0.21817248459958932,
      "grad_norm": 0.052067045122385025,
      "learning_rate": 4.781891683778234e-05,
      "loss": 0.0044,
      "step": 3400
    },
    {
      "epoch": 0.22138090349075976,
      "grad_norm": 0.028881367295980453,
      "learning_rate": 4.778683264887064e-05,
      "loss": 0.0043,
      "step": 3450
    },
    {
      "epoch": 0.2245893223819302,
      "grad_norm": 0.053283706307411194,
      "learning_rate": 4.775474845995894e-05,
      "loss": 0.0043,
      "step": 3500
    },
    {
      "epoch": 0.22779774127310062,
      "grad_norm": 0.1205979660153389,
      "learning_rate": 4.772266427104723e-05,
      "loss": 0.0044,
      "step": 3550
    },
    {
      "epoch": 0.23100616016427106,
      "grad_norm": 0.07989995926618576,
      "learning_rate": 4.769058008213553e-05,
      "loss": 0.0043,
      "step": 3600
    },
    {
      "epoch": 0.2342145790554415,
      "grad_norm": 0.06337898969650269,
      "learning_rate": 4.765849589322382e-05,
      "loss": 0.0044,
      "step": 3650
    },
    {
      "epoch": 0.2374229979466119,
      "grad_norm": 0.04215346649289131,
      "learning_rate": 4.7626411704312116e-05,
      "loss": 0.0043,
      "step": 3700
    },
    {
      "epoch": 0.24063141683778233,
      "grad_norm": 0.08816853910684586,
      "learning_rate": 4.759432751540041e-05,
      "loss": 0.0043,
      "step": 3750
    },
    {
      "epoch": 0.24383983572895276,
      "grad_norm": 0.09294506907463074,
      "learning_rate": 4.756224332648871e-05,
      "loss": 0.0043,
      "step": 3800
    },
    {
      "epoch": 0.2470482546201232,
      "grad_norm": 0.032757263630628586,
      "learning_rate": 4.7530159137577004e-05,
      "loss": 0.0044,
      "step": 3850
    },
    {
      "epoch": 0.25025667351129366,
      "grad_norm": 0.19498154520988464,
      "learning_rate": 4.74980749486653e-05,
      "loss": 0.0044,
      "step": 3900
    },
    {
      "epoch": 0.25346509240246407,
      "grad_norm": 0.07979178428649902,
      "learning_rate": 4.74659907597536e-05,
      "loss": 0.0043,
      "step": 3950
    },
    {
      "epoch": 0.25667351129363447,
      "grad_norm": 0.05014028400182724,
      "learning_rate": 4.743390657084189e-05,
      "loss": 0.0044,
      "step": 4000
    },
    {
      "epoch": 0.25988193018480493,
      "grad_norm": 0.05306795984506607,
      "learning_rate": 4.740182238193019e-05,
      "loss": 0.0043,
      "step": 4050
    },
    {
      "epoch": 0.26309034907597534,
      "grad_norm": 0.04555974155664444,
      "learning_rate": 4.736973819301848e-05,
      "loss": 0.0043,
      "step": 4100
    },
    {
      "epoch": 0.2662987679671458,
      "grad_norm": 0.03591231629252434,
      "learning_rate": 4.733765400410678e-05,
      "loss": 0.0044,
      "step": 4150
    },
    {
      "epoch": 0.2695071868583162,
      "grad_norm": 0.05637434870004654,
      "learning_rate": 4.730556981519507e-05,
      "loss": 0.0044,
      "step": 4200
    },
    {
      "epoch": 0.27271560574948667,
      "grad_norm": 0.04304475337266922,
      "learning_rate": 4.727348562628337e-05,
      "loss": 0.0043,
      "step": 4250
    },
    {
      "epoch": 0.2759240246406571,
      "grad_norm": 0.12044200301170349,
      "learning_rate": 4.724140143737166e-05,
      "loss": 0.0043,
      "step": 4300
    },
    {
      "epoch": 0.27913244353182753,
      "grad_norm": 0.06514829397201538,
      "learning_rate": 4.720931724845996e-05,
      "loss": 0.0043,
      "step": 4350
    },
    {
      "epoch": 0.28234086242299794,
      "grad_norm": 0.11906269192695618,
      "learning_rate": 4.717723305954826e-05,
      "loss": 0.0043,
      "step": 4400
    },
    {
      "epoch": 0.2855492813141684,
      "grad_norm": 0.032890982925891876,
      "learning_rate": 4.714514887063655e-05,
      "loss": 0.0043,
      "step": 4450
    },
    {
      "epoch": 0.2887577002053388,
      "grad_norm": 0.10380711406469345,
      "learning_rate": 4.711306468172485e-05,
      "loss": 0.0043,
      "step": 4500
    },
    {
      "epoch": 0.2919661190965092,
      "grad_norm": 0.12016700953245163,
      "learning_rate": 4.7080980492813144e-05,
      "loss": 0.0043,
      "step": 4550
    },
    {
      "epoch": 0.2951745379876797,
      "grad_norm": 0.06376080214977264,
      "learning_rate": 4.704889630390144e-05,
      "loss": 0.0043,
      "step": 4600
    },
    {
      "epoch": 0.2983829568788501,
      "grad_norm": 0.08602706342935562,
      "learning_rate": 4.701681211498974e-05,
      "loss": 0.0043,
      "step": 4650
    },
    {
      "epoch": 0.30159137577002054,
      "grad_norm": 0.11675678193569183,
      "learning_rate": 4.698472792607803e-05,
      "loss": 0.0043,
      "step": 4700
    },
    {
      "epoch": 0.30479979466119095,
      "grad_norm": 0.03810551017522812,
      "learning_rate": 4.695264373716632e-05,
      "loss": 0.0043,
      "step": 4750
    },
    {
      "epoch": 0.3080082135523614,
      "grad_norm": 0.06640838086605072,
      "learning_rate": 4.6920559548254625e-05,
      "loss": 0.0042,
      "step": 4800
    },
    {
      "epoch": 0.3112166324435318,
      "grad_norm": 0.1310436874628067,
      "learning_rate": 4.688847535934292e-05,
      "loss": 0.0043,
      "step": 4850
    },
    {
      "epoch": 0.3144250513347023,
      "grad_norm": 0.03205977752804756,
      "learning_rate": 4.685639117043121e-05,
      "loss": 0.0044,
      "step": 4900
    },
    {
      "epoch": 0.3176334702258727,
      "grad_norm": 0.07464243471622467,
      "learning_rate": 4.6824306981519514e-05,
      "loss": 0.0043,
      "step": 4950
    },
    {
      "epoch": 0.32084188911704314,
      "grad_norm": 0.02538883686065674,
      "learning_rate": 4.67922227926078e-05,
      "loss": 0.0042,
      "step": 5000
    },
    {
      "epoch": 0.32405030800821355,
      "grad_norm": 0.11021559685468674,
      "learning_rate": 4.67601386036961e-05,
      "loss": 0.0043,
      "step": 5050
    },
    {
      "epoch": 0.32725872689938396,
      "grad_norm": 0.08181644231081009,
      "learning_rate": 4.6728054414784396e-05,
      "loss": 0.0043,
      "step": 5100
    },
    {
      "epoch": 0.3304671457905544,
      "grad_norm": 0.06623771786689758,
      "learning_rate": 4.669597022587269e-05,
      "loss": 0.0043,
      "step": 5150
    },
    {
      "epoch": 0.3336755646817248,
      "grad_norm": 0.01611473225057125,
      "learning_rate": 4.666388603696099e-05,
      "loss": 0.0043,
      "step": 5200
    },
    {
      "epoch": 0.3368839835728953,
      "grad_norm": 0.04907405003905296,
      "learning_rate": 4.6631801848049284e-05,
      "loss": 0.0043,
      "step": 5250
    },
    {
      "epoch": 0.3400924024640657,
      "grad_norm": 0.16261842846870422,
      "learning_rate": 4.659971765913758e-05,
      "loss": 0.0042,
      "step": 5300
    },
    {
      "epoch": 0.34330082135523615,
      "grad_norm": 0.09957654774188995,
      "learning_rate": 4.6567633470225877e-05,
      "loss": 0.0043,
      "step": 5350
    },
    {
      "epoch": 0.34650924024640656,
      "grad_norm": 0.16670316457748413,
      "learning_rate": 4.653554928131417e-05,
      "loss": 0.0043,
      "step": 5400
    },
    {
      "epoch": 0.349717659137577,
      "grad_norm": 0.020741574466228485,
      "learning_rate": 4.650346509240246e-05,
      "loss": 0.0043,
      "step": 5450
    },
    {
      "epoch": 0.3529260780287474,
      "grad_norm": 0.06590058654546738,
      "learning_rate": 4.6471380903490765e-05,
      "loss": 0.0043,
      "step": 5500
    },
    {
      "epoch": 0.3561344969199179,
      "grad_norm": 0.06032881513237953,
      "learning_rate": 4.6439296714579055e-05,
      "loss": 0.0042,
      "step": 5550
    },
    {
      "epoch": 0.3593429158110883,
      "grad_norm": 0.13921396434307098,
      "learning_rate": 4.640721252566735e-05,
      "loss": 0.0043,
      "step": 5600
    },
    {
      "epoch": 0.36255133470225875,
      "grad_norm": 0.03742871806025505,
      "learning_rate": 4.637512833675565e-05,
      "loss": 0.0043,
      "step": 5650
    },
    {
      "epoch": 0.36575975359342916,
      "grad_norm": 0.04425981268286705,
      "learning_rate": 4.634304414784394e-05,
      "loss": 0.0043,
      "step": 5700
    },
    {
      "epoch": 0.36896817248459957,
      "grad_norm": 0.0743546336889267,
      "learning_rate": 4.6310959958932246e-05,
      "loss": 0.0042,
      "step": 5750
    },
    {
      "epoch": 0.37217659137577,
      "grad_norm": 0.037605538964271545,
      "learning_rate": 4.6278875770020535e-05,
      "loss": 0.0042,
      "step": 5800
    },
    {
      "epoch": 0.37538501026694043,
      "grad_norm": 0.07621646672487259,
      "learning_rate": 4.624679158110883e-05,
      "loss": 0.0043,
      "step": 5850
    },
    {
      "epoch": 0.3785934291581109,
      "grad_norm": 0.0631900206208229,
      "learning_rate": 4.621470739219713e-05,
      "loss": 0.0043,
      "step": 5900
    },
    {
      "epoch": 0.3818018480492813,
      "grad_norm": 0.11498724669218063,
      "learning_rate": 4.6182623203285424e-05,
      "loss": 0.0042,
      "step": 5950
    },
    {
      "epoch": 0.38501026694045176,
      "grad_norm": 0.09752059727907181,
      "learning_rate": 4.615053901437372e-05,
      "loss": 0.0043,
      "step": 6000
    },
    {
      "epoch": 0.38821868583162217,
      "grad_norm": 0.08210526406764984,
      "learning_rate": 4.6118454825462016e-05,
      "loss": 0.0042,
      "step": 6050
    },
    {
      "epoch": 0.39142710472279263,
      "grad_norm": 0.12428439408540726,
      "learning_rate": 4.6086370636550306e-05,
      "loss": 0.0043,
      "step": 6100
    },
    {
      "epoch": 0.39463552361396304,
      "grad_norm": 0.12167087942361832,
      "learning_rate": 4.605428644763861e-05,
      "loss": 0.0042,
      "step": 6150
    },
    {
      "epoch": 0.3978439425051335,
      "grad_norm": 0.050861455500125885,
      "learning_rate": 4.6022202258726905e-05,
      "loss": 0.0042,
      "step": 6200
    },
    {
      "epoch": 0.4010523613963039,
      "grad_norm": 0.12330758571624756,
      "learning_rate": 4.5990118069815194e-05,
      "loss": 0.0042,
      "step": 6250
    },
    {
      "epoch": 0.4042607802874743,
      "grad_norm": 0.08731689304113388,
      "learning_rate": 4.59580338809035e-05,
      "loss": 0.0041,
      "step": 6300
    },
    {
      "epoch": 0.40746919917864477,
      "grad_norm": 0.12447068840265274,
      "learning_rate": 4.592594969199179e-05,
      "loss": 0.0042,
      "step": 6350
    },
    {
      "epoch": 0.4106776180698152,
      "grad_norm": 0.04315182566642761,
      "learning_rate": 4.589386550308008e-05,
      "loss": 0.0042,
      "step": 6400
    },
    {
      "epoch": 0.41388603696098564,
      "grad_norm": 0.15824037790298462,
      "learning_rate": 4.586178131416838e-05,
      "loss": 0.0042,
      "step": 6450
    },
    {
      "epoch": 0.41709445585215604,
      "grad_norm": 0.0699651688337326,
      "learning_rate": 4.5829697125256675e-05,
      "loss": 0.0042,
      "step": 6500
    },
    {
      "epoch": 0.4203028747433265,
      "grad_norm": 0.06580092757940292,
      "learning_rate": 4.579761293634497e-05,
      "loss": 0.0043,
      "step": 6550
    },
    {
      "epoch": 0.4235112936344969,
      "grad_norm": 0.09841375052928925,
      "learning_rate": 4.576552874743327e-05,
      "loss": 0.0043,
      "step": 6600
    },
    {
      "epoch": 0.42671971252566737,
      "grad_norm": 0.10347694158554077,
      "learning_rate": 4.5733444558521564e-05,
      "loss": 0.0042,
      "step": 6650
    },
    {
      "epoch": 0.4299281314168378,
      "grad_norm": 0.09105418622493744,
      "learning_rate": 4.570136036960986e-05,
      "loss": 0.0042,
      "step": 6700
    },
    {
      "epoch": 0.43313655030800824,
      "grad_norm": 0.06062815338373184,
      "learning_rate": 4.5669276180698156e-05,
      "loss": 0.0043,
      "step": 6750
    },
    {
      "epoch": 0.43634496919917864,
      "grad_norm": 0.1545829325914383,
      "learning_rate": 4.5637191991786446e-05,
      "loss": 0.0042,
      "step": 6800
    },
    {
      "epoch": 0.43955338809034905,
      "grad_norm": 0.14473003149032593,
      "learning_rate": 4.560510780287475e-05,
      "loss": 0.0043,
      "step": 6850
    },
    {
      "epoch": 0.4427618069815195,
      "grad_norm": 0.1753757894039154,
      "learning_rate": 4.557302361396304e-05,
      "loss": 0.0042,
      "step": 6900
    },
    {
      "epoch": 0.4459702258726899,
      "grad_norm": 0.08605489879846573,
      "learning_rate": 4.554093942505134e-05,
      "loss": 0.0043,
      "step": 6950
    },
    {
      "epoch": 0.4491786447638604,
      "grad_norm": 0.14012521505355835,
      "learning_rate": 4.550885523613963e-05,
      "loss": 0.0043,
      "step": 7000
    },
    {
      "epoch": 0.4523870636550308,
      "grad_norm": 0.17703241109848022,
      "learning_rate": 4.547677104722793e-05,
      "loss": 0.0042,
      "step": 7050
    },
    {
      "epoch": 0.45559548254620125,
      "grad_norm": 0.13319678604602814,
      "learning_rate": 4.544468685831623e-05,
      "loss": 0.0042,
      "step": 7100
    },
    {
      "epoch": 0.45880390143737165,
      "grad_norm": 0.12232106924057007,
      "learning_rate": 4.541260266940452e-05,
      "loss": 0.0042,
      "step": 7150
    },
    {
      "epoch": 0.4620123203285421,
      "grad_norm": 0.16049116849899292,
      "learning_rate": 4.5380518480492815e-05,
      "loss": 0.0042,
      "step": 7200
    },
    {
      "epoch": 0.4652207392197125,
      "grad_norm": 0.10226944088935852,
      "learning_rate": 4.534843429158111e-05,
      "loss": 0.0043,
      "step": 7250
    },
    {
      "epoch": 0.468429158110883,
      "grad_norm": 0.046690840274095535,
      "learning_rate": 4.531635010266941e-05,
      "loss": 0.0042,
      "step": 7300
    },
    {
      "epoch": 0.4716375770020534,
      "grad_norm": 0.12542586028575897,
      "learning_rate": 4.5284265913757704e-05,
      "loss": 0.0042,
      "step": 7350
    },
    {
      "epoch": 0.4748459958932238,
      "grad_norm": 0.1957542449235916,
      "learning_rate": 4.5252181724846e-05,
      "loss": 0.0042,
      "step": 7400
    },
    {
      "epoch": 0.47805441478439425,
      "grad_norm": 0.13214462995529175,
      "learning_rate": 4.522009753593429e-05,
      "loss": 0.0042,
      "step": 7450
    },
    {
      "epoch": 0.48126283367556466,
      "grad_norm": 0.13392311334609985,
      "learning_rate": 4.518801334702259e-05,
      "loss": 0.0042,
      "step": 7500
    },
    {
      "epoch": 0.4844712525667351,
      "grad_norm": 0.0772903561592102,
      "learning_rate": 4.515592915811089e-05,
      "loss": 0.0042,
      "step": 7550
    },
    {
      "epoch": 0.48767967145790553,
      "grad_norm": 0.054369036108255386,
      "learning_rate": 4.512384496919918e-05,
      "loss": 0.0041,
      "step": 7600
    },
    {
      "epoch": 0.490888090349076,
      "grad_norm": 0.09057991951704025,
      "learning_rate": 4.509176078028748e-05,
      "loss": 0.0041,
      "step": 7650
    },
    {
      "epoch": 0.4940965092402464,
      "grad_norm": 0.11504554003477097,
      "learning_rate": 4.505967659137577e-05,
      "loss": 0.0042,
      "step": 7700
    },
    {
      "epoch": 0.49730492813141686,
      "grad_norm": 0.14419105648994446,
      "learning_rate": 4.5027592402464066e-05,
      "loss": 0.0043,
      "step": 7750
    },
    {
      "epoch": 0.5005133470225873,
      "grad_norm": 0.12302153557538986,
      "learning_rate": 4.499550821355236e-05,
      "loss": 0.0042,
      "step": 7800
    },
    {
      "epoch": 0.5037217659137577,
      "grad_norm": 0.12141894549131393,
      "learning_rate": 4.496342402464066e-05,
      "loss": 0.0041,
      "step": 7850
    },
    {
      "epoch": 0.5069301848049281,
      "grad_norm": 0.07456409931182861,
      "learning_rate": 4.4931339835728955e-05,
      "loss": 0.0041,
      "step": 7900
    },
    {
      "epoch": 0.5101386036960985,
      "grad_norm": 0.09006810933351517,
      "learning_rate": 4.489925564681725e-05,
      "loss": 0.0041,
      "step": 7950
    },
    {
      "epoch": 0.5133470225872689,
      "grad_norm": 0.05453994870185852,
      "learning_rate": 4.486717145790554e-05,
      "loss": 0.0041,
      "step": 8000
    },
    {
      "epoch": 0.5165554414784395,
      "grad_norm": 0.09861395508050919,
      "learning_rate": 4.4835087268993844e-05,
      "loss": 0.0042,
      "step": 8050
    },
    {
      "epoch": 0.5197638603696099,
      "grad_norm": 0.07335338741540909,
      "learning_rate": 4.480300308008214e-05,
      "loss": 0.0042,
      "step": 8100
    },
    {
      "epoch": 0.5229722792607803,
      "grad_norm": 0.09831993281841278,
      "learning_rate": 4.477091889117043e-05,
      "loss": 0.0042,
      "step": 8150
    },
    {
      "epoch": 0.5261806981519507,
      "grad_norm": 0.032159414142370224,
      "learning_rate": 4.473883470225873e-05,
      "loss": 0.0041,
      "step": 8200
    },
    {
      "epoch": 0.5293891170431212,
      "grad_norm": 0.02210237644612789,
      "learning_rate": 4.470675051334702e-05,
      "loss": 0.0041,
      "step": 8250
    },
    {
      "epoch": 0.5325975359342916,
      "grad_norm": 0.12126825749874115,
      "learning_rate": 4.4674666324435325e-05,
      "loss": 0.0042,
      "step": 8300
    },
    {
      "epoch": 0.535805954825462,
      "grad_norm": 0.18197846412658691,
      "learning_rate": 4.4642582135523614e-05,
      "loss": 0.0042,
      "step": 8350
    },
    {
      "epoch": 0.5390143737166324,
      "grad_norm": 0.10645260661840439,
      "learning_rate": 4.461049794661191e-05,
      "loss": 0.0042,
      "step": 8400
    },
    {
      "epoch": 0.5422227926078029,
      "grad_norm": 0.022749464958906174,
      "learning_rate": 4.4578413757700206e-05,
      "loss": 0.0042,
      "step": 8450
    },
    {
      "epoch": 0.5454312114989733,
      "grad_norm": 0.07473933696746826,
      "learning_rate": 4.45463295687885e-05,
      "loss": 0.0042,
      "step": 8500
    },
    {
      "epoch": 0.5486396303901437,
      "grad_norm": 0.06217483803629875,
      "learning_rate": 4.45142453798768e-05,
      "loss": 0.0042,
      "step": 8550
    },
    {
      "epoch": 0.5518480492813141,
      "grad_norm": 0.16614930331707,
      "learning_rate": 4.4482161190965095e-05,
      "loss": 0.0042,
      "step": 8600
    },
    {
      "epoch": 0.5550564681724846,
      "grad_norm": 0.09221570193767548,
      "learning_rate": 4.445007700205339e-05,
      "loss": 0.0042,
      "step": 8650
    },
    {
      "epoch": 0.5582648870636551,
      "grad_norm": 0.10425765812397003,
      "learning_rate": 4.441799281314169e-05,
      "loss": 0.0042,
      "step": 8700
    },
    {
      "epoch": 0.5614733059548255,
      "grad_norm": 0.2021375447511673,
      "learning_rate": 4.4385908624229983e-05,
      "loss": 0.0042,
      "step": 8750
    },
    {
      "epoch": 0.5646817248459959,
      "grad_norm": 0.09204760938882828,
      "learning_rate": 4.435382443531827e-05,
      "loss": 0.0042,
      "step": 8800
    },
    {
      "epoch": 0.5678901437371663,
      "grad_norm": 0.06883399188518524,
      "learning_rate": 4.4321740246406576e-05,
      "loss": 0.0042,
      "step": 8850
    },
    {
      "epoch": 0.5710985626283368,
      "grad_norm": 0.18279199302196503,
      "learning_rate": 4.4289656057494865e-05,
      "loss": 0.0041,
      "step": 8900
    },
    {
      "epoch": 0.5743069815195072,
      "grad_norm": 0.05089075490832329,
      "learning_rate": 4.425757186858316e-05,
      "loss": 0.0042,
      "step": 8950
    },
    {
      "epoch": 0.5775154004106776,
      "grad_norm": 0.10018181055784225,
      "learning_rate": 4.4225487679671464e-05,
      "loss": 0.0042,
      "step": 9000
    },
    {
      "epoch": 0.580723819301848,
      "grad_norm": 0.16967801749706268,
      "learning_rate": 4.4193403490759754e-05,
      "loss": 0.0042,
      "step": 9050
    },
    {
      "epoch": 0.5839322381930184,
      "grad_norm": 0.11839661747217178,
      "learning_rate": 4.416131930184805e-05,
      "loss": 0.0042,
      "step": 9100
    },
    {
      "epoch": 0.5871406570841889,
      "grad_norm": 0.1483699232339859,
      "learning_rate": 4.4129235112936346e-05,
      "loss": 0.0042,
      "step": 9150
    },
    {
      "epoch": 0.5903490759753593,
      "grad_norm": 0.10796205699443817,
      "learning_rate": 4.409715092402464e-05,
      "loss": 0.0042,
      "step": 9200
    },
    {
      "epoch": 0.5935574948665298,
      "grad_norm": 0.11165871471166611,
      "learning_rate": 4.406506673511294e-05,
      "loss": 0.0041,
      "step": 9250
    },
    {
      "epoch": 0.5967659137577002,
      "grad_norm": 0.30577337741851807,
      "learning_rate": 4.4032982546201235e-05,
      "loss": 0.0041,
      "step": 9300
    },
    {
      "epoch": 0.5999743326488707,
      "grad_norm": 0.07445946335792542,
      "learning_rate": 4.4000898357289524e-05,
      "loss": 0.0042,
      "step": 9350
    },
    {
      "epoch": 0.6031827515400411,
      "grad_norm": 0.04901031777262688,
      "learning_rate": 4.396881416837783e-05,
      "loss": 0.0041,
      "step": 9400
    },
    {
      "epoch": 0.6063911704312115,
      "grad_norm": 0.13292698562145233,
      "learning_rate": 4.393672997946612e-05,
      "loss": 0.0041,
      "step": 9450
    },
    {
      "epoch": 0.6095995893223819,
      "grad_norm": 0.15001589059829712,
      "learning_rate": 4.390464579055442e-05,
      "loss": 0.0042,
      "step": 9500
    },
    {
      "epoch": 0.6128080082135524,
      "grad_norm": 0.12426796555519104,
      "learning_rate": 4.3872561601642716e-05,
      "loss": 0.0041,
      "step": 9550
    },
    {
      "epoch": 0.6160164271047228,
      "grad_norm": 0.09817077219486237,
      "learning_rate": 4.3840477412731005e-05,
      "loss": 0.0041,
      "step": 9600
    },
    {
      "epoch": 0.6192248459958932,
      "grad_norm": 0.16808061301708221,
      "learning_rate": 4.380839322381931e-05,
      "loss": 0.0041,
      "step": 9650
    },
    {
      "epoch": 0.6224332648870636,
      "grad_norm": 0.16213509440422058,
      "learning_rate": 4.37763090349076e-05,
      "loss": 0.0041,
      "step": 9700
    },
    {
      "epoch": 0.625641683778234,
      "grad_norm": 0.1696890890598297,
      "learning_rate": 4.3744224845995894e-05,
      "loss": 0.0041,
      "step": 9750
    },
    {
      "epoch": 0.6288501026694046,
      "grad_norm": 0.10909920930862427,
      "learning_rate": 4.371214065708419e-05,
      "loss": 0.0042,
      "step": 9800
    },
    {
      "epoch": 0.632058521560575,
      "grad_norm": 0.12883402407169342,
      "learning_rate": 4.3680056468172486e-05,
      "loss": 0.0041,
      "step": 9850
    },
    {
      "epoch": 0.6352669404517454,
      "grad_norm": 0.11434412747621536,
      "learning_rate": 4.364797227926078e-05,
      "loss": 0.0041,
      "step": 9900
    },
    {
      "epoch": 0.6384753593429158,
      "grad_norm": 0.07346458733081818,
      "learning_rate": 4.361588809034908e-05,
      "loss": 0.0042,
      "step": 9950
    },
    {
      "epoch": 0.6416837782340863,
      "grad_norm": 0.049194369465112686,
      "learning_rate": 4.3583803901437375e-05,
      "loss": 0.0041,
      "step": 10000
    },
    {
      "epoch": 0.6448921971252567,
      "grad_norm": 0.02597556822001934,
      "learning_rate": 4.355171971252567e-05,
      "loss": 0.0042,
      "step": 10050
    },
    {
      "epoch": 0.6481006160164271,
      "grad_norm": 0.09386061877012253,
      "learning_rate": 4.351963552361397e-05,
      "loss": 0.0041,
      "step": 10100
    },
    {
      "epoch": 0.6513090349075975,
      "grad_norm": 0.08999032527208328,
      "learning_rate": 4.3487551334702256e-05,
      "loss": 0.0041,
      "step": 10150
    },
    {
      "epoch": 0.6545174537987679,
      "grad_norm": 0.27352985739707947,
      "learning_rate": 4.345546714579056e-05,
      "loss": 0.0041,
      "step": 10200
    },
    {
      "epoch": 0.6577258726899384,
      "grad_norm": 0.2497233897447586,
      "learning_rate": 4.342338295687885e-05,
      "loss": 0.0041,
      "step": 10250
    },
    {
      "epoch": 0.6609342915811088,
      "grad_norm": 0.06845168769359589,
      "learning_rate": 4.3391298767967145e-05,
      "loss": 0.0041,
      "step": 10300
    },
    {
      "epoch": 0.6641427104722792,
      "grad_norm": 0.142910897731781,
      "learning_rate": 4.335921457905545e-05,
      "loss": 0.0041,
      "step": 10350
    },
    {
      "epoch": 0.6673511293634496,
      "grad_norm": 0.08798276633024216,
      "learning_rate": 4.332713039014374e-05,
      "loss": 0.0041,
      "step": 10400
    },
    {
      "epoch": 0.6705595482546202,
      "grad_norm": 0.04656196013092995,
      "learning_rate": 4.3295046201232034e-05,
      "loss": 0.0041,
      "step": 10450
    },
    {
      "epoch": 0.6737679671457906,
      "grad_norm": 0.17179575562477112,
      "learning_rate": 4.326296201232033e-05,
      "loss": 0.0041,
      "step": 10500
    },
    {
      "epoch": 0.676976386036961,
      "grad_norm": 0.11354847997426987,
      "learning_rate": 4.3230877823408626e-05,
      "loss": 0.0041,
      "step": 10550
    },
    {
      "epoch": 0.6801848049281314,
      "grad_norm": 0.14705684781074524,
      "learning_rate": 4.319879363449692e-05,
      "loss": 0.0041,
      "step": 10600
    },
    {
      "epoch": 0.6833932238193019,
      "grad_norm": 0.08584637194871902,
      "learning_rate": 4.316670944558522e-05,
      "loss": 0.0042,
      "step": 10650
    },
    {
      "epoch": 0.6866016427104723,
      "grad_norm": 0.08187839388847351,
      "learning_rate": 4.313462525667351e-05,
      "loss": 0.0041,
      "step": 10700
    },
    {
      "epoch": 0.6898100616016427,
      "grad_norm": 0.04906270280480385,
      "learning_rate": 4.310254106776181e-05,
      "loss": 0.0042,
      "step": 10750
    },
    {
      "epoch": 0.6930184804928131,
      "grad_norm": 0.20431962609291077,
      "learning_rate": 4.307045687885011e-05,
      "loss": 0.004,
      "step": 10800
    },
    {
      "epoch": 0.6962268993839835,
      "grad_norm": 0.09832077473402023,
      "learning_rate": 4.30383726899384e-05,
      "loss": 0.0041,
      "step": 10850
    },
    {
      "epoch": 0.699435318275154,
      "grad_norm": 0.046278417110443115,
      "learning_rate": 4.30062885010267e-05,
      "loss": 0.0041,
      "step": 10900
    },
    {
      "epoch": 0.7026437371663244,
      "grad_norm": 0.08685992658138275,
      "learning_rate": 4.297420431211499e-05,
      "loss": 0.0041,
      "step": 10950
    },
    {
      "epoch": 0.7058521560574949,
      "grad_norm": 0.12955740094184875,
      "learning_rate": 4.294212012320329e-05,
      "loss": 0.0041,
      "step": 11000
    },
    {
      "epoch": 0.7090605749486653,
      "grad_norm": 0.19281964004039764,
      "learning_rate": 4.291003593429158e-05,
      "loss": 0.0041,
      "step": 11050
    },
    {
      "epoch": 0.7122689938398358,
      "grad_norm": 0.24003127217292786,
      "learning_rate": 4.287795174537988e-05,
      "loss": 0.004,
      "step": 11100
    },
    {
      "epoch": 0.7154774127310062,
      "grad_norm": 0.06138087064027786,
      "learning_rate": 4.2845867556468173e-05,
      "loss": 0.004,
      "step": 11150
    },
    {
      "epoch": 0.7186858316221766,
      "grad_norm": 0.21052731573581696,
      "learning_rate": 4.281378336755647e-05,
      "loss": 0.0041,
      "step": 11200
    },
    {
      "epoch": 0.721894250513347,
      "grad_norm": 0.08874576538801193,
      "learning_rate": 4.2781699178644766e-05,
      "loss": 0.0041,
      "step": 11250
    },
    {
      "epoch": 0.7251026694045175,
      "grad_norm": 0.09713373333215714,
      "learning_rate": 4.274961498973306e-05,
      "loss": 0.004,
      "step": 11300
    },
    {
      "epoch": 0.7283110882956879,
      "grad_norm": 0.07982718199491501,
      "learning_rate": 4.271753080082136e-05,
      "loss": 0.004,
      "step": 11350
    },
    {
      "epoch": 0.7315195071868583,
      "grad_norm": 0.10731560736894608,
      "learning_rate": 4.2685446611909654e-05,
      "loss": 0.0041,
      "step": 11400
    },
    {
      "epoch": 0.7347279260780287,
      "grad_norm": 0.03467694669961929,
      "learning_rate": 4.265336242299795e-05,
      "loss": 0.0041,
      "step": 11450
    },
    {
      "epoch": 0.7379363449691991,
      "grad_norm": 0.1743619292974472,
      "learning_rate": 4.262127823408624e-05,
      "loss": 0.004,
      "step": 11500
    },
    {
      "epoch": 0.7411447638603696,
      "grad_norm": 0.08853704482316971,
      "learning_rate": 4.258919404517454e-05,
      "loss": 0.004,
      "step": 11550
    },
    {
      "epoch": 0.74435318275154,
      "grad_norm": 0.09692210704088211,
      "learning_rate": 4.255710985626283e-05,
      "loss": 0.0041,
      "step": 11600
    },
    {
      "epoch": 0.7475616016427105,
      "grad_norm": 0.08064714074134827,
      "learning_rate": 4.252502566735113e-05,
      "loss": 0.0041,
      "step": 11650
    },
    {
      "epoch": 0.7507700205338809,
      "grad_norm": 0.12873943150043488,
      "learning_rate": 4.249294147843943e-05,
      "loss": 0.004,
      "step": 11700
    },
    {
      "epoch": 0.7539784394250514,
      "grad_norm": 0.15204580128192902,
      "learning_rate": 4.246085728952772e-05,
      "loss": 0.0039,
      "step": 11750
    },
    {
      "epoch": 0.7571868583162218,
      "grad_norm": 0.12141528725624084,
      "learning_rate": 4.2428773100616024e-05,
      "loss": 0.004,
      "step": 11800
    },
    {
      "epoch": 0.7603952772073922,
      "grad_norm": 0.2516895830631256,
      "learning_rate": 4.239668891170431e-05,
      "loss": 0.004,
      "step": 11850
    },
    {
      "epoch": 0.7636036960985626,
      "grad_norm": 0.2304108440876007,
      "learning_rate": 4.236460472279261e-05,
      "loss": 0.004,
      "step": 11900
    },
    {
      "epoch": 0.766812114989733,
      "grad_norm": 0.1994566172361374,
      "learning_rate": 4.2332520533880906e-05,
      "loss": 0.004,
      "step": 11950
    },
    {
      "epoch": 0.7700205338809035,
      "grad_norm": 0.19531041383743286,
      "learning_rate": 4.23004363449692e-05,
      "loss": 0.004,
      "step": 12000
    },
    {
      "epoch": 0.7732289527720739,
      "grad_norm": 0.1745152622461319,
      "learning_rate": 4.22683521560575e-05,
      "loss": 0.004,
      "step": 12050
    },
    {
      "epoch": 0.7764373716632443,
      "grad_norm": 0.09381449967622757,
      "learning_rate": 4.2236267967145794e-05,
      "loss": 0.004,
      "step": 12100
    },
    {
      "epoch": 0.7796457905544147,
      "grad_norm": 0.10453466325998306,
      "learning_rate": 4.220418377823409e-05,
      "loss": 0.004,
      "step": 12150
    },
    {
      "epoch": 0.7828542094455853,
      "grad_norm": 0.16465109586715698,
      "learning_rate": 4.2172099589322387e-05,
      "loss": 0.004,
      "step": 12200
    },
    {
      "epoch": 0.7860626283367557,
      "grad_norm": 0.11255551129579544,
      "learning_rate": 4.214001540041068e-05,
      "loss": 0.0039,
      "step": 12250
    },
    {
      "epoch": 0.7892710472279261,
      "grad_norm": 0.06687500327825546,
      "learning_rate": 4.210793121149897e-05,
      "loss": 0.004,
      "step": 12300
    },
    {
      "epoch": 0.7924794661190965,
      "grad_norm": 0.2486545443534851,
      "learning_rate": 4.2075847022587275e-05,
      "loss": 0.004,
      "step": 12350
    },
    {
      "epoch": 0.795687885010267,
      "grad_norm": 0.10154150426387787,
      "learning_rate": 4.2043762833675565e-05,
      "loss": 0.0039,
      "step": 12400
    },
    {
      "epoch": 0.7988963039014374,
      "grad_norm": 0.08654507994651794,
      "learning_rate": 4.201167864476386e-05,
      "loss": 0.0039,
      "step": 12450
    },
    {
      "epoch": 0.8021047227926078,
      "grad_norm": 0.16494342684745789,
      "learning_rate": 4.197959445585216e-05,
      "loss": 0.0039,
      "step": 12500
    },
    {
      "epoch": 0.8053131416837782,
      "grad_norm": 0.20454110205173492,
      "learning_rate": 4.194751026694045e-05,
      "loss": 0.004,
      "step": 12550
    },
    {
      "epoch": 0.8085215605749486,
      "grad_norm": 0.20626898109912872,
      "learning_rate": 4.191542607802875e-05,
      "loss": 0.004,
      "step": 12600
    },
    {
      "epoch": 0.8117299794661191,
      "grad_norm": 0.11304645240306854,
      "learning_rate": 4.1883341889117045e-05,
      "loss": 0.0039,
      "step": 12650
    },
    {
      "epoch": 0.8149383983572895,
      "grad_norm": 0.1434074491262436,
      "learning_rate": 4.185125770020534e-05,
      "loss": 0.004,
      "step": 12700
    },
    {
      "epoch": 0.81814681724846,
      "grad_norm": 0.15268705785274506,
      "learning_rate": 4.181917351129364e-05,
      "loss": 0.004,
      "step": 12750
    },
    {
      "epoch": 0.8213552361396304,
      "grad_norm": 0.1632087081670761,
      "learning_rate": 4.1787089322381934e-05,
      "loss": 0.004,
      "step": 12800
    },
    {
      "epoch": 0.8245636550308009,
      "grad_norm": 0.17254434525966644,
      "learning_rate": 4.1755005133470223e-05,
      "loss": 0.0039,
      "step": 12850
    },
    {
      "epoch": 0.8277720739219713,
      "grad_norm": 0.10161591321229935,
      "learning_rate": 4.1722920944558526e-05,
      "loss": 0.004,
      "step": 12900
    },
    {
      "epoch": 0.8309804928131417,
      "grad_norm": 0.24020400643348694,
      "learning_rate": 4.1690836755646816e-05,
      "loss": 0.0039,
      "step": 12950
    },
    {
      "epoch": 0.8341889117043121,
      "grad_norm": 0.12488757818937302,
      "learning_rate": 4.165875256673511e-05,
      "loss": 0.0039,
      "step": 13000
    },
    {
      "epoch": 0.8373973305954825,
      "grad_norm": 0.18088656663894653,
      "learning_rate": 4.162666837782341e-05,
      "loss": 0.0039,
      "step": 13050
    },
    {
      "epoch": 0.840605749486653,
      "grad_norm": 0.1416269838809967,
      "learning_rate": 4.1594584188911704e-05,
      "loss": 0.004,
      "step": 13100
    },
    {
      "epoch": 0.8438141683778234,
      "grad_norm": 0.14480768144130707,
      "learning_rate": 4.156250000000001e-05,
      "loss": 0.0039,
      "step": 13150
    },
    {
      "epoch": 0.8470225872689938,
      "grad_norm": 0.26628607511520386,
      "learning_rate": 4.15304158110883e-05,
      "loss": 0.0038,
      "step": 13200
    },
    {
      "epoch": 0.8502310061601642,
      "grad_norm": 0.19697800278663635,
      "learning_rate": 4.149833162217659e-05,
      "loss": 0.0039,
      "step": 13250
    },
    {
      "epoch": 0.8534394250513347,
      "grad_norm": 0.10627517104148865,
      "learning_rate": 4.146624743326489e-05,
      "loss": 0.004,
      "step": 13300
    },
    {
      "epoch": 0.8566478439425051,
      "grad_norm": 0.13850699365139008,
      "learning_rate": 4.1434163244353185e-05,
      "loss": 0.0038,
      "step": 13350
    },
    {
      "epoch": 0.8598562628336756,
      "grad_norm": 0.1261112093925476,
      "learning_rate": 4.140207905544148e-05,
      "loss": 0.0039,
      "step": 13400
    },
    {
      "epoch": 0.863064681724846,
      "grad_norm": 0.25686100125312805,
      "learning_rate": 4.136999486652978e-05,
      "loss": 0.0038,
      "step": 13450
    },
    {
      "epoch": 0.8662731006160165,
      "grad_norm": 0.1633051484823227,
      "learning_rate": 4.133791067761807e-05,
      "loss": 0.0039,
      "step": 13500
    },
    {
      "epoch": 0.8694815195071869,
      "grad_norm": 0.22810669243335724,
      "learning_rate": 4.130582648870637e-05,
      "loss": 0.0039,
      "step": 13550
    },
    {
      "epoch": 0.8726899383983573,
      "grad_norm": 0.2408992350101471,
      "learning_rate": 4.1273742299794666e-05,
      "loss": 0.0039,
      "step": 13600
    },
    {
      "epoch": 0.8758983572895277,
      "grad_norm": 0.16102947294712067,
      "learning_rate": 4.1241658110882956e-05,
      "loss": 0.0039,
      "step": 13650
    },
    {
      "epoch": 0.8791067761806981,
      "grad_norm": 0.26577848196029663,
      "learning_rate": 4.120957392197126e-05,
      "loss": 0.0039,
      "step": 13700
    },
    {
      "epoch": 0.8823151950718686,
      "grad_norm": 0.07304937392473221,
      "learning_rate": 4.117748973305955e-05,
      "loss": 0.0039,
      "step": 13750
    },
    {
      "epoch": 0.885523613963039,
      "grad_norm": 0.1983088105916977,
      "learning_rate": 4.1145405544147844e-05,
      "loss": 0.0039,
      "step": 13800
    },
    {
      "epoch": 0.8887320328542094,
      "grad_norm": 0.22581346333026886,
      "learning_rate": 4.111332135523614e-05,
      "loss": 0.0039,
      "step": 13850
    },
    {
      "epoch": 0.8919404517453798,
      "grad_norm": 0.04978558421134949,
      "learning_rate": 4.108123716632444e-05,
      "loss": 0.0039,
      "step": 13900
    },
    {
      "epoch": 0.8951488706365504,
      "grad_norm": 0.4163251519203186,
      "learning_rate": 4.104915297741273e-05,
      "loss": 0.0039,
      "step": 13950
    },
    {
      "epoch": 0.8983572895277208,
      "grad_norm": 0.18861117959022522,
      "learning_rate": 4.101706878850103e-05,
      "loss": 0.0039,
      "step": 14000
    },
    {
      "epoch": 0.9015657084188912,
      "grad_norm": 0.05168028548359871,
      "learning_rate": 4.0984984599589325e-05,
      "loss": 0.0039,
      "step": 14050
    },
    {
      "epoch": 0.9047741273100616,
      "grad_norm": 0.1815251111984253,
      "learning_rate": 4.095290041067762e-05,
      "loss": 0.0039,
      "step": 14100
    },
    {
      "epoch": 0.9079825462012321,
      "grad_norm": 0.10585863143205643,
      "learning_rate": 4.092081622176592e-05,
      "loss": 0.0038,
      "step": 14150
    },
    {
      "epoch": 0.9111909650924025,
      "grad_norm": 0.23117764294147491,
      "learning_rate": 4.088873203285421e-05,
      "loss": 0.0039,
      "step": 14200
    },
    {
      "epoch": 0.9143993839835729,
      "grad_norm": 0.1363682895898819,
      "learning_rate": 4.085664784394251e-05,
      "loss": 0.004,
      "step": 14250
    },
    {
      "epoch": 0.9176078028747433,
      "grad_norm": 0.2096492201089859,
      "learning_rate": 4.08245636550308e-05,
      "loss": 0.0039,
      "step": 14300
    },
    {
      "epoch": 0.9208162217659137,
      "grad_norm": 0.09495562314987183,
      "learning_rate": 4.07924794661191e-05,
      "loss": 0.0039,
      "step": 14350
    },
    {
      "epoch": 0.9240246406570842,
      "grad_norm": 0.08022567629814148,
      "learning_rate": 4.076039527720739e-05,
      "loss": 0.0039,
      "step": 14400
    },
    {
      "epoch": 0.9272330595482546,
      "grad_norm": 0.12694016098976135,
      "learning_rate": 4.072831108829569e-05,
      "loss": 0.0039,
      "step": 14450
    },
    {
      "epoch": 0.930441478439425,
      "grad_norm": 0.22788473963737488,
      "learning_rate": 4.069622689938399e-05,
      "loss": 0.004,
      "step": 14500
    },
    {
      "epoch": 0.9336498973305954,
      "grad_norm": 0.06044092774391174,
      "learning_rate": 4.066414271047228e-05,
      "loss": 0.0039,
      "step": 14550
    },
    {
      "epoch": 0.936858316221766,
      "grad_norm": 0.2578093409538269,
      "learning_rate": 4.0632058521560576e-05,
      "loss": 0.0039,
      "step": 14600
    },
    {
      "epoch": 0.9400667351129364,
      "grad_norm": 0.08708649128675461,
      "learning_rate": 4.059997433264887e-05,
      "loss": 0.0039,
      "step": 14650
    },
    {
      "epoch": 0.9432751540041068,
      "grad_norm": 0.16154305636882782,
      "learning_rate": 4.056789014373717e-05,
      "loss": 0.0038,
      "step": 14700
    },
    {
      "epoch": 0.9464835728952772,
      "grad_norm": 0.17758511006832123,
      "learning_rate": 4.0535805954825465e-05,
      "loss": 0.0038,
      "step": 14750
    },
    {
      "epoch": 0.9496919917864476,
      "grad_norm": 0.36184555292129517,
      "learning_rate": 4.050372176591376e-05,
      "loss": 0.004,
      "step": 14800
    },
    {
      "epoch": 0.9529004106776181,
      "grad_norm": 0.10156596451997757,
      "learning_rate": 4.047163757700205e-05,
      "loss": 0.0038,
      "step": 14850
    },
    {
      "epoch": 0.9561088295687885,
      "grad_norm": 0.07438229769468307,
      "learning_rate": 4.0439553388090354e-05,
      "loss": 0.0039,
      "step": 14900
    },
    {
      "epoch": 0.9593172484599589,
      "grad_norm": 0.13381263613700867,
      "learning_rate": 4.040746919917865e-05,
      "loss": 0.0038,
      "step": 14950
    },
    {
      "epoch": 0.9625256673511293,
      "grad_norm": 0.053017258644104004,
      "learning_rate": 4.037538501026694e-05,
      "loss": 0.0038,
      "step": 15000
    },
    {
      "epoch": 0.9657340862422998,
      "grad_norm": 0.24781180918216705,
      "learning_rate": 4.034330082135524e-05,
      "loss": 0.0039,
      "step": 15050
    },
    {
      "epoch": 0.9689425051334702,
      "grad_norm": 0.19562149047851562,
      "learning_rate": 4.031121663244353e-05,
      "loss": 0.0039,
      "step": 15100
    },
    {
      "epoch": 0.9721509240246407,
      "grad_norm": 0.20482122898101807,
      "learning_rate": 4.027913244353183e-05,
      "loss": 0.0039,
      "step": 15150
    },
    {
      "epoch": 0.9753593429158111,
      "grad_norm": 0.15291772782802582,
      "learning_rate": 4.0247048254620124e-05,
      "loss": 0.0038,
      "step": 15200
    },
    {
      "epoch": 0.9785677618069816,
      "grad_norm": 0.2569286823272705,
      "learning_rate": 4.021496406570842e-05,
      "loss": 0.0038,
      "step": 15250
    },
    {
      "epoch": 0.981776180698152,
      "grad_norm": 0.14269961416721344,
      "learning_rate": 4.0182879876796716e-05,
      "loss": 0.0039,
      "step": 15300
    },
    {
      "epoch": 0.9849845995893224,
      "grad_norm": 0.3127867579460144,
      "learning_rate": 4.015079568788501e-05,
      "loss": 0.0038,
      "step": 15350
    },
    {
      "epoch": 0.9881930184804928,
      "grad_norm": 0.20441696047782898,
      "learning_rate": 4.011871149897331e-05,
      "loss": 0.0038,
      "step": 15400
    },
    {
      "epoch": 0.9914014373716632,
      "grad_norm": 0.19934451580047607,
      "learning_rate": 4.0086627310061605e-05,
      "loss": 0.0039,
      "step": 15450
    },
    {
      "epoch": 0.9946098562628337,
      "grad_norm": 0.15886719524860382,
      "learning_rate": 4.00545431211499e-05,
      "loss": 0.0039,
      "step": 15500
    },
    {
      "epoch": 0.9978182751540041,
      "grad_norm": 0.22327284514904022,
      "learning_rate": 4.002245893223819e-05,
      "loss": 0.0038,
      "step": 15550
    },
    {
      "epoch": 1.0010266940451746,
      "grad_norm": 0.1970493346452713,
      "learning_rate": 3.9990374743326493e-05,
      "loss": 0.0039,
      "step": 15600
    },
    {
      "epoch": 1.004235112936345,
      "grad_norm": 0.11409641057252884,
      "learning_rate": 3.995829055441478e-05,
      "loss": 0.0038,
      "step": 15650
    },
    {
      "epoch": 1.0074435318275154,
      "grad_norm": 0.2007090449333191,
      "learning_rate": 3.9926206365503086e-05,
      "loss": 0.0038,
      "step": 15700
    },
    {
      "epoch": 1.0106519507186857,
      "grad_norm": 0.1526930034160614,
      "learning_rate": 3.9894122176591375e-05,
      "loss": 0.0038,
      "step": 15750
    },
    {
      "epoch": 1.0138603696098563,
      "grad_norm": 0.09816151857376099,
      "learning_rate": 3.986203798767967e-05,
      "loss": 0.0038,
      "step": 15800
    },
    {
      "epoch": 1.0170687885010268,
      "grad_norm": 0.15202397108078003,
      "learning_rate": 3.9829953798767974e-05,
      "loss": 0.0039,
      "step": 15850
    },
    {
      "epoch": 1.020277207392197,
      "grad_norm": 0.3992028832435608,
      "learning_rate": 3.9797869609856264e-05,
      "loss": 0.0038,
      "step": 15900
    },
    {
      "epoch": 1.0234856262833676,
      "grad_norm": 0.3171868920326233,
      "learning_rate": 3.976578542094456e-05,
      "loss": 0.0039,
      "step": 15950
    },
    {
      "epoch": 1.0266940451745379,
      "grad_norm": 0.34828507900238037,
      "learning_rate": 3.9733701232032856e-05,
      "loss": 0.0038,
      "step": 16000
    },
    {
      "epoch": 1.0299024640657084,
      "grad_norm": 0.22206561267375946,
      "learning_rate": 3.970161704312115e-05,
      "loss": 0.0038,
      "step": 16050
    },
    {
      "epoch": 1.033110882956879,
      "grad_norm": 0.05375460535287857,
      "learning_rate": 3.966953285420945e-05,
      "loss": 0.0038,
      "step": 16100
    },
    {
      "epoch": 1.0363193018480492,
      "grad_norm": 0.25841477513313293,
      "learning_rate": 3.9637448665297745e-05,
      "loss": 0.0039,
      "step": 16150
    },
    {
      "epoch": 1.0395277207392197,
      "grad_norm": 0.11899523437023163,
      "learning_rate": 3.9605364476386034e-05,
      "loss": 0.0039,
      "step": 16200
    },
    {
      "epoch": 1.0427361396303902,
      "grad_norm": 0.27049654722213745,
      "learning_rate": 3.957328028747434e-05,
      "loss": 0.0039,
      "step": 16250
    },
    {
      "epoch": 1.0459445585215605,
      "grad_norm": 0.16541573405265808,
      "learning_rate": 3.954119609856263e-05,
      "loss": 0.0038,
      "step": 16300
    },
    {
      "epoch": 1.049152977412731,
      "grad_norm": 0.16679702699184418,
      "learning_rate": 3.950911190965092e-05,
      "loss": 0.0038,
      "step": 16350
    },
    {
      "epoch": 1.0523613963039014,
      "grad_norm": 0.10412614047527313,
      "learning_rate": 3.9477027720739226e-05,
      "loss": 0.0038,
      "step": 16400
    },
    {
      "epoch": 1.0555698151950719,
      "grad_norm": 0.12743762135505676,
      "learning_rate": 3.9444943531827515e-05,
      "loss": 0.0039,
      "step": 16450
    },
    {
      "epoch": 1.0587782340862424,
      "grad_norm": 0.22613297402858734,
      "learning_rate": 3.941285934291581e-05,
      "loss": 0.0038,
      "step": 16500
    },
    {
      "epoch": 1.0619866529774127,
      "grad_norm": 0.9592202305793762,
      "learning_rate": 3.938077515400411e-05,
      "loss": 0.0038,
      "step": 16550
    },
    {
      "epoch": 1.0651950718685832,
      "grad_norm": 0.1441369205713272,
      "learning_rate": 3.9348690965092404e-05,
      "loss": 0.0038,
      "step": 16600
    },
    {
      "epoch": 1.0684034907597535,
      "grad_norm": 0.16411139070987701,
      "learning_rate": 3.93166067761807e-05,
      "loss": 0.0039,
      "step": 16650
    },
    {
      "epoch": 1.071611909650924,
      "grad_norm": 0.2838645279407501,
      "learning_rate": 3.9284522587268996e-05,
      "loss": 0.0038,
      "step": 16700
    },
    {
      "epoch": 1.0748203285420945,
      "grad_norm": 0.11622359603643417,
      "learning_rate": 3.925243839835729e-05,
      "loss": 0.0038,
      "step": 16750
    },
    {
      "epoch": 1.0780287474332648,
      "grad_norm": 0.17647510766983032,
      "learning_rate": 3.922035420944559e-05,
      "loss": 0.0038,
      "step": 16800
    },
    {
      "epoch": 1.0812371663244353,
      "grad_norm": 0.1400604546070099,
      "learning_rate": 3.9188270020533885e-05,
      "loss": 0.0037,
      "step": 16850
    },
    {
      "epoch": 1.0844455852156059,
      "grad_norm": 0.16754551231861115,
      "learning_rate": 3.915618583162218e-05,
      "loss": 0.0039,
      "step": 16900
    },
    {
      "epoch": 1.0876540041067762,
      "grad_norm": 0.32527944445610046,
      "learning_rate": 3.912410164271048e-05,
      "loss": 0.0037,
      "step": 16950
    },
    {
      "epoch": 1.0908624229979467,
      "grad_norm": 0.2147861123085022,
      "learning_rate": 3.9092017453798766e-05,
      "loss": 0.0038,
      "step": 17000
    },
    {
      "epoch": 1.094070841889117,
      "grad_norm": 0.26855021715164185,
      "learning_rate": 3.905993326488707e-05,
      "loss": 0.0038,
      "step": 17050
    },
    {
      "epoch": 1.0972792607802875,
      "grad_norm": 0.197439506649971,
      "learning_rate": 3.902784907597536e-05,
      "loss": 0.0038,
      "step": 17100
    },
    {
      "epoch": 1.100487679671458,
      "grad_norm": 0.17256700992584229,
      "learning_rate": 3.8995764887063655e-05,
      "loss": 0.0038,
      "step": 17150
    },
    {
      "epoch": 1.1036960985626283,
      "grad_norm": 0.3698173761367798,
      "learning_rate": 3.896368069815196e-05,
      "loss": 0.0038,
      "step": 17200
    },
    {
      "epoch": 1.1069045174537988,
      "grad_norm": 0.09914050251245499,
      "learning_rate": 3.893159650924025e-05,
      "loss": 0.0039,
      "step": 17250
    },
    {
      "epoch": 1.110112936344969,
      "grad_norm": 0.17266829311847687,
      "learning_rate": 3.8899512320328544e-05,
      "loss": 0.0038,
      "step": 17300
    },
    {
      "epoch": 1.1133213552361396,
      "grad_norm": 0.1963542401790619,
      "learning_rate": 3.886742813141684e-05,
      "loss": 0.0038,
      "step": 17350
    },
    {
      "epoch": 1.1165297741273101,
      "grad_norm": 0.3318166434764862,
      "learning_rate": 3.8835343942505136e-05,
      "loss": 0.0038,
      "step": 17400
    },
    {
      "epoch": 1.1197381930184804,
      "grad_norm": 0.18690043687820435,
      "learning_rate": 3.880325975359343e-05,
      "loss": 0.0039,
      "step": 17450
    },
    {
      "epoch": 1.122946611909651,
      "grad_norm": 0.13162823021411896,
      "learning_rate": 3.877117556468173e-05,
      "loss": 0.0038,
      "step": 17500
    },
    {
      "epoch": 1.1261550308008212,
      "grad_norm": 0.22239935398101807,
      "learning_rate": 3.873909137577002e-05,
      "loss": 0.0037,
      "step": 17550
    },
    {
      "epoch": 1.1293634496919918,
      "grad_norm": 0.10225942730903625,
      "learning_rate": 3.870700718685832e-05,
      "loss": 0.0039,
      "step": 17600
    },
    {
      "epoch": 1.1325718685831623,
      "grad_norm": 0.19489523768424988,
      "learning_rate": 3.867492299794661e-05,
      "loss": 0.0038,
      "step": 17650
    },
    {
      "epoch": 1.1357802874743326,
      "grad_norm": 0.18639180064201355,
      "learning_rate": 3.8642838809034906e-05,
      "loss": 0.0038,
      "step": 17700
    },
    {
      "epoch": 1.138988706365503,
      "grad_norm": 0.0495031513273716,
      "learning_rate": 3.861075462012321e-05,
      "loss": 0.0038,
      "step": 17750
    },
    {
      "epoch": 1.1421971252566736,
      "grad_norm": 0.17374800145626068,
      "learning_rate": 3.85786704312115e-05,
      "loss": 0.0038,
      "step": 17800
    },
    {
      "epoch": 1.145405544147844,
      "grad_norm": 0.22889171540737152,
      "learning_rate": 3.8546586242299795e-05,
      "loss": 0.0038,
      "step": 17850
    },
    {
      "epoch": 1.1486139630390144,
      "grad_norm": 0.20034514367580414,
      "learning_rate": 3.851450205338809e-05,
      "loss": 0.0038,
      "step": 17900
    },
    {
      "epoch": 1.1518223819301847,
      "grad_norm": 0.5452418327331543,
      "learning_rate": 3.848241786447639e-05,
      "loss": 0.0038,
      "step": 17950
    },
    {
      "epoch": 1.1550308008213552,
      "grad_norm": 0.19082118570804596,
      "learning_rate": 3.8450333675564683e-05,
      "loss": 0.0038,
      "step": 18000
    },
    {
      "epoch": 1.1582392197125257,
      "grad_norm": 0.21382278203964233,
      "learning_rate": 3.841824948665298e-05,
      "loss": 0.0038,
      "step": 18050
    },
    {
      "epoch": 1.161447638603696,
      "grad_norm": 0.08665944635868073,
      "learning_rate": 3.838616529774127e-05,
      "loss": 0.0039,
      "step": 18100
    },
    {
      "epoch": 1.1646560574948666,
      "grad_norm": 0.055435001850128174,
      "learning_rate": 3.835408110882957e-05,
      "loss": 0.0038,
      "step": 18150
    },
    {
      "epoch": 1.167864476386037,
      "grad_norm": 0.08551286160945892,
      "learning_rate": 3.832199691991787e-05,
      "loss": 0.0038,
      "step": 18200
    },
    {
      "epoch": 1.1710728952772074,
      "grad_norm": 0.16855183243751526,
      "learning_rate": 3.8289912731006164e-05,
      "loss": 0.0038,
      "step": 18250
    },
    {
      "epoch": 1.1742813141683779,
      "grad_norm": 0.11242689192295074,
      "learning_rate": 3.825782854209446e-05,
      "loss": 0.0037,
      "step": 18300
    },
    {
      "epoch": 1.1774897330595482,
      "grad_norm": 0.15903913974761963,
      "learning_rate": 3.822574435318275e-05,
      "loss": 0.0038,
      "step": 18350
    },
    {
      "epoch": 1.1806981519507187,
      "grad_norm": 0.06722445785999298,
      "learning_rate": 3.819366016427105e-05,
      "loss": 0.0038,
      "step": 18400
    },
    {
      "epoch": 1.1839065708418892,
      "grad_norm": 0.2724528908729553,
      "learning_rate": 3.816157597535934e-05,
      "loss": 0.0037,
      "step": 18450
    },
    {
      "epoch": 1.1871149897330595,
      "grad_norm": 0.2326502799987793,
      "learning_rate": 3.812949178644764e-05,
      "loss": 0.0039,
      "step": 18500
    },
    {
      "epoch": 1.19032340862423,
      "grad_norm": 0.29411208629608154,
      "learning_rate": 3.8097407597535935e-05,
      "loss": 0.0037,
      "step": 18550
    },
    {
      "epoch": 1.1935318275154003,
      "grad_norm": 0.3098472058773041,
      "learning_rate": 3.806532340862423e-05,
      "loss": 0.0038,
      "step": 18600
    },
    {
      "epoch": 1.1967402464065708,
      "grad_norm": 0.34549203515052795,
      "learning_rate": 3.803323921971253e-05,
      "loss": 0.0038,
      "step": 18650
    },
    {
      "epoch": 1.1999486652977414,
      "grad_norm": 0.3987104892730713,
      "learning_rate": 3.800115503080082e-05,
      "loss": 0.0038,
      "step": 18700
    },
    {
      "epoch": 1.2031570841889117,
      "grad_norm": 0.2303316742181778,
      "learning_rate": 3.796907084188912e-05,
      "loss": 0.0039,
      "step": 18750
    },
    {
      "epoch": 1.2063655030800822,
      "grad_norm": 0.06022636219859123,
      "learning_rate": 3.7936986652977416e-05,
      "loss": 0.0039,
      "step": 18800
    },
    {
      "epoch": 1.2095739219712525,
      "grad_norm": 0.3240177035331726,
      "learning_rate": 3.790490246406571e-05,
      "loss": 0.0038,
      "step": 18850
    },
    {
      "epoch": 1.212782340862423,
      "grad_norm": 0.10971557348966599,
      "learning_rate": 3.7872818275154e-05,
      "loss": 0.0037,
      "step": 18900
    },
    {
      "epoch": 1.2159907597535935,
      "grad_norm": 0.234821155667305,
      "learning_rate": 3.7840734086242304e-05,
      "loss": 0.0038,
      "step": 18950
    },
    {
      "epoch": 1.2191991786447638,
      "grad_norm": 0.16979844868183136,
      "learning_rate": 3.7808649897330594e-05,
      "loss": 0.0038,
      "step": 19000
    },
    {
      "epoch": 1.2224075975359343,
      "grad_norm": 0.12273504585027695,
      "learning_rate": 3.777656570841889e-05,
      "loss": 0.0038,
      "step": 19050
    },
    {
      "epoch": 1.2256160164271046,
      "grad_norm": 0.14110437035560608,
      "learning_rate": 3.774448151950719e-05,
      "loss": 0.0038,
      "step": 19100
    },
    {
      "epoch": 1.2288244353182751,
      "grad_norm": 0.29626837372779846,
      "learning_rate": 3.771239733059548e-05,
      "loss": 0.0038,
      "step": 19150
    },
    {
      "epoch": 1.2320328542094456,
      "grad_norm": 0.1697009801864624,
      "learning_rate": 3.7680313141683785e-05,
      "loss": 0.0038,
      "step": 19200
    },
    {
      "epoch": 1.235241273100616,
      "grad_norm": 0.16293463110923767,
      "learning_rate": 3.7648228952772075e-05,
      "loss": 0.0038,
      "step": 19250
    },
    {
      "epoch": 1.2384496919917864,
      "grad_norm": 0.2520502805709839,
      "learning_rate": 3.761614476386037e-05,
      "loss": 0.0038,
      "step": 19300
    },
    {
      "epoch": 1.241658110882957,
      "grad_norm": 0.1735619455575943,
      "learning_rate": 3.758406057494867e-05,
      "loss": 0.0039,
      "step": 19350
    },
    {
      "epoch": 1.2448665297741273,
      "grad_norm": 0.21375536918640137,
      "learning_rate": 3.755197638603696e-05,
      "loss": 0.0038,
      "step": 19400
    },
    {
      "epoch": 1.2480749486652978,
      "grad_norm": 0.3027384579181671,
      "learning_rate": 3.751989219712526e-05,
      "loss": 0.0037,
      "step": 19450
    },
    {
      "epoch": 1.2512833675564683,
      "grad_norm": 0.13477055728435516,
      "learning_rate": 3.7487808008213556e-05,
      "loss": 0.0039,
      "step": 19500
    },
    {
      "epoch": 1.2544917864476386,
      "grad_norm": 0.14578084647655487,
      "learning_rate": 3.745572381930185e-05,
      "loss": 0.0037,
      "step": 19550
    },
    {
      "epoch": 1.257700205338809,
      "grad_norm": 0.19621872901916504,
      "learning_rate": 3.742363963039015e-05,
      "loss": 0.0038,
      "step": 19600
    },
    {
      "epoch": 1.2609086242299794,
      "grad_norm": 0.051534995436668396,
      "learning_rate": 3.7391555441478444e-05,
      "loss": 0.0038,
      "step": 19650
    },
    {
      "epoch": 1.26411704312115,
      "grad_norm": 0.14888711273670197,
      "learning_rate": 3.7359471252566733e-05,
      "loss": 0.0037,
      "step": 19700
    },
    {
      "epoch": 1.2673254620123204,
      "grad_norm": 0.04130885750055313,
      "learning_rate": 3.7327387063655036e-05,
      "loss": 0.0037,
      "step": 19750
    },
    {
      "epoch": 1.2705338809034907,
      "grad_norm": 0.06293605268001556,
      "learning_rate": 3.7295302874743326e-05,
      "loss": 0.0038,
      "step": 19800
    },
    {
      "epoch": 1.2737422997946612,
      "grad_norm": 0.39086347818374634,
      "learning_rate": 3.726321868583162e-05,
      "loss": 0.0038,
      "step": 19850
    },
    {
      "epoch": 1.2769507186858315,
      "grad_norm": 0.2252141237258911,
      "learning_rate": 3.723113449691992e-05,
      "loss": 0.0037,
      "step": 19900
    },
    {
      "epoch": 1.280159137577002,
      "grad_norm": 0.2580595016479492,
      "learning_rate": 3.7199050308008214e-05,
      "loss": 0.0038,
      "step": 19950
    },
    {
      "epoch": 1.2833675564681726,
      "grad_norm": 0.1805463284254074,
      "learning_rate": 3.716696611909651e-05,
      "loss": 0.0037,
      "step": 20000
    },
    {
      "epoch": 1.2865759753593429,
      "grad_norm": 0.096860371530056,
      "learning_rate": 3.713488193018481e-05,
      "loss": 0.0038,
      "step": 20050
    },
    {
      "epoch": 1.2897843942505134,
      "grad_norm": 0.09311876446008682,
      "learning_rate": 3.71027977412731e-05,
      "loss": 0.0037,
      "step": 20100
    },
    {
      "epoch": 1.2929928131416837,
      "grad_norm": 0.14941035211086273,
      "learning_rate": 3.70707135523614e-05,
      "loss": 0.0037,
      "step": 20150
    },
    {
      "epoch": 1.2962012320328542,
      "grad_norm": 0.24744273722171783,
      "learning_rate": 3.7038629363449695e-05,
      "loss": 0.0038,
      "step": 20200
    },
    {
      "epoch": 1.2994096509240247,
      "grad_norm": 0.24298802018165588,
      "learning_rate": 3.7006545174537985e-05,
      "loss": 0.0037,
      "step": 20250
    },
    {
      "epoch": 1.302618069815195,
      "grad_norm": 0.16377156972885132,
      "learning_rate": 3.697446098562629e-05,
      "loss": 0.0038,
      "step": 20300
    },
    {
      "epoch": 1.3058264887063655,
      "grad_norm": 0.19978082180023193,
      "learning_rate": 3.694237679671458e-05,
      "loss": 0.0037,
      "step": 20350
    },
    {
      "epoch": 1.3090349075975358,
      "grad_norm": 1.6960934400558472,
      "learning_rate": 3.691029260780287e-05,
      "loss": 0.0037,
      "step": 20400
    },
    {
      "epoch": 1.3122433264887063,
      "grad_norm": 0.1434202790260315,
      "learning_rate": 3.6878208418891176e-05,
      "loss": 0.0037,
      "step": 20450
    },
    {
      "epoch": 1.3154517453798769,
      "grad_norm": 0.10102397203445435,
      "learning_rate": 3.6846124229979466e-05,
      "loss": 0.0038,
      "step": 20500
    },
    {
      "epoch": 1.3186601642710472,
      "grad_norm": 0.13971765339374542,
      "learning_rate": 3.681404004106777e-05,
      "loss": 0.0037,
      "step": 20550
    },
    {
      "epoch": 1.3218685831622177,
      "grad_norm": 0.1655501276254654,
      "learning_rate": 3.678195585215606e-05,
      "loss": 0.0037,
      "step": 20600
    },
    {
      "epoch": 1.325077002053388,
      "grad_norm": 0.3544972240924835,
      "learning_rate": 3.6749871663244354e-05,
      "loss": 0.0038,
      "step": 20650
    },
    {
      "epoch": 1.3282854209445585,
      "grad_norm": 0.21388444304466248,
      "learning_rate": 3.671778747433265e-05,
      "loss": 0.0038,
      "step": 20700
    },
    {
      "epoch": 1.331493839835729,
      "grad_norm": 0.274122416973114,
      "learning_rate": 3.668570328542095e-05,
      "loss": 0.0038,
      "step": 20750
    },
    {
      "epoch": 1.3347022587268995,
      "grad_norm": 0.5307288765907288,
      "learning_rate": 3.665361909650924e-05,
      "loss": 0.0037,
      "step": 20800
    },
    {
      "epoch": 1.3379106776180698,
      "grad_norm": 0.22464619576931,
      "learning_rate": 3.662153490759754e-05,
      "loss": 0.0037,
      "step": 20850
    },
    {
      "epoch": 1.3411190965092403,
      "grad_norm": 0.16044867038726807,
      "learning_rate": 3.6589450718685835e-05,
      "loss": 0.0038,
      "step": 20900
    },
    {
      "epoch": 1.3443275154004106,
      "grad_norm": 0.23275811970233917,
      "learning_rate": 3.655736652977413e-05,
      "loss": 0.0037,
      "step": 20950
    },
    {
      "epoch": 1.3475359342915811,
      "grad_norm": 0.3768099248409271,
      "learning_rate": 3.652528234086243e-05,
      "loss": 0.0037,
      "step": 21000
    },
    {
      "epoch": 1.3507443531827517,
      "grad_norm": 0.16145099699497223,
      "learning_rate": 3.649319815195072e-05,
      "loss": 0.0037,
      "step": 21050
    },
    {
      "epoch": 1.353952772073922,
      "grad_norm": 0.08117479085922241,
      "learning_rate": 3.646111396303902e-05,
      "loss": 0.0038,
      "step": 21100
    },
    {
      "epoch": 1.3571611909650925,
      "grad_norm": 0.2644134759902954,
      "learning_rate": 3.642902977412731e-05,
      "loss": 0.0037,
      "step": 21150
    },
    {
      "epoch": 1.3603696098562628,
      "grad_norm": 0.2554287016391754,
      "learning_rate": 3.6396945585215606e-05,
      "loss": 0.0038,
      "step": 21200
    },
    {
      "epoch": 1.3635780287474333,
      "grad_norm": 0.16384544968605042,
      "learning_rate": 3.63648613963039e-05,
      "loss": 0.0037,
      "step": 21250
    },
    {
      "epoch": 1.3667864476386038,
      "grad_norm": 0.24292659759521484,
      "learning_rate": 3.63327772073922e-05,
      "loss": 0.0037,
      "step": 21300
    },
    {
      "epoch": 1.369994866529774,
      "grad_norm": 0.29657691717147827,
      "learning_rate": 3.6300693018480494e-05,
      "loss": 0.0038,
      "step": 21350
    },
    {
      "epoch": 1.3732032854209446,
      "grad_norm": 0.4330075681209564,
      "learning_rate": 3.626860882956879e-05,
      "loss": 0.0037,
      "step": 21400
    },
    {
      "epoch": 1.376411704312115,
      "grad_norm": 0.2677743434906006,
      "learning_rate": 3.6236524640657087e-05,
      "loss": 0.0038,
      "step": 21450
    },
    {
      "epoch": 1.3796201232032854,
      "grad_norm": 0.3357510268688202,
      "learning_rate": 3.620444045174538e-05,
      "loss": 0.0037,
      "step": 21500
    },
    {
      "epoch": 1.382828542094456,
      "grad_norm": 0.2527635097503662,
      "learning_rate": 3.617235626283368e-05,
      "loss": 0.0038,
      "step": 21550
    },
    {
      "epoch": 1.3860369609856262,
      "grad_norm": 0.20057028532028198,
      "learning_rate": 3.614027207392197e-05,
      "loss": 0.0037,
      "step": 21600
    },
    {
      "epoch": 1.3892453798767967,
      "grad_norm": 0.07432234287261963,
      "learning_rate": 3.610818788501027e-05,
      "loss": 0.0037,
      "step": 21650
    },
    {
      "epoch": 1.392453798767967,
      "grad_norm": 0.1866334229707718,
      "learning_rate": 3.607610369609856e-05,
      "loss": 0.0037,
      "step": 21700
    },
    {
      "epoch": 1.3956622176591376,
      "grad_norm": 0.11138916015625,
      "learning_rate": 3.6044019507186864e-05,
      "loss": 0.0037,
      "step": 21750
    },
    {
      "epoch": 1.398870636550308,
      "grad_norm": 0.12042566388845444,
      "learning_rate": 3.601193531827516e-05,
      "loss": 0.0038,
      "step": 21800
    },
    {
      "epoch": 1.4020790554414784,
      "grad_norm": 0.13665896654129028,
      "learning_rate": 3.597985112936345e-05,
      "loss": 0.0038,
      "step": 21850
    },
    {
      "epoch": 1.405287474332649,
      "grad_norm": 0.37289756536483765,
      "learning_rate": 3.594776694045175e-05,
      "loss": 0.0037,
      "step": 21900
    },
    {
      "epoch": 1.4084958932238192,
      "grad_norm": 0.21219103038311005,
      "learning_rate": 3.591568275154004e-05,
      "loss": 0.0037,
      "step": 21950
    },
    {
      "epoch": 1.4117043121149897,
      "grad_norm": 0.13250699639320374,
      "learning_rate": 3.588359856262834e-05,
      "loss": 0.0037,
      "step": 22000
    },
    {
      "epoch": 1.4149127310061602,
      "grad_norm": 0.24032166600227356,
      "learning_rate": 3.5851514373716634e-05,
      "loss": 0.0037,
      "step": 22050
    },
    {
      "epoch": 1.4181211498973305,
      "grad_norm": 0.13648377358913422,
      "learning_rate": 3.581943018480493e-05,
      "loss": 0.0038,
      "step": 22100
    },
    {
      "epoch": 1.421329568788501,
      "grad_norm": 0.3154212534427643,
      "learning_rate": 3.5787345995893226e-05,
      "loss": 0.0037,
      "step": 22150
    },
    {
      "epoch": 1.4245379876796713,
      "grad_norm": 0.10008298605680466,
      "learning_rate": 3.575526180698152e-05,
      "loss": 0.0037,
      "step": 22200
    },
    {
      "epoch": 1.4277464065708418,
      "grad_norm": 0.12496709078550339,
      "learning_rate": 3.572317761806982e-05,
      "loss": 0.0038,
      "step": 22250
    },
    {
      "epoch": 1.4309548254620124,
      "grad_norm": 0.3245674669742584,
      "learning_rate": 3.5691093429158115e-05,
      "loss": 0.0037,
      "step": 22300
    },
    {
      "epoch": 1.4341632443531829,
      "grad_norm": 0.1777394413948059,
      "learning_rate": 3.565900924024641e-05,
      "loss": 0.0037,
      "step": 22350
    },
    {
      "epoch": 1.4373716632443532,
      "grad_norm": 1.7908580303192139,
      "learning_rate": 3.56269250513347e-05,
      "loss": 0.0037,
      "step": 22400
    },
    {
      "epoch": 1.4405800821355237,
      "grad_norm": 0.08824274688959122,
      "learning_rate": 3.5594840862423003e-05,
      "loss": 0.0037,
      "step": 22450
    },
    {
      "epoch": 1.443788501026694,
      "grad_norm": 0.29201164841651917,
      "learning_rate": 3.556275667351129e-05,
      "loss": 0.0037,
      "step": 22500
    },
    {
      "epoch": 1.4469969199178645,
      "grad_norm": 0.5538934469223022,
      "learning_rate": 3.553067248459959e-05,
      "loss": 0.0037,
      "step": 22550
    },
    {
      "epoch": 1.450205338809035,
      "grad_norm": 0.17427882552146912,
      "learning_rate": 3.5498588295687885e-05,
      "loss": 0.0037,
      "step": 22600
    },
    {
      "epoch": 1.4534137577002053,
      "grad_norm": 0.15749108791351318,
      "learning_rate": 3.546650410677618e-05,
      "loss": 0.0037,
      "step": 22650
    },
    {
      "epoch": 1.4566221765913758,
      "grad_norm": 0.11800973117351532,
      "learning_rate": 3.543441991786448e-05,
      "loss": 0.0037,
      "step": 22700
    },
    {
      "epoch": 1.4598305954825461,
      "grad_norm": 0.38189101219177246,
      "learning_rate": 3.5402335728952774e-05,
      "loss": 0.0036,
      "step": 22750
    },
    {
      "epoch": 1.4630390143737166,
      "grad_norm": 0.2598797678947449,
      "learning_rate": 3.537025154004107e-05,
      "loss": 0.0037,
      "step": 22800
    },
    {
      "epoch": 1.4662474332648872,
      "grad_norm": 0.04699712619185448,
      "learning_rate": 3.5338167351129366e-05,
      "loss": 0.0036,
      "step": 22850
    },
    {
      "epoch": 1.4694558521560575,
      "grad_norm": 0.3809613287448883,
      "learning_rate": 3.530608316221766e-05,
      "loss": 0.0037,
      "step": 22900
    },
    {
      "epoch": 1.472664271047228,
      "grad_norm": 0.2824029326438904,
      "learning_rate": 3.527399897330595e-05,
      "loss": 0.0037,
      "step": 22950
    },
    {
      "epoch": 1.4758726899383983,
      "grad_norm": 0.3630271553993225,
      "learning_rate": 3.5241914784394255e-05,
      "loss": 0.0036,
      "step": 23000
    },
    {
      "epoch": 1.4790811088295688,
      "grad_norm": 0.23983797430992126,
      "learning_rate": 3.5209830595482544e-05,
      "loss": 0.0038,
      "step": 23050
    },
    {
      "epoch": 1.4822895277207393,
      "grad_norm": 0.38561689853668213,
      "learning_rate": 3.517774640657085e-05,
      "loss": 0.0037,
      "step": 23100
    },
    {
      "epoch": 1.4854979466119096,
      "grad_norm": 0.30868881940841675,
      "learning_rate": 3.5145662217659137e-05,
      "loss": 0.0037,
      "step": 23150
    },
    {
      "epoch": 1.48870636550308,
      "grad_norm": 0.23438116908073425,
      "learning_rate": 3.511357802874743e-05,
      "loss": 0.0036,
      "step": 23200
    },
    {
      "epoch": 1.4919147843942504,
      "grad_norm": 0.20393986999988556,
      "learning_rate": 3.5081493839835736e-05,
      "loss": 0.0038,
      "step": 23250
    },
    {
      "epoch": 1.495123203285421,
      "grad_norm": 0.14778311550617218,
      "learning_rate": 3.5049409650924025e-05,
      "loss": 0.0037,
      "step": 23300
    },
    {
      "epoch": 1.4983316221765914,
      "grad_norm": 0.10989502817392349,
      "learning_rate": 3.501732546201232e-05,
      "loss": 0.0037,
      "step": 23350
    },
    {
      "epoch": 1.501540041067762,
      "grad_norm": 0.052667032927274704,
      "learning_rate": 3.498524127310062e-05,
      "loss": 0.0037,
      "step": 23400
    },
    {
      "epoch": 1.5047484599589322,
      "grad_norm": 0.14737847447395325,
      "learning_rate": 3.4953157084188914e-05,
      "loss": 0.0037,
      "step": 23450
    },
    {
      "epoch": 1.5079568788501025,
      "grad_norm": 0.24369381368160248,
      "learning_rate": 3.492107289527721e-05,
      "loss": 0.0037,
      "step": 23500
    },
    {
      "epoch": 1.511165297741273,
      "grad_norm": 0.09704646468162537,
      "learning_rate": 3.4888988706365506e-05,
      "loss": 0.0037,
      "step": 23550
    },
    {
      "epoch": 1.5143737166324436,
      "grad_norm": 0.1741628795862198,
      "learning_rate": 3.4856904517453795e-05,
      "loss": 0.0037,
      "step": 23600
    },
    {
      "epoch": 1.517582135523614,
      "grad_norm": 0.14127136766910553,
      "learning_rate": 3.48248203285421e-05,
      "loss": 0.0037,
      "step": 23650
    },
    {
      "epoch": 1.5207905544147844,
      "grad_norm": 0.07852143794298172,
      "learning_rate": 3.4792736139630395e-05,
      "loss": 0.0038,
      "step": 23700
    },
    {
      "epoch": 1.5239989733059547,
      "grad_norm": 0.36621567606925964,
      "learning_rate": 3.4760651950718684e-05,
      "loss": 0.0036,
      "step": 23750
    },
    {
      "epoch": 1.5272073921971252,
      "grad_norm": 0.1304793804883957,
      "learning_rate": 3.472856776180699e-05,
      "loss": 0.0037,
      "step": 23800
    },
    {
      "epoch": 1.5304158110882957,
      "grad_norm": 0.09514132887125015,
      "learning_rate": 3.4696483572895276e-05,
      "loss": 0.0037,
      "step": 23850
    },
    {
      "epoch": 1.5336242299794662,
      "grad_norm": 0.07338306307792664,
      "learning_rate": 3.466439938398357e-05,
      "loss": 0.0038,
      "step": 23900
    },
    {
      "epoch": 1.5368326488706365,
      "grad_norm": 0.13859149813652039,
      "learning_rate": 3.463231519507187e-05,
      "loss": 0.0036,
      "step": 23950
    },
    {
      "epoch": 1.5400410677618068,
      "grad_norm": 0.2677142918109894,
      "learning_rate": 3.4600231006160165e-05,
      "loss": 0.0037,
      "step": 24000
    },
    {
      "epoch": 1.5432494866529773,
      "grad_norm": 0.3633047938346863,
      "learning_rate": 3.456814681724846e-05,
      "loss": 0.0037,
      "step": 24050
    },
    {
      "epoch": 1.5464579055441479,
      "grad_norm": 0.1927863210439682,
      "learning_rate": 3.453606262833676e-05,
      "loss": 0.0038,
      "step": 24100
    },
    {
      "epoch": 1.5496663244353184,
      "grad_norm": 1.5149574279785156,
      "learning_rate": 3.4503978439425054e-05,
      "loss": 0.0037,
      "step": 24150
    },
    {
      "epoch": 1.5528747433264887,
      "grad_norm": 0.3173258900642395,
      "learning_rate": 3.447189425051335e-05,
      "loss": 0.0036,
      "step": 24200
    },
    {
      "epoch": 1.5560831622176592,
      "grad_norm": 0.5236389636993408,
      "learning_rate": 3.4439810061601646e-05,
      "loss": 0.0037,
      "step": 24250
    },
    {
      "epoch": 1.5592915811088295,
      "grad_norm": 0.2379305064678192,
      "learning_rate": 3.440772587268994e-05,
      "loss": 0.0037,
      "step": 24300
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.36188405752182007,
      "learning_rate": 3.437564168377824e-05,
      "loss": 0.0036,
      "step": 24350
    },
    {
      "epoch": 1.5657084188911705,
      "grad_norm": 0.11486470699310303,
      "learning_rate": 3.434355749486653e-05,
      "loss": 0.0037,
      "step": 24400
    },
    {
      "epoch": 1.5689168377823408,
      "grad_norm": 0.18941961228847504,
      "learning_rate": 3.431147330595483e-05,
      "loss": 0.0036,
      "step": 24450
    },
    {
      "epoch": 1.5721252566735113,
      "grad_norm": 0.12678274512290955,
      "learning_rate": 3.427938911704312e-05,
      "loss": 0.0036,
      "step": 24500
    },
    {
      "epoch": 1.5753336755646816,
      "grad_norm": 0.16783198714256287,
      "learning_rate": 3.4247304928131416e-05,
      "loss": 0.0037,
      "step": 24550
    },
    {
      "epoch": 1.5785420944558521,
      "grad_norm": 0.16426652669906616,
      "learning_rate": 3.421522073921972e-05,
      "loss": 0.0037,
      "step": 24600
    },
    {
      "epoch": 1.5817505133470227,
      "grad_norm": 0.09841152280569077,
      "learning_rate": 3.418313655030801e-05,
      "loss": 0.0037,
      "step": 24650
    },
    {
      "epoch": 1.5849589322381932,
      "grad_norm": 0.26221686601638794,
      "learning_rate": 3.4151052361396305e-05,
      "loss": 0.0036,
      "step": 24700
    },
    {
      "epoch": 1.5881673511293635,
      "grad_norm": 0.07489525526762009,
      "learning_rate": 3.41189681724846e-05,
      "loss": 0.0037,
      "step": 24750
    },
    {
      "epoch": 1.5913757700205338,
      "grad_norm": 0.1838255524635315,
      "learning_rate": 3.40868839835729e-05,
      "loss": 0.0037,
      "step": 24800
    },
    {
      "epoch": 1.5945841889117043,
      "grad_norm": 0.16753940284252167,
      "learning_rate": 3.4054799794661193e-05,
      "loss": 0.0038,
      "step": 24850
    },
    {
      "epoch": 1.5977926078028748,
      "grad_norm": 0.10604532808065414,
      "learning_rate": 3.402271560574949e-05,
      "loss": 0.0038,
      "step": 24900
    },
    {
      "epoch": 1.6010010266940453,
      "grad_norm": 0.22862277925014496,
      "learning_rate": 3.399063141683778e-05,
      "loss": 0.0038,
      "step": 24950
    },
    {
      "epoch": 1.6042094455852156,
      "grad_norm": 0.19293726980686188,
      "learning_rate": 3.395854722792608e-05,
      "loss": 0.0036,
      "step": 25000
    },
    {
      "epoch": 1.607417864476386,
      "grad_norm": 0.26345255970954895,
      "learning_rate": 3.392646303901438e-05,
      "loss": 0.0037,
      "step": 25050
    },
    {
      "epoch": 1.6106262833675564,
      "grad_norm": 0.0612652413547039,
      "learning_rate": 3.389437885010267e-05,
      "loss": 0.0037,
      "step": 25100
    },
    {
      "epoch": 1.613834702258727,
      "grad_norm": 0.23783618211746216,
      "learning_rate": 3.386229466119097e-05,
      "loss": 0.0036,
      "step": 25150
    },
    {
      "epoch": 1.6170431211498975,
      "grad_norm": 0.29213446378707886,
      "learning_rate": 3.383021047227926e-05,
      "loss": 0.0037,
      "step": 25200
    },
    {
      "epoch": 1.6202515400410678,
      "grad_norm": 0.11250955611467361,
      "learning_rate": 3.3798126283367556e-05,
      "loss": 0.0037,
      "step": 25250
    },
    {
      "epoch": 1.623459958932238,
      "grad_norm": 0.2173299491405487,
      "learning_rate": 3.376604209445585e-05,
      "loss": 0.0037,
      "step": 25300
    },
    {
      "epoch": 1.6266683778234086,
      "grad_norm": 0.5393164753913879,
      "learning_rate": 3.373395790554415e-05,
      "loss": 0.0036,
      "step": 25350
    },
    {
      "epoch": 1.629876796714579,
      "grad_norm": 0.17000249028205872,
      "learning_rate": 3.3701873716632445e-05,
      "loss": 0.0037,
      "step": 25400
    },
    {
      "epoch": 1.6330852156057496,
      "grad_norm": 0.358175128698349,
      "learning_rate": 3.366978952772074e-05,
      "loss": 0.0037,
      "step": 25450
    },
    {
      "epoch": 1.63629363449692,
      "grad_norm": 0.14061900973320007,
      "learning_rate": 3.363770533880904e-05,
      "loss": 0.0037,
      "step": 25500
    },
    {
      "epoch": 1.6395020533880902,
      "grad_norm": 0.1356060951948166,
      "learning_rate": 3.360562114989733e-05,
      "loss": 0.0038,
      "step": 25550
    },
    {
      "epoch": 1.6427104722792607,
      "grad_norm": 0.11034142971038818,
      "learning_rate": 3.357353696098563e-05,
      "loss": 0.0037,
      "step": 25600
    },
    {
      "epoch": 1.6459188911704312,
      "grad_norm": 0.06021672859787941,
      "learning_rate": 3.3541452772073926e-05,
      "loss": 0.0037,
      "step": 25650
    },
    {
      "epoch": 1.6491273100616017,
      "grad_norm": 0.21230566501617432,
      "learning_rate": 3.350936858316222e-05,
      "loss": 0.0036,
      "step": 25700
    },
    {
      "epoch": 1.652335728952772,
      "grad_norm": 0.18576106429100037,
      "learning_rate": 3.347728439425051e-05,
      "loss": 0.0037,
      "step": 25750
    },
    {
      "epoch": 1.6555441478439425,
      "grad_norm": 0.19035473465919495,
      "learning_rate": 3.3445200205338814e-05,
      "loss": 0.0036,
      "step": 25800
    },
    {
      "epoch": 1.6587525667351128,
      "grad_norm": 0.29028943181037903,
      "learning_rate": 3.3413116016427104e-05,
      "loss": 0.0036,
      "step": 25850
    },
    {
      "epoch": 1.6619609856262834,
      "grad_norm": 0.3944849371910095,
      "learning_rate": 3.33810318275154e-05,
      "loss": 0.0036,
      "step": 25900
    },
    {
      "epoch": 1.6651694045174539,
      "grad_norm": 0.18897700309753418,
      "learning_rate": 3.33489476386037e-05,
      "loss": 0.0037,
      "step": 25950
    },
    {
      "epoch": 1.6683778234086244,
      "grad_norm": 0.14365676045417786,
      "learning_rate": 3.331686344969199e-05,
      "loss": 0.0037,
      "step": 26000
    },
    {
      "epoch": 1.6715862422997947,
      "grad_norm": 0.25576069951057434,
      "learning_rate": 3.328477926078029e-05,
      "loss": 0.0036,
      "step": 26050
    },
    {
      "epoch": 1.674794661190965,
      "grad_norm": 0.14462587237358093,
      "learning_rate": 3.3252695071868585e-05,
      "loss": 0.0038,
      "step": 26100
    },
    {
      "epoch": 1.6780030800821355,
      "grad_norm": 0.1867780238389969,
      "learning_rate": 3.322061088295688e-05,
      "loss": 0.0037,
      "step": 26150
    },
    {
      "epoch": 1.681211498973306,
      "grad_norm": 0.22219626605510712,
      "learning_rate": 3.318852669404518e-05,
      "loss": 0.0037,
      "step": 26200
    },
    {
      "epoch": 1.6844199178644765,
      "grad_norm": 0.2986701726913452,
      "learning_rate": 3.315644250513347e-05,
      "loss": 0.0036,
      "step": 26250
    },
    {
      "epoch": 1.6876283367556468,
      "grad_norm": 0.15593095123767853,
      "learning_rate": 3.312435831622176e-05,
      "loss": 0.0037,
      "step": 26300
    },
    {
      "epoch": 1.6908367556468171,
      "grad_norm": 0.26272618770599365,
      "learning_rate": 3.3092274127310066e-05,
      "loss": 0.0037,
      "step": 26350
    },
    {
      "epoch": 1.6940451745379876,
      "grad_norm": 0.22528299689292908,
      "learning_rate": 3.306018993839836e-05,
      "loss": 0.0037,
      "step": 26400
    },
    {
      "epoch": 1.6972535934291582,
      "grad_norm": 0.5574127435684204,
      "learning_rate": 3.302810574948665e-05,
      "loss": 0.0037,
      "step": 26450
    },
    {
      "epoch": 1.7004620123203287,
      "grad_norm": 0.19172094762325287,
      "learning_rate": 3.2996021560574954e-05,
      "loss": 0.0036,
      "step": 26500
    },
    {
      "epoch": 1.703670431211499,
      "grad_norm": 0.23698249459266663,
      "learning_rate": 3.2963937371663243e-05,
      "loss": 0.0036,
      "step": 26550
    },
    {
      "epoch": 1.7068788501026693,
      "grad_norm": 0.09435153007507324,
      "learning_rate": 3.2931853182751546e-05,
      "loss": 0.0036,
      "step": 26600
    },
    {
      "epoch": 1.7100872689938398,
      "grad_norm": 0.11181540787220001,
      "learning_rate": 3.2899768993839836e-05,
      "loss": 0.0036,
      "step": 26650
    },
    {
      "epoch": 1.7132956878850103,
      "grad_norm": 0.11689569801092148,
      "learning_rate": 3.286768480492813e-05,
      "loss": 0.0037,
      "step": 26700
    },
    {
      "epoch": 1.7165041067761808,
      "grad_norm": 0.24926485121250153,
      "learning_rate": 3.283560061601643e-05,
      "loss": 0.0037,
      "step": 26750
    },
    {
      "epoch": 1.719712525667351,
      "grad_norm": 0.15375486016273499,
      "learning_rate": 3.2803516427104724e-05,
      "loss": 0.0037,
      "step": 26800
    },
    {
      "epoch": 1.7229209445585214,
      "grad_norm": 0.1201038584113121,
      "learning_rate": 3.277143223819302e-05,
      "loss": 0.0037,
      "step": 26850
    },
    {
      "epoch": 1.726129363449692,
      "grad_norm": 0.20408736169338226,
      "learning_rate": 3.273934804928132e-05,
      "loss": 0.0037,
      "step": 26900
    },
    {
      "epoch": 1.7293377823408624,
      "grad_norm": 0.2796834409236908,
      "learning_rate": 3.270726386036961e-05,
      "loss": 0.0036,
      "step": 26950
    },
    {
      "epoch": 1.732546201232033,
      "grad_norm": 0.5021114349365234,
      "learning_rate": 3.267517967145791e-05,
      "loss": 0.0037,
      "step": 27000
    },
    {
      "epoch": 1.7357546201232033,
      "grad_norm": 0.2508232593536377,
      "learning_rate": 3.2643095482546205e-05,
      "loss": 0.0036,
      "step": 27050
    },
    {
      "epoch": 1.7389630390143738,
      "grad_norm": 0.13830187916755676,
      "learning_rate": 3.2611011293634495e-05,
      "loss": 0.0037,
      "step": 27100
    },
    {
      "epoch": 1.742171457905544,
      "grad_norm": 0.2412930130958557,
      "learning_rate": 3.25789271047228e-05,
      "loss": 0.0036,
      "step": 27150
    },
    {
      "epoch": 1.7453798767967146,
      "grad_norm": 0.31298989057540894,
      "learning_rate": 3.254684291581109e-05,
      "loss": 0.0036,
      "step": 27200
    },
    {
      "epoch": 1.748588295687885,
      "grad_norm": 0.29092636704444885,
      "learning_rate": 3.251475872689938e-05,
      "loss": 0.0037,
      "step": 27250
    },
    {
      "epoch": 1.7517967145790554,
      "grad_norm": 0.1280267983675003,
      "learning_rate": 3.248267453798768e-05,
      "loss": 0.0037,
      "step": 27300
    },
    {
      "epoch": 1.755005133470226,
      "grad_norm": 0.21759632229804993,
      "learning_rate": 3.2450590349075976e-05,
      "loss": 0.0036,
      "step": 27350
    },
    {
      "epoch": 1.7582135523613962,
      "grad_norm": 0.2142440378665924,
      "learning_rate": 3.241850616016427e-05,
      "loss": 0.0037,
      "step": 27400
    },
    {
      "epoch": 1.7614219712525667,
      "grad_norm": 0.24911542236804962,
      "learning_rate": 3.238642197125257e-05,
      "loss": 0.0036,
      "step": 27450
    },
    {
      "epoch": 1.7646303901437372,
      "grad_norm": 0.1929522603750229,
      "learning_rate": 3.2354337782340864e-05,
      "loss": 0.0036,
      "step": 27500
    },
    {
      "epoch": 1.7678388090349078,
      "grad_norm": 0.5039837956428528,
      "learning_rate": 3.232225359342916e-05,
      "loss": 0.0037,
      "step": 27550
    },
    {
      "epoch": 1.771047227926078,
      "grad_norm": 0.25292399525642395,
      "learning_rate": 3.229016940451746e-05,
      "loss": 0.0037,
      "step": 27600
    },
    {
      "epoch": 1.7742556468172483,
      "grad_norm": 0.23885373771190643,
      "learning_rate": 3.2258085215605746e-05,
      "loss": 0.0037,
      "step": 27650
    },
    {
      "epoch": 1.7774640657084189,
      "grad_norm": 0.20489774644374847,
      "learning_rate": 3.222600102669405e-05,
      "loss": 0.0037,
      "step": 27700
    },
    {
      "epoch": 1.7806724845995894,
      "grad_norm": 0.21277929842472076,
      "learning_rate": 3.219391683778234e-05,
      "loss": 0.0036,
      "step": 27750
    },
    {
      "epoch": 1.78388090349076,
      "grad_norm": 0.16239115595817566,
      "learning_rate": 3.2161832648870635e-05,
      "loss": 0.0037,
      "step": 27800
    },
    {
      "epoch": 1.7870893223819302,
      "grad_norm": 1.2621694803237915,
      "learning_rate": 3.212974845995894e-05,
      "loss": 0.0037,
      "step": 27850
    },
    {
      "epoch": 1.7902977412731005,
      "grad_norm": 0.13872022926807404,
      "learning_rate": 3.209766427104723e-05,
      "loss": 0.0036,
      "step": 27900
    },
    {
      "epoch": 1.793506160164271,
      "grad_norm": 0.33740052580833435,
      "learning_rate": 3.206558008213553e-05,
      "loss": 0.0036,
      "step": 27950
    },
    {
      "epoch": 1.7967145790554415,
      "grad_norm": 0.5999021530151367,
      "learning_rate": 3.203349589322382e-05,
      "loss": 0.0036,
      "step": 28000
    },
    {
      "epoch": 1.799922997946612,
      "grad_norm": 0.1375802606344223,
      "learning_rate": 3.2001411704312116e-05,
      "loss": 0.0036,
      "step": 28050
    },
    {
      "epoch": 1.8031314168377823,
      "grad_norm": 0.708863377571106,
      "learning_rate": 3.196932751540041e-05,
      "loss": 0.0037,
      "step": 28100
    },
    {
      "epoch": 1.8063398357289526,
      "grad_norm": 0.21187062561511993,
      "learning_rate": 3.193724332648871e-05,
      "loss": 0.0036,
      "step": 28150
    },
    {
      "epoch": 1.8095482546201231,
      "grad_norm": 0.3369452655315399,
      "learning_rate": 3.1905159137577004e-05,
      "loss": 0.0037,
      "step": 28200
    },
    {
      "epoch": 1.8127566735112937,
      "grad_norm": 0.370250403881073,
      "learning_rate": 3.18730749486653e-05,
      "loss": 0.0036,
      "step": 28250
    },
    {
      "epoch": 1.8159650924024642,
      "grad_norm": 0.13021330535411835,
      "learning_rate": 3.1840990759753597e-05,
      "loss": 0.0036,
      "step": 28300
    },
    {
      "epoch": 1.8191735112936345,
      "grad_norm": 0.5549330711364746,
      "learning_rate": 3.180890657084189e-05,
      "loss": 0.0036,
      "step": 28350
    },
    {
      "epoch": 1.8223819301848048,
      "grad_norm": 0.2427944839000702,
      "learning_rate": 3.177682238193019e-05,
      "loss": 0.0037,
      "step": 28400
    },
    {
      "epoch": 1.8255903490759753,
      "grad_norm": 0.6582062244415283,
      "learning_rate": 3.174473819301848e-05,
      "loss": 0.0037,
      "step": 28450
    },
    {
      "epoch": 1.8287987679671458,
      "grad_norm": 0.15820319950580597,
      "learning_rate": 3.171265400410678e-05,
      "loss": 0.0036,
      "step": 28500
    },
    {
      "epoch": 1.8320071868583163,
      "grad_norm": 0.2342059314250946,
      "learning_rate": 3.168056981519507e-05,
      "loss": 0.0036,
      "step": 28550
    },
    {
      "epoch": 1.8352156057494866,
      "grad_norm": 0.17782264947891235,
      "learning_rate": 3.164848562628337e-05,
      "loss": 0.0036,
      "step": 28600
    },
    {
      "epoch": 1.8384240246406571,
      "grad_norm": 0.1430051326751709,
      "learning_rate": 3.161640143737166e-05,
      "loss": 0.0037,
      "step": 28650
    },
    {
      "epoch": 1.8416324435318274,
      "grad_norm": 0.22815273702144623,
      "learning_rate": 3.158431724845996e-05,
      "loss": 0.0036,
      "step": 28700
    },
    {
      "epoch": 1.844840862422998,
      "grad_norm": 0.0984620526432991,
      "learning_rate": 3.1552233059548255e-05,
      "loss": 0.0037,
      "step": 28750
    },
    {
      "epoch": 1.8480492813141685,
      "grad_norm": 0.3060283660888672,
      "learning_rate": 3.152014887063655e-05,
      "loss": 0.0037,
      "step": 28800
    },
    {
      "epoch": 1.851257700205339,
      "grad_norm": 0.49061864614486694,
      "learning_rate": 3.148806468172485e-05,
      "loss": 0.0036,
      "step": 28850
    },
    {
      "epoch": 1.8544661190965093,
      "grad_norm": 0.3101120591163635,
      "learning_rate": 3.1455980492813144e-05,
      "loss": 0.0036,
      "step": 28900
    },
    {
      "epoch": 1.8576745379876796,
      "grad_norm": 0.2808748185634613,
      "learning_rate": 3.142389630390144e-05,
      "loss": 0.0037,
      "step": 28950
    },
    {
      "epoch": 1.86088295687885,
      "grad_norm": 0.26516789197921753,
      "learning_rate": 3.139181211498973e-05,
      "loss": 0.0036,
      "step": 29000
    },
    {
      "epoch": 1.8640913757700206,
      "grad_norm": 0.17893150448799133,
      "learning_rate": 3.135972792607803e-05,
      "loss": 0.0036,
      "step": 29050
    },
    {
      "epoch": 1.8672997946611911,
      "grad_norm": 0.12493187934160233,
      "learning_rate": 3.132764373716632e-05,
      "loss": 0.0037,
      "step": 29100
    },
    {
      "epoch": 1.8705082135523614,
      "grad_norm": 0.16546115279197693,
      "learning_rate": 3.129555954825462e-05,
      "loss": 0.0036,
      "step": 29150
    },
    {
      "epoch": 1.8737166324435317,
      "grad_norm": 0.16949813067913055,
      "learning_rate": 3.126347535934292e-05,
      "loss": 0.0036,
      "step": 29200
    },
    {
      "epoch": 1.8769250513347022,
      "grad_norm": 0.06705913692712784,
      "learning_rate": 3.123139117043121e-05,
      "loss": 0.0036,
      "step": 29250
    },
    {
      "epoch": 1.8801334702258727,
      "grad_norm": 0.35897696018218994,
      "learning_rate": 3.1199306981519514e-05,
      "loss": 0.0036,
      "step": 29300
    },
    {
      "epoch": 1.8833418891170433,
      "grad_norm": 0.2718273103237152,
      "learning_rate": 3.11672227926078e-05,
      "loss": 0.0036,
      "step": 29350
    },
    {
      "epoch": 1.8865503080082136,
      "grad_norm": 0.21646210551261902,
      "learning_rate": 3.11351386036961e-05,
      "loss": 0.0037,
      "step": 29400
    },
    {
      "epoch": 1.8897587268993838,
      "grad_norm": 0.1731221228837967,
      "learning_rate": 3.1103054414784395e-05,
      "loss": 0.0036,
      "step": 29450
    },
    {
      "epoch": 1.8929671457905544,
      "grad_norm": 0.10033570230007172,
      "learning_rate": 3.107097022587269e-05,
      "loss": 0.0036,
      "step": 29500
    },
    {
      "epoch": 1.8961755646817249,
      "grad_norm": 0.21969443559646606,
      "learning_rate": 3.103888603696099e-05,
      "loss": 0.0035,
      "step": 29550
    },
    {
      "epoch": 1.8993839835728954,
      "grad_norm": 0.27599796652793884,
      "learning_rate": 3.1006801848049284e-05,
      "loss": 0.0036,
      "step": 29600
    },
    {
      "epoch": 1.9025924024640657,
      "grad_norm": 0.2163103073835373,
      "learning_rate": 3.097471765913758e-05,
      "loss": 0.0036,
      "step": 29650
    },
    {
      "epoch": 1.905800821355236,
      "grad_norm": 0.2980678081512451,
      "learning_rate": 3.0942633470225876e-05,
      "loss": 0.0036,
      "step": 29700
    },
    {
      "epoch": 1.9090092402464065,
      "grad_norm": 0.2897534668445587,
      "learning_rate": 3.091054928131417e-05,
      "loss": 0.0036,
      "step": 29750
    },
    {
      "epoch": 1.912217659137577,
      "grad_norm": 0.1416112333536148,
      "learning_rate": 3.087846509240246e-05,
      "loss": 0.0036,
      "step": 29800
    },
    {
      "epoch": 1.9154260780287475,
      "grad_norm": 0.2162053883075714,
      "learning_rate": 3.0846380903490765e-05,
      "loss": 0.0036,
      "step": 29850
    },
    {
      "epoch": 1.9186344969199178,
      "grad_norm": 0.36233437061309814,
      "learning_rate": 3.0814296714579054e-05,
      "loss": 0.0036,
      "step": 29900
    },
    {
      "epoch": 1.9218429158110883,
      "grad_norm": 0.2753375470638275,
      "learning_rate": 3.078221252566735e-05,
      "loss": 0.0036,
      "step": 29950
    },
    {
      "epoch": 1.9250513347022586,
      "grad_norm": 0.1815427988767624,
      "learning_rate": 3.0750128336755647e-05,
      "loss": 0.0036,
      "step": 30000
    },
    {
      "epoch": 1.9282597535934292,
      "grad_norm": 0.14614266157150269,
      "learning_rate": 3.071804414784394e-05,
      "loss": 0.0036,
      "step": 30050
    },
    {
      "epoch": 1.9314681724845997,
      "grad_norm": 0.2195582091808319,
      "learning_rate": 3.068595995893224e-05,
      "loss": 0.0036,
      "step": 30100
    },
    {
      "epoch": 1.93467659137577,
      "grad_norm": 0.4704703092575073,
      "learning_rate": 3.0653875770020535e-05,
      "loss": 0.0037,
      "step": 30150
    },
    {
      "epoch": 1.9378850102669405,
      "grad_norm": 0.2316291630268097,
      "learning_rate": 3.062179158110883e-05,
      "loss": 0.0036,
      "step": 30200
    },
    {
      "epoch": 1.9410934291581108,
      "grad_norm": 0.09099879115819931,
      "learning_rate": 3.058970739219713e-05,
      "loss": 0.0036,
      "step": 30250
    },
    {
      "epoch": 1.9443018480492813,
      "grad_norm": 0.1960945725440979,
      "learning_rate": 3.0557623203285424e-05,
      "loss": 0.0036,
      "step": 30300
    },
    {
      "epoch": 1.9475102669404518,
      "grad_norm": 0.14840959012508392,
      "learning_rate": 3.052553901437371e-05,
      "loss": 0.0037,
      "step": 30350
    },
    {
      "epoch": 1.9507186858316223,
      "grad_norm": 0.27871260046958923,
      "learning_rate": 3.0493454825462016e-05,
      "loss": 0.0036,
      "step": 30400
    },
    {
      "epoch": 1.9539271047227926,
      "grad_norm": 0.0872923731803894,
      "learning_rate": 3.0461370636550306e-05,
      "loss": 0.0036,
      "step": 30450
    },
    {
      "epoch": 1.957135523613963,
      "grad_norm": 0.3647383451461792,
      "learning_rate": 3.0429286447638605e-05,
      "loss": 0.0036,
      "step": 30500
    },
    {
      "epoch": 1.9603439425051334,
      "grad_norm": 0.09943243116140366,
      "learning_rate": 3.0397202258726905e-05,
      "loss": 0.0036,
      "step": 30550
    },
    {
      "epoch": 1.963552361396304,
      "grad_norm": 0.1786135584115982,
      "learning_rate": 3.0365118069815197e-05,
      "loss": 0.0036,
      "step": 30600
    },
    {
      "epoch": 1.9667607802874745,
      "grad_norm": 0.3909519612789154,
      "learning_rate": 3.0333033880903494e-05,
      "loss": 0.0037,
      "step": 30650
    },
    {
      "epoch": 1.9699691991786448,
      "grad_norm": 0.09880169481039047,
      "learning_rate": 3.0300949691991786e-05,
      "loss": 0.0036,
      "step": 30700
    },
    {
      "epoch": 1.973177618069815,
      "grad_norm": 0.3708513677120209,
      "learning_rate": 3.0268865503080086e-05,
      "loss": 0.0037,
      "step": 30750
    },
    {
      "epoch": 1.9763860369609856,
      "grad_norm": 0.22492942214012146,
      "learning_rate": 3.023678131416838e-05,
      "loss": 0.0036,
      "step": 30800
    },
    {
      "epoch": 1.979594455852156,
      "grad_norm": 0.4697830080986023,
      "learning_rate": 3.0204697125256675e-05,
      "loss": 0.0036,
      "step": 30850
    },
    {
      "epoch": 1.9828028747433266,
      "grad_norm": 0.2056640386581421,
      "learning_rate": 3.0172612936344968e-05,
      "loss": 0.0036,
      "step": 30900
    },
    {
      "epoch": 1.986011293634497,
      "grad_norm": 0.30129656195640564,
      "learning_rate": 3.0140528747433267e-05,
      "loss": 0.0037,
      "step": 30950
    },
    {
      "epoch": 1.9892197125256672,
      "grad_norm": 0.2088550478219986,
      "learning_rate": 3.0108444558521564e-05,
      "loss": 0.0036,
      "step": 31000
    },
    {
      "epoch": 1.9924281314168377,
      "grad_norm": 0.2962992489337921,
      "learning_rate": 3.0076360369609856e-05,
      "loss": 0.0036,
      "step": 31050
    },
    {
      "epoch": 1.9956365503080082,
      "grad_norm": 0.23626963794231415,
      "learning_rate": 3.0044276180698156e-05,
      "loss": 0.0036,
      "step": 31100
    },
    {
      "epoch": 1.9988449691991788,
      "grad_norm": 0.2370031625032425,
      "learning_rate": 3.001219199178645e-05,
      "loss": 0.0037,
      "step": 31150
    },
    {
      "epoch": 2.0020533880903493,
      "grad_norm": 0.3025228977203369,
      "learning_rate": 2.9980107802874745e-05,
      "loss": 0.0036,
      "step": 31200
    },
    {
      "epoch": 2.0052618069815193,
      "grad_norm": 0.10968680679798126,
      "learning_rate": 2.9948023613963038e-05,
      "loss": 0.0036,
      "step": 31250
    },
    {
      "epoch": 2.00847022587269,
      "grad_norm": 0.21355701982975006,
      "learning_rate": 2.9915939425051337e-05,
      "loss": 0.0036,
      "step": 31300
    },
    {
      "epoch": 2.0116786447638604,
      "grad_norm": 0.1274694800376892,
      "learning_rate": 2.988385523613963e-05,
      "loss": 0.0036,
      "step": 31350
    },
    {
      "epoch": 2.014887063655031,
      "grad_norm": 0.23278431594371796,
      "learning_rate": 2.9851771047227926e-05,
      "loss": 0.0036,
      "step": 31400
    },
    {
      "epoch": 2.0180954825462014,
      "grad_norm": 0.30820757150650024,
      "learning_rate": 2.9819686858316226e-05,
      "loss": 0.0035,
      "step": 31450
    },
    {
      "epoch": 2.0213039014373715,
      "grad_norm": 0.13154271245002747,
      "learning_rate": 2.978760266940452e-05,
      "loss": 0.0035,
      "step": 31500
    },
    {
      "epoch": 2.024512320328542,
      "grad_norm": 0.3519788682460785,
      "learning_rate": 2.9755518480492818e-05,
      "loss": 0.0036,
      "step": 31550
    },
    {
      "epoch": 2.0277207392197125,
      "grad_norm": 0.1336500495672226,
      "learning_rate": 2.9723434291581108e-05,
      "loss": 0.0036,
      "step": 31600
    },
    {
      "epoch": 2.030929158110883,
      "grad_norm": 0.33300480246543884,
      "learning_rate": 2.9691350102669407e-05,
      "loss": 0.0036,
      "step": 31650
    },
    {
      "epoch": 2.0341375770020536,
      "grad_norm": 0.23696042597293854,
      "learning_rate": 2.96592659137577e-05,
      "loss": 0.0036,
      "step": 31700
    },
    {
      "epoch": 2.0373459958932236,
      "grad_norm": 0.09028620272874832,
      "learning_rate": 2.9627181724846e-05,
      "loss": 0.0036,
      "step": 31750
    },
    {
      "epoch": 2.040554414784394,
      "grad_norm": 0.4518531560897827,
      "learning_rate": 2.9595097535934292e-05,
      "loss": 0.0036,
      "step": 31800
    },
    {
      "epoch": 2.0437628336755647,
      "grad_norm": 0.10554298013448715,
      "learning_rate": 2.956301334702259e-05,
      "loss": 0.0037,
      "step": 31850
    },
    {
      "epoch": 2.046971252566735,
      "grad_norm": 0.15939712524414062,
      "learning_rate": 2.9530929158110888e-05,
      "loss": 0.0036,
      "step": 31900
    },
    {
      "epoch": 2.0501796714579057,
      "grad_norm": 0.3307804763317108,
      "learning_rate": 2.949884496919918e-05,
      "loss": 0.0036,
      "step": 31950
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 0.2923300564289093,
      "learning_rate": 2.9466760780287477e-05,
      "loss": 0.0036,
      "step": 32000
    },
    {
      "epoch": 2.0565965092402463,
      "grad_norm": 0.1670057326555252,
      "learning_rate": 2.943467659137577e-05,
      "loss": 0.0036,
      "step": 32050
    },
    {
      "epoch": 2.059804928131417,
      "grad_norm": 0.16514751315116882,
      "learning_rate": 2.940259240246407e-05,
      "loss": 0.0036,
      "step": 32100
    },
    {
      "epoch": 2.0630133470225873,
      "grad_norm": 0.10170702636241913,
      "learning_rate": 2.9370508213552362e-05,
      "loss": 0.0036,
      "step": 32150
    },
    {
      "epoch": 2.066221765913758,
      "grad_norm": 0.1697452813386917,
      "learning_rate": 2.933842402464066e-05,
      "loss": 0.0035,
      "step": 32200
    },
    {
      "epoch": 2.0694301848049284,
      "grad_norm": 0.18875320255756378,
      "learning_rate": 2.930633983572895e-05,
      "loss": 0.0035,
      "step": 32250
    },
    {
      "epoch": 2.0726386036960984,
      "grad_norm": 0.13968850672245026,
      "learning_rate": 2.927425564681725e-05,
      "loss": 0.0036,
      "step": 32300
    },
    {
      "epoch": 2.075847022587269,
      "grad_norm": 0.050153765827417374,
      "learning_rate": 2.9242171457905544e-05,
      "loss": 0.0035,
      "step": 32350
    },
    {
      "epoch": 2.0790554414784395,
      "grad_norm": 2.305856227874756,
      "learning_rate": 2.921008726899384e-05,
      "loss": 0.0035,
      "step": 32400
    },
    {
      "epoch": 2.08226386036961,
      "grad_norm": 0.15987858176231384,
      "learning_rate": 2.917800308008214e-05,
      "loss": 0.0036,
      "step": 32450
    },
    {
      "epoch": 2.0854722792607805,
      "grad_norm": 0.13796953856945038,
      "learning_rate": 2.9145918891170432e-05,
      "loss": 0.0036,
      "step": 32500
    },
    {
      "epoch": 2.0886806981519506,
      "grad_norm": 0.33440402150154114,
      "learning_rate": 2.911383470225873e-05,
      "loss": 0.0035,
      "step": 32550
    },
    {
      "epoch": 2.091889117043121,
      "grad_norm": 0.29536163806915283,
      "learning_rate": 2.908175051334702e-05,
      "loss": 0.0036,
      "step": 32600
    },
    {
      "epoch": 2.0950975359342916,
      "grad_norm": 0.2991204857826233,
      "learning_rate": 2.904966632443532e-05,
      "loss": 0.0036,
      "step": 32650
    },
    {
      "epoch": 2.098305954825462,
      "grad_norm": 0.12086815387010574,
      "learning_rate": 2.9017582135523614e-05,
      "loss": 0.0035,
      "step": 32700
    },
    {
      "epoch": 2.1015143737166326,
      "grad_norm": 0.32464301586151123,
      "learning_rate": 2.898549794661191e-05,
      "loss": 0.0037,
      "step": 32750
    },
    {
      "epoch": 2.1047227926078027,
      "grad_norm": 0.12383412569761276,
      "learning_rate": 2.8953413757700203e-05,
      "loss": 0.0036,
      "step": 32800
    },
    {
      "epoch": 2.1079312114989732,
      "grad_norm": 0.08079775422811508,
      "learning_rate": 2.8921329568788502e-05,
      "loss": 0.0036,
      "step": 32850
    },
    {
      "epoch": 2.1111396303901437,
      "grad_norm": 0.17541176080703735,
      "learning_rate": 2.8889245379876802e-05,
      "loss": 0.0035,
      "step": 32900
    },
    {
      "epoch": 2.1143480492813143,
      "grad_norm": 0.36109480261802673,
      "learning_rate": 2.8857161190965095e-05,
      "loss": 0.0036,
      "step": 32950
    },
    {
      "epoch": 2.1175564681724848,
      "grad_norm": 0.32962262630462646,
      "learning_rate": 2.882507700205339e-05,
      "loss": 0.0036,
      "step": 33000
    },
    {
      "epoch": 2.120764887063655,
      "grad_norm": 0.11470809578895569,
      "learning_rate": 2.8792992813141684e-05,
      "loss": 0.0036,
      "step": 33050
    },
    {
      "epoch": 2.1239733059548254,
      "grad_norm": 0.2667955458164215,
      "learning_rate": 2.8760908624229983e-05,
      "loss": 0.0036,
      "step": 33100
    },
    {
      "epoch": 2.127181724845996,
      "grad_norm": 0.3206733763217926,
      "learning_rate": 2.8728824435318276e-05,
      "loss": 0.0037,
      "step": 33150
    },
    {
      "epoch": 2.1303901437371664,
      "grad_norm": 0.15969498455524445,
      "learning_rate": 2.8696740246406572e-05,
      "loss": 0.0036,
      "step": 33200
    },
    {
      "epoch": 2.133598562628337,
      "grad_norm": 0.13484925031661987,
      "learning_rate": 2.8664656057494865e-05,
      "loss": 0.0036,
      "step": 33250
    },
    {
      "epoch": 2.136806981519507,
      "grad_norm": 0.19061967730522156,
      "learning_rate": 2.8632571868583165e-05,
      "loss": 0.0036,
      "step": 33300
    },
    {
      "epoch": 2.1400154004106775,
      "grad_norm": 0.18148361146450043,
      "learning_rate": 2.860048767967146e-05,
      "loss": 0.0035,
      "step": 33350
    },
    {
      "epoch": 2.143223819301848,
      "grad_norm": 0.2937498688697815,
      "learning_rate": 2.8568403490759753e-05,
      "loss": 0.0036,
      "step": 33400
    },
    {
      "epoch": 2.1464322381930185,
      "grad_norm": 0.35659846663475037,
      "learning_rate": 2.8536319301848053e-05,
      "loss": 0.0036,
      "step": 33450
    },
    {
      "epoch": 2.149640657084189,
      "grad_norm": 0.25240176916122437,
      "learning_rate": 2.8504235112936346e-05,
      "loss": 0.0036,
      "step": 33500
    },
    {
      "epoch": 2.152849075975359,
      "grad_norm": 0.09193851053714752,
      "learning_rate": 2.8472150924024642e-05,
      "loss": 0.0035,
      "step": 33550
    },
    {
      "epoch": 2.1560574948665296,
      "grad_norm": 0.31504684686660767,
      "learning_rate": 2.8440066735112935e-05,
      "loss": 0.0035,
      "step": 33600
    },
    {
      "epoch": 2.1592659137577,
      "grad_norm": 0.13408206403255463,
      "learning_rate": 2.8407982546201234e-05,
      "loss": 0.0037,
      "step": 33650
    },
    {
      "epoch": 2.1624743326488707,
      "grad_norm": 0.45773398876190186,
      "learning_rate": 2.8375898357289527e-05,
      "loss": 0.0036,
      "step": 33700
    },
    {
      "epoch": 2.165682751540041,
      "grad_norm": 0.2957513630390167,
      "learning_rate": 2.8343814168377823e-05,
      "loss": 0.0035,
      "step": 33750
    },
    {
      "epoch": 2.1688911704312117,
      "grad_norm": 0.0794944018125534,
      "learning_rate": 2.8311729979466123e-05,
      "loss": 0.0036,
      "step": 33800
    },
    {
      "epoch": 2.172099589322382,
      "grad_norm": 0.6131895184516907,
      "learning_rate": 2.8279645790554416e-05,
      "loss": 0.0036,
      "step": 33850
    },
    {
      "epoch": 2.1753080082135523,
      "grad_norm": 0.24102367460727692,
      "learning_rate": 2.8247561601642712e-05,
      "loss": 0.0036,
      "step": 33900
    },
    {
      "epoch": 2.178516427104723,
      "grad_norm": 0.14532265067100525,
      "learning_rate": 2.8215477412731005e-05,
      "loss": 0.0035,
      "step": 33950
    },
    {
      "epoch": 2.1817248459958933,
      "grad_norm": 0.47705474495887756,
      "learning_rate": 2.8183393223819304e-05,
      "loss": 0.0035,
      "step": 34000
    },
    {
      "epoch": 2.184933264887064,
      "grad_norm": 0.09054413437843323,
      "learning_rate": 2.8151309034907597e-05,
      "loss": 0.0036,
      "step": 34050
    },
    {
      "epoch": 2.188141683778234,
      "grad_norm": 0.21821728348731995,
      "learning_rate": 2.8119224845995897e-05,
      "loss": 0.0035,
      "step": 34100
    },
    {
      "epoch": 2.1913501026694044,
      "grad_norm": 0.39226385951042175,
      "learning_rate": 2.8087140657084186e-05,
      "loss": 0.0035,
      "step": 34150
    },
    {
      "epoch": 2.194558521560575,
      "grad_norm": 0.44233378767967224,
      "learning_rate": 2.8055056468172486e-05,
      "loss": 0.0035,
      "step": 34200
    },
    {
      "epoch": 2.1977669404517455,
      "grad_norm": 0.21532174944877625,
      "learning_rate": 2.8022972279260785e-05,
      "loss": 0.0036,
      "step": 34250
    },
    {
      "epoch": 2.200975359342916,
      "grad_norm": 0.21636782586574554,
      "learning_rate": 2.7990888090349078e-05,
      "loss": 0.0036,
      "step": 34300
    },
    {
      "epoch": 2.204183778234086,
      "grad_norm": 0.35348787903785706,
      "learning_rate": 2.7958803901437374e-05,
      "loss": 0.0036,
      "step": 34350
    },
    {
      "epoch": 2.2073921971252566,
      "grad_norm": 0.212178573012352,
      "learning_rate": 2.7926719712525667e-05,
      "loss": 0.0036,
      "step": 34400
    },
    {
      "epoch": 2.210600616016427,
      "grad_norm": 0.1697520762681961,
      "learning_rate": 2.7894635523613967e-05,
      "loss": 0.0036,
      "step": 34450
    },
    {
      "epoch": 2.2138090349075976,
      "grad_norm": 0.05557950213551521,
      "learning_rate": 2.786255133470226e-05,
      "loss": 0.0035,
      "step": 34500
    },
    {
      "epoch": 2.217017453798768,
      "grad_norm": 0.354693740606308,
      "learning_rate": 2.7830467145790556e-05,
      "loss": 0.0036,
      "step": 34550
    },
    {
      "epoch": 2.220225872689938,
      "grad_norm": 0.1364336758852005,
      "learning_rate": 2.779838295687885e-05,
      "loss": 0.0036,
      "step": 34600
    },
    {
      "epoch": 2.2234342915811087,
      "grad_norm": 0.07390398532152176,
      "learning_rate": 2.7766298767967148e-05,
      "loss": 0.0036,
      "step": 34650
    },
    {
      "epoch": 2.2266427104722792,
      "grad_norm": 0.25571978092193604,
      "learning_rate": 2.7734214579055444e-05,
      "loss": 0.0035,
      "step": 34700
    },
    {
      "epoch": 2.2298511293634498,
      "grad_norm": 0.21458962559700012,
      "learning_rate": 2.7702130390143737e-05,
      "loss": 0.0036,
      "step": 34750
    },
    {
      "epoch": 2.2330595482546203,
      "grad_norm": 0.10001694411039352,
      "learning_rate": 2.7670046201232037e-05,
      "loss": 0.0035,
      "step": 34800
    },
    {
      "epoch": 2.2362679671457903,
      "grad_norm": 0.17951065301895142,
      "learning_rate": 2.763796201232033e-05,
      "loss": 0.0036,
      "step": 34850
    },
    {
      "epoch": 2.239476386036961,
      "grad_norm": 0.34424495697021484,
      "learning_rate": 2.7605877823408626e-05,
      "loss": 0.0035,
      "step": 34900
    },
    {
      "epoch": 2.2426848049281314,
      "grad_norm": 0.41100752353668213,
      "learning_rate": 2.757379363449692e-05,
      "loss": 0.0035,
      "step": 34950
    },
    {
      "epoch": 2.245893223819302,
      "grad_norm": 0.11486845463514328,
      "learning_rate": 2.7541709445585218e-05,
      "loss": 0.0036,
      "step": 35000
    },
    {
      "epoch": 2.2491016427104724,
      "grad_norm": 0.38133785128593445,
      "learning_rate": 2.750962525667351e-05,
      "loss": 0.0035,
      "step": 35050
    },
    {
      "epoch": 2.2523100616016425,
      "grad_norm": 0.1316654235124588,
      "learning_rate": 2.7477541067761807e-05,
      "loss": 0.0036,
      "step": 35100
    },
    {
      "epoch": 2.255518480492813,
      "grad_norm": 0.35604411363601685,
      "learning_rate": 2.7445456878850107e-05,
      "loss": 0.0036,
      "step": 35150
    },
    {
      "epoch": 2.2587268993839835,
      "grad_norm": 0.07446983456611633,
      "learning_rate": 2.74133726899384e-05,
      "loss": 0.0036,
      "step": 35200
    },
    {
      "epoch": 2.261935318275154,
      "grad_norm": 0.47031763195991516,
      "learning_rate": 2.73812885010267e-05,
      "loss": 0.0035,
      "step": 35250
    },
    {
      "epoch": 2.2651437371663246,
      "grad_norm": 0.17544244229793549,
      "learning_rate": 2.734920431211499e-05,
      "loss": 0.0036,
      "step": 35300
    },
    {
      "epoch": 2.268352156057495,
      "grad_norm": 0.1684339940547943,
      "learning_rate": 2.7317120123203288e-05,
      "loss": 0.0035,
      "step": 35350
    },
    {
      "epoch": 2.271560574948665,
      "grad_norm": 0.23538830876350403,
      "learning_rate": 2.728503593429158e-05,
      "loss": 0.0035,
      "step": 35400
    },
    {
      "epoch": 2.2747689938398357,
      "grad_norm": 0.19907371699810028,
      "learning_rate": 2.725295174537988e-05,
      "loss": 0.0036,
      "step": 35450
    },
    {
      "epoch": 2.277977412731006,
      "grad_norm": 0.222630113363266,
      "learning_rate": 2.7220867556468173e-05,
      "loss": 0.0035,
      "step": 35500
    },
    {
      "epoch": 2.2811858316221767,
      "grad_norm": 0.3174300491809845,
      "learning_rate": 2.718878336755647e-05,
      "loss": 0.0036,
      "step": 35550
    },
    {
      "epoch": 2.284394250513347,
      "grad_norm": 0.4678170084953308,
      "learning_rate": 2.715669917864477e-05,
      "loss": 0.0036,
      "step": 35600
    },
    {
      "epoch": 2.2876026694045173,
      "grad_norm": 0.1281731277704239,
      "learning_rate": 2.712461498973306e-05,
      "loss": 0.0036,
      "step": 35650
    },
    {
      "epoch": 2.290811088295688,
      "grad_norm": 0.126005619764328,
      "learning_rate": 2.7092530800821358e-05,
      "loss": 0.0035,
      "step": 35700
    },
    {
      "epoch": 2.2940195071868583,
      "grad_norm": 0.36295393109321594,
      "learning_rate": 2.706044661190965e-05,
      "loss": 0.0036,
      "step": 35750
    },
    {
      "epoch": 2.297227926078029,
      "grad_norm": 0.09294068813323975,
      "learning_rate": 2.702836242299795e-05,
      "loss": 0.0036,
      "step": 35800
    },
    {
      "epoch": 2.3004363449691994,
      "grad_norm": 0.18156830966472626,
      "learning_rate": 2.6996278234086243e-05,
      "loss": 0.0036,
      "step": 35850
    },
    {
      "epoch": 2.3036447638603694,
      "grad_norm": 0.12334533780813217,
      "learning_rate": 2.696419404517454e-05,
      "loss": 0.0035,
      "step": 35900
    },
    {
      "epoch": 2.30685318275154,
      "grad_norm": 0.2629472315311432,
      "learning_rate": 2.6932109856262832e-05,
      "loss": 0.0036,
      "step": 35950
    },
    {
      "epoch": 2.3100616016427105,
      "grad_norm": 0.07089126110076904,
      "learning_rate": 2.690002566735113e-05,
      "loss": 0.0035,
      "step": 36000
    },
    {
      "epoch": 2.313270020533881,
      "grad_norm": 0.4210197627544403,
      "learning_rate": 2.6867941478439428e-05,
      "loss": 0.0036,
      "step": 36050
    },
    {
      "epoch": 2.3164784394250515,
      "grad_norm": 0.16595971584320068,
      "learning_rate": 2.683585728952772e-05,
      "loss": 0.0035,
      "step": 36100
    },
    {
      "epoch": 2.3196868583162216,
      "grad_norm": 0.08489201217889786,
      "learning_rate": 2.680377310061602e-05,
      "loss": 0.0035,
      "step": 36150
    },
    {
      "epoch": 2.322895277207392,
      "grad_norm": 0.21944713592529297,
      "learning_rate": 2.6771688911704313e-05,
      "loss": 0.0035,
      "step": 36200
    },
    {
      "epoch": 2.3261036960985626,
      "grad_norm": 0.3060074746608734,
      "learning_rate": 2.673960472279261e-05,
      "loss": 0.0036,
      "step": 36250
    },
    {
      "epoch": 2.329312114989733,
      "grad_norm": 0.3113778829574585,
      "learning_rate": 2.6707520533880902e-05,
      "loss": 0.0036,
      "step": 36300
    },
    {
      "epoch": 2.3325205338809036,
      "grad_norm": 0.21352171897888184,
      "learning_rate": 2.66754363449692e-05,
      "loss": 0.0035,
      "step": 36350
    },
    {
      "epoch": 2.335728952772074,
      "grad_norm": 0.2354370802640915,
      "learning_rate": 2.6643352156057494e-05,
      "loss": 0.0035,
      "step": 36400
    },
    {
      "epoch": 2.3389373716632442,
      "grad_norm": 0.25547289848327637,
      "learning_rate": 2.661126796714579e-05,
      "loss": 0.0035,
      "step": 36450
    },
    {
      "epoch": 2.3421457905544147,
      "grad_norm": 0.164847731590271,
      "learning_rate": 2.657918377823409e-05,
      "loss": 0.0035,
      "step": 36500
    },
    {
      "epoch": 2.3453542094455853,
      "grad_norm": 0.21264642477035522,
      "learning_rate": 2.6547099589322383e-05,
      "loss": 0.0036,
      "step": 36550
    },
    {
      "epoch": 2.3485626283367558,
      "grad_norm": 0.27415725588798523,
      "learning_rate": 2.6515015400410682e-05,
      "loss": 0.0036,
      "step": 36600
    },
    {
      "epoch": 2.351771047227926,
      "grad_norm": 0.11930245906114578,
      "learning_rate": 2.6482931211498975e-05,
      "loss": 0.0036,
      "step": 36650
    },
    {
      "epoch": 2.3549794661190964,
      "grad_norm": 0.10134892910718918,
      "learning_rate": 2.645084702258727e-05,
      "loss": 0.0036,
      "step": 36700
    },
    {
      "epoch": 2.358187885010267,
      "grad_norm": 0.27216559648513794,
      "learning_rate": 2.6418762833675564e-05,
      "loss": 0.0036,
      "step": 36750
    },
    {
      "epoch": 2.3613963039014374,
      "grad_norm": 0.16903714835643768,
      "learning_rate": 2.6386678644763864e-05,
      "loss": 0.0036,
      "step": 36800
    },
    {
      "epoch": 2.364604722792608,
      "grad_norm": 0.21666637063026428,
      "learning_rate": 2.6354594455852157e-05,
      "loss": 0.0035,
      "step": 36850
    },
    {
      "epoch": 2.3678131416837784,
      "grad_norm": 0.08072599023580551,
      "learning_rate": 2.6322510266940453e-05,
      "loss": 0.0036,
      "step": 36900
    },
    {
      "epoch": 2.3710215605749485,
      "grad_norm": 0.19681251049041748,
      "learning_rate": 2.6290426078028752e-05,
      "loss": 0.0036,
      "step": 36950
    },
    {
      "epoch": 2.374229979466119,
      "grad_norm": 0.27094581723213196,
      "learning_rate": 2.6258341889117045e-05,
      "loss": 0.0035,
      "step": 37000
    },
    {
      "epoch": 2.3774383983572895,
      "grad_norm": 0.3739728629589081,
      "learning_rate": 2.622625770020534e-05,
      "loss": 0.0035,
      "step": 37050
    },
    {
      "epoch": 2.38064681724846,
      "grad_norm": 0.15770836174488068,
      "learning_rate": 2.6194173511293634e-05,
      "loss": 0.0036,
      "step": 37100
    },
    {
      "epoch": 2.3838552361396306,
      "grad_norm": 0.15003517270088196,
      "learning_rate": 2.6162089322381934e-05,
      "loss": 0.0035,
      "step": 37150
    },
    {
      "epoch": 2.3870636550308006,
      "grad_norm": 0.5262555480003357,
      "learning_rate": 2.6130005133470227e-05,
      "loss": 0.0036,
      "step": 37200
    },
    {
      "epoch": 2.390272073921971,
      "grad_norm": 1.4097416400909424,
      "learning_rate": 2.6097920944558523e-05,
      "loss": 0.0035,
      "step": 37250
    },
    {
      "epoch": 2.3934804928131417,
      "grad_norm": 1.0029709339141846,
      "learning_rate": 2.6065836755646816e-05,
      "loss": 0.0036,
      "step": 37300
    },
    {
      "epoch": 2.396688911704312,
      "grad_norm": 0.24399380385875702,
      "learning_rate": 2.6033752566735115e-05,
      "loss": 0.0036,
      "step": 37350
    },
    {
      "epoch": 2.3998973305954827,
      "grad_norm": 0.27279970049858093,
      "learning_rate": 2.6001668377823408e-05,
      "loss": 0.0035,
      "step": 37400
    },
    {
      "epoch": 2.403105749486653,
      "grad_norm": 0.13062657415866852,
      "learning_rate": 2.5969584188911704e-05,
      "loss": 0.0035,
      "step": 37450
    },
    {
      "epoch": 2.4063141683778233,
      "grad_norm": 1.1348152160644531,
      "learning_rate": 2.5937500000000004e-05,
      "loss": 0.0036,
      "step": 37500
    },
    {
      "epoch": 2.409522587268994,
      "grad_norm": 0.7826855182647705,
      "learning_rate": 2.5905415811088296e-05,
      "loss": 0.0035,
      "step": 37550
    },
    {
      "epoch": 2.4127310061601643,
      "grad_norm": 0.27261054515838623,
      "learning_rate": 2.5873331622176593e-05,
      "loss": 0.0035,
      "step": 37600
    },
    {
      "epoch": 2.415939425051335,
      "grad_norm": 0.23158349096775055,
      "learning_rate": 2.5841247433264885e-05,
      "loss": 0.0035,
      "step": 37650
    },
    {
      "epoch": 2.419147843942505,
      "grad_norm": 0.37971141934394836,
      "learning_rate": 2.5809163244353185e-05,
      "loss": 0.0035,
      "step": 37700
    },
    {
      "epoch": 2.4223562628336754,
      "grad_norm": 0.31948745250701904,
      "learning_rate": 2.5777079055441478e-05,
      "loss": 0.0035,
      "step": 37750
    },
    {
      "epoch": 2.425564681724846,
      "grad_norm": 0.0992727279663086,
      "learning_rate": 2.5744994866529777e-05,
      "loss": 0.0036,
      "step": 37800
    },
    {
      "epoch": 2.4287731006160165,
      "grad_norm": 5.757015228271484,
      "learning_rate": 2.5712910677618067e-05,
      "loss": 0.0035,
      "step": 37850
    },
    {
      "epoch": 2.431981519507187,
      "grad_norm": 0.1326494812965393,
      "learning_rate": 2.5680826488706366e-05,
      "loss": 0.0036,
      "step": 37900
    },
    {
      "epoch": 2.4351899383983575,
      "grad_norm": 0.4834175109863281,
      "learning_rate": 2.5648742299794666e-05,
      "loss": 0.0035,
      "step": 37950
    },
    {
      "epoch": 2.4383983572895276,
      "grad_norm": 0.2766624093055725,
      "learning_rate": 2.561665811088296e-05,
      "loss": 0.0035,
      "step": 38000
    },
    {
      "epoch": 2.441606776180698,
      "grad_norm": 0.09014774113893509,
      "learning_rate": 2.5584573921971255e-05,
      "loss": 0.0035,
      "step": 38050
    },
    {
      "epoch": 2.4448151950718686,
      "grad_norm": 0.10074030607938766,
      "learning_rate": 2.5552489733059548e-05,
      "loss": 0.0035,
      "step": 38100
    },
    {
      "epoch": 2.448023613963039,
      "grad_norm": 4.35972785949707,
      "learning_rate": 2.5520405544147847e-05,
      "loss": 0.0035,
      "step": 38150
    },
    {
      "epoch": 2.451232032854209,
      "grad_norm": 1.0382158756256104,
      "learning_rate": 2.548832135523614e-05,
      "loss": 0.0036,
      "step": 38200
    },
    {
      "epoch": 2.4544404517453797,
      "grad_norm": 0.15587718784809113,
      "learning_rate": 2.5456237166324436e-05,
      "loss": 0.0036,
      "step": 38250
    },
    {
      "epoch": 2.4576488706365502,
      "grad_norm": 0.3726879358291626,
      "learning_rate": 2.542415297741273e-05,
      "loss": 0.0035,
      "step": 38300
    },
    {
      "epoch": 2.4608572895277208,
      "grad_norm": 0.7667755484580994,
      "learning_rate": 2.539206878850103e-05,
      "loss": 0.0036,
      "step": 38350
    },
    {
      "epoch": 2.4640657084188913,
      "grad_norm": 3.4295012950897217,
      "learning_rate": 2.5359984599589325e-05,
      "loss": 0.0036,
      "step": 38400
    },
    {
      "epoch": 2.467274127310062,
      "grad_norm": 0.16231252253055573,
      "learning_rate": 2.5327900410677618e-05,
      "loss": 0.0035,
      "step": 38450
    },
    {
      "epoch": 2.470482546201232,
      "grad_norm": 0.5243769884109497,
      "learning_rate": 2.5295816221765917e-05,
      "loss": 0.0035,
      "step": 38500
    },
    {
      "epoch": 2.4736909650924024,
      "grad_norm": 0.14796312153339386,
      "learning_rate": 2.526373203285421e-05,
      "loss": 0.0036,
      "step": 38550
    },
    {
      "epoch": 2.476899383983573,
      "grad_norm": 0.1630672812461853,
      "learning_rate": 2.5231647843942506e-05,
      "loss": 0.0036,
      "step": 38600
    },
    {
      "epoch": 2.4801078028747434,
      "grad_norm": 0.09256282448768616,
      "learning_rate": 2.51995636550308e-05,
      "loss": 0.0035,
      "step": 38650
    },
    {
      "epoch": 2.483316221765914,
      "grad_norm": 0.5380796194076538,
      "learning_rate": 2.51674794661191e-05,
      "loss": 0.0035,
      "step": 38700
    },
    {
      "epoch": 2.486524640657084,
      "grad_norm": 0.2860276699066162,
      "learning_rate": 2.513539527720739e-05,
      "loss": 0.0035,
      "step": 38750
    },
    {
      "epoch": 2.4897330595482545,
      "grad_norm": 0.28378260135650635,
      "learning_rate": 2.5103311088295688e-05,
      "loss": 0.0035,
      "step": 38800
    },
    {
      "epoch": 2.492941478439425,
      "grad_norm": 0.08544007688760757,
      "learning_rate": 2.5071226899383987e-05,
      "loss": 0.0035,
      "step": 38850
    },
    {
      "epoch": 2.4961498973305956,
      "grad_norm": 0.6147679090499878,
      "learning_rate": 2.503914271047228e-05,
      "loss": 0.0035,
      "step": 38900
    },
    {
      "epoch": 2.499358316221766,
      "grad_norm": 0.6971316933631897,
      "learning_rate": 2.500705852156058e-05,
      "loss": 0.0035,
      "step": 38950
    },
    {
      "epoch": 2.5025667351129366,
      "grad_norm": 0.1937674880027771,
      "learning_rate": 2.497497433264887e-05,
      "loss": 0.0036,
      "step": 39000
    },
    {
      "epoch": 2.5057751540041067,
      "grad_norm": 0.44309496879577637,
      "learning_rate": 2.494289014373717e-05,
      "loss": 0.0035,
      "step": 39050
    },
    {
      "epoch": 2.508983572895277,
      "grad_norm": 0.3591617941856384,
      "learning_rate": 2.4910805954825465e-05,
      "loss": 0.0035,
      "step": 39100
    },
    {
      "epoch": 2.5121919917864477,
      "grad_norm": 0.6278764009475708,
      "learning_rate": 2.487872176591376e-05,
      "loss": 0.0034,
      "step": 39150
    },
    {
      "epoch": 2.515400410677618,
      "grad_norm": 0.27432307600975037,
      "learning_rate": 2.4846637577002054e-05,
      "loss": 0.0035,
      "step": 39200
    },
    {
      "epoch": 2.5186088295687883,
      "grad_norm": 0.4174344539642334,
      "learning_rate": 2.481455338809035e-05,
      "loss": 0.0036,
      "step": 39250
    },
    {
      "epoch": 2.521817248459959,
      "grad_norm": 0.240203395485878,
      "learning_rate": 2.4782469199178646e-05,
      "loss": 0.0036,
      "step": 39300
    },
    {
      "epoch": 2.5250256673511293,
      "grad_norm": 2.1753857135772705,
      "learning_rate": 2.4750385010266942e-05,
      "loss": 0.0035,
      "step": 39350
    },
    {
      "epoch": 2.5282340862423,
      "grad_norm": 0.08083072304725647,
      "learning_rate": 2.4718300821355235e-05,
      "loss": 0.0035,
      "step": 39400
    },
    {
      "epoch": 2.5314425051334704,
      "grad_norm": 0.2001209259033203,
      "learning_rate": 2.468621663244353e-05,
      "loss": 0.0035,
      "step": 39450
    },
    {
      "epoch": 2.534650924024641,
      "grad_norm": 0.2868061065673828,
      "learning_rate": 2.465413244353183e-05,
      "loss": 0.0035,
      "step": 39500
    },
    {
      "epoch": 2.537859342915811,
      "grad_norm": 0.33359023928642273,
      "learning_rate": 2.4622048254620124e-05,
      "loss": 0.0035,
      "step": 39550
    },
    {
      "epoch": 2.5410677618069815,
      "grad_norm": 1.9277509450912476,
      "learning_rate": 2.458996406570842e-05,
      "loss": 0.0035,
      "step": 39600
    },
    {
      "epoch": 2.544276180698152,
      "grad_norm": 1.807996392250061,
      "learning_rate": 2.4557879876796716e-05,
      "loss": 0.0035,
      "step": 39650
    },
    {
      "epoch": 2.5474845995893225,
      "grad_norm": 0.11783163994550705,
      "learning_rate": 2.4525795687885012e-05,
      "loss": 0.0036,
      "step": 39700
    },
    {
      "epoch": 2.5506930184804926,
      "grad_norm": 0.24942292273044586,
      "learning_rate": 2.449371149897331e-05,
      "loss": 0.0035,
      "step": 39750
    },
    {
      "epoch": 2.553901437371663,
      "grad_norm": 0.62944495677948,
      "learning_rate": 2.44616273100616e-05,
      "loss": 0.0035,
      "step": 39800
    },
    {
      "epoch": 2.5571098562628336,
      "grad_norm": 0.23618443310260773,
      "learning_rate": 2.4429543121149897e-05,
      "loss": 0.0035,
      "step": 39850
    },
    {
      "epoch": 2.560318275154004,
      "grad_norm": 0.4954160451889038,
      "learning_rate": 2.4397458932238194e-05,
      "loss": 0.0035,
      "step": 39900
    },
    {
      "epoch": 2.5635266940451746,
      "grad_norm": 0.24534647166728973,
      "learning_rate": 2.436537474332649e-05,
      "loss": 0.0036,
      "step": 39950
    },
    {
      "epoch": 2.566735112936345,
      "grad_norm": 0.240215003490448,
      "learning_rate": 2.4333290554414786e-05,
      "loss": 0.0035,
      "step": 40000
    },
    {
      "epoch": 2.5699435318275157,
      "grad_norm": 0.2167045623064041,
      "learning_rate": 2.4301206365503082e-05,
      "loss": 0.0035,
      "step": 40050
    },
    {
      "epoch": 2.5731519507186857,
      "grad_norm": 0.2887073755264282,
      "learning_rate": 2.426912217659138e-05,
      "loss": 0.0035,
      "step": 40100
    },
    {
      "epoch": 2.5763603696098563,
      "grad_norm": 0.3342592418193817,
      "learning_rate": 2.423703798767967e-05,
      "loss": 0.0035,
      "step": 40150
    },
    {
      "epoch": 2.5795687885010268,
      "grad_norm": 0.4677979350090027,
      "learning_rate": 2.4204953798767967e-05,
      "loss": 0.0035,
      "step": 40200
    },
    {
      "epoch": 2.582777207392197,
      "grad_norm": 0.07910466194152832,
      "learning_rate": 2.4172869609856264e-05,
      "loss": 0.0036,
      "step": 40250
    },
    {
      "epoch": 2.5859856262833674,
      "grad_norm": 0.22525407373905182,
      "learning_rate": 2.414078542094456e-05,
      "loss": 0.0035,
      "step": 40300
    },
    {
      "epoch": 2.589194045174538,
      "grad_norm": 0.12562468647956848,
      "learning_rate": 2.4108701232032856e-05,
      "loss": 0.0034,
      "step": 40350
    },
    {
      "epoch": 2.5924024640657084,
      "grad_norm": 2.0637006759643555,
      "learning_rate": 2.4076617043121152e-05,
      "loss": 0.0035,
      "step": 40400
    },
    {
      "epoch": 2.595610882956879,
      "grad_norm": 0.26560893654823303,
      "learning_rate": 2.4044532854209448e-05,
      "loss": 0.0036,
      "step": 40450
    },
    {
      "epoch": 2.5988193018480494,
      "grad_norm": 0.24298295378684998,
      "learning_rate": 2.4012448665297744e-05,
      "loss": 0.0035,
      "step": 40500
    },
    {
      "epoch": 2.60202772073922,
      "grad_norm": 0.28487837314605713,
      "learning_rate": 2.3980364476386037e-05,
      "loss": 0.0035,
      "step": 40550
    },
    {
      "epoch": 2.60523613963039,
      "grad_norm": 0.8018052577972412,
      "learning_rate": 2.3948280287474333e-05,
      "loss": 0.0036,
      "step": 40600
    },
    {
      "epoch": 2.6084445585215605,
      "grad_norm": 0.22371947765350342,
      "learning_rate": 2.391619609856263e-05,
      "loss": 0.0035,
      "step": 40650
    },
    {
      "epoch": 2.611652977412731,
      "grad_norm": 0.2931861877441406,
      "learning_rate": 2.3884111909650926e-05,
      "loss": 0.0035,
      "step": 40700
    },
    {
      "epoch": 2.6148613963039016,
      "grad_norm": 0.30647212266921997,
      "learning_rate": 2.385202772073922e-05,
      "loss": 0.0035,
      "step": 40750
    },
    {
      "epoch": 2.6180698151950716,
      "grad_norm": 0.20735710859298706,
      "learning_rate": 2.3819943531827515e-05,
      "loss": 0.0035,
      "step": 40800
    },
    {
      "epoch": 2.621278234086242,
      "grad_norm": 0.3359732925891876,
      "learning_rate": 2.378785934291581e-05,
      "loss": 0.0035,
      "step": 40850
    },
    {
      "epoch": 2.6244866529774127,
      "grad_norm": 0.41641154885292053,
      "learning_rate": 2.375577515400411e-05,
      "loss": 0.0035,
      "step": 40900
    },
    {
      "epoch": 2.627695071868583,
      "grad_norm": 0.12554889917373657,
      "learning_rate": 2.3723690965092403e-05,
      "loss": 0.0035,
      "step": 40950
    },
    {
      "epoch": 2.6309034907597537,
      "grad_norm": 0.36722052097320557,
      "learning_rate": 2.36916067761807e-05,
      "loss": 0.0035,
      "step": 41000
    },
    {
      "epoch": 2.6341119096509242,
      "grad_norm": 0.17863628268241882,
      "learning_rate": 2.3659522587268996e-05,
      "loss": 0.0035,
      "step": 41050
    },
    {
      "epoch": 2.6373203285420943,
      "grad_norm": 0.4791720509529114,
      "learning_rate": 2.3627438398357292e-05,
      "loss": 0.0035,
      "step": 41100
    },
    {
      "epoch": 2.640528747433265,
      "grad_norm": 0.27228471636772156,
      "learning_rate": 2.3595354209445585e-05,
      "loss": 0.0034,
      "step": 41150
    },
    {
      "epoch": 2.6437371663244353,
      "grad_norm": 0.16493676602840424,
      "learning_rate": 2.356327002053388e-05,
      "loss": 0.0035,
      "step": 41200
    },
    {
      "epoch": 2.646945585215606,
      "grad_norm": 0.298958420753479,
      "learning_rate": 2.3531185831622177e-05,
      "loss": 0.0036,
      "step": 41250
    },
    {
      "epoch": 2.650154004106776,
      "grad_norm": 0.12388624995946884,
      "learning_rate": 2.3499101642710473e-05,
      "loss": 0.0036,
      "step": 41300
    },
    {
      "epoch": 2.6533624229979464,
      "grad_norm": 0.14291127026081085,
      "learning_rate": 2.346701745379877e-05,
      "loss": 0.0036,
      "step": 41350
    },
    {
      "epoch": 2.656570841889117,
      "grad_norm": 0.25226646661758423,
      "learning_rate": 2.3434933264887066e-05,
      "loss": 0.0035,
      "step": 41400
    },
    {
      "epoch": 2.6597792607802875,
      "grad_norm": 0.1924322545528412,
      "learning_rate": 2.3402849075975362e-05,
      "loss": 0.0035,
      "step": 41450
    },
    {
      "epoch": 2.662987679671458,
      "grad_norm": 0.27441316843032837,
      "learning_rate": 2.3370764887063658e-05,
      "loss": 0.0036,
      "step": 41500
    },
    {
      "epoch": 2.6661960985626285,
      "grad_norm": 0.11474227905273438,
      "learning_rate": 2.333868069815195e-05,
      "loss": 0.0035,
      "step": 41550
    },
    {
      "epoch": 2.669404517453799,
      "grad_norm": 0.31557023525238037,
      "learning_rate": 2.3306596509240247e-05,
      "loss": 0.0035,
      "step": 41600
    },
    {
      "epoch": 2.672612936344969,
      "grad_norm": 0.199958935379982,
      "learning_rate": 2.3274512320328543e-05,
      "loss": 0.0034,
      "step": 41650
    },
    {
      "epoch": 2.6758213552361396,
      "grad_norm": 0.2300022691488266,
      "learning_rate": 2.324242813141684e-05,
      "loss": 0.0035,
      "step": 41700
    },
    {
      "epoch": 2.67902977412731,
      "grad_norm": 0.1428890824317932,
      "learning_rate": 2.3210343942505132e-05,
      "loss": 0.0035,
      "step": 41750
    },
    {
      "epoch": 2.6822381930184807,
      "grad_norm": 0.4073318541049957,
      "learning_rate": 2.3178259753593432e-05,
      "loss": 0.0035,
      "step": 41800
    },
    {
      "epoch": 2.6854466119096507,
      "grad_norm": 0.15260018408298492,
      "learning_rate": 2.3146175564681728e-05,
      "loss": 0.0036,
      "step": 41850
    },
    {
      "epoch": 2.6886550308008212,
      "grad_norm": 0.3645138740539551,
      "learning_rate": 2.311409137577002e-05,
      "loss": 0.0034,
      "step": 41900
    },
    {
      "epoch": 2.6918634496919918,
      "grad_norm": 1.0903815031051636,
      "learning_rate": 2.3082007186858317e-05,
      "loss": 0.0036,
      "step": 41950
    },
    {
      "epoch": 2.6950718685831623,
      "grad_norm": 0.3041260838508606,
      "learning_rate": 2.3049922997946613e-05,
      "loss": 0.0035,
      "step": 42000
    },
    {
      "epoch": 2.698280287474333,
      "grad_norm": 0.27292412519454956,
      "learning_rate": 2.301783880903491e-05,
      "loss": 0.0035,
      "step": 42050
    },
    {
      "epoch": 2.7014887063655033,
      "grad_norm": 0.1120656430721283,
      "learning_rate": 2.2985754620123202e-05,
      "loss": 0.0035,
      "step": 42100
    },
    {
      "epoch": 2.7046971252566734,
      "grad_norm": 0.22031740844249725,
      "learning_rate": 2.29536704312115e-05,
      "loss": 0.0036,
      "step": 42150
    },
    {
      "epoch": 2.707905544147844,
      "grad_norm": 1.1817405223846436,
      "learning_rate": 2.2921586242299795e-05,
      "loss": 0.0035,
      "step": 42200
    },
    {
      "epoch": 2.7111139630390144,
      "grad_norm": 0.17766936123371124,
      "learning_rate": 2.2889502053388094e-05,
      "loss": 0.0035,
      "step": 42250
    },
    {
      "epoch": 2.714322381930185,
      "grad_norm": 0.2839791774749756,
      "learning_rate": 2.2857417864476387e-05,
      "loss": 0.0035,
      "step": 42300
    },
    {
      "epoch": 2.717530800821355,
      "grad_norm": 0.2730913758277893,
      "learning_rate": 2.2825333675564683e-05,
      "loss": 0.0035,
      "step": 42350
    },
    {
      "epoch": 2.7207392197125255,
      "grad_norm": 0.06323109567165375,
      "learning_rate": 2.279324948665298e-05,
      "loss": 0.0035,
      "step": 42400
    },
    {
      "epoch": 2.723947638603696,
      "grad_norm": 0.1177268847823143,
      "learning_rate": 2.2761165297741275e-05,
      "loss": 0.0035,
      "step": 42450
    },
    {
      "epoch": 2.7271560574948666,
      "grad_norm": 0.11257040500640869,
      "learning_rate": 2.2729081108829568e-05,
      "loss": 0.0035,
      "step": 42500
    },
    {
      "epoch": 2.730364476386037,
      "grad_norm": 0.2863900661468506,
      "learning_rate": 2.2696996919917864e-05,
      "loss": 0.0035,
      "step": 42550
    },
    {
      "epoch": 2.7335728952772076,
      "grad_norm": 0.6028996706008911,
      "learning_rate": 2.266491273100616e-05,
      "loss": 0.0034,
      "step": 42600
    },
    {
      "epoch": 2.7367813141683777,
      "grad_norm": 0.2325339913368225,
      "learning_rate": 2.2632828542094457e-05,
      "loss": 0.0035,
      "step": 42650
    },
    {
      "epoch": 2.739989733059548,
      "grad_norm": 0.317063570022583,
      "learning_rate": 2.2600744353182753e-05,
      "loss": 0.0035,
      "step": 42700
    },
    {
      "epoch": 2.7431981519507187,
      "grad_norm": 0.472545325756073,
      "learning_rate": 2.256866016427105e-05,
      "loss": 0.0035,
      "step": 42750
    },
    {
      "epoch": 2.746406570841889,
      "grad_norm": 0.21539492905139923,
      "learning_rate": 2.2536575975359345e-05,
      "loss": 0.0035,
      "step": 42800
    },
    {
      "epoch": 2.7496149897330593,
      "grad_norm": 0.1871449202299118,
      "learning_rate": 2.250449178644764e-05,
      "loss": 0.0035,
      "step": 42850
    },
    {
      "epoch": 2.75282340862423,
      "grad_norm": 0.2651555836200714,
      "learning_rate": 2.2472407597535934e-05,
      "loss": 0.0035,
      "step": 42900
    },
    {
      "epoch": 2.7560318275154003,
      "grad_norm": 0.17889413237571716,
      "learning_rate": 2.244032340862423e-05,
      "loss": 0.0035,
      "step": 42950
    },
    {
      "epoch": 2.759240246406571,
      "grad_norm": 0.2662552297115326,
      "learning_rate": 2.2408239219712527e-05,
      "loss": 0.0035,
      "step": 43000
    },
    {
      "epoch": 2.7624486652977414,
      "grad_norm": 0.21771125495433807,
      "learning_rate": 2.2376155030800823e-05,
      "loss": 0.0035,
      "step": 43050
    },
    {
      "epoch": 2.765657084188912,
      "grad_norm": 0.14537759125232697,
      "learning_rate": 2.2344070841889116e-05,
      "loss": 0.0036,
      "step": 43100
    },
    {
      "epoch": 2.7688655030800824,
      "grad_norm": 0.1420576125383377,
      "learning_rate": 2.2311986652977412e-05,
      "loss": 0.0035,
      "step": 43150
    },
    {
      "epoch": 2.7720739219712525,
      "grad_norm": 0.2681174874305725,
      "learning_rate": 2.227990246406571e-05,
      "loss": 0.0035,
      "step": 43200
    },
    {
      "epoch": 2.775282340862423,
      "grad_norm": 0.19637823104858398,
      "learning_rate": 2.2247818275154004e-05,
      "loss": 0.0036,
      "step": 43250
    },
    {
      "epoch": 2.7784907597535935,
      "grad_norm": 0.8579379320144653,
      "learning_rate": 2.22157340862423e-05,
      "loss": 0.0036,
      "step": 43300
    },
    {
      "epoch": 2.781699178644764,
      "grad_norm": 0.17512288689613342,
      "learning_rate": 2.2183649897330597e-05,
      "loss": 0.0035,
      "step": 43350
    },
    {
      "epoch": 2.784907597535934,
      "grad_norm": 0.22612643241882324,
      "learning_rate": 2.2151565708418893e-05,
      "loss": 0.0035,
      "step": 43400
    },
    {
      "epoch": 2.7881160164271046,
      "grad_norm": 0.8142549991607666,
      "learning_rate": 2.211948151950719e-05,
      "loss": 0.0034,
      "step": 43450
    },
    {
      "epoch": 2.791324435318275,
      "grad_norm": 1.6072524785995483,
      "learning_rate": 2.2087397330595482e-05,
      "loss": 0.0035,
      "step": 43500
    },
    {
      "epoch": 2.7945328542094456,
      "grad_norm": 0.13585788011550903,
      "learning_rate": 2.2055313141683778e-05,
      "loss": 0.0036,
      "step": 43550
    },
    {
      "epoch": 2.797741273100616,
      "grad_norm": 0.5800737142562866,
      "learning_rate": 2.2023228952772074e-05,
      "loss": 0.0035,
      "step": 43600
    },
    {
      "epoch": 2.8009496919917867,
      "grad_norm": 0.22300241887569427,
      "learning_rate": 2.199114476386037e-05,
      "loss": 0.0034,
      "step": 43650
    },
    {
      "epoch": 2.8041581108829567,
      "grad_norm": 0.541608989238739,
      "learning_rate": 2.1959060574948667e-05,
      "loss": 0.0035,
      "step": 43700
    },
    {
      "epoch": 2.8073665297741273,
      "grad_norm": 0.29025018215179443,
      "learning_rate": 2.1926976386036963e-05,
      "loss": 0.0035,
      "step": 43750
    },
    {
      "epoch": 2.810574948665298,
      "grad_norm": 0.2300301343202591,
      "learning_rate": 2.189489219712526e-05,
      "loss": 0.0035,
      "step": 43800
    },
    {
      "epoch": 2.8137833675564683,
      "grad_norm": 0.8904486894607544,
      "learning_rate": 2.1862808008213552e-05,
      "loss": 0.0035,
      "step": 43850
    },
    {
      "epoch": 2.8169917864476384,
      "grad_norm": 0.30144360661506653,
      "learning_rate": 2.1830723819301848e-05,
      "loss": 0.0035,
      "step": 43900
    },
    {
      "epoch": 2.820200205338809,
      "grad_norm": 0.2503197491168976,
      "learning_rate": 2.1798639630390144e-05,
      "loss": 0.0035,
      "step": 43950
    },
    {
      "epoch": 2.8234086242299794,
      "grad_norm": 2.806255340576172,
      "learning_rate": 2.176655544147844e-05,
      "loss": 0.0034,
      "step": 44000
    },
    {
      "epoch": 2.82661704312115,
      "grad_norm": 0.19112171232700348,
      "learning_rate": 2.1734471252566737e-05,
      "loss": 0.0034,
      "step": 44050
    },
    {
      "epoch": 2.8298254620123204,
      "grad_norm": 0.11306896805763245,
      "learning_rate": 2.1702387063655033e-05,
      "loss": 0.0035,
      "step": 44100
    },
    {
      "epoch": 2.833033880903491,
      "grad_norm": 0.8182893395423889,
      "learning_rate": 2.167030287474333e-05,
      "loss": 0.0035,
      "step": 44150
    },
    {
      "epoch": 2.836242299794661,
      "grad_norm": 0.4725021719932556,
      "learning_rate": 2.1638218685831625e-05,
      "loss": 0.0034,
      "step": 44200
    },
    {
      "epoch": 2.8394507186858315,
      "grad_norm": 0.18566453456878662,
      "learning_rate": 2.1606134496919918e-05,
      "loss": 0.0035,
      "step": 44250
    },
    {
      "epoch": 2.842659137577002,
      "grad_norm": 0.32512086629867554,
      "learning_rate": 2.1574050308008214e-05,
      "loss": 0.0036,
      "step": 44300
    },
    {
      "epoch": 2.8458675564681726,
      "grad_norm": 0.29765430092811584,
      "learning_rate": 2.154196611909651e-05,
      "loss": 0.0035,
      "step": 44350
    },
    {
      "epoch": 2.8490759753593426,
      "grad_norm": 0.18876950442790985,
      "learning_rate": 2.1509881930184806e-05,
      "loss": 0.0036,
      "step": 44400
    },
    {
      "epoch": 2.852284394250513,
      "grad_norm": 0.21846149861812592,
      "learning_rate": 2.14777977412731e-05,
      "loss": 0.0035,
      "step": 44450
    },
    {
      "epoch": 2.8554928131416837,
      "grad_norm": 0.17861875891685486,
      "learning_rate": 2.1445713552361395e-05,
      "loss": 0.0035,
      "step": 44500
    },
    {
      "epoch": 2.858701232032854,
      "grad_norm": 0.2490263134241104,
      "learning_rate": 2.1413629363449695e-05,
      "loss": 0.0035,
      "step": 44550
    },
    {
      "epoch": 2.8619096509240247,
      "grad_norm": 0.17355290055274963,
      "learning_rate": 2.138154517453799e-05,
      "loss": 0.0035,
      "step": 44600
    },
    {
      "epoch": 2.8651180698151952,
      "grad_norm": 0.5134071111679077,
      "learning_rate": 2.1349460985626284e-05,
      "loss": 0.0034,
      "step": 44650
    },
    {
      "epoch": 2.8683264887063658,
      "grad_norm": 0.32489070296287537,
      "learning_rate": 2.131737679671458e-05,
      "loss": 0.0034,
      "step": 44700
    },
    {
      "epoch": 2.871534907597536,
      "grad_norm": 0.18118317425251007,
      "learning_rate": 2.1285292607802876e-05,
      "loss": 0.0034,
      "step": 44750
    },
    {
      "epoch": 2.8747433264887063,
      "grad_norm": 1.1186548471450806,
      "learning_rate": 2.1253208418891173e-05,
      "loss": 0.0034,
      "step": 44800
    },
    {
      "epoch": 2.877951745379877,
      "grad_norm": 0.27160030603408813,
      "learning_rate": 2.1221124229979465e-05,
      "loss": 0.0035,
      "step": 44850
    },
    {
      "epoch": 2.8811601642710474,
      "grad_norm": 0.8360978960990906,
      "learning_rate": 2.118904004106776e-05,
      "loss": 0.0034,
      "step": 44900
    },
    {
      "epoch": 2.8843685831622174,
      "grad_norm": 0.4573891758918762,
      "learning_rate": 2.1156955852156058e-05,
      "loss": 0.0035,
      "step": 44950
    },
    {
      "epoch": 2.887577002053388,
      "grad_norm": 0.9264399409294128,
      "learning_rate": 2.1124871663244354e-05,
      "loss": 0.0035,
      "step": 45000
    },
    {
      "epoch": 2.8907854209445585,
      "grad_norm": 0.28266412019729614,
      "learning_rate": 2.109278747433265e-05,
      "loss": 0.0035,
      "step": 45050
    },
    {
      "epoch": 2.893993839835729,
      "grad_norm": 0.4043048918247223,
      "learning_rate": 2.1060703285420946e-05,
      "loss": 0.0034,
      "step": 45100
    },
    {
      "epoch": 2.8972022587268995,
      "grad_norm": 0.25294309854507446,
      "learning_rate": 2.1028619096509243e-05,
      "loss": 0.0034,
      "step": 45150
    },
    {
      "epoch": 2.90041067761807,
      "grad_norm": 0.28507092595100403,
      "learning_rate": 2.099653490759754e-05,
      "loss": 0.0035,
      "step": 45200
    },
    {
      "epoch": 2.90361909650924,
      "grad_norm": 0.31985339522361755,
      "learning_rate": 2.096445071868583e-05,
      "loss": 0.0035,
      "step": 45250
    },
    {
      "epoch": 2.9068275154004106,
      "grad_norm": 0.06521850824356079,
      "learning_rate": 2.0932366529774128e-05,
      "loss": 0.0035,
      "step": 45300
    },
    {
      "epoch": 2.910035934291581,
      "grad_norm": 0.3987174928188324,
      "learning_rate": 2.0900282340862424e-05,
      "loss": 0.0035,
      "step": 45350
    },
    {
      "epoch": 2.9132443531827517,
      "grad_norm": 0.17345748841762543,
      "learning_rate": 2.086819815195072e-05,
      "loss": 0.0035,
      "step": 45400
    },
    {
      "epoch": 2.9164527720739217,
      "grad_norm": 1.9434345960617065,
      "learning_rate": 2.0836113963039016e-05,
      "loss": 0.0035,
      "step": 45450
    },
    {
      "epoch": 2.9196611909650922,
      "grad_norm": 0.25302231311798096,
      "learning_rate": 2.0804029774127312e-05,
      "loss": 0.0034,
      "step": 45500
    },
    {
      "epoch": 2.9228696098562628,
      "grad_norm": 0.16604024171829224,
      "learning_rate": 2.077194558521561e-05,
      "loss": 0.0035,
      "step": 45550
    },
    {
      "epoch": 2.9260780287474333,
      "grad_norm": 0.2895413339138031,
      "learning_rate": 2.07398613963039e-05,
      "loss": 0.0035,
      "step": 45600
    },
    {
      "epoch": 2.929286447638604,
      "grad_norm": 1.187839150428772,
      "learning_rate": 2.0707777207392198e-05,
      "loss": 0.0035,
      "step": 45650
    },
    {
      "epoch": 2.9324948665297743,
      "grad_norm": 0.33244815468788147,
      "learning_rate": 2.0675693018480494e-05,
      "loss": 0.0034,
      "step": 45700
    },
    {
      "epoch": 2.935703285420945,
      "grad_norm": 0.16347850859165192,
      "learning_rate": 2.064360882956879e-05,
      "loss": 0.0035,
      "step": 45750
    },
    {
      "epoch": 2.938911704312115,
      "grad_norm": 0.18522241711616516,
      "learning_rate": 2.0611524640657083e-05,
      "loss": 0.0035,
      "step": 45800
    },
    {
      "epoch": 2.9421201232032854,
      "grad_norm": 0.1596716195344925,
      "learning_rate": 2.057944045174538e-05,
      "loss": 0.0035,
      "step": 45850
    },
    {
      "epoch": 2.945328542094456,
      "grad_norm": 0.3017200827598572,
      "learning_rate": 2.0547356262833675e-05,
      "loss": 0.0034,
      "step": 45900
    },
    {
      "epoch": 2.948536960985626,
      "grad_norm": 0.25525417923927307,
      "learning_rate": 2.0515272073921975e-05,
      "loss": 0.0035,
      "step": 45950
    },
    {
      "epoch": 2.9517453798767965,
      "grad_norm": 0.12370959669351578,
      "learning_rate": 2.0483187885010268e-05,
      "loss": 0.0034,
      "step": 46000
    },
    {
      "epoch": 2.954953798767967,
      "grad_norm": 0.4238070547580719,
      "learning_rate": 2.0451103696098564e-05,
      "loss": 0.0035,
      "step": 46050
    },
    {
      "epoch": 2.9581622176591376,
      "grad_norm": 0.4132530689239502,
      "learning_rate": 2.041901950718686e-05,
      "loss": 0.0035,
      "step": 46100
    },
    {
      "epoch": 2.961370636550308,
      "grad_norm": 0.1337694376707077,
      "learning_rate": 2.0386935318275156e-05,
      "loss": 0.0035,
      "step": 46150
    },
    {
      "epoch": 2.9645790554414786,
      "grad_norm": 0.8258590698242188,
      "learning_rate": 2.035485112936345e-05,
      "loss": 0.0035,
      "step": 46200
    },
    {
      "epoch": 2.967787474332649,
      "grad_norm": 0.21856501698493958,
      "learning_rate": 2.0322766940451745e-05,
      "loss": 0.0036,
      "step": 46250
    },
    {
      "epoch": 2.970995893223819,
      "grad_norm": 0.3769925832748413,
      "learning_rate": 2.029068275154004e-05,
      "loss": 0.0034,
      "step": 46300
    },
    {
      "epoch": 2.9742043121149897,
      "grad_norm": 0.5248160362243652,
      "learning_rate": 2.0258598562628337e-05,
      "loss": 0.0035,
      "step": 46350
    },
    {
      "epoch": 2.97741273100616,
      "grad_norm": 0.17876261472702026,
      "learning_rate": 2.0226514373716634e-05,
      "loss": 0.0034,
      "step": 46400
    },
    {
      "epoch": 2.9806211498973307,
      "grad_norm": 0.18290318548679352,
      "learning_rate": 2.019443018480493e-05,
      "loss": 0.0035,
      "step": 46450
    },
    {
      "epoch": 2.983829568788501,
      "grad_norm": 0.21181373298168182,
      "learning_rate": 2.0162345995893226e-05,
      "loss": 0.0034,
      "step": 46500
    },
    {
      "epoch": 2.9870379876796713,
      "grad_norm": 0.44116687774658203,
      "learning_rate": 2.0130261806981522e-05,
      "loss": 0.0034,
      "step": 46550
    },
    {
      "epoch": 2.990246406570842,
      "grad_norm": 0.46899843215942383,
      "learning_rate": 2.0098177618069815e-05,
      "loss": 0.0035,
      "step": 46600
    },
    {
      "epoch": 2.9934548254620124,
      "grad_norm": 0.038923606276512146,
      "learning_rate": 2.006609342915811e-05,
      "loss": 0.0035,
      "step": 46650
    },
    {
      "epoch": 2.996663244353183,
      "grad_norm": 0.33931005001068115,
      "learning_rate": 2.0034009240246407e-05,
      "loss": 0.0034,
      "step": 46700
    },
    {
      "epoch": 2.9998716632443534,
      "grad_norm": 0.11055944859981537,
      "learning_rate": 2.0001925051334704e-05,
      "loss": 0.0035,
      "step": 46750
    },
    {
      "epoch": 3.0030800821355235,
      "grad_norm": 0.04509923607110977,
      "learning_rate": 1.9969840862422996e-05,
      "loss": 0.0034,
      "step": 46800
    },
    {
      "epoch": 3.006288501026694,
      "grad_norm": 0.12394165992736816,
      "learning_rate": 1.9937756673511296e-05,
      "loss": 0.0035,
      "step": 46850
    },
    {
      "epoch": 3.0094969199178645,
      "grad_norm": 0.34936919808387756,
      "learning_rate": 1.9905672484599592e-05,
      "loss": 0.0034,
      "step": 46900
    },
    {
      "epoch": 3.012705338809035,
      "grad_norm": 0.2753061056137085,
      "learning_rate": 1.9873588295687885e-05,
      "loss": 0.0035,
      "step": 46950
    },
    {
      "epoch": 3.0159137577002055,
      "grad_norm": 0.2642756998538971,
      "learning_rate": 1.984150410677618e-05,
      "loss": 0.0035,
      "step": 47000
    },
    {
      "epoch": 3.0191221765913756,
      "grad_norm": 0.3353767693042755,
      "learning_rate": 1.9809419917864477e-05,
      "loss": 0.0034,
      "step": 47050
    },
    {
      "epoch": 3.022330595482546,
      "grad_norm": 0.5023985505104065,
      "learning_rate": 1.9777335728952774e-05,
      "loss": 0.0034,
      "step": 47100
    },
    {
      "epoch": 3.0255390143737166,
      "grad_norm": 0.2309284210205078,
      "learning_rate": 1.974525154004107e-05,
      "loss": 0.0035,
      "step": 47150
    },
    {
      "epoch": 3.028747433264887,
      "grad_norm": 0.9166390299797058,
      "learning_rate": 1.9713167351129363e-05,
      "loss": 0.0034,
      "step": 47200
    },
    {
      "epoch": 3.0319558521560577,
      "grad_norm": 0.20810076594352722,
      "learning_rate": 1.968108316221766e-05,
      "loss": 0.0034,
      "step": 47250
    },
    {
      "epoch": 3.0351642710472277,
      "grad_norm": 0.08256685733795166,
      "learning_rate": 1.9648998973305958e-05,
      "loss": 0.0036,
      "step": 47300
    },
    {
      "epoch": 3.0383726899383983,
      "grad_norm": 0.29696139693260193,
      "learning_rate": 1.961691478439425e-05,
      "loss": 0.0034,
      "step": 47350
    },
    {
      "epoch": 3.041581108829569,
      "grad_norm": 0.5156021118164062,
      "learning_rate": 1.9584830595482547e-05,
      "loss": 0.0035,
      "step": 47400
    },
    {
      "epoch": 3.0447895277207393,
      "grad_norm": 0.09028828889131546,
      "learning_rate": 1.9552746406570843e-05,
      "loss": 0.0035,
      "step": 47450
    },
    {
      "epoch": 3.04799794661191,
      "grad_norm": 0.19742946326732635,
      "learning_rate": 1.952066221765914e-05,
      "loss": 0.0035,
      "step": 47500
    },
    {
      "epoch": 3.05120636550308,
      "grad_norm": 0.42289385199546814,
      "learning_rate": 1.9488578028747432e-05,
      "loss": 0.0034,
      "step": 47550
    },
    {
      "epoch": 3.0544147843942504,
      "grad_norm": 0.266366183757782,
      "learning_rate": 1.945649383983573e-05,
      "loss": 0.0034,
      "step": 47600
    },
    {
      "epoch": 3.057623203285421,
      "grad_norm": 0.7868438959121704,
      "learning_rate": 1.9424409650924025e-05,
      "loss": 0.0034,
      "step": 47650
    },
    {
      "epoch": 3.0608316221765914,
      "grad_norm": 0.49548590183258057,
      "learning_rate": 1.939232546201232e-05,
      "loss": 0.0035,
      "step": 47700
    },
    {
      "epoch": 3.064040041067762,
      "grad_norm": 0.1253058910369873,
      "learning_rate": 1.9360241273100617e-05,
      "loss": 0.0035,
      "step": 47750
    },
    {
      "epoch": 3.067248459958932,
      "grad_norm": 0.45918214321136475,
      "learning_rate": 1.9328157084188913e-05,
      "loss": 0.0034,
      "step": 47800
    },
    {
      "epoch": 3.0704568788501025,
      "grad_norm": 1.0110080242156982,
      "learning_rate": 1.929607289527721e-05,
      "loss": 0.0035,
      "step": 47850
    },
    {
      "epoch": 3.073665297741273,
      "grad_norm": 0.30283278226852417,
      "learning_rate": 1.9263988706365506e-05,
      "loss": 0.0034,
      "step": 47900
    },
    {
      "epoch": 3.0768737166324436,
      "grad_norm": 0.40177369117736816,
      "learning_rate": 1.92319045174538e-05,
      "loss": 0.0034,
      "step": 47950
    },
    {
      "epoch": 3.080082135523614,
      "grad_norm": 1.128579020500183,
      "learning_rate": 1.9199820328542095e-05,
      "loss": 0.0035,
      "step": 48000
    },
    {
      "epoch": 3.083290554414784,
      "grad_norm": 0.30128124356269836,
      "learning_rate": 1.916773613963039e-05,
      "loss": 0.0035,
      "step": 48050
    },
    {
      "epoch": 3.0864989733059547,
      "grad_norm": 0.27594515681266785,
      "learning_rate": 1.9135651950718687e-05,
      "loss": 0.0034,
      "step": 48100
    },
    {
      "epoch": 3.089707392197125,
      "grad_norm": 0.0930681899189949,
      "learning_rate": 1.910356776180698e-05,
      "loss": 0.0034,
      "step": 48150
    },
    {
      "epoch": 3.0929158110882957,
      "grad_norm": 0.4241175055503845,
      "learning_rate": 1.9071483572895276e-05,
      "loss": 0.0034,
      "step": 48200
    },
    {
      "epoch": 3.0961242299794662,
      "grad_norm": 0.10544321686029434,
      "learning_rate": 1.9039399383983576e-05,
      "loss": 0.0035,
      "step": 48250
    },
    {
      "epoch": 3.0993326488706368,
      "grad_norm": 0.35578295588493347,
      "learning_rate": 1.9007315195071872e-05,
      "loss": 0.0035,
      "step": 48300
    },
    {
      "epoch": 3.102541067761807,
      "grad_norm": 0.21775929629802704,
      "learning_rate": 1.8975231006160165e-05,
      "loss": 0.0034,
      "step": 48350
    },
    {
      "epoch": 3.1057494866529773,
      "grad_norm": 0.49641165137290955,
      "learning_rate": 1.894314681724846e-05,
      "loss": 0.0034,
      "step": 48400
    },
    {
      "epoch": 3.108957905544148,
      "grad_norm": 3.729383707046509,
      "learning_rate": 1.8911062628336757e-05,
      "loss": 0.0034,
      "step": 48450
    },
    {
      "epoch": 3.1121663244353184,
      "grad_norm": 0.7595447301864624,
      "learning_rate": 1.8878978439425053e-05,
      "loss": 0.0035,
      "step": 48500
    },
    {
      "epoch": 3.115374743326489,
      "grad_norm": 0.28274697065353394,
      "learning_rate": 1.8846894250513346e-05,
      "loss": 0.0035,
      "step": 48550
    },
    {
      "epoch": 3.118583162217659,
      "grad_norm": 0.16198289394378662,
      "learning_rate": 1.8814810061601642e-05,
      "loss": 0.0035,
      "step": 48600
    },
    {
      "epoch": 3.1217915811088295,
      "grad_norm": 0.29280203580856323,
      "learning_rate": 1.878272587268994e-05,
      "loss": 0.0034,
      "step": 48650
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.11278188973665237,
      "learning_rate": 1.8750641683778235e-05,
      "loss": 0.0034,
      "step": 48700
    },
    {
      "epoch": 3.1282084188911705,
      "grad_norm": 0.4060060381889343,
      "learning_rate": 1.871855749486653e-05,
      "loss": 0.0034,
      "step": 48750
    },
    {
      "epoch": 3.131416837782341,
      "grad_norm": 0.39082932472229004,
      "learning_rate": 1.8686473305954827e-05,
      "loss": 0.0035,
      "step": 48800
    },
    {
      "epoch": 3.134625256673511,
      "grad_norm": 0.2856425344944,
      "learning_rate": 1.8654389117043123e-05,
      "loss": 0.0035,
      "step": 48850
    },
    {
      "epoch": 3.1378336755646816,
      "grad_norm": 0.2726331949234009,
      "learning_rate": 1.862230492813142e-05,
      "loss": 0.0034,
      "step": 48900
    },
    {
      "epoch": 3.141042094455852,
      "grad_norm": 0.11991673707962036,
      "learning_rate": 1.8590220739219712e-05,
      "loss": 0.0036,
      "step": 48950
    },
    {
      "epoch": 3.1442505133470227,
      "grad_norm": 0.2996685802936554,
      "learning_rate": 1.855813655030801e-05,
      "loss": 0.0034,
      "step": 49000
    },
    {
      "epoch": 3.147458932238193,
      "grad_norm": 0.1649111956357956,
      "learning_rate": 1.8526052361396305e-05,
      "loss": 0.0034,
      "step": 49050
    },
    {
      "epoch": 3.1506673511293632,
      "grad_norm": 0.23144611716270447,
      "learning_rate": 1.84939681724846e-05,
      "loss": 0.0035,
      "step": 49100
    },
    {
      "epoch": 3.1538757700205338,
      "grad_norm": 0.15641747415065765,
      "learning_rate": 1.8461883983572897e-05,
      "loss": 0.0035,
      "step": 49150
    },
    {
      "epoch": 3.1570841889117043,
      "grad_norm": 0.3135356307029724,
      "learning_rate": 1.8429799794661193e-05,
      "loss": 0.0034,
      "step": 49200
    },
    {
      "epoch": 3.160292607802875,
      "grad_norm": 0.2272643744945526,
      "learning_rate": 1.839771560574949e-05,
      "loss": 0.0035,
      "step": 49250
    },
    {
      "epoch": 3.1635010266940453,
      "grad_norm": 0.5787152647972107,
      "learning_rate": 1.8365631416837782e-05,
      "loss": 0.0034,
      "step": 49300
    },
    {
      "epoch": 3.166709445585216,
      "grad_norm": 0.3475128710269928,
      "learning_rate": 1.8333547227926078e-05,
      "loss": 0.0035,
      "step": 49350
    },
    {
      "epoch": 3.169917864476386,
      "grad_norm": 0.29525816440582275,
      "learning_rate": 1.8301463039014374e-05,
      "loss": 0.0035,
      "step": 49400
    },
    {
      "epoch": 3.1731262833675564,
      "grad_norm": 1.4967920780181885,
      "learning_rate": 1.826937885010267e-05,
      "loss": 0.0034,
      "step": 49450
    },
    {
      "epoch": 3.176334702258727,
      "grad_norm": 0.17856942117214203,
      "learning_rate": 1.8237294661190963e-05,
      "loss": 0.0035,
      "step": 49500
    },
    {
      "epoch": 3.1795431211498975,
      "grad_norm": 0.24142399430274963,
      "learning_rate": 1.820521047227926e-05,
      "loss": 0.0034,
      "step": 49550
    },
    {
      "epoch": 3.1827515400410675,
      "grad_norm": 0.2080034464597702,
      "learning_rate": 1.817312628336756e-05,
      "loss": 0.0034,
      "step": 49600
    },
    {
      "epoch": 3.185959958932238,
      "grad_norm": 0.459820419549942,
      "learning_rate": 1.8141042094455855e-05,
      "loss": 0.0034,
      "step": 49650
    },
    {
      "epoch": 3.1891683778234086,
      "grad_norm": 0.23188117146492004,
      "learning_rate": 1.8108957905544148e-05,
      "loss": 0.0035,
      "step": 49700
    },
    {
      "epoch": 3.192376796714579,
      "grad_norm": 0.1796615868806839,
      "learning_rate": 1.8076873716632444e-05,
      "loss": 0.0035,
      "step": 49750
    },
    {
      "epoch": 3.1955852156057496,
      "grad_norm": 0.5621793270111084,
      "learning_rate": 1.804478952772074e-05,
      "loss": 0.0034,
      "step": 49800
    },
    {
      "epoch": 3.19879363449692,
      "grad_norm": 0.4275481700897217,
      "learning_rate": 1.8012705338809037e-05,
      "loss": 0.0034,
      "step": 49850
    },
    {
      "epoch": 3.20200205338809,
      "grad_norm": 0.3978222608566284,
      "learning_rate": 1.798062114989733e-05,
      "loss": 0.0034,
      "step": 49900
    },
    {
      "epoch": 3.2052104722792607,
      "grad_norm": 0.198909729719162,
      "learning_rate": 1.7948536960985626e-05,
      "loss": 0.0035,
      "step": 49950
    },
    {
      "epoch": 3.208418891170431,
      "grad_norm": 0.14793512225151062,
      "learning_rate": 1.7916452772073922e-05,
      "loss": 0.0034,
      "step": 50000
    },
    {
      "epoch": 3.2116273100616017,
      "grad_norm": 0.6594222187995911,
      "learning_rate": 1.788436858316222e-05,
      "loss": 0.0035,
      "step": 50050
    },
    {
      "epoch": 3.2148357289527723,
      "grad_norm": 1.6013621091842651,
      "learning_rate": 1.7852284394250514e-05,
      "loss": 0.0034,
      "step": 50100
    },
    {
      "epoch": 3.2180441478439423,
      "grad_norm": 0.16536404192447662,
      "learning_rate": 1.782020020533881e-05,
      "loss": 0.0035,
      "step": 50150
    },
    {
      "epoch": 3.221252566735113,
      "grad_norm": 0.40979915857315063,
      "learning_rate": 1.7788116016427107e-05,
      "loss": 0.0034,
      "step": 50200
    },
    {
      "epoch": 3.2244609856262834,
      "grad_norm": 0.3572305738925934,
      "learning_rate": 1.7756031827515403e-05,
      "loss": 0.0034,
      "step": 50250
    },
    {
      "epoch": 3.227669404517454,
      "grad_norm": 0.3533537983894348,
      "learning_rate": 1.7723947638603696e-05,
      "loss": 0.0034,
      "step": 50300
    },
    {
      "epoch": 3.2308778234086244,
      "grad_norm": 0.45698490738868713,
      "learning_rate": 1.7691863449691992e-05,
      "loss": 0.0035,
      "step": 50350
    },
    {
      "epoch": 3.2340862422997945,
      "grad_norm": 0.44988352060317993,
      "learning_rate": 1.7659779260780288e-05,
      "loss": 0.0034,
      "step": 50400
    },
    {
      "epoch": 3.237294661190965,
      "grad_norm": 0.46567538380622864,
      "learning_rate": 1.7627695071868584e-05,
      "loss": 0.0034,
      "step": 50450
    },
    {
      "epoch": 3.2405030800821355,
      "grad_norm": 0.28067973256111145,
      "learning_rate": 1.7595610882956877e-05,
      "loss": 0.0036,
      "step": 50500
    },
    {
      "epoch": 3.243711498973306,
      "grad_norm": 0.2862951159477234,
      "learning_rate": 1.7563526694045177e-05,
      "loss": 0.0035,
      "step": 50550
    },
    {
      "epoch": 3.2469199178644765,
      "grad_norm": 0.2230009138584137,
      "learning_rate": 1.7531442505133473e-05,
      "loss": 0.0034,
      "step": 50600
    },
    {
      "epoch": 3.2501283367556466,
      "grad_norm": 0.3387492299079895,
      "learning_rate": 1.7499358316221766e-05,
      "loss": 0.0034,
      "step": 50650
    },
    {
      "epoch": 3.253336755646817,
      "grad_norm": 1.0432476997375488,
      "learning_rate": 1.7467274127310062e-05,
      "loss": 0.0034,
      "step": 50700
    },
    {
      "epoch": 3.2565451745379876,
      "grad_norm": 0.2660195231437683,
      "learning_rate": 1.7435189938398358e-05,
      "loss": 0.0035,
      "step": 50750
    },
    {
      "epoch": 3.259753593429158,
      "grad_norm": 0.5065397620201111,
      "learning_rate": 1.7403105749486654e-05,
      "loss": 0.0035,
      "step": 50800
    },
    {
      "epoch": 3.2629620123203287,
      "grad_norm": 0.21684348583221436,
      "learning_rate": 1.737102156057495e-05,
      "loss": 0.0034,
      "step": 50850
    },
    {
      "epoch": 3.266170431211499,
      "grad_norm": 0.43843820691108704,
      "learning_rate": 1.7338937371663243e-05,
      "loss": 0.0034,
      "step": 50900
    },
    {
      "epoch": 3.2693788501026693,
      "grad_norm": 0.6847459077835083,
      "learning_rate": 1.730685318275154e-05,
      "loss": 0.0035,
      "step": 50950
    },
    {
      "epoch": 3.27258726899384,
      "grad_norm": 0.11798649281263351,
      "learning_rate": 1.727476899383984e-05,
      "loss": 0.0034,
      "step": 51000
    },
    {
      "epoch": 3.2757956878850103,
      "grad_norm": 0.3481258749961853,
      "learning_rate": 1.7242684804928132e-05,
      "loss": 0.0034,
      "step": 51050
    },
    {
      "epoch": 3.279004106776181,
      "grad_norm": 0.5209830403327942,
      "learning_rate": 1.7210600616016428e-05,
      "loss": 0.0034,
      "step": 51100
    },
    {
      "epoch": 3.282212525667351,
      "grad_norm": 0.4840106666088104,
      "learning_rate": 1.7178516427104724e-05,
      "loss": 0.0034,
      "step": 51150
    },
    {
      "epoch": 3.2854209445585214,
      "grad_norm": 0.33392533659935,
      "learning_rate": 1.714643223819302e-05,
      "loss": 0.0034,
      "step": 51200
    },
    {
      "epoch": 3.288629363449692,
      "grad_norm": 0.7912552356719971,
      "learning_rate": 1.7114348049281313e-05,
      "loss": 0.0034,
      "step": 51250
    },
    {
      "epoch": 3.2918377823408624,
      "grad_norm": 0.3199231028556824,
      "learning_rate": 1.708226386036961e-05,
      "loss": 0.0034,
      "step": 51300
    },
    {
      "epoch": 3.295046201232033,
      "grad_norm": 0.15611036121845245,
      "learning_rate": 1.7050179671457905e-05,
      "loss": 0.0034,
      "step": 51350
    },
    {
      "epoch": 3.2982546201232035,
      "grad_norm": 0.4907662272453308,
      "learning_rate": 1.70180954825462e-05,
      "loss": 0.0034,
      "step": 51400
    },
    {
      "epoch": 3.3014630390143735,
      "grad_norm": 0.5051186084747314,
      "learning_rate": 1.6986011293634498e-05,
      "loss": 0.0033,
      "step": 51450
    },
    {
      "epoch": 3.304671457905544,
      "grad_norm": 0.10656944662332535,
      "learning_rate": 1.6953927104722794e-05,
      "loss": 0.0035,
      "step": 51500
    },
    {
      "epoch": 3.3078798767967146,
      "grad_norm": 0.3359445631504059,
      "learning_rate": 1.692184291581109e-05,
      "loss": 0.0036,
      "step": 51550
    },
    {
      "epoch": 3.311088295687885,
      "grad_norm": 0.4380284547805786,
      "learning_rate": 1.6889758726899386e-05,
      "loss": 0.0034,
      "step": 51600
    },
    {
      "epoch": 3.3142967145790556,
      "grad_norm": 0.030668821185827255,
      "learning_rate": 1.685767453798768e-05,
      "loss": 0.0034,
      "step": 51650
    },
    {
      "epoch": 3.3175051334702257,
      "grad_norm": 0.23935376107692719,
      "learning_rate": 1.6825590349075975e-05,
      "loss": 0.0035,
      "step": 51700
    },
    {
      "epoch": 3.320713552361396,
      "grad_norm": 0.3196527659893036,
      "learning_rate": 1.679350616016427e-05,
      "loss": 0.0034,
      "step": 51750
    },
    {
      "epoch": 3.3239219712525667,
      "grad_norm": 2.3530383110046387,
      "learning_rate": 1.6761421971252568e-05,
      "loss": 0.0034,
      "step": 51800
    },
    {
      "epoch": 3.3271303901437372,
      "grad_norm": 0.5746733546257019,
      "learning_rate": 1.672933778234086e-05,
      "loss": 0.0034,
      "step": 51850
    },
    {
      "epoch": 3.3303388090349078,
      "grad_norm": 0.39520445466041565,
      "learning_rate": 1.669725359342916e-05,
      "loss": 0.0034,
      "step": 51900
    },
    {
      "epoch": 3.3335472279260783,
      "grad_norm": 0.39857062697410583,
      "learning_rate": 1.6665169404517456e-05,
      "loss": 0.0033,
      "step": 51950
    },
    {
      "epoch": 3.3367556468172483,
      "grad_norm": 0.5061632394790649,
      "learning_rate": 1.6633085215605753e-05,
      "loss": 0.0035,
      "step": 52000
    },
    {
      "epoch": 3.339964065708419,
      "grad_norm": 0.20792342722415924,
      "learning_rate": 1.6601001026694045e-05,
      "loss": 0.0034,
      "step": 52050
    },
    {
      "epoch": 3.3431724845995894,
      "grad_norm": 0.30289173126220703,
      "learning_rate": 1.656891683778234e-05,
      "loss": 0.0034,
      "step": 52100
    },
    {
      "epoch": 3.34638090349076,
      "grad_norm": 0.42700034379959106,
      "learning_rate": 1.6536832648870638e-05,
      "loss": 0.0035,
      "step": 52150
    },
    {
      "epoch": 3.34958932238193,
      "grad_norm": 0.22911067306995392,
      "learning_rate": 1.6504748459958934e-05,
      "loss": 0.0034,
      "step": 52200
    },
    {
      "epoch": 3.3527977412731005,
      "grad_norm": 0.39000383019447327,
      "learning_rate": 1.6472664271047227e-05,
      "loss": 0.0035,
      "step": 52250
    },
    {
      "epoch": 3.356006160164271,
      "grad_norm": 0.5744708180427551,
      "learning_rate": 1.6440580082135523e-05,
      "loss": 0.0034,
      "step": 52300
    },
    {
      "epoch": 3.3592145790554415,
      "grad_norm": 3.7843177318573,
      "learning_rate": 1.6408495893223822e-05,
      "loss": 0.0034,
      "step": 52350
    },
    {
      "epoch": 3.362422997946612,
      "grad_norm": 0.19974005222320557,
      "learning_rate": 1.6376411704312115e-05,
      "loss": 0.0035,
      "step": 52400
    },
    {
      "epoch": 3.3656314168377826,
      "grad_norm": 0.27813172340393066,
      "learning_rate": 1.634432751540041e-05,
      "loss": 0.0035,
      "step": 52450
    },
    {
      "epoch": 3.3688398357289526,
      "grad_norm": 0.593326985836029,
      "learning_rate": 1.6312243326488708e-05,
      "loss": 0.0034,
      "step": 52500
    },
    {
      "epoch": 3.372048254620123,
      "grad_norm": 0.3124006688594818,
      "learning_rate": 1.6280159137577004e-05,
      "loss": 0.0034,
      "step": 52550
    },
    {
      "epoch": 3.3752566735112937,
      "grad_norm": 0.35992956161499023,
      "learning_rate": 1.62480749486653e-05,
      "loss": 0.0034,
      "step": 52600
    },
    {
      "epoch": 3.378465092402464,
      "grad_norm": 0.2768406569957733,
      "learning_rate": 1.6215990759753593e-05,
      "loss": 0.0034,
      "step": 52650
    },
    {
      "epoch": 3.3816735112936342,
      "grad_norm": 0.38588154315948486,
      "learning_rate": 1.618390657084189e-05,
      "loss": 0.0034,
      "step": 52700
    },
    {
      "epoch": 3.3848819301848048,
      "grad_norm": 0.26646649837493896,
      "learning_rate": 1.6151822381930185e-05,
      "loss": 0.0034,
      "step": 52750
    },
    {
      "epoch": 3.3880903490759753,
      "grad_norm": 0.20587202906608582,
      "learning_rate": 1.611973819301848e-05,
      "loss": 0.0035,
      "step": 52800
    },
    {
      "epoch": 3.391298767967146,
      "grad_norm": 0.45238128304481506,
      "learning_rate": 1.6087654004106778e-05,
      "loss": 0.0034,
      "step": 52850
    },
    {
      "epoch": 3.3945071868583163,
      "grad_norm": 0.14281661808490753,
      "learning_rate": 1.6055569815195074e-05,
      "loss": 0.0033,
      "step": 52900
    },
    {
      "epoch": 3.397715605749487,
      "grad_norm": 1.472650170326233,
      "learning_rate": 1.602348562628337e-05,
      "loss": 0.0034,
      "step": 52950
    },
    {
      "epoch": 3.400924024640657,
      "grad_norm": 0.4338282346725464,
      "learning_rate": 1.5991401437371663e-05,
      "loss": 0.0034,
      "step": 53000
    },
    {
      "epoch": 3.4041324435318274,
      "grad_norm": 0.2645011842250824,
      "learning_rate": 1.595931724845996e-05,
      "loss": 0.0035,
      "step": 53050
    },
    {
      "epoch": 3.407340862422998,
      "grad_norm": 0.37317073345184326,
      "learning_rate": 1.5927233059548255e-05,
      "loss": 0.0034,
      "step": 53100
    },
    {
      "epoch": 3.4105492813141685,
      "grad_norm": 0.47357383370399475,
      "learning_rate": 1.589514887063655e-05,
      "loss": 0.0035,
      "step": 53150
    },
    {
      "epoch": 3.413757700205339,
      "grad_norm": 0.262603223323822,
      "learning_rate": 1.5863064681724844e-05,
      "loss": 0.0035,
      "step": 53200
    },
    {
      "epoch": 3.416966119096509,
      "grad_norm": 0.6822951436042786,
      "learning_rate": 1.583098049281314e-05,
      "loss": 0.0035,
      "step": 53250
    },
    {
      "epoch": 3.4201745379876796,
      "grad_norm": 0.4612521827220917,
      "learning_rate": 1.579889630390144e-05,
      "loss": 0.0033,
      "step": 53300
    },
    {
      "epoch": 3.42338295687885,
      "grad_norm": 2.05757212638855,
      "learning_rate": 1.5766812114989736e-05,
      "loss": 0.0034,
      "step": 53350
    },
    {
      "epoch": 3.4265913757700206,
      "grad_norm": 0.253303587436676,
      "learning_rate": 1.573472792607803e-05,
      "loss": 0.0034,
      "step": 53400
    },
    {
      "epoch": 3.429799794661191,
      "grad_norm": 0.08615898340940475,
      "learning_rate": 1.5702643737166325e-05,
      "loss": 0.0034,
      "step": 53450
    },
    {
      "epoch": 3.4330082135523616,
      "grad_norm": 0.11130623519420624,
      "learning_rate": 1.567055954825462e-05,
      "loss": 0.0034,
      "step": 53500
    },
    {
      "epoch": 3.4362166324435317,
      "grad_norm": 0.2974247932434082,
      "learning_rate": 1.5638475359342917e-05,
      "loss": 0.0034,
      "step": 53550
    },
    {
      "epoch": 3.439425051334702,
      "grad_norm": 0.06372757256031036,
      "learning_rate": 1.560639117043121e-05,
      "loss": 0.0034,
      "step": 53600
    },
    {
      "epoch": 3.4426334702258727,
      "grad_norm": 0.44418105483055115,
      "learning_rate": 1.5574306981519506e-05,
      "loss": 0.0034,
      "step": 53650
    },
    {
      "epoch": 3.4458418891170433,
      "grad_norm": 0.644311785697937,
      "learning_rate": 1.5542222792607803e-05,
      "loss": 0.0035,
      "step": 53700
    },
    {
      "epoch": 3.4490503080082133,
      "grad_norm": 0.4982832968235016,
      "learning_rate": 1.5510138603696102e-05,
      "loss": 0.0034,
      "step": 53750
    },
    {
      "epoch": 3.452258726899384,
      "grad_norm": 0.38945066928863525,
      "learning_rate": 1.5478054414784395e-05,
      "loss": 0.0034,
      "step": 53800
    },
    {
      "epoch": 3.4554671457905544,
      "grad_norm": 0.34233757853507996,
      "learning_rate": 1.544597022587269e-05,
      "loss": 0.0034,
      "step": 53850
    },
    {
      "epoch": 3.458675564681725,
      "grad_norm": 0.25811558961868286,
      "learning_rate": 1.5413886036960987e-05,
      "loss": 0.0034,
      "step": 53900
    },
    {
      "epoch": 3.4618839835728954,
      "grad_norm": 1.5562777519226074,
      "learning_rate": 1.5381801848049284e-05,
      "loss": 0.0034,
      "step": 53950
    },
    {
      "epoch": 3.465092402464066,
      "grad_norm": 2.3128674030303955,
      "learning_rate": 1.5349717659137576e-05,
      "loss": 0.0034,
      "step": 54000
    },
    {
      "epoch": 3.468300821355236,
      "grad_norm": 0.1859920620918274,
      "learning_rate": 1.5317633470225873e-05,
      "loss": 0.0034,
      "step": 54050
    },
    {
      "epoch": 3.4715092402464065,
      "grad_norm": 1.3965903520584106,
      "learning_rate": 1.528554928131417e-05,
      "loss": 0.0034,
      "step": 54100
    },
    {
      "epoch": 3.474717659137577,
      "grad_norm": 5.1292290687561035,
      "learning_rate": 1.5253465092402463e-05,
      "loss": 0.0034,
      "step": 54150
    },
    {
      "epoch": 3.4779260780287475,
      "grad_norm": 0.3775976002216339,
      "learning_rate": 1.5221380903490761e-05,
      "loss": 0.0035,
      "step": 54200
    },
    {
      "epoch": 3.481134496919918,
      "grad_norm": 0.553473949432373,
      "learning_rate": 1.5189296714579057e-05,
      "loss": 0.0034,
      "step": 54250
    },
    {
      "epoch": 3.484342915811088,
      "grad_norm": 0.548590362071991,
      "learning_rate": 1.5157212525667352e-05,
      "loss": 0.0034,
      "step": 54300
    },
    {
      "epoch": 3.4875513347022586,
      "grad_norm": 0.2439570277929306,
      "learning_rate": 1.5125128336755648e-05,
      "loss": 0.0033,
      "step": 54350
    },
    {
      "epoch": 3.490759753593429,
      "grad_norm": 0.13669946789741516,
      "learning_rate": 1.5093044147843942e-05,
      "loss": 0.0033,
      "step": 54400
    },
    {
      "epoch": 3.4939681724845997,
      "grad_norm": 0.40772101283073425,
      "learning_rate": 1.5060959958932239e-05,
      "loss": 0.0034,
      "step": 54450
    },
    {
      "epoch": 3.49717659137577,
      "grad_norm": 6.549164295196533,
      "learning_rate": 1.5028875770020535e-05,
      "loss": 0.0035,
      "step": 54500
    },
    {
      "epoch": 3.5003850102669407,
      "grad_norm": 0.28601592779159546,
      "learning_rate": 1.499679158110883e-05,
      "loss": 0.0034,
      "step": 54550
    },
    {
      "epoch": 3.503593429158111,
      "grad_norm": 0.28428715467453003,
      "learning_rate": 1.4964707392197126e-05,
      "loss": 0.0033,
      "step": 54600
    },
    {
      "epoch": 3.5068018480492813,
      "grad_norm": 0.28161805868148804,
      "learning_rate": 1.4932623203285423e-05,
      "loss": 0.0034,
      "step": 54650
    },
    {
      "epoch": 3.510010266940452,
      "grad_norm": 5.9879326820373535,
      "learning_rate": 1.4900539014373718e-05,
      "loss": 0.0034,
      "step": 54700
    },
    {
      "epoch": 3.5132186858316223,
      "grad_norm": 0.8242578506469727,
      "learning_rate": 1.4868454825462014e-05,
      "loss": 0.0034,
      "step": 54750
    },
    {
      "epoch": 3.5164271047227924,
      "grad_norm": 0.2896604537963867,
      "learning_rate": 1.4836370636550309e-05,
      "loss": 0.0034,
      "step": 54800
    },
    {
      "epoch": 3.519635523613963,
      "grad_norm": 0.6632634401321411,
      "learning_rate": 1.4804286447638605e-05,
      "loss": 0.0034,
      "step": 54850
    },
    {
      "epoch": 3.5228439425051334,
      "grad_norm": 0.47734102606773376,
      "learning_rate": 1.47722022587269e-05,
      "loss": 0.0034,
      "step": 54900
    },
    {
      "epoch": 3.526052361396304,
      "grad_norm": 0.29850420355796814,
      "learning_rate": 1.4740118069815195e-05,
      "loss": 0.0033,
      "step": 54950
    },
    {
      "epoch": 3.5292607802874745,
      "grad_norm": 0.11217562109231949,
      "learning_rate": 1.470803388090349e-05,
      "loss": 0.0035,
      "step": 55000
    },
    {
      "epoch": 3.532469199178645,
      "grad_norm": 0.4100649058818817,
      "learning_rate": 1.4675949691991786e-05,
      "loss": 0.0034,
      "step": 55050
    },
    {
      "epoch": 3.535677618069815,
      "grad_norm": 0.14171873033046722,
      "learning_rate": 1.4643865503080084e-05,
      "loss": 0.0034,
      "step": 55100
    },
    {
      "epoch": 3.5388860369609856,
      "grad_norm": 0.050372812896966934,
      "learning_rate": 1.461178131416838e-05,
      "loss": 0.0035,
      "step": 55150
    },
    {
      "epoch": 3.542094455852156,
      "grad_norm": 0.26845625042915344,
      "learning_rate": 1.4579697125256675e-05,
      "loss": 0.0034,
      "step": 55200
    },
    {
      "epoch": 3.5453028747433266,
      "grad_norm": 0.7488003969192505,
      "learning_rate": 1.4547612936344971e-05,
      "loss": 0.0034,
      "step": 55250
    },
    {
      "epoch": 3.5485112936344967,
      "grad_norm": 1.5361144542694092,
      "learning_rate": 1.4515528747433265e-05,
      "loss": 0.0034,
      "step": 55300
    },
    {
      "epoch": 3.551719712525667,
      "grad_norm": 0.3512510657310486,
      "learning_rate": 1.4483444558521562e-05,
      "loss": 0.0035,
      "step": 55350
    },
    {
      "epoch": 3.5549281314168377,
      "grad_norm": 0.5043157935142517,
      "learning_rate": 1.4451360369609856e-05,
      "loss": 0.0034,
      "step": 55400
    },
    {
      "epoch": 3.5581365503080082,
      "grad_norm": 0.29707232117652893,
      "learning_rate": 1.4419276180698152e-05,
      "loss": 0.0034,
      "step": 55450
    },
    {
      "epoch": 3.5613449691991788,
      "grad_norm": 0.4614992141723633,
      "learning_rate": 1.4387191991786447e-05,
      "loss": 0.0034,
      "step": 55500
    },
    {
      "epoch": 3.5645533880903493,
      "grad_norm": 0.13877752423286438,
      "learning_rate": 1.4355107802874743e-05,
      "loss": 0.0034,
      "step": 55550
    },
    {
      "epoch": 3.5677618069815193,
      "grad_norm": 0.8211866617202759,
      "learning_rate": 1.432302361396304e-05,
      "loss": 0.0034,
      "step": 55600
    },
    {
      "epoch": 3.57097022587269,
      "grad_norm": 0.5404528379440308,
      "learning_rate": 1.4290939425051337e-05,
      "loss": 0.0033,
      "step": 55650
    },
    {
      "epoch": 3.5741786447638604,
      "grad_norm": 0.5424327254295349,
      "learning_rate": 1.4258855236139631e-05,
      "loss": 0.0034,
      "step": 55700
    },
    {
      "epoch": 3.577387063655031,
      "grad_norm": 0.24199724197387695,
      "learning_rate": 1.4226771047227928e-05,
      "loss": 0.0034,
      "step": 55750
    },
    {
      "epoch": 3.580595482546201,
      "grad_norm": 0.13964517414569855,
      "learning_rate": 1.4194686858316222e-05,
      "loss": 0.0033,
      "step": 55800
    },
    {
      "epoch": 3.5838039014373715,
      "grad_norm": 0.5718145966529846,
      "learning_rate": 1.4162602669404518e-05,
      "loss": 0.0034,
      "step": 55850
    },
    {
      "epoch": 3.587012320328542,
      "grad_norm": 0.4105300307273865,
      "learning_rate": 1.4130518480492813e-05,
      "loss": 0.0034,
      "step": 55900
    },
    {
      "epoch": 3.5902207392197125,
      "grad_norm": 0.17291301488876343,
      "learning_rate": 1.4098434291581109e-05,
      "loss": 0.0034,
      "step": 55950
    },
    {
      "epoch": 3.593429158110883,
      "grad_norm": 0.35003310441970825,
      "learning_rate": 1.4066350102669404e-05,
      "loss": 0.0034,
      "step": 56000
    },
    {
      "epoch": 3.5966375770020536,
      "grad_norm": 0.41680455207824707,
      "learning_rate": 1.4034265913757701e-05,
      "loss": 0.0034,
      "step": 56050
    },
    {
      "epoch": 3.599845995893224,
      "grad_norm": 0.3560991585254669,
      "learning_rate": 1.4002181724845998e-05,
      "loss": 0.0033,
      "step": 56100
    },
    {
      "epoch": 3.603054414784394,
      "grad_norm": 0.46231967210769653,
      "learning_rate": 1.3970097535934292e-05,
      "loss": 0.0034,
      "step": 56150
    },
    {
      "epoch": 3.6062628336755647,
      "grad_norm": 0.3369150459766388,
      "learning_rate": 1.3938013347022588e-05,
      "loss": 0.0034,
      "step": 56200
    },
    {
      "epoch": 3.609471252566735,
      "grad_norm": 2.308668613433838,
      "learning_rate": 1.3905929158110883e-05,
      "loss": 0.0034,
      "step": 56250
    },
    {
      "epoch": 3.6126796714579057,
      "grad_norm": 0.5206376910209656,
      "learning_rate": 1.3873844969199179e-05,
      "loss": 0.0034,
      "step": 56300
    },
    {
      "epoch": 3.6158880903490758,
      "grad_norm": 0.4900071322917938,
      "learning_rate": 1.3841760780287475e-05,
      "loss": 0.0034,
      "step": 56350
    },
    {
      "epoch": 3.6190965092402463,
      "grad_norm": 0.3755456209182739,
      "learning_rate": 1.380967659137577e-05,
      "loss": 0.0034,
      "step": 56400
    },
    {
      "epoch": 3.622304928131417,
      "grad_norm": 0.4123137593269348,
      "learning_rate": 1.3777592402464066e-05,
      "loss": 0.0034,
      "step": 56450
    },
    {
      "epoch": 3.6255133470225873,
      "grad_norm": 0.4748319685459137,
      "learning_rate": 1.3745508213552364e-05,
      "loss": 0.0034,
      "step": 56500
    },
    {
      "epoch": 3.628721765913758,
      "grad_norm": 0.33337676525115967,
      "learning_rate": 1.3713424024640658e-05,
      "loss": 0.0034,
      "step": 56550
    },
    {
      "epoch": 3.6319301848049284,
      "grad_norm": 2.451174020767212,
      "learning_rate": 1.3681339835728954e-05,
      "loss": 0.0034,
      "step": 56600
    },
    {
      "epoch": 3.6351386036960984,
      "grad_norm": 0.8708333969116211,
      "learning_rate": 1.3649255646817249e-05,
      "loss": 0.0034,
      "step": 56650
    },
    {
      "epoch": 3.638347022587269,
      "grad_norm": 0.6181653738021851,
      "learning_rate": 1.3617171457905545e-05,
      "loss": 0.0033,
      "step": 56700
    },
    {
      "epoch": 3.6415554414784395,
      "grad_norm": 0.4221080243587494,
      "learning_rate": 1.358508726899384e-05,
      "loss": 0.0034,
      "step": 56750
    },
    {
      "epoch": 3.64476386036961,
      "grad_norm": 0.5602437853813171,
      "learning_rate": 1.3553003080082136e-05,
      "loss": 0.0034,
      "step": 56800
    },
    {
      "epoch": 3.64797227926078,
      "grad_norm": 0.8640221953392029,
      "learning_rate": 1.352091889117043e-05,
      "loss": 0.0033,
      "step": 56850
    },
    {
      "epoch": 3.6511806981519506,
      "grad_norm": 0.07071911543607712,
      "learning_rate": 1.3488834702258726e-05,
      "loss": 0.0034,
      "step": 56900
    },
    {
      "epoch": 3.654389117043121,
      "grad_norm": 0.34813210368156433,
      "learning_rate": 1.3456750513347024e-05,
      "loss": 0.0034,
      "step": 56950
    },
    {
      "epoch": 3.6575975359342916,
      "grad_norm": 0.16022618114948273,
      "learning_rate": 1.342466632443532e-05,
      "loss": 0.0034,
      "step": 57000
    },
    {
      "epoch": 3.660805954825462,
      "grad_norm": 0.5169892907142639,
      "learning_rate": 1.3392582135523615e-05,
      "loss": 0.0033,
      "step": 57050
    },
    {
      "epoch": 3.6640143737166326,
      "grad_norm": 0.399667352437973,
      "learning_rate": 1.3360497946611911e-05,
      "loss": 0.0034,
      "step": 57100
    },
    {
      "epoch": 3.667222792607803,
      "grad_norm": 0.6479724645614624,
      "learning_rate": 1.3328413757700206e-05,
      "loss": 0.0034,
      "step": 57150
    },
    {
      "epoch": 3.6704312114989732,
      "grad_norm": 0.10364150255918503,
      "learning_rate": 1.3296329568788502e-05,
      "loss": 0.0034,
      "step": 57200
    },
    {
      "epoch": 3.6736396303901437,
      "grad_norm": 0.23336556553840637,
      "learning_rate": 1.3264245379876796e-05,
      "loss": 0.0034,
      "step": 57250
    },
    {
      "epoch": 3.6768480492813143,
      "grad_norm": 0.33286088705062866,
      "learning_rate": 1.3232161190965093e-05,
      "loss": 0.0034,
      "step": 57300
    },
    {
      "epoch": 3.6800564681724843,
      "grad_norm": 0.6246663928031921,
      "learning_rate": 1.3200077002053387e-05,
      "loss": 0.0034,
      "step": 57350
    },
    {
      "epoch": 3.683264887063655,
      "grad_norm": 0.36866700649261475,
      "learning_rate": 1.3167992813141685e-05,
      "loss": 0.0034,
      "step": 57400
    },
    {
      "epoch": 3.6864733059548254,
      "grad_norm": 0.6625705361366272,
      "learning_rate": 1.3135908624229981e-05,
      "loss": 0.0033,
      "step": 57450
    },
    {
      "epoch": 3.689681724845996,
      "grad_norm": 0.35548922419548035,
      "learning_rate": 1.3103824435318277e-05,
      "loss": 0.0034,
      "step": 57500
    },
    {
      "epoch": 3.6928901437371664,
      "grad_norm": 0.7131523489952087,
      "learning_rate": 1.3071740246406572e-05,
      "loss": 0.0034,
      "step": 57550
    },
    {
      "epoch": 3.696098562628337,
      "grad_norm": 2.2264068126678467,
      "learning_rate": 1.3039656057494868e-05,
      "loss": 0.0034,
      "step": 57600
    },
    {
      "epoch": 3.6993069815195074,
      "grad_norm": 0.238725945353508,
      "learning_rate": 1.3007571868583162e-05,
      "loss": 0.0034,
      "step": 57650
    },
    {
      "epoch": 3.7025154004106775,
      "grad_norm": 0.3105585277080536,
      "learning_rate": 1.2975487679671459e-05,
      "loss": 0.0034,
      "step": 57700
    },
    {
      "epoch": 3.705723819301848,
      "grad_norm": 0.14895392954349518,
      "learning_rate": 1.2943403490759753e-05,
      "loss": 0.0033,
      "step": 57750
    },
    {
      "epoch": 3.7089322381930185,
      "grad_norm": 0.20002683997154236,
      "learning_rate": 1.291131930184805e-05,
      "loss": 0.0034,
      "step": 57800
    },
    {
      "epoch": 3.712140657084189,
      "grad_norm": 0.16291923820972443,
      "learning_rate": 1.2879235112936344e-05,
      "loss": 0.0034,
      "step": 57850
    },
    {
      "epoch": 3.715349075975359,
      "grad_norm": 0.35745084285736084,
      "learning_rate": 1.2847150924024642e-05,
      "loss": 0.0034,
      "step": 57900
    },
    {
      "epoch": 3.7185574948665296,
      "grad_norm": 0.5416596531867981,
      "learning_rate": 1.2815066735112938e-05,
      "loss": 0.0034,
      "step": 57950
    },
    {
      "epoch": 3.7217659137577,
      "grad_norm": 0.7867857813835144,
      "learning_rate": 1.2782982546201232e-05,
      "loss": 0.0034,
      "step": 58000
    },
    {
      "epoch": 3.7249743326488707,
      "grad_norm": 0.3692723512649536,
      "learning_rate": 1.2750898357289529e-05,
      "loss": 0.0033,
      "step": 58050
    },
    {
      "epoch": 3.728182751540041,
      "grad_norm": 0.10053150355815887,
      "learning_rate": 1.2718814168377823e-05,
      "loss": 0.0034,
      "step": 58100
    },
    {
      "epoch": 3.7313911704312117,
      "grad_norm": 0.1356937289237976,
      "learning_rate": 1.268672997946612e-05,
      "loss": 0.0034,
      "step": 58150
    },
    {
      "epoch": 3.734599589322382,
      "grad_norm": 0.3745270073413849,
      "learning_rate": 1.2654645790554415e-05,
      "loss": 0.0033,
      "step": 58200
    },
    {
      "epoch": 3.7378080082135523,
      "grad_norm": 0.43145138025283813,
      "learning_rate": 1.262256160164271e-05,
      "loss": 0.0033,
      "step": 58250
    },
    {
      "epoch": 3.741016427104723,
      "grad_norm": 0.26654863357543945,
      "learning_rate": 1.2590477412731006e-05,
      "loss": 0.0033,
      "step": 58300
    },
    {
      "epoch": 3.7442248459958933,
      "grad_norm": 0.15917035937309265,
      "learning_rate": 1.2558393223819304e-05,
      "loss": 0.0034,
      "step": 58350
    },
    {
      "epoch": 3.7474332648870634,
      "grad_norm": 1.2139828205108643,
      "learning_rate": 1.2526309034907599e-05,
      "loss": 0.0034,
      "step": 58400
    },
    {
      "epoch": 3.750641683778234,
      "grad_norm": 0.3027723431587219,
      "learning_rate": 1.2494224845995895e-05,
      "loss": 0.0034,
      "step": 58450
    },
    {
      "epoch": 3.7538501026694044,
      "grad_norm": 0.48336756229400635,
      "learning_rate": 1.246214065708419e-05,
      "loss": 0.0034,
      "step": 58500
    },
    {
      "epoch": 3.757058521560575,
      "grad_norm": 0.27763620018959045,
      "learning_rate": 1.2430056468172485e-05,
      "loss": 0.0035,
      "step": 58550
    },
    {
      "epoch": 3.7602669404517455,
      "grad_norm": 0.10638920217752457,
      "learning_rate": 1.239797227926078e-05,
      "loss": 0.0034,
      "step": 58600
    },
    {
      "epoch": 3.763475359342916,
      "grad_norm": 0.42227819561958313,
      "learning_rate": 1.2365888090349076e-05,
      "loss": 0.0033,
      "step": 58650
    },
    {
      "epoch": 3.7666837782340865,
      "grad_norm": 0.23241819441318512,
      "learning_rate": 1.2333803901437372e-05,
      "loss": 0.0034,
      "step": 58700
    },
    {
      "epoch": 3.7698921971252566,
      "grad_norm": 0.4360526502132416,
      "learning_rate": 1.2301719712525668e-05,
      "loss": 0.0034,
      "step": 58750
    },
    {
      "epoch": 3.773100616016427,
      "grad_norm": 0.10712625086307526,
      "learning_rate": 1.2269635523613963e-05,
      "loss": 0.0033,
      "step": 58800
    },
    {
      "epoch": 3.7763090349075976,
      "grad_norm": 0.2628578543663025,
      "learning_rate": 1.2237551334702259e-05,
      "loss": 0.0033,
      "step": 58850
    },
    {
      "epoch": 3.7795174537987677,
      "grad_norm": 0.6865004897117615,
      "learning_rate": 1.2205467145790555e-05,
      "loss": 0.0034,
      "step": 58900
    },
    {
      "epoch": 3.782725872689938,
      "grad_norm": 0.3055351674556732,
      "learning_rate": 1.2173382956878852e-05,
      "loss": 0.0034,
      "step": 58950
    },
    {
      "epoch": 3.7859342915811087,
      "grad_norm": 0.8109578490257263,
      "learning_rate": 1.2141298767967146e-05,
      "loss": 0.0033,
      "step": 59000
    },
    {
      "epoch": 3.7891427104722792,
      "grad_norm": 0.40504398941993713,
      "learning_rate": 1.2109214579055442e-05,
      "loss": 0.0034,
      "step": 59050
    },
    {
      "epoch": 3.7923511293634498,
      "grad_norm": 0.663276731967926,
      "learning_rate": 1.2077130390143737e-05,
      "loss": 0.0034,
      "step": 59100
    },
    {
      "epoch": 3.7955595482546203,
      "grad_norm": 0.33111512660980225,
      "learning_rate": 1.2045046201232035e-05,
      "loss": 0.0033,
      "step": 59150
    },
    {
      "epoch": 3.798767967145791,
      "grad_norm": 0.2367868721485138,
      "learning_rate": 1.2012962012320329e-05,
      "loss": 0.0034,
      "step": 59200
    },
    {
      "epoch": 3.801976386036961,
      "grad_norm": 0.3262222409248352,
      "learning_rate": 1.1980877823408625e-05,
      "loss": 0.0034,
      "step": 59250
    },
    {
      "epoch": 3.8051848049281314,
      "grad_norm": 0.35396692156791687,
      "learning_rate": 1.194879363449692e-05,
      "loss": 0.0034,
      "step": 59300
    },
    {
      "epoch": 3.808393223819302,
      "grad_norm": 0.5480507612228394,
      "learning_rate": 1.1916709445585218e-05,
      "loss": 0.0034,
      "step": 59350
    },
    {
      "epoch": 3.8116016427104724,
      "grad_norm": 0.33977335691452026,
      "learning_rate": 1.1884625256673512e-05,
      "loss": 0.0034,
      "step": 59400
    },
    {
      "epoch": 3.8148100616016425,
      "grad_norm": 0.42980465292930603,
      "learning_rate": 1.1852541067761808e-05,
      "loss": 0.0033,
      "step": 59450
    },
    {
      "epoch": 3.818018480492813,
      "grad_norm": 0.2972402572631836,
      "learning_rate": 1.1820456878850103e-05,
      "loss": 0.0033,
      "step": 59500
    },
    {
      "epoch": 3.8212268993839835,
      "grad_norm": 0.5095663666725159,
      "learning_rate": 1.1788372689938399e-05,
      "loss": 0.0034,
      "step": 59550
    },
    {
      "epoch": 3.824435318275154,
      "grad_norm": 0.40533748269081116,
      "learning_rate": 1.1756288501026695e-05,
      "loss": 0.0034,
      "step": 59600
    },
    {
      "epoch": 3.8276437371663246,
      "grad_norm": 1.5684882402420044,
      "learning_rate": 1.1724204312114991e-05,
      "loss": 0.0033,
      "step": 59650
    },
    {
      "epoch": 3.830852156057495,
      "grad_norm": 0.190491184592247,
      "learning_rate": 1.1692120123203286e-05,
      "loss": 0.0033,
      "step": 59700
    },
    {
      "epoch": 3.834060574948665,
      "grad_norm": 0.41403913497924805,
      "learning_rate": 1.1660035934291582e-05,
      "loss": 0.0033,
      "step": 59750
    },
    {
      "epoch": 3.8372689938398357,
      "grad_norm": 0.5870712995529175,
      "learning_rate": 1.1627951745379877e-05,
      "loss": 0.0034,
      "step": 59800
    },
    {
      "epoch": 3.840477412731006,
      "grad_norm": 0.47878485918045044,
      "learning_rate": 1.1595867556468173e-05,
      "loss": 0.0033,
      "step": 59850
    },
    {
      "epoch": 3.8436858316221767,
      "grad_norm": 0.1669457107782364,
      "learning_rate": 1.1563783367556469e-05,
      "loss": 0.0034,
      "step": 59900
    },
    {
      "epoch": 3.8468942505133468,
      "grad_norm": 0.7616376876831055,
      "learning_rate": 1.1531699178644763e-05,
      "loss": 0.0034,
      "step": 59950
    },
    {
      "epoch": 3.8501026694045173,
      "grad_norm": 0.4341253936290741,
      "learning_rate": 1.149961498973306e-05,
      "loss": 0.0034,
      "step": 60000
    },
    {
      "epoch": 3.853311088295688,
      "grad_norm": 0.39536431431770325,
      "learning_rate": 1.1467530800821356e-05,
      "loss": 0.0034,
      "step": 60050
    },
    {
      "epoch": 3.8565195071868583,
      "grad_norm": 0.31121379137039185,
      "learning_rate": 1.1435446611909652e-05,
      "loss": 0.0034,
      "step": 60100
    },
    {
      "epoch": 3.859727926078029,
      "grad_norm": 0.21104776859283447,
      "learning_rate": 1.1403362422997946e-05,
      "loss": 0.0034,
      "step": 60150
    },
    {
      "epoch": 3.8629363449691994,
      "grad_norm": 0.515037477016449,
      "learning_rate": 1.1371278234086243e-05,
      "loss": 0.0033,
      "step": 60200
    },
    {
      "epoch": 3.86614476386037,
      "grad_norm": 0.6317582726478577,
      "learning_rate": 1.1339194045174537e-05,
      "loss": 0.0034,
      "step": 60250
    },
    {
      "epoch": 3.86935318275154,
      "grad_norm": 0.5529748797416687,
      "learning_rate": 1.1307109856262835e-05,
      "loss": 0.0034,
      "step": 60300
    },
    {
      "epoch": 3.8725616016427105,
      "grad_norm": 0.31707537174224854,
      "learning_rate": 1.127502566735113e-05,
      "loss": 0.0034,
      "step": 60350
    },
    {
      "epoch": 3.875770020533881,
      "grad_norm": 0.4084685444831848,
      "learning_rate": 1.1242941478439426e-05,
      "loss": 0.0034,
      "step": 60400
    },
    {
      "epoch": 3.8789784394250515,
      "grad_norm": 0.09379987418651581,
      "learning_rate": 1.121085728952772e-05,
      "loss": 0.0034,
      "step": 60450
    },
    {
      "epoch": 3.8821868583162216,
      "grad_norm": 1.0768787860870361,
      "learning_rate": 1.1178773100616018e-05,
      "loss": 0.0034,
      "step": 60500
    },
    {
      "epoch": 3.885395277207392,
      "grad_norm": 0.5269536375999451,
      "learning_rate": 1.1146688911704313e-05,
      "loss": 0.0034,
      "step": 60550
    },
    {
      "epoch": 3.8886036960985626,
      "grad_norm": 0.2500568926334381,
      "learning_rate": 1.1114604722792609e-05,
      "loss": 0.0034,
      "step": 60600
    },
    {
      "epoch": 3.891812114989733,
      "grad_norm": 0.4890387952327728,
      "learning_rate": 1.1082520533880903e-05,
      "loss": 0.0034,
      "step": 60650
    },
    {
      "epoch": 3.8950205338809036,
      "grad_norm": 0.33381661772727966,
      "learning_rate": 1.10504363449692e-05,
      "loss": 0.0034,
      "step": 60700
    },
    {
      "epoch": 3.898228952772074,
      "grad_norm": 0.3041466772556305,
      "learning_rate": 1.1018352156057496e-05,
      "loss": 0.0033,
      "step": 60750
    },
    {
      "epoch": 3.9014373716632442,
      "grad_norm": 0.33250436186790466,
      "learning_rate": 1.0986267967145792e-05,
      "loss": 0.0034,
      "step": 60800
    },
    {
      "epoch": 3.9046457905544147,
      "grad_norm": 0.301688551902771,
      "learning_rate": 1.0954183778234086e-05,
      "loss": 0.0034,
      "step": 60850
    },
    {
      "epoch": 3.9078542094455853,
      "grad_norm": 0.5628645420074463,
      "learning_rate": 1.0922099589322383e-05,
      "loss": 0.0033,
      "step": 60900
    },
    {
      "epoch": 3.9110626283367558,
      "grad_norm": 0.315378338098526,
      "learning_rate": 1.0890015400410677e-05,
      "loss": 0.0034,
      "step": 60950
    },
    {
      "epoch": 3.914271047227926,
      "grad_norm": 0.4827401041984558,
      "learning_rate": 1.0857931211498975e-05,
      "loss": 0.0033,
      "step": 61000
    },
    {
      "epoch": 3.9174794661190964,
      "grad_norm": 0.660292387008667,
      "learning_rate": 1.082584702258727e-05,
      "loss": 0.0034,
      "step": 61050
    },
    {
      "epoch": 3.920687885010267,
      "grad_norm": 0.23951533436775208,
      "learning_rate": 1.0793762833675566e-05,
      "loss": 0.0034,
      "step": 61100
    },
    {
      "epoch": 3.9238963039014374,
      "grad_norm": 0.40620967745780945,
      "learning_rate": 1.076167864476386e-05,
      "loss": 0.0034,
      "step": 61150
    },
    {
      "epoch": 3.927104722792608,
      "grad_norm": 1.1496162414550781,
      "learning_rate": 1.0729594455852158e-05,
      "loss": 0.0033,
      "step": 61200
    },
    {
      "epoch": 3.9303131416837784,
      "grad_norm": 0.30361905694007874,
      "learning_rate": 1.0697510266940452e-05,
      "loss": 0.0034,
      "step": 61250
    },
    {
      "epoch": 3.9335215605749485,
      "grad_norm": 0.632930338382721,
      "learning_rate": 1.0665426078028749e-05,
      "loss": 0.0034,
      "step": 61300
    },
    {
      "epoch": 3.936729979466119,
      "grad_norm": 0.541559636592865,
      "learning_rate": 1.0633341889117043e-05,
      "loss": 0.0033,
      "step": 61350
    },
    {
      "epoch": 3.9399383983572895,
      "grad_norm": 0.7204554677009583,
      "learning_rate": 1.060125770020534e-05,
      "loss": 0.0034,
      "step": 61400
    },
    {
      "epoch": 3.94314681724846,
      "grad_norm": 2.2268764972686768,
      "learning_rate": 1.0569173511293636e-05,
      "loss": 0.0033,
      "step": 61450
    },
    {
      "epoch": 3.94635523613963,
      "grad_norm": 0.8215426802635193,
      "learning_rate": 1.053708932238193e-05,
      "loss": 0.0034,
      "step": 61500
    },
    {
      "epoch": 3.9495636550308006,
      "grad_norm": 0.5136041045188904,
      "learning_rate": 1.0505005133470226e-05,
      "loss": 0.0034,
      "step": 61550
    },
    {
      "epoch": 3.952772073921971,
      "grad_norm": 7.696578025817871,
      "learning_rate": 1.0472920944558522e-05,
      "loss": 0.0033,
      "step": 61600
    },
    {
      "epoch": 3.9559804928131417,
      "grad_norm": 1.5433520078659058,
      "learning_rate": 1.0440836755646819e-05,
      "loss": 0.0033,
      "step": 61650
    },
    {
      "epoch": 3.959188911704312,
      "grad_norm": 0.41719701886177063,
      "learning_rate": 1.0408752566735113e-05,
      "loss": 0.0034,
      "step": 61700
    },
    {
      "epoch": 3.9623973305954827,
      "grad_norm": 0.15486247837543488,
      "learning_rate": 1.037666837782341e-05,
      "loss": 0.0034,
      "step": 61750
    },
    {
      "epoch": 3.9656057494866532,
      "grad_norm": 0.39473986625671387,
      "learning_rate": 1.0344584188911704e-05,
      "loss": 0.0033,
      "step": 61800
    },
    {
      "epoch": 3.9688141683778233,
      "grad_norm": 2.7329139709472656,
      "learning_rate": 1.03125e-05,
      "loss": 0.0034,
      "step": 61850
    },
    {
      "epoch": 3.972022587268994,
      "grad_norm": 0.47567835450172424,
      "learning_rate": 1.0280415811088296e-05,
      "loss": 0.0033,
      "step": 61900
    },
    {
      "epoch": 3.9752310061601643,
      "grad_norm": 0.8050919771194458,
      "learning_rate": 1.0248331622176592e-05,
      "loss": 0.0033,
      "step": 61950
    },
    {
      "epoch": 3.978439425051335,
      "grad_norm": 0.492266982793808,
      "learning_rate": 1.0216247433264887e-05,
      "loss": 0.0034,
      "step": 62000
    },
    {
      "epoch": 3.981647843942505,
      "grad_norm": 0.18906182050704956,
      "learning_rate": 1.0184163244353183e-05,
      "loss": 0.0033,
      "step": 62050
    },
    {
      "epoch": 3.9848562628336754,
      "grad_norm": 0.36448702216148376,
      "learning_rate": 1.0152079055441477e-05,
      "loss": 0.0033,
      "step": 62100
    },
    {
      "epoch": 3.988064681724846,
      "grad_norm": 1.753255844116211,
      "learning_rate": 1.0119994866529775e-05,
      "loss": 0.0033,
      "step": 62150
    },
    {
      "epoch": 3.9912731006160165,
      "grad_norm": 0.464443176984787,
      "learning_rate": 1.008791067761807e-05,
      "loss": 0.0034,
      "step": 62200
    },
    {
      "epoch": 3.994481519507187,
      "grad_norm": 0.2587611973285675,
      "learning_rate": 1.0055826488706366e-05,
      "loss": 0.0033,
      "step": 62250
    },
    {
      "epoch": 3.9976899383983575,
      "grad_norm": 0.6157249808311462,
      "learning_rate": 1.002374229979466e-05,
      "loss": 0.0033,
      "step": 62300
    },
    {
      "epoch": 4.000898357289528,
      "grad_norm": 1.7177127599716187,
      "learning_rate": 9.991658110882958e-06,
      "loss": 0.0034,
      "step": 62350
    },
    {
      "epoch": 4.0041067761806985,
      "grad_norm": 0.5237195491790771,
      "learning_rate": 9.959573921971253e-06,
      "loss": 0.0033,
      "step": 62400
    },
    {
      "epoch": 4.007315195071868,
      "grad_norm": 0.7417501211166382,
      "learning_rate": 9.927489733059549e-06,
      "loss": 0.0033,
      "step": 62450
    },
    {
      "epoch": 4.010523613963039,
      "grad_norm": 0.14608663320541382,
      "learning_rate": 9.895405544147844e-06,
      "loss": 0.0034,
      "step": 62500
    },
    {
      "epoch": 4.013732032854209,
      "grad_norm": 0.7162834405899048,
      "learning_rate": 9.86332135523614e-06,
      "loss": 0.0033,
      "step": 62550
    },
    {
      "epoch": 4.01694045174538,
      "grad_norm": 0.5180167555809021,
      "learning_rate": 9.831237166324436e-06,
      "loss": 0.0033,
      "step": 62600
    },
    {
      "epoch": 4.02014887063655,
      "grad_norm": 0.3339095711708069,
      "learning_rate": 9.799152977412732e-06,
      "loss": 0.0033,
      "step": 62650
    },
    {
      "epoch": 4.023357289527721,
      "grad_norm": 0.3795962333679199,
      "learning_rate": 9.767068788501027e-06,
      "loss": 0.0034,
      "step": 62700
    },
    {
      "epoch": 4.026565708418891,
      "grad_norm": 0.6857028603553772,
      "learning_rate": 9.734984599589323e-06,
      "loss": 0.0034,
      "step": 62750
    },
    {
      "epoch": 4.029774127310062,
      "grad_norm": 0.5237581133842468,
      "learning_rate": 9.702900410677619e-06,
      "loss": 0.0033,
      "step": 62800
    },
    {
      "epoch": 4.032982546201232,
      "grad_norm": 0.04406707361340523,
      "learning_rate": 9.670816221765915e-06,
      "loss": 0.0033,
      "step": 62850
    },
    {
      "epoch": 4.036190965092403,
      "grad_norm": 1.4088809490203857,
      "learning_rate": 9.63873203285421e-06,
      "loss": 0.0034,
      "step": 62900
    },
    {
      "epoch": 4.0393993839835725,
      "grad_norm": 0.9430177211761475,
      "learning_rate": 9.606647843942506e-06,
      "loss": 0.0033,
      "step": 62950
    },
    {
      "epoch": 4.042607802874743,
      "grad_norm": 0.6001526713371277,
      "learning_rate": 9.5745636550308e-06,
      "loss": 0.0033,
      "step": 63000
    },
    {
      "epoch": 4.0458162217659135,
      "grad_norm": 1.8345558643341064,
      "learning_rate": 9.542479466119098e-06,
      "loss": 0.0033,
      "step": 63050
    },
    {
      "epoch": 4.049024640657084,
      "grad_norm": 0.3226584494113922,
      "learning_rate": 9.510395277207393e-06,
      "loss": 0.0034,
      "step": 63100
    },
    {
      "epoch": 4.0522330595482545,
      "grad_norm": 0.8917007446289062,
      "learning_rate": 9.478311088295689e-06,
      "loss": 0.0033,
      "step": 63150
    },
    {
      "epoch": 4.055441478439425,
      "grad_norm": 0.30325818061828613,
      "learning_rate": 9.446226899383983e-06,
      "loss": 0.0033,
      "step": 63200
    },
    {
      "epoch": 4.058649897330596,
      "grad_norm": 0.27512291073799133,
      "learning_rate": 9.41414271047228e-06,
      "loss": 0.0033,
      "step": 63250
    },
    {
      "epoch": 4.061858316221766,
      "grad_norm": 2.168987512588501,
      "learning_rate": 9.382058521560576e-06,
      "loss": 0.0033,
      "step": 63300
    },
    {
      "epoch": 4.065066735112937,
      "grad_norm": 0.9882110357284546,
      "learning_rate": 9.34997433264887e-06,
      "loss": 0.0034,
      "step": 63350
    },
    {
      "epoch": 4.068275154004107,
      "grad_norm": 0.7023141980171204,
      "learning_rate": 9.317890143737167e-06,
      "loss": 0.0033,
      "step": 63400
    },
    {
      "epoch": 4.071483572895278,
      "grad_norm": 0.7167120575904846,
      "learning_rate": 9.285805954825463e-06,
      "loss": 0.0033,
      "step": 63450
    },
    {
      "epoch": 4.074691991786447,
      "grad_norm": 0.12756972014904022,
      "learning_rate": 9.253721765913759e-06,
      "loss": 0.0033,
      "step": 63500
    },
    {
      "epoch": 4.077900410677618,
      "grad_norm": 0.4692765474319458,
      "learning_rate": 9.221637577002053e-06,
      "loss": 0.0032,
      "step": 63550
    },
    {
      "epoch": 4.081108829568788,
      "grad_norm": 1.0529285669326782,
      "learning_rate": 9.18955338809035e-06,
      "loss": 0.0034,
      "step": 63600
    },
    {
      "epoch": 4.084317248459959,
      "grad_norm": 0.5744394063949585,
      "learning_rate": 9.157469199178644e-06,
      "loss": 0.0033,
      "step": 63650
    },
    {
      "epoch": 4.087525667351129,
      "grad_norm": 0.3539091944694519,
      "learning_rate": 9.12538501026694e-06,
      "loss": 0.0033,
      "step": 63700
    },
    {
      "epoch": 4.0907340862423,
      "grad_norm": 0.5922630429267883,
      "learning_rate": 9.093300821355236e-06,
      "loss": 0.0033,
      "step": 63750
    },
    {
      "epoch": 4.09394250513347,
      "grad_norm": 0.3597484529018402,
      "learning_rate": 9.061216632443533e-06,
      "loss": 0.0034,
      "step": 63800
    },
    {
      "epoch": 4.097150924024641,
      "grad_norm": 0.14812986552715302,
      "learning_rate": 9.029132443531827e-06,
      "loss": 0.0033,
      "step": 63850
    },
    {
      "epoch": 4.100359342915811,
      "grad_norm": 0.5565234422683716,
      "learning_rate": 8.997048254620123e-06,
      "loss": 0.0033,
      "step": 63900
    },
    {
      "epoch": 4.103567761806982,
      "grad_norm": 2.7188973426818848,
      "learning_rate": 8.96496406570842e-06,
      "loss": 0.0034,
      "step": 63950
    },
    {
      "epoch": 4.1067761806981515,
      "grad_norm": 0.9316067099571228,
      "learning_rate": 8.932879876796716e-06,
      "loss": 0.0034,
      "step": 64000
    },
    {
      "epoch": 4.109984599589322,
      "grad_norm": 0.5303091406822205,
      "learning_rate": 8.90079568788501e-06,
      "loss": 0.0034,
      "step": 64050
    },
    {
      "epoch": 4.113193018480493,
      "grad_norm": 0.4764145612716675,
      "learning_rate": 8.868711498973306e-06,
      "loss": 0.0033,
      "step": 64100
    },
    {
      "epoch": 4.116401437371663,
      "grad_norm": 1.6230605840682983,
      "learning_rate": 8.836627310061601e-06,
      "loss": 0.0033,
      "step": 64150
    },
    {
      "epoch": 4.119609856262834,
      "grad_norm": 0.5009334087371826,
      "learning_rate": 8.804543121149899e-06,
      "loss": 0.0033,
      "step": 64200
    },
    {
      "epoch": 4.122818275154004,
      "grad_norm": 0.7511565685272217,
      "learning_rate": 8.772458932238193e-06,
      "loss": 0.0034,
      "step": 64250
    },
    {
      "epoch": 4.126026694045175,
      "grad_norm": 0.6009323596954346,
      "learning_rate": 8.74037474332649e-06,
      "loss": 0.0034,
      "step": 64300
    },
    {
      "epoch": 4.129235112936345,
      "grad_norm": 0.23398582637310028,
      "learning_rate": 8.708290554414784e-06,
      "loss": 0.0033,
      "step": 64350
    },
    {
      "epoch": 4.132443531827516,
      "grad_norm": 0.3883340060710907,
      "learning_rate": 8.676206365503082e-06,
      "loss": 0.0034,
      "step": 64400
    },
    {
      "epoch": 4.135651950718686,
      "grad_norm": 0.7557648420333862,
      "learning_rate": 8.644122176591376e-06,
      "loss": 0.0033,
      "step": 64450
    },
    {
      "epoch": 4.138860369609857,
      "grad_norm": 0.29719996452331543,
      "learning_rate": 8.612037987679673e-06,
      "loss": 0.0034,
      "step": 64500
    },
    {
      "epoch": 4.142068788501026,
      "grad_norm": 0.11908989399671555,
      "learning_rate": 8.579953798767967e-06,
      "loss": 0.0034,
      "step": 64550
    },
    {
      "epoch": 4.145277207392197,
      "grad_norm": 0.14332452416419983,
      "learning_rate": 8.547869609856263e-06,
      "loss": 0.0033,
      "step": 64600
    },
    {
      "epoch": 4.148485626283367,
      "grad_norm": 0.16732528805732727,
      "learning_rate": 8.51578542094456e-06,
      "loss": 0.0033,
      "step": 64650
    },
    {
      "epoch": 4.151694045174538,
      "grad_norm": 0.32273009419441223,
      "learning_rate": 8.483701232032856e-06,
      "loss": 0.0033,
      "step": 64700
    },
    {
      "epoch": 4.154902464065708,
      "grad_norm": 0.5089094042778015,
      "learning_rate": 8.45161704312115e-06,
      "loss": 0.0034,
      "step": 64750
    },
    {
      "epoch": 4.158110882956879,
      "grad_norm": 0.4279218316078186,
      "learning_rate": 8.419532854209446e-06,
      "loss": 0.0033,
      "step": 64800
    },
    {
      "epoch": 4.161319301848049,
      "grad_norm": 0.8241550922393799,
      "learning_rate": 8.38744866529774e-06,
      "loss": 0.0033,
      "step": 64850
    },
    {
      "epoch": 4.16452772073922,
      "grad_norm": 1.1497387886047363,
      "learning_rate": 8.355364476386039e-06,
      "loss": 0.0033,
      "step": 64900
    },
    {
      "epoch": 4.1677361396303905,
      "grad_norm": 1.9427762031555176,
      "learning_rate": 8.323280287474333e-06,
      "loss": 0.0033,
      "step": 64950
    },
    {
      "epoch": 4.170944558521561,
      "grad_norm": 0.08996178954839706,
      "learning_rate": 8.29119609856263e-06,
      "loss": 0.0033,
      "step": 65000
    },
    {
      "epoch": 4.174152977412731,
      "grad_norm": 0.9532421827316284,
      "learning_rate": 8.259111909650924e-06,
      "loss": 0.0033,
      "step": 65050
    },
    {
      "epoch": 4.177361396303901,
      "grad_norm": 0.18700629472732544,
      "learning_rate": 8.22702772073922e-06,
      "loss": 0.0033,
      "step": 65100
    },
    {
      "epoch": 4.180569815195072,
      "grad_norm": 0.3481604754924774,
      "learning_rate": 8.194943531827516e-06,
      "loss": 0.0033,
      "step": 65150
    },
    {
      "epoch": 4.183778234086242,
      "grad_norm": 1.7115137577056885,
      "learning_rate": 8.16285934291581e-06,
      "loss": 0.0034,
      "step": 65200
    },
    {
      "epoch": 4.186986652977413,
      "grad_norm": 0.4285071790218353,
      "learning_rate": 8.130775154004107e-06,
      "loss": 0.0034,
      "step": 65250
    },
    {
      "epoch": 4.190195071868583,
      "grad_norm": 0.47298574447631836,
      "learning_rate": 8.098690965092403e-06,
      "loss": 0.0033,
      "step": 65300
    },
    {
      "epoch": 4.193403490759754,
      "grad_norm": 0.7407085299491882,
      "learning_rate": 8.0666067761807e-06,
      "loss": 0.0033,
      "step": 65350
    },
    {
      "epoch": 4.196611909650924,
      "grad_norm": 1.5308820009231567,
      "learning_rate": 8.034522587268994e-06,
      "loss": 0.0033,
      "step": 65400
    },
    {
      "epoch": 4.199820328542095,
      "grad_norm": 0.45561105012893677,
      "learning_rate": 8.00243839835729e-06,
      "loss": 0.0033,
      "step": 65450
    },
    {
      "epoch": 4.203028747433265,
      "grad_norm": 0.2730771005153656,
      "learning_rate": 7.970354209445584e-06,
      "loss": 0.0034,
      "step": 65500
    },
    {
      "epoch": 4.206237166324435,
      "grad_norm": 0.5289994478225708,
      "learning_rate": 7.938270020533882e-06,
      "loss": 0.0033,
      "step": 65550
    },
    {
      "epoch": 4.209445585215605,
      "grad_norm": 0.43031060695648193,
      "learning_rate": 7.906185831622177e-06,
      "loss": 0.0033,
      "step": 65600
    },
    {
      "epoch": 4.212654004106776,
      "grad_norm": 0.1784953474998474,
      "learning_rate": 7.874101642710473e-06,
      "loss": 0.0033,
      "step": 65650
    },
    {
      "epoch": 4.2158624229979464,
      "grad_norm": 2.092211961746216,
      "learning_rate": 7.842017453798767e-06,
      "loss": 0.0033,
      "step": 65700
    },
    {
      "epoch": 4.219070841889117,
      "grad_norm": 0.6395919919013977,
      "learning_rate": 7.809933264887064e-06,
      "loss": 0.0035,
      "step": 65750
    },
    {
      "epoch": 4.2222792607802875,
      "grad_norm": 0.31924664974212646,
      "learning_rate": 7.77784907597536e-06,
      "loss": 0.0033,
      "step": 65800
    },
    {
      "epoch": 4.225487679671458,
      "grad_norm": 0.9670960903167725,
      "learning_rate": 7.745764887063656e-06,
      "loss": 0.0033,
      "step": 65850
    },
    {
      "epoch": 4.2286960985626285,
      "grad_norm": 0.08600787818431854,
      "learning_rate": 7.71368069815195e-06,
      "loss": 0.0033,
      "step": 65900
    },
    {
      "epoch": 4.231904517453799,
      "grad_norm": 2.4631550312042236,
      "learning_rate": 7.681596509240247e-06,
      "loss": 0.0033,
      "step": 65950
    },
    {
      "epoch": 4.2351129363449695,
      "grad_norm": 0.06692364066839218,
      "learning_rate": 7.649512320328541e-06,
      "loss": 0.0033,
      "step": 66000
    },
    {
      "epoch": 4.23832135523614,
      "grad_norm": 0.5077640414237976,
      "learning_rate": 7.617428131416838e-06,
      "loss": 0.0034,
      "step": 66050
    },
    {
      "epoch": 4.24152977412731,
      "grad_norm": 0.7151884436607361,
      "learning_rate": 7.585343942505134e-06,
      "loss": 0.0034,
      "step": 66100
    },
    {
      "epoch": 4.24473819301848,
      "grad_norm": 0.6006274819374084,
      "learning_rate": 7.55325975359343e-06,
      "loss": 0.0033,
      "step": 66150
    },
    {
      "epoch": 4.247946611909651,
      "grad_norm": 0.36916032433509827,
      "learning_rate": 7.521175564681725e-06,
      "loss": 0.0033,
      "step": 66200
    },
    {
      "epoch": 4.251155030800821,
      "grad_norm": 0.11118769645690918,
      "learning_rate": 7.489091375770021e-06,
      "loss": 0.0033,
      "step": 66250
    },
    {
      "epoch": 4.254363449691992,
      "grad_norm": 0.1366693675518036,
      "learning_rate": 7.457007186858317e-06,
      "loss": 0.0033,
      "step": 66300
    },
    {
      "epoch": 4.257571868583162,
      "grad_norm": 0.3407880365848541,
      "learning_rate": 7.424922997946612e-06,
      "loss": 0.0033,
      "step": 66350
    },
    {
      "epoch": 4.260780287474333,
      "grad_norm": 0.2523617446422577,
      "learning_rate": 7.392838809034907e-06,
      "loss": 0.0033,
      "step": 66400
    },
    {
      "epoch": 4.263988706365503,
      "grad_norm": 1.0856279134750366,
      "learning_rate": 7.360754620123203e-06,
      "loss": 0.0033,
      "step": 66450
    },
    {
      "epoch": 4.267197125256674,
      "grad_norm": 0.2447688728570938,
      "learning_rate": 7.3286704312115e-06,
      "loss": 0.0033,
      "step": 66500
    },
    {
      "epoch": 4.270405544147844,
      "grad_norm": 0.42910465598106384,
      "learning_rate": 7.296586242299795e-06,
      "loss": 0.0033,
      "step": 66550
    },
    {
      "epoch": 4.273613963039014,
      "grad_norm": 0.5941967964172363,
      "learning_rate": 7.26450205338809e-06,
      "loss": 0.0033,
      "step": 66600
    },
    {
      "epoch": 4.2768223819301845,
      "grad_norm": 0.300192654132843,
      "learning_rate": 7.232417864476386e-06,
      "loss": 0.0034,
      "step": 66650
    },
    {
      "epoch": 4.280030800821355,
      "grad_norm": 0.22245897352695465,
      "learning_rate": 7.200333675564683e-06,
      "loss": 0.0034,
      "step": 66700
    },
    {
      "epoch": 4.2832392197125255,
      "grad_norm": 0.4392184615135193,
      "learning_rate": 7.168249486652978e-06,
      "loss": 0.0033,
      "step": 66750
    },
    {
      "epoch": 4.286447638603696,
      "grad_norm": 0.25190213322639465,
      "learning_rate": 7.1361652977412734e-06,
      "loss": 0.0034,
      "step": 66800
    },
    {
      "epoch": 4.289656057494867,
      "grad_norm": 0.404318243265152,
      "learning_rate": 7.104081108829569e-06,
      "loss": 0.0033,
      "step": 66850
    },
    {
      "epoch": 4.292864476386037,
      "grad_norm": 0.8136270642280579,
      "learning_rate": 7.071996919917864e-06,
      "loss": 0.0034,
      "step": 66900
    },
    {
      "epoch": 4.296072895277208,
      "grad_norm": 0.24659991264343262,
      "learning_rate": 7.039912731006161e-06,
      "loss": 0.0034,
      "step": 66950
    },
    {
      "epoch": 4.299281314168378,
      "grad_norm": 0.7338709235191345,
      "learning_rate": 7.0078285420944565e-06,
      "loss": 0.0032,
      "step": 67000
    },
    {
      "epoch": 4.302489733059549,
      "grad_norm": 1.1678876876831055,
      "learning_rate": 6.975744353182752e-06,
      "loss": 0.0033,
      "step": 67050
    },
    {
      "epoch": 4.305698151950718,
      "grad_norm": 2.720041275024414,
      "learning_rate": 6.943660164271047e-06,
      "loss": 0.0033,
      "step": 67100
    },
    {
      "epoch": 4.308906570841889,
      "grad_norm": 0.10048414021730423,
      "learning_rate": 6.9115759753593425e-06,
      "loss": 0.0033,
      "step": 67150
    },
    {
      "epoch": 4.312114989733059,
      "grad_norm": 3.672335147857666,
      "learning_rate": 6.8794917864476396e-06,
      "loss": 0.0033,
      "step": 67200
    },
    {
      "epoch": 4.31532340862423,
      "grad_norm": 2.435025930404663,
      "learning_rate": 6.847407597535935e-06,
      "loss": 0.0033,
      "step": 67250
    },
    {
      "epoch": 4.3185318275154,
      "grad_norm": 0.46165037155151367,
      "learning_rate": 6.81532340862423e-06,
      "loss": 0.0033,
      "step": 67300
    },
    {
      "epoch": 4.321740246406571,
      "grad_norm": 0.4827786684036255,
      "learning_rate": 6.783239219712526e-06,
      "loss": 0.0033,
      "step": 67350
    },
    {
      "epoch": 4.324948665297741,
      "grad_norm": 2.760129690170288,
      "learning_rate": 6.751155030800823e-06,
      "loss": 0.0033,
      "step": 67400
    },
    {
      "epoch": 4.328157084188912,
      "grad_norm": 1.5523130893707275,
      "learning_rate": 6.719070841889118e-06,
      "loss": 0.0034,
      "step": 67450
    },
    {
      "epoch": 4.331365503080082,
      "grad_norm": 0.28668755292892456,
      "learning_rate": 6.686986652977413e-06,
      "loss": 0.0033,
      "step": 67500
    },
    {
      "epoch": 4.334573921971253,
      "grad_norm": 0.9635302424430847,
      "learning_rate": 6.654902464065709e-06,
      "loss": 0.0033,
      "step": 67550
    },
    {
      "epoch": 4.337782340862423,
      "grad_norm": 0.835024893283844,
      "learning_rate": 6.622818275154004e-06,
      "loss": 0.0032,
      "step": 67600
    },
    {
      "epoch": 4.340990759753593,
      "grad_norm": 1.248194694519043,
      "learning_rate": 6.590734086242301e-06,
      "loss": 0.0033,
      "step": 67650
    },
    {
      "epoch": 4.344199178644764,
      "grad_norm": 0.24806925654411316,
      "learning_rate": 6.558649897330596e-06,
      "loss": 0.0034,
      "step": 67700
    },
    {
      "epoch": 4.347407597535934,
      "grad_norm": 0.5127958655357361,
      "learning_rate": 6.526565708418892e-06,
      "loss": 0.0033,
      "step": 67750
    },
    {
      "epoch": 4.350616016427105,
      "grad_norm": 1.0832148790359497,
      "learning_rate": 6.494481519507187e-06,
      "loss": 0.0033,
      "step": 67800
    },
    {
      "epoch": 4.353824435318275,
      "grad_norm": 0.12687388062477112,
      "learning_rate": 6.462397330595483e-06,
      "loss": 0.0033,
      "step": 67850
    },
    {
      "epoch": 4.357032854209446,
      "grad_norm": 0.05386737361550331,
      "learning_rate": 6.4303131416837786e-06,
      "loss": 0.0033,
      "step": 67900
    },
    {
      "epoch": 4.360241273100616,
      "grad_norm": 0.365875244140625,
      "learning_rate": 6.398228952772074e-06,
      "loss": 0.0033,
      "step": 67950
    },
    {
      "epoch": 4.363449691991787,
      "grad_norm": 0.08728711307048798,
      "learning_rate": 6.36614476386037e-06,
      "loss": 0.0033,
      "step": 68000
    },
    {
      "epoch": 4.366658110882957,
      "grad_norm": 1.209925651550293,
      "learning_rate": 6.3340605749486654e-06,
      "loss": 0.0033,
      "step": 68050
    },
    {
      "epoch": 4.369866529774128,
      "grad_norm": 0.13052116334438324,
      "learning_rate": 6.301976386036962e-06,
      "loss": 0.0033,
      "step": 68100
    },
    {
      "epoch": 4.373074948665297,
      "grad_norm": 0.253196656703949,
      "learning_rate": 6.269892197125257e-06,
      "loss": 0.0033,
      "step": 68150
    },
    {
      "epoch": 4.376283367556468,
      "grad_norm": 1.635929822921753,
      "learning_rate": 6.237808008213552e-06,
      "loss": 0.0033,
      "step": 68200
    },
    {
      "epoch": 4.379491786447638,
      "grad_norm": 0.6289747953414917,
      "learning_rate": 6.2057238193018485e-06,
      "loss": 0.0033,
      "step": 68250
    },
    {
      "epoch": 4.382700205338809,
      "grad_norm": 0.6106948256492615,
      "learning_rate": 6.173639630390144e-06,
      "loss": 0.0033,
      "step": 68300
    },
    {
      "epoch": 4.385908624229979,
      "grad_norm": 0.3718414604663849,
      "learning_rate": 6.141555441478439e-06,
      "loss": 0.0034,
      "step": 68350
    },
    {
      "epoch": 4.38911704312115,
      "grad_norm": 0.670978307723999,
      "learning_rate": 6.109471252566735e-06,
      "loss": 0.0033,
      "step": 68400
    },
    {
      "epoch": 4.39232546201232,
      "grad_norm": 0.5146058797836304,
      "learning_rate": 6.077387063655031e-06,
      "loss": 0.0032,
      "step": 68450
    },
    {
      "epoch": 4.395533880903491,
      "grad_norm": 2.3699183464050293,
      "learning_rate": 6.045302874743327e-06,
      "loss": 0.0033,
      "step": 68500
    },
    {
      "epoch": 4.3987422997946615,
      "grad_norm": 0.4805558919906616,
      "learning_rate": 6.013218685831622e-06,
      "loss": 0.0034,
      "step": 68550
    },
    {
      "epoch": 4.401950718685832,
      "grad_norm": 0.2414451688528061,
      "learning_rate": 5.9811344969199184e-06,
      "loss": 0.0033,
      "step": 68600
    },
    {
      "epoch": 4.405159137577002,
      "grad_norm": 0.5278611183166504,
      "learning_rate": 5.949050308008214e-06,
      "loss": 0.0033,
      "step": 68650
    },
    {
      "epoch": 4.408367556468172,
      "grad_norm": 0.21943052113056183,
      "learning_rate": 5.916966119096509e-06,
      "loss": 0.0033,
      "step": 68700
    },
    {
      "epoch": 4.411575975359343,
      "grad_norm": 2.9190003871917725,
      "learning_rate": 5.884881930184805e-06,
      "loss": 0.0033,
      "step": 68750
    },
    {
      "epoch": 4.414784394250513,
      "grad_norm": 0.5224994421005249,
      "learning_rate": 5.852797741273101e-06,
      "loss": 0.0033,
      "step": 68800
    },
    {
      "epoch": 4.417992813141684,
      "grad_norm": 0.3872968554496765,
      "learning_rate": 5.820713552361397e-06,
      "loss": 0.0033,
      "step": 68850
    },
    {
      "epoch": 4.421201232032854,
      "grad_norm": 0.6207482814788818,
      "learning_rate": 5.788629363449692e-06,
      "loss": 0.0033,
      "step": 68900
    },
    {
      "epoch": 4.424409650924025,
      "grad_norm": 0.42307472229003906,
      "learning_rate": 5.756545174537988e-06,
      "loss": 0.0033,
      "step": 68950
    },
    {
      "epoch": 4.427618069815195,
      "grad_norm": 0.9643703699111938,
      "learning_rate": 5.724460985626284e-06,
      "loss": 0.0033,
      "step": 69000
    },
    {
      "epoch": 4.430826488706366,
      "grad_norm": 0.054582379758358,
      "learning_rate": 5.692376796714579e-06,
      "loss": 0.0032,
      "step": 69050
    },
    {
      "epoch": 4.434034907597536,
      "grad_norm": 0.49862030148506165,
      "learning_rate": 5.660292607802875e-06,
      "loss": 0.0033,
      "step": 69100
    },
    {
      "epoch": 4.437243326488707,
      "grad_norm": 0.44313010573387146,
      "learning_rate": 5.6282084188911706e-06,
      "loss": 0.0033,
      "step": 69150
    },
    {
      "epoch": 4.440451745379876,
      "grad_norm": 0.7204736471176147,
      "learning_rate": 5.596124229979467e-06,
      "loss": 0.0033,
      "step": 69200
    },
    {
      "epoch": 4.443660164271047,
      "grad_norm": 1.195271611213684,
      "learning_rate": 5.564040041067762e-06,
      "loss": 0.0033,
      "step": 69250
    },
    {
      "epoch": 4.4468685831622174,
      "grad_norm": 0.10584207624197006,
      "learning_rate": 5.531955852156058e-06,
      "loss": 0.0033,
      "step": 69300
    },
    {
      "epoch": 4.450077002053388,
      "grad_norm": 0.22993570566177368,
      "learning_rate": 5.499871663244354e-06,
      "loss": 0.0032,
      "step": 69350
    },
    {
      "epoch": 4.4532854209445585,
      "grad_norm": 0.6434277296066284,
      "learning_rate": 5.46778747433265e-06,
      "loss": 0.0033,
      "step": 69400
    },
    {
      "epoch": 4.456493839835729,
      "grad_norm": 0.913169264793396,
      "learning_rate": 5.435703285420945e-06,
      "loss": 0.0033,
      "step": 69450
    },
    {
      "epoch": 4.4597022587268995,
      "grad_norm": 0.2014862447977066,
      "learning_rate": 5.4036190965092405e-06,
      "loss": 0.0033,
      "step": 69500
    },
    {
      "epoch": 4.46291067761807,
      "grad_norm": 0.4116579592227936,
      "learning_rate": 5.371534907597537e-06,
      "loss": 0.0033,
      "step": 69550
    },
    {
      "epoch": 4.4661190965092405,
      "grad_norm": 0.6694000363349915,
      "learning_rate": 5.339450718685832e-06,
      "loss": 0.0033,
      "step": 69600
    },
    {
      "epoch": 4.469327515400411,
      "grad_norm": 0.5320536494255066,
      "learning_rate": 5.307366529774127e-06,
      "loss": 0.0033,
      "step": 69650
    },
    {
      "epoch": 4.472535934291581,
      "grad_norm": 0.6978477835655212,
      "learning_rate": 5.2752823408624236e-06,
      "loss": 0.0033,
      "step": 69700
    },
    {
      "epoch": 4.475744353182751,
      "grad_norm": 0.469536691904068,
      "learning_rate": 5.243198151950719e-06,
      "loss": 0.0033,
      "step": 69750
    },
    {
      "epoch": 4.478952772073922,
      "grad_norm": 0.858483612537384,
      "learning_rate": 5.211113963039014e-06,
      "loss": 0.0033,
      "step": 69800
    },
    {
      "epoch": 4.482161190965092,
      "grad_norm": 0.9211593270301819,
      "learning_rate": 5.17902977412731e-06,
      "loss": 0.0033,
      "step": 69850
    },
    {
      "epoch": 4.485369609856263,
      "grad_norm": 0.34686341881752014,
      "learning_rate": 5.146945585215606e-06,
      "loss": 0.0033,
      "step": 69900
    },
    {
      "epoch": 4.488578028747433,
      "grad_norm": 0.19663546979427338,
      "learning_rate": 5.114861396303901e-06,
      "loss": 0.0033,
      "step": 69950
    },
    {
      "epoch": 4.491786447638604,
      "grad_norm": 0.7591748833656311,
      "learning_rate": 5.082777207392197e-06,
      "loss": 0.0033,
      "step": 70000
    },
    {
      "epoch": 4.494994866529774,
      "grad_norm": 0.3078452944755554,
      "learning_rate": 5.050693018480493e-06,
      "loss": 0.0033,
      "step": 70050
    },
    {
      "epoch": 4.498203285420945,
      "grad_norm": 2.127758502960205,
      "learning_rate": 5.018608829568789e-06,
      "loss": 0.0033,
      "step": 70100
    },
    {
      "epoch": 4.501411704312115,
      "grad_norm": 0.28091976046562195,
      "learning_rate": 4.986524640657084e-06,
      "loss": 0.0033,
      "step": 70150
    },
    {
      "epoch": 4.504620123203285,
      "grad_norm": 0.08916350454092026,
      "learning_rate": 4.9544404517453795e-06,
      "loss": 0.0033,
      "step": 70200
    },
    {
      "epoch": 4.5078285420944555,
      "grad_norm": 0.8616999983787537,
      "learning_rate": 4.922356262833676e-06,
      "loss": 0.0033,
      "step": 70250
    },
    {
      "epoch": 4.511036960985626,
      "grad_norm": 1.017115592956543,
      "learning_rate": 4.890272073921971e-06,
      "loss": 0.0033,
      "step": 70300
    },
    {
      "epoch": 4.5142453798767965,
      "grad_norm": 0.7722034454345703,
      "learning_rate": 4.858187885010267e-06,
      "loss": 0.0033,
      "step": 70350
    },
    {
      "epoch": 4.517453798767967,
      "grad_norm": 0.5186411738395691,
      "learning_rate": 4.8261036960985626e-06,
      "loss": 0.0033,
      "step": 70400
    },
    {
      "epoch": 4.520662217659138,
      "grad_norm": 0.2415648251771927,
      "learning_rate": 4.794019507186859e-06,
      "loss": 0.0033,
      "step": 70450
    },
    {
      "epoch": 4.523870636550308,
      "grad_norm": 0.3681708872318268,
      "learning_rate": 4.761935318275154e-06,
      "loss": 0.0033,
      "step": 70500
    },
    {
      "epoch": 4.527079055441479,
      "grad_norm": 0.8871569037437439,
      "learning_rate": 4.72985112936345e-06,
      "loss": 0.0032,
      "step": 70550
    },
    {
      "epoch": 4.530287474332649,
      "grad_norm": 2.4334402084350586,
      "learning_rate": 4.697766940451746e-06,
      "loss": 0.0033,
      "step": 70600
    },
    {
      "epoch": 4.53349589322382,
      "grad_norm": 0.4093632400035858,
      "learning_rate": 4.665682751540041e-06,
      "loss": 0.0033,
      "step": 70650
    },
    {
      "epoch": 4.53670431211499,
      "grad_norm": 0.9553887248039246,
      "learning_rate": 4.633598562628337e-06,
      "loss": 0.0033,
      "step": 70700
    },
    {
      "epoch": 4.53991273100616,
      "grad_norm": 0.5117054581642151,
      "learning_rate": 4.6015143737166325e-06,
      "loss": 0.0033,
      "step": 70750
    },
    {
      "epoch": 4.54312114989733,
      "grad_norm": 0.9973759055137634,
      "learning_rate": 4.569430184804929e-06,
      "loss": 0.0033,
      "step": 70800
    },
    {
      "epoch": 4.546329568788501,
      "grad_norm": 1.0284318923950195,
      "learning_rate": 4.537345995893224e-06,
      "loss": 0.0033,
      "step": 70850
    },
    {
      "epoch": 4.549537987679671,
      "grad_norm": 0.4425086975097656,
      "learning_rate": 4.50526180698152e-06,
      "loss": 0.0033,
      "step": 70900
    },
    {
      "epoch": 4.552746406570842,
      "grad_norm": 0.7012813091278076,
      "learning_rate": 4.4731776180698156e-06,
      "loss": 0.0033,
      "step": 70950
    },
    {
      "epoch": 4.555954825462012,
      "grad_norm": 0.3117215633392334,
      "learning_rate": 4.441093429158111e-06,
      "loss": 0.0033,
      "step": 71000
    },
    {
      "epoch": 4.559163244353183,
      "grad_norm": 0.16699138283729553,
      "learning_rate": 4.409009240246407e-06,
      "loss": 0.0034,
      "step": 71050
    },
    {
      "epoch": 4.562371663244353,
      "grad_norm": 0.507073700428009,
      "learning_rate": 4.376925051334702e-06,
      "loss": 0.0033,
      "step": 71100
    },
    {
      "epoch": 4.565580082135524,
      "grad_norm": 0.4274881184101105,
      "learning_rate": 4.344840862422999e-06,
      "loss": 0.0033,
      "step": 71150
    },
    {
      "epoch": 4.568788501026694,
      "grad_norm": 0.5256556272506714,
      "learning_rate": 4.312756673511294e-06,
      "loss": 0.0033,
      "step": 71200
    },
    {
      "epoch": 4.571996919917865,
      "grad_norm": 0.34266772866249084,
      "learning_rate": 4.28067248459959e-06,
      "loss": 0.0033,
      "step": 71250
    },
    {
      "epoch": 4.575205338809035,
      "grad_norm": 0.20275390148162842,
      "learning_rate": 4.2485882956878855e-06,
      "loss": 0.0033,
      "step": 71300
    },
    {
      "epoch": 4.578413757700205,
      "grad_norm": 0.9892776608467102,
      "learning_rate": 4.216504106776181e-06,
      "loss": 0.0033,
      "step": 71350
    },
    {
      "epoch": 4.581622176591376,
      "grad_norm": 0.4125831425189972,
      "learning_rate": 4.184419917864477e-06,
      "loss": 0.0033,
      "step": 71400
    },
    {
      "epoch": 4.584830595482546,
      "grad_norm": 1.1767500638961792,
      "learning_rate": 4.152335728952772e-06,
      "loss": 0.0033,
      "step": 71450
    },
    {
      "epoch": 4.588039014373717,
      "grad_norm": 1.6353129148483276,
      "learning_rate": 4.120251540041068e-06,
      "loss": 0.0033,
      "step": 71500
    },
    {
      "epoch": 4.591247433264887,
      "grad_norm": 0.1552068144083023,
      "learning_rate": 4.088167351129364e-06,
      "loss": 0.0033,
      "step": 71550
    },
    {
      "epoch": 4.594455852156058,
      "grad_norm": 0.8643826246261597,
      "learning_rate": 4.056083162217659e-06,
      "loss": 0.0033,
      "step": 71600
    },
    {
      "epoch": 4.597664271047228,
      "grad_norm": 0.249228835105896,
      "learning_rate": 4.0239989733059546e-06,
      "loss": 0.0033,
      "step": 71650
    },
    {
      "epoch": 4.600872689938399,
      "grad_norm": 0.3966675102710724,
      "learning_rate": 3.991914784394251e-06,
      "loss": 0.0033,
      "step": 71700
    },
    {
      "epoch": 4.604081108829568,
      "grad_norm": 0.7379343509674072,
      "learning_rate": 3.959830595482546e-06,
      "loss": 0.0033,
      "step": 71750
    },
    {
      "epoch": 4.607289527720739,
      "grad_norm": 1.2259210348129272,
      "learning_rate": 3.9277464065708414e-06,
      "loss": 0.0033,
      "step": 71800
    },
    {
      "epoch": 4.610497946611909,
      "grad_norm": 0.3666227161884308,
      "learning_rate": 3.895662217659138e-06,
      "loss": 0.0033,
      "step": 71850
    },
    {
      "epoch": 4.61370636550308,
      "grad_norm": 2.257044792175293,
      "learning_rate": 3.863578028747433e-06,
      "loss": 0.0033,
      "step": 71900
    },
    {
      "epoch": 4.61691478439425,
      "grad_norm": 0.4612762928009033,
      "learning_rate": 3.831493839835729e-06,
      "loss": 0.0033,
      "step": 71950
    },
    {
      "epoch": 4.620123203285421,
      "grad_norm": 1.3491672277450562,
      "learning_rate": 3.799409650924025e-06,
      "loss": 0.0033,
      "step": 72000
    },
    {
      "epoch": 4.623331622176591,
      "grad_norm": 0.4245784878730774,
      "learning_rate": 3.7673254620123207e-06,
      "loss": 0.0033,
      "step": 72050
    },
    {
      "epoch": 4.626540041067762,
      "grad_norm": 0.695128858089447,
      "learning_rate": 3.735241273100616e-06,
      "loss": 0.0033,
      "step": 72100
    },
    {
      "epoch": 4.6297484599589325,
      "grad_norm": 0.44404688477516174,
      "learning_rate": 3.7031570841889114e-06,
      "loss": 0.0033,
      "step": 72150
    },
    {
      "epoch": 4.632956878850103,
      "grad_norm": 1.4833191633224487,
      "learning_rate": 3.6710728952772075e-06,
      "loss": 0.0033,
      "step": 72200
    },
    {
      "epoch": 4.6361652977412735,
      "grad_norm": 0.7658335566520691,
      "learning_rate": 3.638988706365503e-06,
      "loss": 0.0033,
      "step": 72250
    },
    {
      "epoch": 4.639373716632443,
      "grad_norm": 1.0478087663650513,
      "learning_rate": 3.606904517453799e-06,
      "loss": 0.0033,
      "step": 72300
    },
    {
      "epoch": 4.642582135523614,
      "grad_norm": 0.2415173500776291,
      "learning_rate": 3.5748203285420944e-06,
      "loss": 0.0033,
      "step": 72350
    },
    {
      "epoch": 4.645790554414784,
      "grad_norm": 1.0487895011901855,
      "learning_rate": 3.5427361396303906e-06,
      "loss": 0.0032,
      "step": 72400
    },
    {
      "epoch": 4.648998973305955,
      "grad_norm": 0.35754266381263733,
      "learning_rate": 3.510651950718686e-06,
      "loss": 0.0033,
      "step": 72450
    },
    {
      "epoch": 4.652207392197125,
      "grad_norm": 0.1266200989484787,
      "learning_rate": 3.478567761806982e-06,
      "loss": 0.0032,
      "step": 72500
    },
    {
      "epoch": 4.655415811088296,
      "grad_norm": 0.8928900361061096,
      "learning_rate": 3.4464835728952775e-06,
      "loss": 0.0033,
      "step": 72550
    },
    {
      "epoch": 4.658624229979466,
      "grad_norm": 0.2128746658563614,
      "learning_rate": 3.414399383983573e-06,
      "loss": 0.0033,
      "step": 72600
    },
    {
      "epoch": 4.661832648870637,
      "grad_norm": 0.4179367125034332,
      "learning_rate": 3.382315195071869e-06,
      "loss": 0.0033,
      "step": 72650
    },
    {
      "epoch": 4.665041067761807,
      "grad_norm": 0.49015867710113525,
      "learning_rate": 3.3502310061601643e-06,
      "loss": 0.0033,
      "step": 72700
    },
    {
      "epoch": 4.668249486652978,
      "grad_norm": 0.4080524146556854,
      "learning_rate": 3.3181468172484605e-06,
      "loss": 0.0033,
      "step": 72750
    },
    {
      "epoch": 4.671457905544148,
      "grad_norm": 0.1260986626148224,
      "learning_rate": 3.286062628336756e-06,
      "loss": 0.0033,
      "step": 72800
    },
    {
      "epoch": 4.674666324435318,
      "grad_norm": 0.37158483266830444,
      "learning_rate": 3.2539784394250516e-06,
      "loss": 0.0033,
      "step": 72850
    },
    {
      "epoch": 4.6778747433264884,
      "grad_norm": 1.2078808546066284,
      "learning_rate": 3.221894250513347e-06,
      "loss": 0.0032,
      "step": 72900
    },
    {
      "epoch": 4.681083162217659,
      "grad_norm": 0.3347119987010956,
      "learning_rate": 3.1898100616016427e-06,
      "loss": 0.0032,
      "step": 72950
    },
    {
      "epoch": 4.6842915811088295,
      "grad_norm": 0.8645628094673157,
      "learning_rate": 3.1577258726899385e-06,
      "loss": 0.0033,
      "step": 73000
    },
    {
      "epoch": 4.6875,
      "grad_norm": 2.8710062503814697,
      "learning_rate": 3.125641683778234e-06,
      "loss": 0.0032,
      "step": 73050
    },
    {
      "epoch": 4.6907084188911705,
      "grad_norm": 1.4087625741958618,
      "learning_rate": 3.0935574948665296e-06,
      "loss": 0.0033,
      "step": 73100
    },
    {
      "epoch": 4.693916837782341,
      "grad_norm": 0.40588557720184326,
      "learning_rate": 3.0614733059548254e-06,
      "loss": 0.0033,
      "step": 73150
    },
    {
      "epoch": 4.6971252566735116,
      "grad_norm": 0.7152729630470276,
      "learning_rate": 3.029389117043121e-06,
      "loss": 0.0033,
      "step": 73200
    },
    {
      "epoch": 4.700333675564682,
      "grad_norm": 3.5636558532714844,
      "learning_rate": 2.997304928131417e-06,
      "loss": 0.0033,
      "step": 73250
    },
    {
      "epoch": 4.703542094455852,
      "grad_norm": 0.7215332388877869,
      "learning_rate": 2.9652207392197127e-06,
      "loss": 0.0033,
      "step": 73300
    },
    {
      "epoch": 4.706750513347022,
      "grad_norm": 2.147205352783203,
      "learning_rate": 2.9331365503080084e-06,
      "loss": 0.0033,
      "step": 73350
    },
    {
      "epoch": 4.709958932238193,
      "grad_norm": 0.22912771999835968,
      "learning_rate": 2.901052361396304e-06,
      "loss": 0.0033,
      "step": 73400
    },
    {
      "epoch": 4.713167351129363,
      "grad_norm": 1.0496224164962769,
      "learning_rate": 2.8689681724846e-06,
      "loss": 0.0032,
      "step": 73450
    },
    {
      "epoch": 4.716375770020534,
      "grad_norm": 0.9369361400604248,
      "learning_rate": 2.8368839835728953e-06,
      "loss": 0.0032,
      "step": 73500
    },
    {
      "epoch": 4.719584188911704,
      "grad_norm": 1.1836858987808228,
      "learning_rate": 2.804799794661191e-06,
      "loss": 0.0032,
      "step": 73550
    },
    {
      "epoch": 4.722792607802875,
      "grad_norm": 0.08056360483169556,
      "learning_rate": 2.772715605749487e-06,
      "loss": 0.0033,
      "step": 73600
    },
    {
      "epoch": 4.726001026694045,
      "grad_norm": 0.35966789722442627,
      "learning_rate": 2.7406314168377826e-06,
      "loss": 0.0032,
      "step": 73650
    },
    {
      "epoch": 4.729209445585216,
      "grad_norm": 0.12732037901878357,
      "learning_rate": 2.7085472279260784e-06,
      "loss": 0.0033,
      "step": 73700
    },
    {
      "epoch": 4.732417864476386,
      "grad_norm": 0.22865240275859833,
      "learning_rate": 2.6764630390143737e-06,
      "loss": 0.0033,
      "step": 73750
    },
    {
      "epoch": 4.735626283367557,
      "grad_norm": 0.4963943660259247,
      "learning_rate": 2.6443788501026695e-06,
      "loss": 0.0032,
      "step": 73800
    },
    {
      "epoch": 4.7388347022587265,
      "grad_norm": 1.0450721979141235,
      "learning_rate": 2.6122946611909652e-06,
      "loss": 0.0033,
      "step": 73850
    },
    {
      "epoch": 4.742043121149897,
      "grad_norm": 0.6313163042068481,
      "learning_rate": 2.5802104722792606e-06,
      "loss": 0.0033,
      "step": 73900
    },
    {
      "epoch": 4.7452515400410675,
      "grad_norm": 0.5506870150566101,
      "learning_rate": 2.5481262833675563e-06,
      "loss": 0.0033,
      "step": 73950
    },
    {
      "epoch": 4.748459958932238,
      "grad_norm": 0.4966866672039032,
      "learning_rate": 2.516042094455852e-06,
      "loss": 0.0033,
      "step": 74000
    },
    {
      "epoch": 4.751668377823409,
      "grad_norm": 0.16116654872894287,
      "learning_rate": 2.483957905544148e-06,
      "loss": 0.0033,
      "step": 74050
    },
    {
      "epoch": 4.754876796714579,
      "grad_norm": 1.2257554531097412,
      "learning_rate": 2.4518737166324436e-06,
      "loss": 0.0033,
      "step": 74100
    },
    {
      "epoch": 4.75808521560575,
      "grad_norm": 0.9272171258926392,
      "learning_rate": 2.4197895277207394e-06,
      "loss": 0.0033,
      "step": 74150
    },
    {
      "epoch": 4.76129363449692,
      "grad_norm": 1.2097852230072021,
      "learning_rate": 2.387705338809035e-06,
      "loss": 0.0032,
      "step": 74200
    },
    {
      "epoch": 4.764502053388091,
      "grad_norm": 0.8734240531921387,
      "learning_rate": 2.355621149897331e-06,
      "loss": 0.0032,
      "step": 74250
    },
    {
      "epoch": 4.767710472279261,
      "grad_norm": 2.8967015743255615,
      "learning_rate": 2.3235369609856263e-06,
      "loss": 0.0033,
      "step": 74300
    },
    {
      "epoch": 4.770918891170432,
      "grad_norm": 0.833695113658905,
      "learning_rate": 2.291452772073922e-06,
      "loss": 0.0033,
      "step": 74350
    },
    {
      "epoch": 4.774127310061601,
      "grad_norm": 0.580532968044281,
      "learning_rate": 2.259368583162218e-06,
      "loss": 0.0033,
      "step": 74400
    },
    {
      "epoch": 4.777335728952772,
      "grad_norm": 0.14702875912189484,
      "learning_rate": 2.2272843942505136e-06,
      "loss": 0.0033,
      "step": 74450
    },
    {
      "epoch": 4.780544147843942,
      "grad_norm": 2.543276786804199,
      "learning_rate": 2.1952002053388093e-06,
      "loss": 0.0033,
      "step": 74500
    },
    {
      "epoch": 4.783752566735113,
      "grad_norm": 1.849238395690918,
      "learning_rate": 2.163116016427105e-06,
      "loss": 0.0032,
      "step": 74550
    },
    {
      "epoch": 4.786960985626283,
      "grad_norm": 0.7048991918563843,
      "learning_rate": 2.1310318275154004e-06,
      "loss": 0.0033,
      "step": 74600
    },
    {
      "epoch": 4.790169404517454,
      "grad_norm": 0.5736880898475647,
      "learning_rate": 2.098947638603696e-06,
      "loss": 0.0033,
      "step": 74650
    },
    {
      "epoch": 4.793377823408624,
      "grad_norm": 0.16274699568748474,
      "learning_rate": 2.066863449691992e-06,
      "loss": 0.0032,
      "step": 74700
    },
    {
      "epoch": 4.796586242299795,
      "grad_norm": 0.5890797972679138,
      "learning_rate": 2.0347792607802873e-06,
      "loss": 0.0033,
      "step": 74750
    },
    {
      "epoch": 4.799794661190965,
      "grad_norm": 0.545612096786499,
      "learning_rate": 2.002695071868583e-06,
      "loss": 0.0033,
      "step": 74800
    },
    {
      "epoch": 4.803003080082135,
      "grad_norm": 0.47590887546539307,
      "learning_rate": 1.970610882956879e-06,
      "loss": 0.0033,
      "step": 74850
    },
    {
      "epoch": 4.806211498973306,
      "grad_norm": 0.2281808704137802,
      "learning_rate": 1.9385266940451746e-06,
      "loss": 0.0033,
      "step": 74900
    },
    {
      "epoch": 4.809419917864476,
      "grad_norm": 0.23315726220607758,
      "learning_rate": 1.9064425051334704e-06,
      "loss": 0.0033,
      "step": 74950
    },
    {
      "epoch": 4.812628336755647,
      "grad_norm": 0.08853531628847122,
      "learning_rate": 1.8743583162217661e-06,
      "loss": 0.0033,
      "step": 75000
    },
    {
      "epoch": 4.815836755646817,
      "grad_norm": 1.7936124801635742,
      "learning_rate": 1.8422741273100615e-06,
      "loss": 0.0032,
      "step": 75050
    },
    {
      "epoch": 4.819045174537988,
      "grad_norm": 0.938449501991272,
      "learning_rate": 1.8101899383983572e-06,
      "loss": 0.0032,
      "step": 75100
    },
    {
      "epoch": 4.822253593429158,
      "grad_norm": 0.9329490661621094,
      "learning_rate": 1.778105749486653e-06,
      "loss": 0.0033,
      "step": 75150
    },
    {
      "epoch": 4.825462012320329,
      "grad_norm": 0.28174692392349243,
      "learning_rate": 1.7460215605749488e-06,
      "loss": 0.0033,
      "step": 75200
    },
    {
      "epoch": 4.828670431211499,
      "grad_norm": 0.05381006747484207,
      "learning_rate": 1.7139373716632445e-06,
      "loss": 0.0033,
      "step": 75250
    },
    {
      "epoch": 4.83187885010267,
      "grad_norm": 0.7871588468551636,
      "learning_rate": 1.6818531827515403e-06,
      "loss": 0.0033,
      "step": 75300
    },
    {
      "epoch": 4.83508726899384,
      "grad_norm": 0.2968423366546631,
      "learning_rate": 1.6497689938398358e-06,
      "loss": 0.0032,
      "step": 75350
    },
    {
      "epoch": 4.83829568788501,
      "grad_norm": 2.1339175701141357,
      "learning_rate": 1.6176848049281316e-06,
      "loss": 0.0032,
      "step": 75400
    },
    {
      "epoch": 4.84150410677618,
      "grad_norm": 0.5439243912696838,
      "learning_rate": 1.585600616016427e-06,
      "loss": 0.0032,
      "step": 75450
    },
    {
      "epoch": 4.844712525667351,
      "grad_norm": 0.2934853136539459,
      "learning_rate": 1.553516427104723e-06,
      "loss": 0.0033,
      "step": 75500
    },
    {
      "epoch": 4.847920944558521,
      "grad_norm": 0.481445848941803,
      "learning_rate": 1.5214322381930185e-06,
      "loss": 0.0033,
      "step": 75550
    },
    {
      "epoch": 4.851129363449692,
      "grad_norm": 0.4911966025829315,
      "learning_rate": 1.4893480492813142e-06,
      "loss": 0.0033,
      "step": 75600
    },
    {
      "epoch": 4.854337782340862,
      "grad_norm": 0.16832703351974487,
      "learning_rate": 1.45726386036961e-06,
      "loss": 0.0033,
      "step": 75650
    },
    {
      "epoch": 4.857546201232033,
      "grad_norm": 0.5570563077926636,
      "learning_rate": 1.4251796714579058e-06,
      "loss": 0.0033,
      "step": 75700
    },
    {
      "epoch": 4.8607546201232035,
      "grad_norm": 0.4125027656555176,
      "learning_rate": 1.3930954825462013e-06,
      "loss": 0.0033,
      "step": 75750
    },
    {
      "epoch": 4.863963039014374,
      "grad_norm": 0.5817660093307495,
      "learning_rate": 1.3610112936344969e-06,
      "loss": 0.0032,
      "step": 75800
    },
    {
      "epoch": 4.8671714579055445,
      "grad_norm": 3.750339984893799,
      "learning_rate": 1.3289271047227926e-06,
      "loss": 0.0033,
      "step": 75850
    },
    {
      "epoch": 4.870379876796715,
      "grad_norm": 0.5748980641365051,
      "learning_rate": 1.2968429158110882e-06,
      "loss": 0.0033,
      "step": 75900
    },
    {
      "epoch": 4.873588295687885,
      "grad_norm": 1.0433809757232666,
      "learning_rate": 1.264758726899384e-06,
      "loss": 0.0033,
      "step": 75950
    },
    {
      "epoch": 4.876796714579055,
      "grad_norm": 0.8028440475463867,
      "learning_rate": 1.2326745379876797e-06,
      "loss": 0.0033,
      "step": 76000
    },
    {
      "epoch": 4.880005133470226,
      "grad_norm": 0.46021541953086853,
      "learning_rate": 1.2005903490759755e-06,
      "loss": 0.0033,
      "step": 76050
    },
    {
      "epoch": 4.883213552361396,
      "grad_norm": 0.4548143148422241,
      "learning_rate": 1.168506160164271e-06,
      "loss": 0.0032,
      "step": 76100
    },
    {
      "epoch": 4.886421971252567,
      "grad_norm": 1.602670431137085,
      "learning_rate": 1.1364219712525668e-06,
      "loss": 0.0033,
      "step": 76150
    },
    {
      "epoch": 4.889630390143737,
      "grad_norm": 0.4870607256889343,
      "learning_rate": 1.1043377823408626e-06,
      "loss": 0.0033,
      "step": 76200
    },
    {
      "epoch": 4.892838809034908,
      "grad_norm": 0.5331494212150574,
      "learning_rate": 1.0722535934291581e-06,
      "loss": 0.0032,
      "step": 76250
    },
    {
      "epoch": 4.896047227926078,
      "grad_norm": 0.8913092613220215,
      "learning_rate": 1.0401694045174537e-06,
      "loss": 0.0033,
      "step": 76300
    },
    {
      "epoch": 4.899255646817249,
      "grad_norm": 2.350555896759033,
      "learning_rate": 1.0080852156057494e-06,
      "loss": 0.0032,
      "step": 76350
    },
    {
      "epoch": 4.902464065708418,
      "grad_norm": 0.9206303954124451,
      "learning_rate": 9.760010266940452e-07,
      "loss": 0.0033,
      "step": 76400
    },
    {
      "epoch": 4.905672484599589,
      "grad_norm": 0.4085852801799774,
      "learning_rate": 9.43916837782341e-07,
      "loss": 0.0032,
      "step": 76450
    },
    {
      "epoch": 4.9088809034907595,
      "grad_norm": 0.3349953889846802,
      "learning_rate": 9.118326488706365e-07,
      "loss": 0.0033,
      "step": 76500
    },
    {
      "epoch": 4.91208932238193,
      "grad_norm": 0.33176204562187195,
      "learning_rate": 8.797484599589323e-07,
      "loss": 0.0032,
      "step": 76550
    },
    {
      "epoch": 4.9152977412731005,
      "grad_norm": 0.2239229679107666,
      "learning_rate": 8.47664271047228e-07,
      "loss": 0.0032,
      "step": 76600
    },
    {
      "epoch": 4.918506160164271,
      "grad_norm": 0.4675254821777344,
      "learning_rate": 8.155800821355237e-07,
      "loss": 0.0032,
      "step": 76650
    },
    {
      "epoch": 4.9217145790554415,
      "grad_norm": 1.0325565338134766,
      "learning_rate": 7.834958932238193e-07,
      "loss": 0.0033,
      "step": 76700
    },
    {
      "epoch": 4.924922997946612,
      "grad_norm": 1.744050145149231,
      "learning_rate": 7.51411704312115e-07,
      "loss": 0.0033,
      "step": 76750
    },
    {
      "epoch": 4.9281314168377826,
      "grad_norm": 0.18960636854171753,
      "learning_rate": 7.193275154004107e-07,
      "loss": 0.0032,
      "step": 76800
    },
    {
      "epoch": 4.931339835728953,
      "grad_norm": 0.29419541358947754,
      "learning_rate": 6.872433264887064e-07,
      "loss": 0.0033,
      "step": 76850
    },
    {
      "epoch": 4.934548254620124,
      "grad_norm": 1.4852219820022583,
      "learning_rate": 6.551591375770021e-07,
      "loss": 0.0032,
      "step": 76900
    },
    {
      "epoch": 4.937756673511293,
      "grad_norm": 0.3177928626537323,
      "learning_rate": 6.230749486652978e-07,
      "loss": 0.0032,
      "step": 76950
    },
    {
      "epoch": 4.940965092402464,
      "grad_norm": 0.21307139098644257,
      "learning_rate": 5.909907597535935e-07,
      "loss": 0.0032,
      "step": 77000
    },
    {
      "epoch": 4.944173511293634,
      "grad_norm": 0.853519856929779,
      "learning_rate": 5.589065708418891e-07,
      "loss": 0.0033,
      "step": 77050
    },
    {
      "epoch": 4.947381930184805,
      "grad_norm": 0.8633171319961548,
      "learning_rate": 5.268223819301849e-07,
      "loss": 0.0032,
      "step": 77100
    },
    {
      "epoch": 4.950590349075975,
      "grad_norm": 0.8419379591941833,
      "learning_rate": 4.947381930184805e-07,
      "loss": 0.0033,
      "step": 77150
    },
    {
      "epoch": 4.953798767967146,
      "grad_norm": 0.1783541738986969,
      "learning_rate": 4.6265400410677623e-07,
      "loss": 0.0032,
      "step": 77200
    },
    {
      "epoch": 4.957007186858316,
      "grad_norm": 0.30667614936828613,
      "learning_rate": 4.305698151950719e-07,
      "loss": 0.0033,
      "step": 77250
    },
    {
      "epoch": 4.960215605749487,
      "grad_norm": 0.3969564735889435,
      "learning_rate": 3.984856262833676e-07,
      "loss": 0.0033,
      "step": 77300
    },
    {
      "epoch": 4.963424024640657,
      "grad_norm": 1.0044101476669312,
      "learning_rate": 3.6640143737166326e-07,
      "loss": 0.0033,
      "step": 77350
    },
    {
      "epoch": 4.966632443531828,
      "grad_norm": 0.09692985564470291,
      "learning_rate": 3.3431724845995897e-07,
      "loss": 0.0032,
      "step": 77400
    },
    {
      "epoch": 4.969840862422998,
      "grad_norm": 0.6437609791755676,
      "learning_rate": 3.0223305954825463e-07,
      "loss": 0.0032,
      "step": 77450
    },
    {
      "epoch": 4.973049281314168,
      "grad_norm": 0.874670147895813,
      "learning_rate": 2.7014887063655034e-07,
      "loss": 0.0032,
      "step": 77500
    },
    {
      "epoch": 4.9762577002053385,
      "grad_norm": 0.1665516495704651,
      "learning_rate": 2.3806468172484602e-07,
      "loss": 0.0032,
      "step": 77550
    },
    {
      "epoch": 4.979466119096509,
      "grad_norm": 0.39521297812461853,
      "learning_rate": 2.059804928131417e-07,
      "loss": 0.0032,
      "step": 77600
    },
    {
      "epoch": 4.98267453798768,
      "grad_norm": 0.4265356957912445,
      "learning_rate": 1.738963039014374e-07,
      "loss": 0.0033,
      "step": 77650
    },
    {
      "epoch": 4.98588295687885,
      "grad_norm": 0.20281408727169037,
      "learning_rate": 1.4181211498973305e-07,
      "loss": 0.0032,
      "step": 77700
    },
    {
      "epoch": 4.989091375770021,
      "grad_norm": 0.5056915283203125,
      "learning_rate": 1.0972792607802874e-07,
      "loss": 0.0033,
      "step": 77750
    },
    {
      "epoch": 4.992299794661191,
      "grad_norm": 0.17012549936771393,
      "learning_rate": 7.764373716632444e-08,
      "loss": 0.0032,
      "step": 77800
    },
    {
      "epoch": 4.995508213552362,
      "grad_norm": 0.26766201853752136,
      "learning_rate": 4.555954825462012e-08,
      "loss": 0.0032,
      "step": 77850
    },
    {
      "epoch": 4.998716632443532,
      "grad_norm": 0.8174044489860535,
      "learning_rate": 1.3475359342915813e-08,
      "loss": 0.0032,
      "step": 77900
    }
  ],
  "logging_steps": 50,
  "max_steps": 77920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
