{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.97690234826126,
  "eval_steps": 500,
  "global_step": 155500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032080071859360965,
      "grad_norm": 2.7874526977539062,
      "learning_rate": 0.0004998428076478891,
      "loss": 0.0957,
      "step": 50
    },
    {
      "epoch": 0.006416014371872193,
      "grad_norm": 1.1609188318252563,
      "learning_rate": 0.0004996824072885923,
      "loss": 0.0154,
      "step": 100
    },
    {
      "epoch": 0.009624021557808289,
      "grad_norm": 0.37361574172973633,
      "learning_rate": 0.0004995220069292955,
      "loss": 0.0031,
      "step": 150
    },
    {
      "epoch": 0.012832028743744386,
      "grad_norm": 0.11159341782331467,
      "learning_rate": 0.0004993616065699987,
      "loss": 0.0009,
      "step": 200
    },
    {
      "epoch": 0.016040035929680483,
      "grad_norm": 0.13370740413665771,
      "learning_rate": 0.000499201206210702,
      "loss": 0.0007,
      "step": 250
    },
    {
      "epoch": 0.019248043115616578,
      "grad_norm": 0.1697465181350708,
      "learning_rate": 0.0004990408058514051,
      "loss": 0.0006,
      "step": 300
    },
    {
      "epoch": 0.022456050301552677,
      "grad_norm": 0.07021225988864899,
      "learning_rate": 0.0004988804054921084,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.025664057487488772,
      "grad_norm": 0.22134844958782196,
      "learning_rate": 0.0004987200051328115,
      "loss": 0.0007,
      "step": 400
    },
    {
      "epoch": 0.028872064673424867,
      "grad_norm": 0.12399349361658096,
      "learning_rate": 0.0004985596047735147,
      "loss": 0.0006,
      "step": 450
    },
    {
      "epoch": 0.032080071859360966,
      "grad_norm": 0.03362179920077324,
      "learning_rate": 0.0004983992044142179,
      "loss": 0.0006,
      "step": 500
    },
    {
      "epoch": 0.035288079045297065,
      "grad_norm": 0.34633997082710266,
      "learning_rate": 0.0004982388040549211,
      "loss": 0.0006,
      "step": 550
    },
    {
      "epoch": 0.038496086231233156,
      "grad_norm": 0.22066164016723633,
      "learning_rate": 0.0004980784036956243,
      "loss": 0.0004,
      "step": 600
    },
    {
      "epoch": 0.041704093417169255,
      "grad_norm": 0.23141556978225708,
      "learning_rate": 0.0004979180033363275,
      "loss": 0.0007,
      "step": 650
    },
    {
      "epoch": 0.044912100603105354,
      "grad_norm": 0.13089635968208313,
      "learning_rate": 0.0004977576029770306,
      "loss": 0.0005,
      "step": 700
    },
    {
      "epoch": 0.048120107789041446,
      "grad_norm": 0.08525769412517548,
      "learning_rate": 0.0004975972026177339,
      "loss": 0.0004,
      "step": 750
    },
    {
      "epoch": 0.051328114974977544,
      "grad_norm": 0.1455956995487213,
      "learning_rate": 0.0004974368022584371,
      "loss": 0.0004,
      "step": 800
    },
    {
      "epoch": 0.05453612216091364,
      "grad_norm": 0.04650497809052467,
      "learning_rate": 0.0004972764018991402,
      "loss": 0.0004,
      "step": 850
    },
    {
      "epoch": 0.057744129346849735,
      "grad_norm": 0.066243976354599,
      "learning_rate": 0.0004971160015398435,
      "loss": 0.0006,
      "step": 900
    },
    {
      "epoch": 0.06095213653278583,
      "grad_norm": 0.1104879230260849,
      "learning_rate": 0.0004969556011805466,
      "loss": 0.0005,
      "step": 950
    },
    {
      "epoch": 0.06416014371872193,
      "grad_norm": 0.01483255997300148,
      "learning_rate": 0.0004967952008212499,
      "loss": 0.0004,
      "step": 1000
    },
    {
      "epoch": 0.06736815090465803,
      "grad_norm": 0.04422774538397789,
      "learning_rate": 0.000496634800461953,
      "loss": 0.0003,
      "step": 1050
    },
    {
      "epoch": 0.07057615809059413,
      "grad_norm": 0.0676034614443779,
      "learning_rate": 0.0004964744001026563,
      "loss": 0.0004,
      "step": 1100
    },
    {
      "epoch": 0.07378416527653021,
      "grad_norm": 0.08748050779104233,
      "learning_rate": 0.0004963139997433595,
      "loss": 0.0004,
      "step": 1150
    },
    {
      "epoch": 0.07699217246246631,
      "grad_norm": 0.027702702209353447,
      "learning_rate": 0.0004961535993840626,
      "loss": 0.0003,
      "step": 1200
    },
    {
      "epoch": 0.08020017964840241,
      "grad_norm": 0.4254811108112335,
      "learning_rate": 0.0004959931990247658,
      "loss": 0.0004,
      "step": 1250
    },
    {
      "epoch": 0.08340818683433851,
      "grad_norm": 0.0075369952246546745,
      "learning_rate": 0.000495832798665469,
      "loss": 0.0004,
      "step": 1300
    },
    {
      "epoch": 0.08661619402027461,
      "grad_norm": 0.09899734705686569,
      "learning_rate": 0.0004956723983061722,
      "loss": 0.0004,
      "step": 1350
    },
    {
      "epoch": 0.08982420120621071,
      "grad_norm": 0.04064398631453514,
      "learning_rate": 0.0004955119979468754,
      "loss": 0.0003,
      "step": 1400
    },
    {
      "epoch": 0.09303220839214679,
      "grad_norm": 0.12426898628473282,
      "learning_rate": 0.0004953515975875786,
      "loss": 0.0002,
      "step": 1450
    },
    {
      "epoch": 0.09624021557808289,
      "grad_norm": 0.06712661683559418,
      "learning_rate": 0.0004951911972282819,
      "loss": 0.0003,
      "step": 1500
    },
    {
      "epoch": 0.09944822276401899,
      "grad_norm": 0.07282934337854385,
      "learning_rate": 0.000495030796868985,
      "loss": 0.0004,
      "step": 1550
    },
    {
      "epoch": 0.10265622994995509,
      "grad_norm": 0.07124921679496765,
      "learning_rate": 0.0004948703965096882,
      "loss": 0.0005,
      "step": 1600
    },
    {
      "epoch": 0.10586423713589119,
      "grad_norm": 0.025600040331482887,
      "learning_rate": 0.0004947099961503913,
      "loss": 0.0002,
      "step": 1650
    },
    {
      "epoch": 0.10907224432182729,
      "grad_norm": 0.22589512169361115,
      "learning_rate": 0.0004945495957910946,
      "loss": 0.0003,
      "step": 1700
    },
    {
      "epoch": 0.11228025150776337,
      "grad_norm": 0.11290105432271957,
      "learning_rate": 0.0004943891954317977,
      "loss": 0.0005,
      "step": 1750
    },
    {
      "epoch": 0.11548825869369947,
      "grad_norm": 0.08855477720499039,
      "learning_rate": 0.000494228795072501,
      "loss": 0.0004,
      "step": 1800
    },
    {
      "epoch": 0.11869626587963557,
      "grad_norm": 0.0391530804336071,
      "learning_rate": 0.0004940683947132042,
      "loss": 0.0003,
      "step": 1850
    },
    {
      "epoch": 0.12190427306557167,
      "grad_norm": 0.11244828999042511,
      "learning_rate": 0.0004939079943539074,
      "loss": 0.0004,
      "step": 1900
    },
    {
      "epoch": 0.12511228025150775,
      "grad_norm": 0.17341136932373047,
      "learning_rate": 0.0004937475939946106,
      "loss": 0.0003,
      "step": 1950
    },
    {
      "epoch": 0.12832028743744386,
      "grad_norm": 0.055141400545835495,
      "learning_rate": 0.0004935871936353137,
      "loss": 0.0002,
      "step": 2000
    },
    {
      "epoch": 0.13152829462337995,
      "grad_norm": 0.045700620859861374,
      "learning_rate": 0.000493426793276017,
      "loss": 0.0003,
      "step": 2050
    },
    {
      "epoch": 0.13473630180931606,
      "grad_norm": 0.1026436984539032,
      "learning_rate": 0.0004932663929167201,
      "loss": 0.0006,
      "step": 2100
    },
    {
      "epoch": 0.13794430899525215,
      "grad_norm": 0.2353973537683487,
      "learning_rate": 0.0004931059925574234,
      "loss": 0.0003,
      "step": 2150
    },
    {
      "epoch": 0.14115231618118826,
      "grad_norm": 0.10376102477312088,
      "learning_rate": 0.0004929455921981265,
      "loss": 0.0003,
      "step": 2200
    },
    {
      "epoch": 0.14436032336712434,
      "grad_norm": 0.10442747175693512,
      "learning_rate": 0.0004927851918388298,
      "loss": 0.0003,
      "step": 2250
    },
    {
      "epoch": 0.14756833055306043,
      "grad_norm": 0.11600814759731293,
      "learning_rate": 0.000492624791479533,
      "loss": 0.0002,
      "step": 2300
    },
    {
      "epoch": 0.15077633773899654,
      "grad_norm": 0.2279071807861328,
      "learning_rate": 0.0004924643911202361,
      "loss": 0.0003,
      "step": 2350
    },
    {
      "epoch": 0.15398434492493263,
      "grad_norm": 0.07598400115966797,
      "learning_rate": 0.0004923039907609393,
      "loss": 0.0002,
      "step": 2400
    },
    {
      "epoch": 0.15719235211086874,
      "grad_norm": 0.06469191610813141,
      "learning_rate": 0.0004921435904016425,
      "loss": 0.0002,
      "step": 2450
    },
    {
      "epoch": 0.16040035929680482,
      "grad_norm": 0.17781855165958405,
      "learning_rate": 0.0004919831900423457,
      "loss": 0.0002,
      "step": 2500
    },
    {
      "epoch": 0.1636083664827409,
      "grad_norm": 0.08926516771316528,
      "learning_rate": 0.0004918227896830489,
      "loss": 0.0003,
      "step": 2550
    },
    {
      "epoch": 0.16681637366867702,
      "grad_norm": 0.03858611360192299,
      "learning_rate": 0.0004916623893237521,
      "loss": 0.0002,
      "step": 2600
    },
    {
      "epoch": 0.1700243808546131,
      "grad_norm": 0.20253996551036835,
      "learning_rate": 0.0004915019889644553,
      "loss": 0.0004,
      "step": 2650
    },
    {
      "epoch": 0.17323238804054922,
      "grad_norm": 0.21309107542037964,
      "learning_rate": 0.0004913415886051585,
      "loss": 0.0004,
      "step": 2700
    },
    {
      "epoch": 0.1764403952264853,
      "grad_norm": 0.05175703391432762,
      "learning_rate": 0.0004911811882458616,
      "loss": 0.0003,
      "step": 2750
    },
    {
      "epoch": 0.17964840241242142,
      "grad_norm": 0.08856209367513657,
      "learning_rate": 0.0004910207878865649,
      "loss": 0.0003,
      "step": 2800
    },
    {
      "epoch": 0.1828564095983575,
      "grad_norm": 0.07088322192430496,
      "learning_rate": 0.0004908603875272681,
      "loss": 0.0002,
      "step": 2850
    },
    {
      "epoch": 0.18606441678429358,
      "grad_norm": 0.02861957997083664,
      "learning_rate": 0.0004906999871679712,
      "loss": 0.0004,
      "step": 2900
    },
    {
      "epoch": 0.1892724239702297,
      "grad_norm": 0.06874095648527145,
      "learning_rate": 0.0004905395868086745,
      "loss": 0.0002,
      "step": 2950
    },
    {
      "epoch": 0.19248043115616578,
      "grad_norm": 0.03585677221417427,
      "learning_rate": 0.0004903791864493776,
      "loss": 0.0004,
      "step": 3000
    },
    {
      "epoch": 0.1956884383421019,
      "grad_norm": 0.059736836701631546,
      "learning_rate": 0.0004902187860900809,
      "loss": 0.0003,
      "step": 3050
    },
    {
      "epoch": 0.19889644552803798,
      "grad_norm": 0.06277687102556229,
      "learning_rate": 0.000490058385730784,
      "loss": 0.0003,
      "step": 3100
    },
    {
      "epoch": 0.2021044527139741,
      "grad_norm": 0.1831575334072113,
      "learning_rate": 0.0004898979853714872,
      "loss": 0.0003,
      "step": 3150
    },
    {
      "epoch": 0.20531245989991018,
      "grad_norm": 0.10698172450065613,
      "learning_rate": 0.0004897375850121905,
      "loss": 0.0002,
      "step": 3200
    },
    {
      "epoch": 0.20852046708584626,
      "grad_norm": 0.03970090299844742,
      "learning_rate": 0.0004895771846528936,
      "loss": 0.0003,
      "step": 3250
    },
    {
      "epoch": 0.21172847427178237,
      "grad_norm": 0.18285074830055237,
      "learning_rate": 0.0004894167842935969,
      "loss": 0.0002,
      "step": 3300
    },
    {
      "epoch": 0.21493648145771846,
      "grad_norm": 0.15009528398513794,
      "learning_rate": 0.0004892563839343,
      "loss": 0.0003,
      "step": 3350
    },
    {
      "epoch": 0.21814448864365457,
      "grad_norm": 0.09251591563224792,
      "learning_rate": 0.0004890959835750033,
      "loss": 0.0003,
      "step": 3400
    },
    {
      "epoch": 0.22135249582959066,
      "grad_norm": 0.081759512424469,
      "learning_rate": 0.0004889355832157064,
      "loss": 0.0002,
      "step": 3450
    },
    {
      "epoch": 0.22456050301552674,
      "grad_norm": 0.0793808102607727,
      "learning_rate": 0.0004887751828564096,
      "loss": 0.0002,
      "step": 3500
    },
    {
      "epoch": 0.22776851020146285,
      "grad_norm": 0.12087945640087128,
      "learning_rate": 0.0004886147824971128,
      "loss": 0.0003,
      "step": 3550
    },
    {
      "epoch": 0.23097651738739894,
      "grad_norm": 0.12528258562088013,
      "learning_rate": 0.000488454382137816,
      "loss": 0.0003,
      "step": 3600
    },
    {
      "epoch": 0.23418452457333505,
      "grad_norm": 0.0870431512594223,
      "learning_rate": 0.0004882939817785192,
      "loss": 0.0002,
      "step": 3650
    },
    {
      "epoch": 0.23739253175927114,
      "grad_norm": 0.10553000122308731,
      "learning_rate": 0.00048813358141922236,
      "loss": 0.0002,
      "step": 3700
    },
    {
      "epoch": 0.24060053894520725,
      "grad_norm": 0.17876166105270386,
      "learning_rate": 0.0004879731810599256,
      "loss": 0.0003,
      "step": 3750
    },
    {
      "epoch": 0.24380854613114333,
      "grad_norm": 0.06151522696018219,
      "learning_rate": 0.0004878127807006288,
      "loss": 0.0002,
      "step": 3800
    },
    {
      "epoch": 0.24701655331707942,
      "grad_norm": 0.018663998693227768,
      "learning_rate": 0.000487652380341332,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 0.2502245605030155,
      "grad_norm": 0.019055506214499474,
      "learning_rate": 0.00048749197998203514,
      "loss": 0.0002,
      "step": 3900
    },
    {
      "epoch": 0.2534325676889516,
      "grad_norm": 0.044522784650325775,
      "learning_rate": 0.0004873315796227384,
      "loss": 0.0002,
      "step": 3950
    },
    {
      "epoch": 0.25664057487488773,
      "grad_norm": 0.16879303753376007,
      "learning_rate": 0.00048717117926344155,
      "loss": 0.0002,
      "step": 4000
    },
    {
      "epoch": 0.25984858206082384,
      "grad_norm": 0.014229247346520424,
      "learning_rate": 0.00048701077890414476,
      "loss": 0.0004,
      "step": 4050
    },
    {
      "epoch": 0.2630565892467599,
      "grad_norm": 0.09862218797206879,
      "learning_rate": 0.0004868503785448479,
      "loss": 0.0003,
      "step": 4100
    },
    {
      "epoch": 0.266264596432696,
      "grad_norm": 0.027032142505049706,
      "learning_rate": 0.00048668997818555117,
      "loss": 0.0002,
      "step": 4150
    },
    {
      "epoch": 0.2694726036186321,
      "grad_norm": 0.10862484574317932,
      "learning_rate": 0.0004865295778262543,
      "loss": 0.0002,
      "step": 4200
    },
    {
      "epoch": 0.2726806108045682,
      "grad_norm": 0.12300305813550949,
      "learning_rate": 0.00048636917746695753,
      "loss": 0.0001,
      "step": 4250
    },
    {
      "epoch": 0.2758886179905043,
      "grad_norm": 0.03173543140292168,
      "learning_rate": 0.0004862087771076607,
      "loss": 0.0002,
      "step": 4300
    },
    {
      "epoch": 0.2790966251764404,
      "grad_norm": 0.11696744710206985,
      "learning_rate": 0.00048604837674836394,
      "loss": 0.0002,
      "step": 4350
    },
    {
      "epoch": 0.2823046323623765,
      "grad_norm": 0.025614984333515167,
      "learning_rate": 0.0004858879763890671,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 0.2855126395483126,
      "grad_norm": 0.016181103885173798,
      "learning_rate": 0.0004857275760297703,
      "loss": 0.0002,
      "step": 4450
    },
    {
      "epoch": 0.2887206467342487,
      "grad_norm": 0.03505270555615425,
      "learning_rate": 0.00048556717567047356,
      "loss": 0.0002,
      "step": 4500
    },
    {
      "epoch": 0.2919286539201848,
      "grad_norm": 0.045672886073589325,
      "learning_rate": 0.0004854067753111767,
      "loss": 0.0002,
      "step": 4550
    },
    {
      "epoch": 0.29513666110612086,
      "grad_norm": 0.01732156053185463,
      "learning_rate": 0.0004852463749518799,
      "loss": 0.0002,
      "step": 4600
    },
    {
      "epoch": 0.29834466829205697,
      "grad_norm": 0.009253589436411858,
      "learning_rate": 0.0004850859745925831,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 0.3015526754779931,
      "grad_norm": 0.12975195050239563,
      "learning_rate": 0.00048492557423328634,
      "loss": 0.0002,
      "step": 4700
    },
    {
      "epoch": 0.3047606826639292,
      "grad_norm": 0.07110650837421417,
      "learning_rate": 0.0004847651738739895,
      "loss": 0.0004,
      "step": 4750
    },
    {
      "epoch": 0.30796868984986525,
      "grad_norm": 0.02337094582617283,
      "learning_rate": 0.0004846047735146927,
      "loss": 0.0002,
      "step": 4800
    },
    {
      "epoch": 0.31117669703580136,
      "grad_norm": 0.10656902939081192,
      "learning_rate": 0.00048444437315539585,
      "loss": 0.0002,
      "step": 4850
    },
    {
      "epoch": 0.3143847042217375,
      "grad_norm": 0.1202077567577362,
      "learning_rate": 0.0004842839727960991,
      "loss": 0.0002,
      "step": 4900
    },
    {
      "epoch": 0.31759271140767353,
      "grad_norm": 0.01342197135090828,
      "learning_rate": 0.00048412357243680226,
      "loss": 0.0001,
      "step": 4950
    },
    {
      "epoch": 0.32080071859360965,
      "grad_norm": 0.026951022446155548,
      "learning_rate": 0.00048396317207750547,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 0.32400872577954576,
      "grad_norm": 0.04507722333073616,
      "learning_rate": 0.0004838027717182086,
      "loss": 0.0002,
      "step": 5050
    },
    {
      "epoch": 0.3272167329654818,
      "grad_norm": 0.02836189605295658,
      "learning_rate": 0.0004836423713589119,
      "loss": 0.0002,
      "step": 5100
    },
    {
      "epoch": 0.33042474015141793,
      "grad_norm": 0.02210119366645813,
      "learning_rate": 0.00048348197099961504,
      "loss": 0.0001,
      "step": 5150
    },
    {
      "epoch": 0.33363274733735404,
      "grad_norm": 0.1108202189207077,
      "learning_rate": 0.00048332157064031824,
      "loss": 0.0001,
      "step": 5200
    },
    {
      "epoch": 0.33684075452329015,
      "grad_norm": 0.022661816328763962,
      "learning_rate": 0.00048316117028102145,
      "loss": 0.0002,
      "step": 5250
    },
    {
      "epoch": 0.3400487617092262,
      "grad_norm": 0.042992204427719116,
      "learning_rate": 0.00048300076992172466,
      "loss": 0.0001,
      "step": 5300
    },
    {
      "epoch": 0.3432567688951623,
      "grad_norm": 0.10341641306877136,
      "learning_rate": 0.0004828403695624278,
      "loss": 0.0001,
      "step": 5350
    },
    {
      "epoch": 0.34646477608109844,
      "grad_norm": 0.07307270914316177,
      "learning_rate": 0.000482679969203131,
      "loss": 0.0002,
      "step": 5400
    },
    {
      "epoch": 0.3496727832670345,
      "grad_norm": 0.05958746746182442,
      "learning_rate": 0.0004825195688438342,
      "loss": 0.0002,
      "step": 5450
    },
    {
      "epoch": 0.3528807904529706,
      "grad_norm": 0.0422019325196743,
      "learning_rate": 0.00048235916848453743,
      "loss": 0.0002,
      "step": 5500
    },
    {
      "epoch": 0.3560887976389067,
      "grad_norm": 0.07537517696619034,
      "learning_rate": 0.0004821987681252406,
      "loss": 0.0001,
      "step": 5550
    },
    {
      "epoch": 0.35929680482484283,
      "grad_norm": 0.04481982812285423,
      "learning_rate": 0.0004820383677659438,
      "loss": 0.0002,
      "step": 5600
    },
    {
      "epoch": 0.3625048120107789,
      "grad_norm": 0.03604774922132492,
      "learning_rate": 0.000481877967406647,
      "loss": 0.0001,
      "step": 5650
    },
    {
      "epoch": 0.365712819196715,
      "grad_norm": 0.07311289757490158,
      "learning_rate": 0.0004817175670473502,
      "loss": 0.0002,
      "step": 5700
    },
    {
      "epoch": 0.3689208263826511,
      "grad_norm": 0.015661366283893585,
      "learning_rate": 0.00048155716668805336,
      "loss": 0.0003,
      "step": 5750
    },
    {
      "epoch": 0.37212883356858717,
      "grad_norm": 0.05592857673764229,
      "learning_rate": 0.00048139676632875657,
      "loss": 0.0001,
      "step": 5800
    },
    {
      "epoch": 0.3753368407545233,
      "grad_norm": 0.11253323405981064,
      "learning_rate": 0.00048123636596945977,
      "loss": 0.0001,
      "step": 5850
    },
    {
      "epoch": 0.3785448479404594,
      "grad_norm": 0.040089040994644165,
      "learning_rate": 0.000481075965610163,
      "loss": 0.0002,
      "step": 5900
    },
    {
      "epoch": 0.3817528551263955,
      "grad_norm": 0.06634669005870819,
      "learning_rate": 0.0004809155652508662,
      "loss": 0.0001,
      "step": 5950
    },
    {
      "epoch": 0.38496086231233156,
      "grad_norm": 0.041995465755462646,
      "learning_rate": 0.00048075516489156934,
      "loss": 0.0001,
      "step": 6000
    },
    {
      "epoch": 0.3881688694982677,
      "grad_norm": 0.0994446650147438,
      "learning_rate": 0.0004805947645322726,
      "loss": 0.0002,
      "step": 6050
    },
    {
      "epoch": 0.3913768766842038,
      "grad_norm": 0.051575955003499985,
      "learning_rate": 0.00048043436417297575,
      "loss": 0.0001,
      "step": 6100
    },
    {
      "epoch": 0.39458488387013985,
      "grad_norm": 0.12402010709047318,
      "learning_rate": 0.00048027396381367896,
      "loss": 0.0002,
      "step": 6150
    },
    {
      "epoch": 0.39779289105607596,
      "grad_norm": 0.028787454590201378,
      "learning_rate": 0.00048011356345438217,
      "loss": 0.0001,
      "step": 6200
    },
    {
      "epoch": 0.40100089824201207,
      "grad_norm": 0.06732513010501862,
      "learning_rate": 0.0004799531630950854,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 0.4042089054279482,
      "grad_norm": 0.09879051893949509,
      "learning_rate": 0.0004797927627357885,
      "loss": 0.0003,
      "step": 6300
    },
    {
      "epoch": 0.40741691261388424,
      "grad_norm": 0.1456693559885025,
      "learning_rate": 0.00047963236237649173,
      "loss": 0.0002,
      "step": 6350
    },
    {
      "epoch": 0.41062491979982035,
      "grad_norm": 0.019603686407208443,
      "learning_rate": 0.00047947196201719494,
      "loss": 0.0002,
      "step": 6400
    },
    {
      "epoch": 0.41383292698575647,
      "grad_norm": 0.01780766434967518,
      "learning_rate": 0.00047931156165789815,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 0.4170409341716925,
      "grad_norm": 0.017461979761719704,
      "learning_rate": 0.0004791511612986013,
      "loss": 0.0001,
      "step": 6500
    },
    {
      "epoch": 0.42024894135762864,
      "grad_norm": 0.040155161172151566,
      "learning_rate": 0.0004789907609393045,
      "loss": 0.0001,
      "step": 6550
    },
    {
      "epoch": 0.42345694854356475,
      "grad_norm": 0.0761139914393425,
      "learning_rate": 0.0004788303605800077,
      "loss": 0.0001,
      "step": 6600
    },
    {
      "epoch": 0.42666495572950086,
      "grad_norm": 0.038520026952028275,
      "learning_rate": 0.0004786699602207109,
      "loss": 0.0001,
      "step": 6650
    },
    {
      "epoch": 0.4298729629154369,
      "grad_norm": 0.044070590287446976,
      "learning_rate": 0.0004785095598614141,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 0.43308097010137303,
      "grad_norm": 0.08201124519109726,
      "learning_rate": 0.0004783491595021173,
      "loss": 0.0001,
      "step": 6750
    },
    {
      "epoch": 0.43628897728730914,
      "grad_norm": 0.031287722289562225,
      "learning_rate": 0.0004781887591428205,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 0.4394969844732452,
      "grad_norm": 0.02403346821665764,
      "learning_rate": 0.0004780283587835237,
      "loss": 0.0001,
      "step": 6850
    },
    {
      "epoch": 0.4427049916591813,
      "grad_norm": 0.011905480176210403,
      "learning_rate": 0.00047786795842422685,
      "loss": 0.0001,
      "step": 6900
    },
    {
      "epoch": 0.4459129988451174,
      "grad_norm": 0.012710465118288994,
      "learning_rate": 0.00047770755806493005,
      "loss": 0.0001,
      "step": 6950
    },
    {
      "epoch": 0.4491210060310535,
      "grad_norm": 0.08204573392868042,
      "learning_rate": 0.00047754715770563326,
      "loss": 0.0002,
      "step": 7000
    },
    {
      "epoch": 0.4523290132169896,
      "grad_norm": 0.04066120460629463,
      "learning_rate": 0.00047738675734633647,
      "loss": 0.0001,
      "step": 7050
    },
    {
      "epoch": 0.4555370204029257,
      "grad_norm": 0.044824231415987015,
      "learning_rate": 0.0004772263569870396,
      "loss": 0.0001,
      "step": 7100
    },
    {
      "epoch": 0.4587450275888618,
      "grad_norm": 0.06973196566104889,
      "learning_rate": 0.0004770659566277429,
      "loss": 0.0001,
      "step": 7150
    },
    {
      "epoch": 0.4619530347747979,
      "grad_norm": 0.018626688048243523,
      "learning_rate": 0.00047690555626844603,
      "loss": 0.0003,
      "step": 7200
    },
    {
      "epoch": 0.465161041960734,
      "grad_norm": 0.015605639666318893,
      "learning_rate": 0.00047674515590914924,
      "loss": 0.0001,
      "step": 7250
    },
    {
      "epoch": 0.4683690491466701,
      "grad_norm": 0.0716555267572403,
      "learning_rate": 0.00047658475554985245,
      "loss": 0.0001,
      "step": 7300
    },
    {
      "epoch": 0.47157705633260616,
      "grad_norm": 0.03268392011523247,
      "learning_rate": 0.00047642435519055566,
      "loss": 0.0001,
      "step": 7350
    },
    {
      "epoch": 0.47478506351854227,
      "grad_norm": 0.019503477960824966,
      "learning_rate": 0.00047626395483125886,
      "loss": 0.0001,
      "step": 7400
    },
    {
      "epoch": 0.4779930707044784,
      "grad_norm": 0.051853831857442856,
      "learning_rate": 0.000476103554471962,
      "loss": 0.0001,
      "step": 7450
    },
    {
      "epoch": 0.4812010778904145,
      "grad_norm": 0.0058986721560359,
      "learning_rate": 0.0004759431541126652,
      "loss": 0.0001,
      "step": 7500
    },
    {
      "epoch": 0.48440908507635055,
      "grad_norm": 0.07578713446855545,
      "learning_rate": 0.00047578275375336843,
      "loss": 0.0002,
      "step": 7550
    },
    {
      "epoch": 0.48761709226228667,
      "grad_norm": 0.050803497433662415,
      "learning_rate": 0.00047562235339407164,
      "loss": 0.0002,
      "step": 7600
    },
    {
      "epoch": 0.4908250994482228,
      "grad_norm": 0.008024051785469055,
      "learning_rate": 0.0004754619530347748,
      "loss": 0.0001,
      "step": 7650
    },
    {
      "epoch": 0.49403310663415884,
      "grad_norm": 0.03001522645354271,
      "learning_rate": 0.000475301552675478,
      "loss": 0.0001,
      "step": 7700
    },
    {
      "epoch": 0.49724111382009495,
      "grad_norm": 0.026085488498210907,
      "learning_rate": 0.0004751411523161812,
      "loss": 0.0001,
      "step": 7750
    },
    {
      "epoch": 0.500449121006031,
      "grad_norm": 0.033960238099098206,
      "learning_rate": 0.0004749807519568844,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 0.5036571281919672,
      "grad_norm": 0.00719981687143445,
      "learning_rate": 0.00047482035159758756,
      "loss": 0.0001,
      "step": 7850
    },
    {
      "epoch": 0.5068651353779032,
      "grad_norm": 0.018845288082957268,
      "learning_rate": 0.0004746599512382908,
      "loss": 0.0001,
      "step": 7900
    },
    {
      "epoch": 0.5100731425638393,
      "grad_norm": 0.01858602650463581,
      "learning_rate": 0.000474499550878994,
      "loss": 0.0001,
      "step": 7950
    },
    {
      "epoch": 0.5132811497497755,
      "grad_norm": 0.10548003762960434,
      "learning_rate": 0.0004743391505196972,
      "loss": 0.0001,
      "step": 8000
    },
    {
      "epoch": 0.5164891569357115,
      "grad_norm": 0.04110144078731537,
      "learning_rate": 0.00047417875016040034,
      "loss": 0.0002,
      "step": 8050
    },
    {
      "epoch": 0.5196971641216477,
      "grad_norm": 0.05657394602894783,
      "learning_rate": 0.0004740183498011036,
      "loss": 0.0001,
      "step": 8100
    },
    {
      "epoch": 0.5229051713075837,
      "grad_norm": 0.0830913707613945,
      "learning_rate": 0.00047385794944180675,
      "loss": 0.0001,
      "step": 8150
    },
    {
      "epoch": 0.5261131784935198,
      "grad_norm": 0.05803103372454643,
      "learning_rate": 0.00047369754908250996,
      "loss": 0.0001,
      "step": 8200
    },
    {
      "epoch": 0.529321185679456,
      "grad_norm": 0.050698645412921906,
      "learning_rate": 0.0004735371487232131,
      "loss": 0.0001,
      "step": 8250
    },
    {
      "epoch": 0.532529192865392,
      "grad_norm": 0.03004155308008194,
      "learning_rate": 0.00047337674836391637,
      "loss": 0.0001,
      "step": 8300
    },
    {
      "epoch": 0.5357372000513281,
      "grad_norm": 0.035960979759693146,
      "learning_rate": 0.0004732163480046195,
      "loss": 0.0001,
      "step": 8350
    },
    {
      "epoch": 0.5389452072372642,
      "grad_norm": 0.06144210696220398,
      "learning_rate": 0.00047305594764532273,
      "loss": 0.0002,
      "step": 8400
    },
    {
      "epoch": 0.5421532144232003,
      "grad_norm": 0.060969918966293335,
      "learning_rate": 0.0004728955472860259,
      "loss": 0.0001,
      "step": 8450
    },
    {
      "epoch": 0.5453612216091364,
      "grad_norm": 0.08491823822259903,
      "learning_rate": 0.00047273514692672914,
      "loss": 0.0001,
      "step": 8500
    },
    {
      "epoch": 0.5485692287950725,
      "grad_norm": 0.041452761739492416,
      "learning_rate": 0.0004725747465674323,
      "loss": 0.0001,
      "step": 8550
    },
    {
      "epoch": 0.5517772359810086,
      "grad_norm": 0.04308638349175453,
      "learning_rate": 0.0004724143462081355,
      "loss": 0.0001,
      "step": 8600
    },
    {
      "epoch": 0.5549852431669446,
      "grad_norm": 0.0489630252122879,
      "learning_rate": 0.0004722539458488387,
      "loss": 0.0001,
      "step": 8650
    },
    {
      "epoch": 0.5581932503528808,
      "grad_norm": 0.0384347029030323,
      "learning_rate": 0.0004720935454895419,
      "loss": 0.0001,
      "step": 8700
    },
    {
      "epoch": 0.5614012575388169,
      "grad_norm": 0.01528926007449627,
      "learning_rate": 0.0004719331451302451,
      "loss": 0.0001,
      "step": 8750
    },
    {
      "epoch": 0.564609264724753,
      "grad_norm": 0.006852911785244942,
      "learning_rate": 0.0004717727447709483,
      "loss": 0.0001,
      "step": 8800
    },
    {
      "epoch": 0.5678172719106891,
      "grad_norm": 0.06359417736530304,
      "learning_rate": 0.00047161234441165154,
      "loss": 0.0001,
      "step": 8850
    },
    {
      "epoch": 0.5710252790966251,
      "grad_norm": 0.046476442366838455,
      "learning_rate": 0.0004714519440523547,
      "loss": 0.0001,
      "step": 8900
    },
    {
      "epoch": 0.5742332862825613,
      "grad_norm": 0.007277050521224737,
      "learning_rate": 0.0004712915436930579,
      "loss": 0.0001,
      "step": 8950
    },
    {
      "epoch": 0.5774412934684974,
      "grad_norm": 0.04925166070461273,
      "learning_rate": 0.00047113114333376105,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 0.5806493006544334,
      "grad_norm": 0.0811963751912117,
      "learning_rate": 0.0004709707429744643,
      "loss": 0.0002,
      "step": 9050
    },
    {
      "epoch": 0.5838573078403696,
      "grad_norm": 0.05782656744122505,
      "learning_rate": 0.00047081034261516747,
      "loss": 0.0002,
      "step": 9100
    },
    {
      "epoch": 0.5870653150263057,
      "grad_norm": 0.048311736434698105,
      "learning_rate": 0.00047064994225587067,
      "loss": 0.0001,
      "step": 9150
    },
    {
      "epoch": 0.5902733222122417,
      "grad_norm": 0.04510015994310379,
      "learning_rate": 0.0004704895418965738,
      "loss": 0.0001,
      "step": 9200
    },
    {
      "epoch": 0.5934813293981779,
      "grad_norm": 0.012286605313420296,
      "learning_rate": 0.0004703291415372771,
      "loss": 0.0001,
      "step": 9250
    },
    {
      "epoch": 0.5966893365841139,
      "grad_norm": 0.027274005115032196,
      "learning_rate": 0.00047016874117798024,
      "loss": 0.0001,
      "step": 9300
    },
    {
      "epoch": 0.59989734377005,
      "grad_norm": 0.05288856476545334,
      "learning_rate": 0.00047000834081868345,
      "loss": 0.0001,
      "step": 9350
    },
    {
      "epoch": 0.6031053509559862,
      "grad_norm": 0.034275297075510025,
      "learning_rate": 0.0004698479404593866,
      "loss": 0.0001,
      "step": 9400
    },
    {
      "epoch": 0.6063133581419222,
      "grad_norm": 0.010829932987689972,
      "learning_rate": 0.00046968754010008986,
      "loss": 0.0002,
      "step": 9450
    },
    {
      "epoch": 0.6095213653278584,
      "grad_norm": 0.032858334481716156,
      "learning_rate": 0.000469527139740793,
      "loss": 0.0001,
      "step": 9500
    },
    {
      "epoch": 0.6127293725137944,
      "grad_norm": 0.06230791285634041,
      "learning_rate": 0.0004693667393814962,
      "loss": 0.0001,
      "step": 9550
    },
    {
      "epoch": 0.6159373796997305,
      "grad_norm": 0.012870530597865582,
      "learning_rate": 0.0004692063390221994,
      "loss": 0.0001,
      "step": 9600
    },
    {
      "epoch": 0.6191453868856667,
      "grad_norm": 0.0210748128592968,
      "learning_rate": 0.00046904593866290263,
      "loss": 0.0001,
      "step": 9650
    },
    {
      "epoch": 0.6223533940716027,
      "grad_norm": 0.04189096391201019,
      "learning_rate": 0.0004688855383036058,
      "loss": 0.0001,
      "step": 9700
    },
    {
      "epoch": 0.6255614012575388,
      "grad_norm": 0.020627614110708237,
      "learning_rate": 0.000468725137944309,
      "loss": 0.0001,
      "step": 9750
    },
    {
      "epoch": 0.628769408443475,
      "grad_norm": 0.023681974038481712,
      "learning_rate": 0.0004685647375850122,
      "loss": 0.0001,
      "step": 9800
    },
    {
      "epoch": 0.631977415629411,
      "grad_norm": 0.07768455147743225,
      "learning_rate": 0.0004684043372257154,
      "loss": 0.0002,
      "step": 9850
    },
    {
      "epoch": 0.6351854228153471,
      "grad_norm": 0.04792577400803566,
      "learning_rate": 0.00046824393686641856,
      "loss": 0.0002,
      "step": 9900
    },
    {
      "epoch": 0.6383934300012832,
      "grad_norm": 0.02434270828962326,
      "learning_rate": 0.00046808353650712177,
      "loss": 0.0001,
      "step": 9950
    },
    {
      "epoch": 0.6416014371872193,
      "grad_norm": 0.052627865225076675,
      "learning_rate": 0.00046792313614782503,
      "loss": 0.0001,
      "step": 10000
    },
    {
      "epoch": 0.6448094443731553,
      "grad_norm": 0.018769219517707825,
      "learning_rate": 0.0004677627357885282,
      "loss": 0.0001,
      "step": 10050
    },
    {
      "epoch": 0.6480174515590915,
      "grad_norm": 0.01703464612364769,
      "learning_rate": 0.0004676023354292314,
      "loss": 0.0001,
      "step": 10100
    },
    {
      "epoch": 0.6512254587450276,
      "grad_norm": 0.030425772070884705,
      "learning_rate": 0.00046744193506993454,
      "loss": 0.0001,
      "step": 10150
    },
    {
      "epoch": 0.6544334659309636,
      "grad_norm": 0.049591924995183945,
      "learning_rate": 0.0004672815347106378,
      "loss": 0.0001,
      "step": 10200
    },
    {
      "epoch": 0.6576414731168998,
      "grad_norm": 0.050755247473716736,
      "learning_rate": 0.00046712113435134095,
      "loss": 0.0001,
      "step": 10250
    },
    {
      "epoch": 0.6608494803028359,
      "grad_norm": 0.04948838800191879,
      "learning_rate": 0.00046696073399204416,
      "loss": 0.0001,
      "step": 10300
    },
    {
      "epoch": 0.664057487488772,
      "grad_norm": 0.036543138325214386,
      "learning_rate": 0.0004668003336327473,
      "loss": 0.0001,
      "step": 10350
    },
    {
      "epoch": 0.6672654946747081,
      "grad_norm": 0.018262775614857674,
      "learning_rate": 0.0004666399332734506,
      "loss": 0.0001,
      "step": 10400
    },
    {
      "epoch": 0.6704735018606441,
      "grad_norm": 0.10048145055770874,
      "learning_rate": 0.00046647953291415373,
      "loss": 0.0001,
      "step": 10450
    },
    {
      "epoch": 0.6736815090465803,
      "grad_norm": 0.06128887087106705,
      "learning_rate": 0.00046631913255485693,
      "loss": 0.0001,
      "step": 10500
    },
    {
      "epoch": 0.6768895162325164,
      "grad_norm": 0.0331755131483078,
      "learning_rate": 0.00046615873219556014,
      "loss": 0.0001,
      "step": 10550
    },
    {
      "epoch": 0.6800975234184524,
      "grad_norm": 0.07030585408210754,
      "learning_rate": 0.00046599833183626335,
      "loss": 0.0001,
      "step": 10600
    },
    {
      "epoch": 0.6833055306043886,
      "grad_norm": 0.04269058257341385,
      "learning_rate": 0.0004658379314769665,
      "loss": 0.0001,
      "step": 10650
    },
    {
      "epoch": 0.6865135377903246,
      "grad_norm": 0.07758226245641708,
      "learning_rate": 0.0004656775311176697,
      "loss": 0.0001,
      "step": 10700
    },
    {
      "epoch": 0.6897215449762607,
      "grad_norm": 0.023304494097828865,
      "learning_rate": 0.0004655171307583729,
      "loss": 0.0001,
      "step": 10750
    },
    {
      "epoch": 0.6929295521621969,
      "grad_norm": 0.008035160601139069,
      "learning_rate": 0.0004653567303990761,
      "loss": 0.0001,
      "step": 10800
    },
    {
      "epoch": 0.6961375593481329,
      "grad_norm": 0.012319782748818398,
      "learning_rate": 0.0004651963300397793,
      "loss": 0.0001,
      "step": 10850
    },
    {
      "epoch": 0.699345566534069,
      "grad_norm": 0.00982111506164074,
      "learning_rate": 0.0004650359296804825,
      "loss": 0.0001,
      "step": 10900
    },
    {
      "epoch": 0.7025535737200052,
      "grad_norm": 0.10636448860168457,
      "learning_rate": 0.0004648755293211857,
      "loss": 0.0001,
      "step": 10950
    },
    {
      "epoch": 0.7057615809059412,
      "grad_norm": 0.062008973211050034,
      "learning_rate": 0.0004647151289618889,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 0.7089695880918774,
      "grad_norm": 0.09562015533447266,
      "learning_rate": 0.00046455472860259205,
      "loss": 0.0001,
      "step": 11050
    },
    {
      "epoch": 0.7121775952778134,
      "grad_norm": 0.030382005497813225,
      "learning_rate": 0.00046439432824329526,
      "loss": 0.0001,
      "step": 11100
    },
    {
      "epoch": 0.7153856024637495,
      "grad_norm": 0.10135436803102493,
      "learning_rate": 0.00046423392788399846,
      "loss": 0.0001,
      "step": 11150
    },
    {
      "epoch": 0.7185936096496857,
      "grad_norm": 0.043116018176078796,
      "learning_rate": 0.00046407352752470167,
      "loss": 0.0001,
      "step": 11200
    },
    {
      "epoch": 0.7218016168356217,
      "grad_norm": 0.03260478004813194,
      "learning_rate": 0.0004639131271654048,
      "loss": 0.0001,
      "step": 11250
    },
    {
      "epoch": 0.7250096240215578,
      "grad_norm": 0.041552409529685974,
      "learning_rate": 0.0004637527268061081,
      "loss": 0.0001,
      "step": 11300
    },
    {
      "epoch": 0.7282176312074939,
      "grad_norm": 0.021123018115758896,
      "learning_rate": 0.0004635923264468113,
      "loss": 0.0001,
      "step": 11350
    },
    {
      "epoch": 0.73142563839343,
      "grad_norm": 0.054353438317775726,
      "learning_rate": 0.00046343192608751444,
      "loss": 0.0001,
      "step": 11400
    },
    {
      "epoch": 0.7346336455793661,
      "grad_norm": 0.018071088939905167,
      "learning_rate": 0.00046327152572821765,
      "loss": 0.0001,
      "step": 11450
    },
    {
      "epoch": 0.7378416527653022,
      "grad_norm": 0.02945489063858986,
      "learning_rate": 0.00046311112536892086,
      "loss": 0.0001,
      "step": 11500
    },
    {
      "epoch": 0.7410496599512383,
      "grad_norm": 0.02973938174545765,
      "learning_rate": 0.00046295072500962406,
      "loss": 0.0001,
      "step": 11550
    },
    {
      "epoch": 0.7442576671371743,
      "grad_norm": 0.039421167224645615,
      "learning_rate": 0.0004627903246503272,
      "loss": 0.0001,
      "step": 11600
    },
    {
      "epoch": 0.7474656743231105,
      "grad_norm": 0.035457804799079895,
      "learning_rate": 0.0004626299242910304,
      "loss": 0.0001,
      "step": 11650
    },
    {
      "epoch": 0.7506736815090466,
      "grad_norm": 0.010445374995470047,
      "learning_rate": 0.00046246952393173363,
      "loss": 0.0001,
      "step": 11700
    },
    {
      "epoch": 0.7538816886949826,
      "grad_norm": 0.013771653175354004,
      "learning_rate": 0.00046230912357243684,
      "loss": 0.0001,
      "step": 11750
    },
    {
      "epoch": 0.7570896958809188,
      "grad_norm": 0.04502677172422409,
      "learning_rate": 0.00046214872321314,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 0.7602977030668548,
      "grad_norm": 0.00926420371979475,
      "learning_rate": 0.0004619883228538432,
      "loss": 0.0001,
      "step": 11850
    },
    {
      "epoch": 0.763505710252791,
      "grad_norm": 0.04309313744306564,
      "learning_rate": 0.0004618279224945464,
      "loss": 0.0001,
      "step": 11900
    },
    {
      "epoch": 0.7667137174387271,
      "grad_norm": 0.0569438710808754,
      "learning_rate": 0.0004616675221352496,
      "loss": 0.0001,
      "step": 11950
    },
    {
      "epoch": 0.7699217246246631,
      "grad_norm": 0.01557493768632412,
      "learning_rate": 0.00046150712177595276,
      "loss": 0.0001,
      "step": 12000
    },
    {
      "epoch": 0.7731297318105993,
      "grad_norm": 0.031101254746317863,
      "learning_rate": 0.00046134672141665597,
      "loss": 0.0001,
      "step": 12050
    },
    {
      "epoch": 0.7763377389965354,
      "grad_norm": 0.02447189763188362,
      "learning_rate": 0.0004611863210573592,
      "loss": 0.0001,
      "step": 12100
    },
    {
      "epoch": 0.7795457461824714,
      "grad_norm": 0.05721279978752136,
      "learning_rate": 0.0004610259206980624,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 0.7827537533684076,
      "grad_norm": 0.020139530301094055,
      "learning_rate": 0.00046086552033876554,
      "loss": 0.0001,
      "step": 12200
    },
    {
      "epoch": 0.7859617605543436,
      "grad_norm": 0.03706767410039902,
      "learning_rate": 0.0004607051199794688,
      "loss": 0.0001,
      "step": 12250
    },
    {
      "epoch": 0.7891697677402797,
      "grad_norm": 0.008662703447043896,
      "learning_rate": 0.00046054471962017195,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 0.7923777749262159,
      "grad_norm": 0.0422535240650177,
      "learning_rate": 0.00046038431926087516,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 0.7955857821121519,
      "grad_norm": 0.017822014167904854,
      "learning_rate": 0.0004602239189015783,
      "loss": 0.0001,
      "step": 12400
    },
    {
      "epoch": 0.798793789298088,
      "grad_norm": 0.02603950910270214,
      "learning_rate": 0.00046006351854228157,
      "loss": 0.0001,
      "step": 12450
    },
    {
      "epoch": 0.8020017964840241,
      "grad_norm": 0.020091664046049118,
      "learning_rate": 0.0004599031181829847,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 0.8052098036699602,
      "grad_norm": 0.0440838448703289,
      "learning_rate": 0.00045974271782368793,
      "loss": 0.0001,
      "step": 12550
    },
    {
      "epoch": 0.8084178108558964,
      "grad_norm": 0.037105631083250046,
      "learning_rate": 0.0004595823174643911,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 0.8116258180418324,
      "grad_norm": 0.027068842202425003,
      "learning_rate": 0.00045942191710509435,
      "loss": 0.0001,
      "step": 12650
    },
    {
      "epoch": 0.8148338252277685,
      "grad_norm": 0.026331281289458275,
      "learning_rate": 0.0004592615167457975,
      "loss": 0.0001,
      "step": 12700
    },
    {
      "epoch": 0.8180418324137047,
      "grad_norm": 0.034060560166835785,
      "learning_rate": 0.0004591011163865007,
      "loss": 0.0001,
      "step": 12750
    },
    {
      "epoch": 0.8212498395996407,
      "grad_norm": 0.03559830039739609,
      "learning_rate": 0.0004589407160272039,
      "loss": 0.0001,
      "step": 12800
    },
    {
      "epoch": 0.8244578467855768,
      "grad_norm": 0.07583771646022797,
      "learning_rate": 0.0004587803156679071,
      "loss": 0.0001,
      "step": 12850
    },
    {
      "epoch": 0.8276658539715129,
      "grad_norm": 0.03388422727584839,
      "learning_rate": 0.0004586199153086103,
      "loss": 0.0001,
      "step": 12900
    },
    {
      "epoch": 0.830873861157449,
      "grad_norm": 0.061838265508413315,
      "learning_rate": 0.0004584595149493135,
      "loss": 0.0001,
      "step": 12950
    },
    {
      "epoch": 0.834081868343385,
      "grad_norm": 0.08841529488563538,
      "learning_rate": 0.0004582991145900167,
      "loss": 0.0001,
      "step": 13000
    },
    {
      "epoch": 0.8372898755293212,
      "grad_norm": 0.054125960916280746,
      "learning_rate": 0.0004581387142307199,
      "loss": 0.0001,
      "step": 13050
    },
    {
      "epoch": 0.8404978827152573,
      "grad_norm": 0.05866668373346329,
      "learning_rate": 0.0004579783138714231,
      "loss": 0.0001,
      "step": 13100
    },
    {
      "epoch": 0.8437058899011933,
      "grad_norm": 0.04310236871242523,
      "learning_rate": 0.00045781791351212625,
      "loss": 0.0001,
      "step": 13150
    },
    {
      "epoch": 0.8469138970871295,
      "grad_norm": 0.012434333562850952,
      "learning_rate": 0.0004576575131528295,
      "loss": 0.0001,
      "step": 13200
    },
    {
      "epoch": 0.8501219042730656,
      "grad_norm": 0.022669805213809013,
      "learning_rate": 0.00045749711279353267,
      "loss": 0.0001,
      "step": 13250
    },
    {
      "epoch": 0.8533299114590017,
      "grad_norm": 0.00795426033437252,
      "learning_rate": 0.0004573367124342359,
      "loss": 0.0001,
      "step": 13300
    },
    {
      "epoch": 0.8565379186449378,
      "grad_norm": 0.002207415411248803,
      "learning_rate": 0.000457176312074939,
      "loss": 0.0001,
      "step": 13350
    },
    {
      "epoch": 0.8597459258308738,
      "grad_norm": 0.0350298248231411,
      "learning_rate": 0.0004570159117156423,
      "loss": 0.0001,
      "step": 13400
    },
    {
      "epoch": 0.86295393301681,
      "grad_norm": 0.014206469990313053,
      "learning_rate": 0.00045685551135634544,
      "loss": 0.0001,
      "step": 13450
    },
    {
      "epoch": 0.8661619402027461,
      "grad_norm": 0.006528057157993317,
      "learning_rate": 0.00045669511099704865,
      "loss": 0.0001,
      "step": 13500
    },
    {
      "epoch": 0.8693699473886821,
      "grad_norm": 0.03209399804472923,
      "learning_rate": 0.0004565347106377518,
      "loss": 0.0001,
      "step": 13550
    },
    {
      "epoch": 0.8725779545746183,
      "grad_norm": 0.028507057577371597,
      "learning_rate": 0.00045637431027845506,
      "loss": 0.0001,
      "step": 13600
    },
    {
      "epoch": 0.8757859617605543,
      "grad_norm": 0.010053394362330437,
      "learning_rate": 0.0004562139099191582,
      "loss": 0.0001,
      "step": 13650
    },
    {
      "epoch": 0.8789939689464904,
      "grad_norm": 0.010053050704300404,
      "learning_rate": 0.0004560535095598614,
      "loss": 0.0001,
      "step": 13700
    },
    {
      "epoch": 0.8822019761324266,
      "grad_norm": 0.015438583679497242,
      "learning_rate": 0.0004558931092005646,
      "loss": 0.0001,
      "step": 13750
    },
    {
      "epoch": 0.8854099833183626,
      "grad_norm": 0.02183060720562935,
      "learning_rate": 0.00045573270884126783,
      "loss": 0.0001,
      "step": 13800
    },
    {
      "epoch": 0.8886179905042987,
      "grad_norm": 0.011094809509813786,
      "learning_rate": 0.000455572308481971,
      "loss": 0.0001,
      "step": 13850
    },
    {
      "epoch": 0.8918259976902349,
      "grad_norm": 0.050951067358255386,
      "learning_rate": 0.0004554119081226742,
      "loss": 0.0001,
      "step": 13900
    },
    {
      "epoch": 0.8950340048761709,
      "grad_norm": 0.012866541743278503,
      "learning_rate": 0.0004552515077633774,
      "loss": 0.0,
      "step": 13950
    },
    {
      "epoch": 0.898242012062107,
      "grad_norm": 0.030655359849333763,
      "learning_rate": 0.0004550911074040806,
      "loss": 0.0001,
      "step": 14000
    },
    {
      "epoch": 0.9014500192480431,
      "grad_norm": 0.0366126149892807,
      "learning_rate": 0.00045493070704478376,
      "loss": 0.0001,
      "step": 14050
    },
    {
      "epoch": 0.9046580264339792,
      "grad_norm": 0.03078520856797695,
      "learning_rate": 0.00045477030668548697,
      "loss": 0.0001,
      "step": 14100
    },
    {
      "epoch": 0.9078660336199154,
      "grad_norm": 0.035945720970630646,
      "learning_rate": 0.00045460990632619023,
      "loss": 0.0001,
      "step": 14150
    },
    {
      "epoch": 0.9110740408058514,
      "grad_norm": 0.019101591780781746,
      "learning_rate": 0.0004544495059668934,
      "loss": 0.0001,
      "step": 14200
    },
    {
      "epoch": 0.9142820479917875,
      "grad_norm": 0.011158401146531105,
      "learning_rate": 0.0004542891056075966,
      "loss": 0.0001,
      "step": 14250
    },
    {
      "epoch": 0.9174900551777236,
      "grad_norm": 0.04245796427130699,
      "learning_rate": 0.00045412870524829974,
      "loss": 0.0001,
      "step": 14300
    },
    {
      "epoch": 0.9206980623636597,
      "grad_norm": 0.016071712598204613,
      "learning_rate": 0.000453968304889003,
      "loss": 0.0001,
      "step": 14350
    },
    {
      "epoch": 0.9239060695495958,
      "grad_norm": 0.03452877327799797,
      "learning_rate": 0.00045380790452970616,
      "loss": 0.0001,
      "step": 14400
    },
    {
      "epoch": 0.9271140767355319,
      "grad_norm": 0.04247383400797844,
      "learning_rate": 0.00045364750417040936,
      "loss": 0.0001,
      "step": 14450
    },
    {
      "epoch": 0.930322083921468,
      "grad_norm": 0.01998269557952881,
      "learning_rate": 0.0004534871038111125,
      "loss": 0.0001,
      "step": 14500
    },
    {
      "epoch": 0.933530091107404,
      "grad_norm": 0.007757761050015688,
      "learning_rate": 0.0004533267034518158,
      "loss": 0.0001,
      "step": 14550
    },
    {
      "epoch": 0.9367380982933402,
      "grad_norm": 0.021784378215670586,
      "learning_rate": 0.00045316630309251893,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 0.9399461054792763,
      "grad_norm": 0.024713413789868355,
      "learning_rate": 0.00045300590273322214,
      "loss": 0.0,
      "step": 14650
    },
    {
      "epoch": 0.9431541126652123,
      "grad_norm": 0.024949301034212112,
      "learning_rate": 0.0004528455023739253,
      "loss": 0.0001,
      "step": 14700
    },
    {
      "epoch": 0.9463621198511485,
      "grad_norm": 0.007640664000064135,
      "learning_rate": 0.00045268510201462855,
      "loss": 0.0001,
      "step": 14750
    },
    {
      "epoch": 0.9495701270370845,
      "grad_norm": 0.030346138402819633,
      "learning_rate": 0.0004525247016553317,
      "loss": 0.0001,
      "step": 14800
    },
    {
      "epoch": 0.9527781342230207,
      "grad_norm": 0.023103946819901466,
      "learning_rate": 0.0004523643012960349,
      "loss": 0.0001,
      "step": 14850
    },
    {
      "epoch": 0.9559861414089568,
      "grad_norm": 0.012761306017637253,
      "learning_rate": 0.0004522039009367381,
      "loss": 0.0001,
      "step": 14900
    },
    {
      "epoch": 0.9591941485948928,
      "grad_norm": 0.021000327542424202,
      "learning_rate": 0.0004520435005774413,
      "loss": 0.0001,
      "step": 14950
    },
    {
      "epoch": 0.962402155780829,
      "grad_norm": 0.02966308780014515,
      "learning_rate": 0.0004518831002181445,
      "loss": 0.0001,
      "step": 15000
    },
    {
      "epoch": 0.965610162966765,
      "grad_norm": 0.01926841400563717,
      "learning_rate": 0.0004517226998588477,
      "loss": 0.0001,
      "step": 15050
    },
    {
      "epoch": 0.9688181701527011,
      "grad_norm": 0.03098657913506031,
      "learning_rate": 0.0004515622994995509,
      "loss": 0.0001,
      "step": 15100
    },
    {
      "epoch": 0.9720261773386373,
      "grad_norm": 0.04376194253563881,
      "learning_rate": 0.0004514018991402541,
      "loss": 0.0,
      "step": 15150
    },
    {
      "epoch": 0.9752341845245733,
      "grad_norm": 0.02408481016755104,
      "learning_rate": 0.00045124149878095725,
      "loss": 0.0001,
      "step": 15200
    },
    {
      "epoch": 0.9784421917105094,
      "grad_norm": 0.042488448321819305,
      "learning_rate": 0.00045108109842166046,
      "loss": 0.0001,
      "step": 15250
    },
    {
      "epoch": 0.9816501988964456,
      "grad_norm": 0.03231306001543999,
      "learning_rate": 0.00045092069806236366,
      "loss": 0.0001,
      "step": 15300
    },
    {
      "epoch": 0.9848582060823816,
      "grad_norm": 0.020209338515996933,
      "learning_rate": 0.00045076029770306687,
      "loss": 0.0001,
      "step": 15350
    },
    {
      "epoch": 0.9880662132683177,
      "grad_norm": 0.011146166361868382,
      "learning_rate": 0.00045059989734377,
      "loss": 0.0001,
      "step": 15400
    },
    {
      "epoch": 0.9912742204542538,
      "grad_norm": 0.03868165612220764,
      "learning_rate": 0.00045043949698447323,
      "loss": 0.0001,
      "step": 15450
    },
    {
      "epoch": 0.9944822276401899,
      "grad_norm": 0.06194644421339035,
      "learning_rate": 0.0004502790966251765,
      "loss": 0.0001,
      "step": 15500
    },
    {
      "epoch": 0.9976902348261261,
      "grad_norm": 0.018486687913537025,
      "learning_rate": 0.00045011869626587964,
      "loss": 0.0001,
      "step": 15550
    },
    {
      "epoch": 1.000898242012062,
      "grad_norm": 0.04134305194020271,
      "learning_rate": 0.00044995829590658285,
      "loss": 0.0001,
      "step": 15600
    },
    {
      "epoch": 1.0041062491979982,
      "grad_norm": 0.027163861319422722,
      "learning_rate": 0.00044979789554728606,
      "loss": 0.0001,
      "step": 15650
    },
    {
      "epoch": 1.0073142563839343,
      "grad_norm": 0.02825492061674595,
      "learning_rate": 0.00044963749518798926,
      "loss": 0.0001,
      "step": 15700
    },
    {
      "epoch": 1.0105222635698703,
      "grad_norm": 0.021245772019028664,
      "learning_rate": 0.0004494770948286924,
      "loss": 0.0001,
      "step": 15750
    },
    {
      "epoch": 1.0137302707558065,
      "grad_norm": 0.018648426979780197,
      "learning_rate": 0.0004493166944693956,
      "loss": 0.0001,
      "step": 15800
    },
    {
      "epoch": 1.0169382779417426,
      "grad_norm": 0.0472714938223362,
      "learning_rate": 0.00044915629411009883,
      "loss": 0.0001,
      "step": 15850
    },
    {
      "epoch": 1.0201462851276788,
      "grad_norm": 0.03682935982942581,
      "learning_rate": 0.00044899589375080204,
      "loss": 0.0001,
      "step": 15900
    },
    {
      "epoch": 1.0233542923136147,
      "grad_norm": 0.052660465240478516,
      "learning_rate": 0.0004488354933915052,
      "loss": 0.0001,
      "step": 15950
    },
    {
      "epoch": 1.026562299499551,
      "grad_norm": 0.018003296107053757,
      "learning_rate": 0.0004486750930322084,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 1.029770306685487,
      "grad_norm": 0.010685603134334087,
      "learning_rate": 0.0004485146926729116,
      "loss": 0.0001,
      "step": 16050
    },
    {
      "epoch": 1.032978313871423,
      "grad_norm": 0.045751772820949554,
      "learning_rate": 0.0004483542923136148,
      "loss": 0.0001,
      "step": 16100
    },
    {
      "epoch": 1.0361863210573592,
      "grad_norm": 0.013053975068032742,
      "learning_rate": 0.00044819389195431796,
      "loss": 0.0001,
      "step": 16150
    },
    {
      "epoch": 1.0393943282432954,
      "grad_norm": 0.0013028657995164394,
      "learning_rate": 0.00044803349159502117,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 1.0426023354292313,
      "grad_norm": 0.02548636682331562,
      "learning_rate": 0.0004478730912357244,
      "loss": 0.0001,
      "step": 16250
    },
    {
      "epoch": 1.0458103426151675,
      "grad_norm": 0.010535188019275665,
      "learning_rate": 0.0004477126908764276,
      "loss": 0.0001,
      "step": 16300
    },
    {
      "epoch": 1.0490183498011036,
      "grad_norm": 0.008470818400382996,
      "learning_rate": 0.00044755229051713074,
      "loss": 0.0,
      "step": 16350
    },
    {
      "epoch": 1.0522263569870396,
      "grad_norm": 0.05931992456316948,
      "learning_rate": 0.00044739189015783395,
      "loss": 0.0001,
      "step": 16400
    },
    {
      "epoch": 1.0554343641729758,
      "grad_norm": 0.008067824877798557,
      "learning_rate": 0.00044723148979853715,
      "loss": 0.0001,
      "step": 16450
    },
    {
      "epoch": 1.058642371358912,
      "grad_norm": 0.02540319226682186,
      "learning_rate": 0.00044707108943924036,
      "loss": 0.0001,
      "step": 16500
    },
    {
      "epoch": 1.0618503785448479,
      "grad_norm": 0.025151221081614494,
      "learning_rate": 0.0004469106890799435,
      "loss": 0.0001,
      "step": 16550
    },
    {
      "epoch": 1.065058385730784,
      "grad_norm": 0.06149361655116081,
      "learning_rate": 0.0004467502887206468,
      "loss": 0.0001,
      "step": 16600
    },
    {
      "epoch": 1.0682663929167202,
      "grad_norm": 0.03823423385620117,
      "learning_rate": 0.0004465898883613499,
      "loss": 0.0001,
      "step": 16650
    },
    {
      "epoch": 1.0714744001026562,
      "grad_norm": 0.05692025274038315,
      "learning_rate": 0.00044642948800205313,
      "loss": 0.0001,
      "step": 16700
    },
    {
      "epoch": 1.0746824072885923,
      "grad_norm": 0.03055010363459587,
      "learning_rate": 0.0004462690876427563,
      "loss": 0.0001,
      "step": 16750
    },
    {
      "epoch": 1.0778904144745285,
      "grad_norm": 0.012305257841944695,
      "learning_rate": 0.00044610868728345955,
      "loss": 0.0001,
      "step": 16800
    },
    {
      "epoch": 1.0810984216604644,
      "grad_norm": 0.04386956989765167,
      "learning_rate": 0.00044594828692416275,
      "loss": 0.0001,
      "step": 16850
    },
    {
      "epoch": 1.0843064288464006,
      "grad_norm": 0.01974938064813614,
      "learning_rate": 0.0004457878865648659,
      "loss": 0.0001,
      "step": 16900
    },
    {
      "epoch": 1.0875144360323368,
      "grad_norm": 0.027476612478494644,
      "learning_rate": 0.0004456274862055691,
      "loss": 0.0001,
      "step": 16950
    },
    {
      "epoch": 1.0907224432182727,
      "grad_norm": 0.012841278687119484,
      "learning_rate": 0.0004454670858462723,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 1.0939304504042089,
      "grad_norm": 0.011186162009835243,
      "learning_rate": 0.0004453066854869755,
      "loss": 0.0001,
      "step": 17050
    },
    {
      "epoch": 1.097138457590145,
      "grad_norm": 0.024959327653050423,
      "learning_rate": 0.0004451462851276787,
      "loss": 0.0001,
      "step": 17100
    },
    {
      "epoch": 1.100346464776081,
      "grad_norm": 0.025585774332284927,
      "learning_rate": 0.0004449858847683819,
      "loss": 0.0,
      "step": 17150
    },
    {
      "epoch": 1.1035544719620172,
      "grad_norm": 0.019155850633978844,
      "learning_rate": 0.0004448254844090851,
      "loss": 0.0001,
      "step": 17200
    },
    {
      "epoch": 1.1067624791479533,
      "grad_norm": 0.0462164543569088,
      "learning_rate": 0.0004446650840497883,
      "loss": 0.0001,
      "step": 17250
    },
    {
      "epoch": 1.1099704863338893,
      "grad_norm": 0.014746299013495445,
      "learning_rate": 0.00044450468369049145,
      "loss": 0.0001,
      "step": 17300
    },
    {
      "epoch": 1.1131784935198255,
      "grad_norm": 0.03516506031155586,
      "learning_rate": 0.0004443442833311947,
      "loss": 0.0001,
      "step": 17350
    },
    {
      "epoch": 1.1163865007057616,
      "grad_norm": 0.03608390688896179,
      "learning_rate": 0.00044418388297189787,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 1.1195945078916978,
      "grad_norm": 0.013612493872642517,
      "learning_rate": 0.0004440234826126011,
      "loss": 0.0,
      "step": 17450
    },
    {
      "epoch": 1.1228025150776337,
      "grad_norm": 0.04743010178208351,
      "learning_rate": 0.0004438630822533042,
      "loss": 0.0001,
      "step": 17500
    },
    {
      "epoch": 1.12601052226357,
      "grad_norm": 0.041202764958143234,
      "learning_rate": 0.0004437026818940075,
      "loss": 0.0001,
      "step": 17550
    },
    {
      "epoch": 1.1292185294495058,
      "grad_norm": 0.017884887754917145,
      "learning_rate": 0.00044354228153471064,
      "loss": 0.0001,
      "step": 17600
    },
    {
      "epoch": 1.132426536635442,
      "grad_norm": 0.025076081976294518,
      "learning_rate": 0.00044338188117541385,
      "loss": 0.0,
      "step": 17650
    },
    {
      "epoch": 1.1356345438213782,
      "grad_norm": 0.05762708932161331,
      "learning_rate": 0.000443221480816117,
      "loss": 0.0001,
      "step": 17700
    },
    {
      "epoch": 1.1388425510073144,
      "grad_norm": 0.0143423555418849,
      "learning_rate": 0.00044306108045682026,
      "loss": 0.0001,
      "step": 17750
    },
    {
      "epoch": 1.1420505581932503,
      "grad_norm": 0.006518540438264608,
      "learning_rate": 0.0004429006800975234,
      "loss": 0.0001,
      "step": 17800
    },
    {
      "epoch": 1.1452585653791865,
      "grad_norm": 0.03506503254175186,
      "learning_rate": 0.0004427402797382266,
      "loss": 0.0001,
      "step": 17850
    },
    {
      "epoch": 1.1484665725651226,
      "grad_norm": 0.023900015279650688,
      "learning_rate": 0.0004425798793789298,
      "loss": 0.0001,
      "step": 17900
    },
    {
      "epoch": 1.1516745797510586,
      "grad_norm": 0.020136462524533272,
      "learning_rate": 0.00044241947901963304,
      "loss": 0.0001,
      "step": 17950
    },
    {
      "epoch": 1.1548825869369947,
      "grad_norm": 0.0577431358397007,
      "learning_rate": 0.0004422590786603362,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 1.158090594122931,
      "grad_norm": 0.013501321896910667,
      "learning_rate": 0.0004420986783010394,
      "loss": 0.0001,
      "step": 18050
    },
    {
      "epoch": 1.1612986013088669,
      "grad_norm": 0.03151145577430725,
      "learning_rate": 0.00044193827794174255,
      "loss": 0.0001,
      "step": 18100
    },
    {
      "epoch": 1.164506608494803,
      "grad_norm": 0.08335071802139282,
      "learning_rate": 0.0004417778775824458,
      "loss": 0.0001,
      "step": 18150
    },
    {
      "epoch": 1.1677146156807392,
      "grad_norm": 0.024284042418003082,
      "learning_rate": 0.000441617477223149,
      "loss": 0.0001,
      "step": 18200
    },
    {
      "epoch": 1.1709226228666751,
      "grad_norm": 0.01743440516293049,
      "learning_rate": 0.00044145707686385217,
      "loss": 0.0,
      "step": 18250
    },
    {
      "epoch": 1.1741306300526113,
      "grad_norm": 0.04463240131735802,
      "learning_rate": 0.00044129667650455543,
      "loss": 0.0001,
      "step": 18300
    },
    {
      "epoch": 1.1773386372385475,
      "grad_norm": 0.018259013071656227,
      "learning_rate": 0.0004411362761452586,
      "loss": 0.0001,
      "step": 18350
    },
    {
      "epoch": 1.1805466444244834,
      "grad_norm": 0.03597308695316315,
      "learning_rate": 0.0004409758757859618,
      "loss": 0.0001,
      "step": 18400
    },
    {
      "epoch": 1.1837546516104196,
      "grad_norm": 0.027463478967547417,
      "learning_rate": 0.00044081547542666494,
      "loss": 0.0,
      "step": 18450
    },
    {
      "epoch": 1.1869626587963558,
      "grad_norm": 0.07168995589017868,
      "learning_rate": 0.0004406550750673682,
      "loss": 0.0001,
      "step": 18500
    },
    {
      "epoch": 1.1901706659822917,
      "grad_norm": 0.006517953705042601,
      "learning_rate": 0.00044049467470807136,
      "loss": 0.0,
      "step": 18550
    },
    {
      "epoch": 1.1933786731682279,
      "grad_norm": 0.042018625885248184,
      "learning_rate": 0.00044033427434877456,
      "loss": 0.0001,
      "step": 18600
    },
    {
      "epoch": 1.196586680354164,
      "grad_norm": 0.024536103010177612,
      "learning_rate": 0.0004401738739894777,
      "loss": 0.0,
      "step": 18650
    },
    {
      "epoch": 1.1997946875401002,
      "grad_norm": 0.03543558344244957,
      "learning_rate": 0.000440013473630181,
      "loss": 0.0,
      "step": 18700
    },
    {
      "epoch": 1.2030026947260362,
      "grad_norm": 0.040335576981306076,
      "learning_rate": 0.00043985307327088413,
      "loss": 0.0001,
      "step": 18750
    },
    {
      "epoch": 1.2062107019119723,
      "grad_norm": 0.012090664356946945,
      "learning_rate": 0.00043969267291158734,
      "loss": 0.0001,
      "step": 18800
    },
    {
      "epoch": 1.2094187090979083,
      "grad_norm": 0.054832182824611664,
      "learning_rate": 0.0004395322725522905,
      "loss": 0.0001,
      "step": 18850
    },
    {
      "epoch": 1.2126267162838444,
      "grad_norm": 0.01241223979741335,
      "learning_rate": 0.00043937187219299375,
      "loss": 0.0,
      "step": 18900
    },
    {
      "epoch": 1.2158347234697806,
      "grad_norm": 0.024760715663433075,
      "learning_rate": 0.0004392114718336969,
      "loss": 0.0001,
      "step": 18950
    },
    {
      "epoch": 1.2190427306557168,
      "grad_norm": 0.015011261217296124,
      "learning_rate": 0.0004390510714744001,
      "loss": 0.0001,
      "step": 19000
    },
    {
      "epoch": 1.2222507378416527,
      "grad_norm": 0.024734092876315117,
      "learning_rate": 0.00043889067111510326,
      "loss": 0.0,
      "step": 19050
    },
    {
      "epoch": 1.225458745027589,
      "grad_norm": 0.02200978249311447,
      "learning_rate": 0.0004387302707558065,
      "loss": 0.0001,
      "step": 19100
    },
    {
      "epoch": 1.2286667522135248,
      "grad_norm": 0.02338533289730549,
      "learning_rate": 0.0004385698703965097,
      "loss": 0.0,
      "step": 19150
    },
    {
      "epoch": 1.231874759399461,
      "grad_norm": 0.03967868164181709,
      "learning_rate": 0.0004384094700372129,
      "loss": 0.0001,
      "step": 19200
    },
    {
      "epoch": 1.2350827665853972,
      "grad_norm": 0.028133368119597435,
      "learning_rate": 0.0004382490696779161,
      "loss": 0.0001,
      "step": 19250
    },
    {
      "epoch": 1.2382907737713333,
      "grad_norm": 0.02301637828350067,
      "learning_rate": 0.0004380886693186193,
      "loss": 0.0001,
      "step": 19300
    },
    {
      "epoch": 1.2414987809572693,
      "grad_norm": 0.023630205541849136,
      "learning_rate": 0.00043792826895932245,
      "loss": 0.0001,
      "step": 19350
    },
    {
      "epoch": 1.2447067881432055,
      "grad_norm": 0.014630322344601154,
      "learning_rate": 0.00043776786860002566,
      "loss": 0.0001,
      "step": 19400
    },
    {
      "epoch": 1.2479147953291416,
      "grad_norm": 0.05097983032464981,
      "learning_rate": 0.00043760746824072886,
      "loss": 0.0001,
      "step": 19450
    },
    {
      "epoch": 1.2511228025150776,
      "grad_norm": 0.017608534544706345,
      "learning_rate": 0.00043744706788143207,
      "loss": 0.0001,
      "step": 19500
    },
    {
      "epoch": 1.2543308097010137,
      "grad_norm": 0.01684590056538582,
      "learning_rate": 0.0004372866675221352,
      "loss": 0.0001,
      "step": 19550
    },
    {
      "epoch": 1.25753881688695,
      "grad_norm": 0.03070732019841671,
      "learning_rate": 0.00043712626716283843,
      "loss": 0.0001,
      "step": 19600
    },
    {
      "epoch": 1.2607468240728859,
      "grad_norm": 0.044708412140607834,
      "learning_rate": 0.0004369658668035417,
      "loss": 0.0,
      "step": 19650
    },
    {
      "epoch": 1.263954831258822,
      "grad_norm": 0.028875967487692833,
      "learning_rate": 0.00043680546644424484,
      "loss": 0.0,
      "step": 19700
    },
    {
      "epoch": 1.2671628384447582,
      "grad_norm": 0.011189913377165794,
      "learning_rate": 0.00043664506608494805,
      "loss": 0.0,
      "step": 19750
    },
    {
      "epoch": 1.2703708456306941,
      "grad_norm": 0.022468939423561096,
      "learning_rate": 0.0004364846657256512,
      "loss": 0.0,
      "step": 19800
    },
    {
      "epoch": 1.2735788528166303,
      "grad_norm": 0.029122015461325645,
      "learning_rate": 0.00043632426536635447,
      "loss": 0.0,
      "step": 19850
    },
    {
      "epoch": 1.2767868600025665,
      "grad_norm": 0.032893676310777664,
      "learning_rate": 0.0004361638650070576,
      "loss": 0.0,
      "step": 19900
    },
    {
      "epoch": 1.2799948671885026,
      "grad_norm": 0.018148882314562798,
      "learning_rate": 0.0004360034646477608,
      "loss": 0.0001,
      "step": 19950
    },
    {
      "epoch": 1.2832028743744386,
      "grad_norm": 0.0171397365629673,
      "learning_rate": 0.00043584306428846403,
      "loss": 0.0,
      "step": 20000
    },
    {
      "epoch": 1.2864108815603748,
      "grad_norm": 0.020561015233397484,
      "learning_rate": 0.00043568266392916724,
      "loss": 0.0,
      "step": 20050
    },
    {
      "epoch": 1.2896188887463107,
      "grad_norm": 0.004352354910224676,
      "learning_rate": 0.0004355222635698704,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 1.2928268959322469,
      "grad_norm": 0.01819675788283348,
      "learning_rate": 0.0004353618632105736,
      "loss": 0.0,
      "step": 20150
    },
    {
      "epoch": 1.296034903118183,
      "grad_norm": 0.004175008274614811,
      "learning_rate": 0.0004352014628512768,
      "loss": 0.0,
      "step": 20200
    },
    {
      "epoch": 1.2992429103041192,
      "grad_norm": 0.03109739162027836,
      "learning_rate": 0.00043504106249198,
      "loss": 0.0,
      "step": 20250
    },
    {
      "epoch": 1.3024509174900551,
      "grad_norm": 0.03456946462392807,
      "learning_rate": 0.00043488066213268317,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 1.3056589246759913,
      "grad_norm": 0.016418419778347015,
      "learning_rate": 0.00043472026177338637,
      "loss": 0.0001,
      "step": 20350
    },
    {
      "epoch": 1.3088669318619273,
      "grad_norm": 0.07812115550041199,
      "learning_rate": 0.0004345598614140896,
      "loss": 0.0001,
      "step": 20400
    },
    {
      "epoch": 1.3120749390478634,
      "grad_norm": 0.010902337729930878,
      "learning_rate": 0.0004343994610547928,
      "loss": 0.0001,
      "step": 20450
    },
    {
      "epoch": 1.3152829462337996,
      "grad_norm": 0.024361416697502136,
      "learning_rate": 0.00043423906069549594,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 1.3184909534197358,
      "grad_norm": 0.024064812809228897,
      "learning_rate": 0.00043407866033619915,
      "loss": 0.0,
      "step": 20550
    },
    {
      "epoch": 1.3216989606056717,
      "grad_norm": 0.008358588442206383,
      "learning_rate": 0.00043391825997690235,
      "loss": 0.0,
      "step": 20600
    },
    {
      "epoch": 1.3249069677916079,
      "grad_norm": 0.013588561676442623,
      "learning_rate": 0.00043375785961760556,
      "loss": 0.0,
      "step": 20650
    },
    {
      "epoch": 1.3281149749775438,
      "grad_norm": 0.0245994720607996,
      "learning_rate": 0.0004335974592583087,
      "loss": 0.0001,
      "step": 20700
    },
    {
      "epoch": 1.33132298216348,
      "grad_norm": 0.005913509987294674,
      "learning_rate": 0.0004334370588990119,
      "loss": 0.0,
      "step": 20750
    },
    {
      "epoch": 1.3345309893494162,
      "grad_norm": 0.015714777633547783,
      "learning_rate": 0.0004332766585397151,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 1.3377389965353523,
      "grad_norm": 0.039439182728528976,
      "learning_rate": 0.00043311625818041833,
      "loss": 0.0001,
      "step": 20850
    },
    {
      "epoch": 1.3409470037212883,
      "grad_norm": 0.025211434811353683,
      "learning_rate": 0.0004329558578211215,
      "loss": 0.0,
      "step": 20900
    },
    {
      "epoch": 1.3441550109072244,
      "grad_norm": 0.023329662159085274,
      "learning_rate": 0.00043279545746182475,
      "loss": 0.0001,
      "step": 20950
    },
    {
      "epoch": 1.3473630180931604,
      "grad_norm": 0.013014491647481918,
      "learning_rate": 0.00043263505710252795,
      "loss": 0.0001,
      "step": 21000
    },
    {
      "epoch": 1.3505710252790966,
      "grad_norm": 0.010400521568953991,
      "learning_rate": 0.0004324746567432311,
      "loss": 0.0001,
      "step": 21050
    },
    {
      "epoch": 1.3537790324650327,
      "grad_norm": 0.01612558402121067,
      "learning_rate": 0.0004323142563839343,
      "loss": 0.0,
      "step": 21100
    },
    {
      "epoch": 1.356987039650969,
      "grad_norm": 0.011333356611430645,
      "learning_rate": 0.0004321538560246375,
      "loss": 0.0001,
      "step": 21150
    },
    {
      "epoch": 1.3601950468369048,
      "grad_norm": 0.00836791843175888,
      "learning_rate": 0.00043199345566534073,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 1.363403054022841,
      "grad_norm": 0.03557371348142624,
      "learning_rate": 0.0004318330553060439,
      "loss": 0.0001,
      "step": 21250
    },
    {
      "epoch": 1.3666110612087772,
      "grad_norm": 0.02212381735444069,
      "learning_rate": 0.0004316726549467471,
      "loss": 0.0001,
      "step": 21300
    },
    {
      "epoch": 1.3698190683947131,
      "grad_norm": 0.016204938292503357,
      "learning_rate": 0.0004315122545874503,
      "loss": 0.0,
      "step": 21350
    },
    {
      "epoch": 1.3730270755806493,
      "grad_norm": 0.01405493263155222,
      "learning_rate": 0.0004313518542281535,
      "loss": 0.0,
      "step": 21400
    },
    {
      "epoch": 1.3762350827665855,
      "grad_norm": 0.014793094247579575,
      "learning_rate": 0.00043119145386885665,
      "loss": 0.0,
      "step": 21450
    },
    {
      "epoch": 1.3794430899525216,
      "grad_norm": 0.05687969550490379,
      "learning_rate": 0.00043103105350955986,
      "loss": 0.0,
      "step": 21500
    },
    {
      "epoch": 1.3826510971384576,
      "grad_norm": 0.04596710577607155,
      "learning_rate": 0.00043087065315026307,
      "loss": 0.0001,
      "step": 21550
    },
    {
      "epoch": 1.3858591043243937,
      "grad_norm": 0.030291732400655746,
      "learning_rate": 0.0004307102527909663,
      "loss": 0.0001,
      "step": 21600
    },
    {
      "epoch": 1.3890671115103297,
      "grad_norm": 0.012532410211861134,
      "learning_rate": 0.00043054985243166943,
      "loss": 0.0,
      "step": 21650
    },
    {
      "epoch": 1.3922751186962659,
      "grad_norm": 0.039450325071811676,
      "learning_rate": 0.0004303894520723727,
      "loss": 0.0,
      "step": 21700
    },
    {
      "epoch": 1.395483125882202,
      "grad_norm": 0.031115636229515076,
      "learning_rate": 0.00043022905171307584,
      "loss": 0.0001,
      "step": 21750
    },
    {
      "epoch": 1.3986911330681382,
      "grad_norm": 0.014297574758529663,
      "learning_rate": 0.00043006865135377905,
      "loss": 0.0001,
      "step": 21800
    },
    {
      "epoch": 1.4018991402540741,
      "grad_norm": 0.006110277492552996,
      "learning_rate": 0.0004299082509944822,
      "loss": 0.0,
      "step": 21850
    },
    {
      "epoch": 1.4051071474400103,
      "grad_norm": 0.024614524096250534,
      "learning_rate": 0.00042974785063518546,
      "loss": 0.0,
      "step": 21900
    },
    {
      "epoch": 1.4083151546259463,
      "grad_norm": 0.008928370662033558,
      "learning_rate": 0.0004295874502758886,
      "loss": 0.0001,
      "step": 21950
    },
    {
      "epoch": 1.4115231618118824,
      "grad_norm": 0.012139055877923965,
      "learning_rate": 0.0004294270499165918,
      "loss": 0.0001,
      "step": 22000
    },
    {
      "epoch": 1.4147311689978186,
      "grad_norm": 0.035194214433431625,
      "learning_rate": 0.000429266649557295,
      "loss": 0.0,
      "step": 22050
    },
    {
      "epoch": 1.4179391761837548,
      "grad_norm": 0.00432855449616909,
      "learning_rate": 0.00042910624919799824,
      "loss": 0.0001,
      "step": 22100
    },
    {
      "epoch": 1.4211471833696907,
      "grad_norm": 0.049672987312078476,
      "learning_rate": 0.0004289458488387014,
      "loss": 0.0001,
      "step": 22150
    },
    {
      "epoch": 1.4243551905556269,
      "grad_norm": 0.010415591299533844,
      "learning_rate": 0.0004287854484794046,
      "loss": 0.0,
      "step": 22200
    },
    {
      "epoch": 1.4275631977415628,
      "grad_norm": 0.015970269218087196,
      "learning_rate": 0.00042862504812010775,
      "loss": 0.0001,
      "step": 22250
    },
    {
      "epoch": 1.430771204927499,
      "grad_norm": 0.0212705135345459,
      "learning_rate": 0.000428464647760811,
      "loss": 0.0001,
      "step": 22300
    },
    {
      "epoch": 1.4339792121134352,
      "grad_norm": 0.022214889526367188,
      "learning_rate": 0.0004283042474015142,
      "loss": 0.0001,
      "step": 22350
    },
    {
      "epoch": 1.4371872192993713,
      "grad_norm": 0.028628166764974594,
      "learning_rate": 0.00042814384704221737,
      "loss": 0.0001,
      "step": 22400
    },
    {
      "epoch": 1.4403952264853073,
      "grad_norm": 0.030188798904418945,
      "learning_rate": 0.0004279834466829206,
      "loss": 0.0,
      "step": 22450
    },
    {
      "epoch": 1.4436032336712434,
      "grad_norm": 0.016776414588093758,
      "learning_rate": 0.0004278230463236238,
      "loss": 0.0001,
      "step": 22500
    },
    {
      "epoch": 1.4468112408571794,
      "grad_norm": 0.028632381930947304,
      "learning_rate": 0.000427662645964327,
      "loss": 0.0001,
      "step": 22550
    },
    {
      "epoch": 1.4500192480431155,
      "grad_norm": 0.018091419711709023,
      "learning_rate": 0.00042750224560503014,
      "loss": 0.0001,
      "step": 22600
    },
    {
      "epoch": 1.4532272552290517,
      "grad_norm": 0.02545086108148098,
      "learning_rate": 0.0004273418452457334,
      "loss": 0.0,
      "step": 22650
    },
    {
      "epoch": 1.4564352624149879,
      "grad_norm": 0.03537323325872421,
      "learning_rate": 0.00042718144488643656,
      "loss": 0.0,
      "step": 22700
    },
    {
      "epoch": 1.4596432696009238,
      "grad_norm": 0.0484638437628746,
      "learning_rate": 0.00042702104452713976,
      "loss": 0.0001,
      "step": 22750
    },
    {
      "epoch": 1.46285127678686,
      "grad_norm": 0.027047770097851753,
      "learning_rate": 0.0004268606441678429,
      "loss": 0.0,
      "step": 22800
    },
    {
      "epoch": 1.4660592839727962,
      "grad_norm": 0.013600093312561512,
      "learning_rate": 0.0004267002438085462,
      "loss": 0.0,
      "step": 22850
    },
    {
      "epoch": 1.4692672911587321,
      "grad_norm": 0.01893647573888302,
      "learning_rate": 0.00042653984344924933,
      "loss": 0.0001,
      "step": 22900
    },
    {
      "epoch": 1.4724752983446683,
      "grad_norm": 0.01112004742026329,
      "learning_rate": 0.00042637944308995254,
      "loss": 0.0,
      "step": 22950
    },
    {
      "epoch": 1.4756833055306044,
      "grad_norm": 0.04107937216758728,
      "learning_rate": 0.0004262190427306557,
      "loss": 0.0,
      "step": 23000
    },
    {
      "epoch": 1.4788913127165406,
      "grad_norm": 0.011471517384052277,
      "learning_rate": 0.00042605864237135895,
      "loss": 0.0,
      "step": 23050
    },
    {
      "epoch": 1.4820993199024766,
      "grad_norm": 0.01745206117630005,
      "learning_rate": 0.0004258982420120621,
      "loss": 0.0,
      "step": 23100
    },
    {
      "epoch": 1.4853073270884127,
      "grad_norm": 0.032990679144859314,
      "learning_rate": 0.0004257378416527653,
      "loss": 0.0001,
      "step": 23150
    },
    {
      "epoch": 1.4885153342743487,
      "grad_norm": 0.030265800654888153,
      "learning_rate": 0.00042557744129346846,
      "loss": 0.0,
      "step": 23200
    },
    {
      "epoch": 1.4917233414602848,
      "grad_norm": 0.012856300920248032,
      "learning_rate": 0.0004254170409341717,
      "loss": 0.0,
      "step": 23250
    },
    {
      "epoch": 1.494931348646221,
      "grad_norm": 0.05028437823057175,
      "learning_rate": 0.0004252566405748749,
      "loss": 0.0001,
      "step": 23300
    },
    {
      "epoch": 1.4981393558321572,
      "grad_norm": 0.02557728812098503,
      "learning_rate": 0.0004250962402155781,
      "loss": 0.0,
      "step": 23350
    },
    {
      "epoch": 1.5013473630180931,
      "grad_norm": 0.020779935643076897,
      "learning_rate": 0.0004249358398562813,
      "loss": 0.0,
      "step": 23400
    },
    {
      "epoch": 1.5045553702040293,
      "grad_norm": 0.021552449092268944,
      "learning_rate": 0.0004247754394969845,
      "loss": 0.0,
      "step": 23450
    },
    {
      "epoch": 1.5077633773899652,
      "grad_norm": 0.007258301600813866,
      "learning_rate": 0.00042461503913768765,
      "loss": 0.0,
      "step": 23500
    },
    {
      "epoch": 1.5109713845759014,
      "grad_norm": 0.02613077685236931,
      "learning_rate": 0.00042445463877839086,
      "loss": 0.0,
      "step": 23550
    },
    {
      "epoch": 1.5141793917618376,
      "grad_norm": 0.007074384950101376,
      "learning_rate": 0.00042429423841909407,
      "loss": 0.0,
      "step": 23600
    },
    {
      "epoch": 1.5173873989477737,
      "grad_norm": 0.011093275621533394,
      "learning_rate": 0.00042413383805979727,
      "loss": 0.0,
      "step": 23650
    },
    {
      "epoch": 1.5205954061337097,
      "grad_norm": 0.008939453400671482,
      "learning_rate": 0.0004239734377005005,
      "loss": 0.0,
      "step": 23700
    },
    {
      "epoch": 1.5238034133196459,
      "grad_norm": 0.011361307464540005,
      "learning_rate": 0.00042381303734120363,
      "loss": 0.0,
      "step": 23750
    },
    {
      "epoch": 1.5270114205055818,
      "grad_norm": 0.011721402406692505,
      "learning_rate": 0.0004236526369819069,
      "loss": 0.0,
      "step": 23800
    },
    {
      "epoch": 1.530219427691518,
      "grad_norm": 0.009157123975455761,
      "learning_rate": 0.00042349223662261005,
      "loss": 0.0,
      "step": 23850
    },
    {
      "epoch": 1.5334274348774541,
      "grad_norm": 0.012140084058046341,
      "learning_rate": 0.00042333183626331325,
      "loss": 0.0,
      "step": 23900
    },
    {
      "epoch": 1.5366354420633903,
      "grad_norm": 0.03943556174635887,
      "learning_rate": 0.0004231714359040164,
      "loss": 0.0001,
      "step": 23950
    },
    {
      "epoch": 1.5398434492493265,
      "grad_norm": 0.017495548352599144,
      "learning_rate": 0.00042301103554471967,
      "loss": 0.0,
      "step": 24000
    },
    {
      "epoch": 1.5430514564352624,
      "grad_norm": 0.03517076000571251,
      "learning_rate": 0.0004228506351854228,
      "loss": 0.0,
      "step": 24050
    },
    {
      "epoch": 1.5462594636211984,
      "grad_norm": 0.0020800489000976086,
      "learning_rate": 0.000422690234826126,
      "loss": 0.0,
      "step": 24100
    },
    {
      "epoch": 1.5494674708071345,
      "grad_norm": 0.012424283660948277,
      "learning_rate": 0.0004225298344668292,
      "loss": 0.0,
      "step": 24150
    },
    {
      "epoch": 1.5526754779930707,
      "grad_norm": 0.029902780428528786,
      "learning_rate": 0.00042236943410753244,
      "loss": 0.0,
      "step": 24200
    },
    {
      "epoch": 1.5558834851790069,
      "grad_norm": 0.005699215456843376,
      "learning_rate": 0.0004222090337482356,
      "loss": 0.0,
      "step": 24250
    },
    {
      "epoch": 1.559091492364943,
      "grad_norm": 0.020558912307024002,
      "learning_rate": 0.0004220486333889388,
      "loss": 0.0,
      "step": 24300
    },
    {
      "epoch": 1.562299499550879,
      "grad_norm": 0.02875882014632225,
      "learning_rate": 0.000421888233029642,
      "loss": 0.0,
      "step": 24350
    },
    {
      "epoch": 1.565507506736815,
      "grad_norm": 0.03944835811853409,
      "learning_rate": 0.0004217278326703452,
      "loss": 0.0,
      "step": 24400
    },
    {
      "epoch": 1.568715513922751,
      "grad_norm": 0.00662332633510232,
      "learning_rate": 0.00042156743231104837,
      "loss": 0.0001,
      "step": 24450
    },
    {
      "epoch": 1.5719235211086873,
      "grad_norm": 0.019434086978435516,
      "learning_rate": 0.0004214070319517516,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 1.5751315282946234,
      "grad_norm": 0.01638258434832096,
      "learning_rate": 0.0004212466315924548,
      "loss": 0.0,
      "step": 24550
    },
    {
      "epoch": 1.5783395354805596,
      "grad_norm": 0.05379204452037811,
      "learning_rate": 0.000421086231233158,
      "loss": 0.0001,
      "step": 24600
    },
    {
      "epoch": 1.5815475426664956,
      "grad_norm": 0.005762937478721142,
      "learning_rate": 0.00042092583087386114,
      "loss": 0.0,
      "step": 24650
    },
    {
      "epoch": 1.5847555498524317,
      "grad_norm": 0.011024859733879566,
      "learning_rate": 0.00042076543051456435,
      "loss": 0.0,
      "step": 24700
    },
    {
      "epoch": 1.5879635570383677,
      "grad_norm": 0.012715522199869156,
      "learning_rate": 0.00042060503015526755,
      "loss": 0.0,
      "step": 24750
    },
    {
      "epoch": 1.5911715642243038,
      "grad_norm": 0.010996890254318714,
      "learning_rate": 0.00042044462979597076,
      "loss": 0.0,
      "step": 24800
    },
    {
      "epoch": 1.59437957141024,
      "grad_norm": 0.03952711448073387,
      "learning_rate": 0.0004202842294366739,
      "loss": 0.0001,
      "step": 24850
    },
    {
      "epoch": 1.5975875785961762,
      "grad_norm": 0.03558940067887306,
      "learning_rate": 0.0004201238290773771,
      "loss": 0.0001,
      "step": 24900
    },
    {
      "epoch": 1.6007955857821121,
      "grad_norm": 0.05162686109542847,
      "learning_rate": 0.00041996342871808033,
      "loss": 0.0001,
      "step": 24950
    },
    {
      "epoch": 1.6040035929680483,
      "grad_norm": 0.01917281560599804,
      "learning_rate": 0.00041980302835878353,
      "loss": 0.0,
      "step": 25000
    },
    {
      "epoch": 1.6072116001539842,
      "grad_norm": 0.028656454756855965,
      "learning_rate": 0.00041964262799948674,
      "loss": 0.0,
      "step": 25050
    },
    {
      "epoch": 1.6104196073399204,
      "grad_norm": 0.01782911829650402,
      "learning_rate": 0.0004194822276401899,
      "loss": 0.0001,
      "step": 25100
    },
    {
      "epoch": 1.6136276145258566,
      "grad_norm": 0.03110230341553688,
      "learning_rate": 0.00041932182728089316,
      "loss": 0.0001,
      "step": 25150
    },
    {
      "epoch": 1.6168356217117927,
      "grad_norm": 0.020865006372332573,
      "learning_rate": 0.0004191614269215963,
      "loss": 0.0,
      "step": 25200
    },
    {
      "epoch": 1.6200436288977287,
      "grad_norm": 0.005305970087647438,
      "learning_rate": 0.0004190010265622995,
      "loss": 0.0,
      "step": 25250
    },
    {
      "epoch": 1.6232516360836649,
      "grad_norm": 0.003610530635342002,
      "learning_rate": 0.0004188406262030027,
      "loss": 0.0,
      "step": 25300
    },
    {
      "epoch": 1.6264596432696008,
      "grad_norm": 0.01889425702393055,
      "learning_rate": 0.00041868022584370593,
      "loss": 0.0,
      "step": 25350
    },
    {
      "epoch": 1.629667650455537,
      "grad_norm": 0.02449275180697441,
      "learning_rate": 0.0004185198254844091,
      "loss": 0.0,
      "step": 25400
    },
    {
      "epoch": 1.6328756576414731,
      "grad_norm": 0.030266333371400833,
      "learning_rate": 0.0004183594251251123,
      "loss": 0.0001,
      "step": 25450
    },
    {
      "epoch": 1.6360836648274093,
      "grad_norm": 0.0245869942009449,
      "learning_rate": 0.0004181990247658155,
      "loss": 0.0001,
      "step": 25500
    },
    {
      "epoch": 1.6392916720133455,
      "grad_norm": 0.026188259944319725,
      "learning_rate": 0.0004180386244065187,
      "loss": 0.0,
      "step": 25550
    },
    {
      "epoch": 1.6424996791992814,
      "grad_norm": 0.019722305238246918,
      "learning_rate": 0.00041787822404722186,
      "loss": 0.0,
      "step": 25600
    },
    {
      "epoch": 1.6457076863852174,
      "grad_norm": 0.03044251725077629,
      "learning_rate": 0.00041771782368792506,
      "loss": 0.0,
      "step": 25650
    },
    {
      "epoch": 1.6489156935711535,
      "grad_norm": 0.03670815750956535,
      "learning_rate": 0.00041755742332862827,
      "loss": 0.0001,
      "step": 25700
    },
    {
      "epoch": 1.6521237007570897,
      "grad_norm": 0.041932374238967896,
      "learning_rate": 0.0004173970229693315,
      "loss": 0.0001,
      "step": 25750
    },
    {
      "epoch": 1.6553317079430259,
      "grad_norm": 0.03357832878828049,
      "learning_rate": 0.00041723662261003463,
      "loss": 0.0001,
      "step": 25800
    },
    {
      "epoch": 1.658539715128962,
      "grad_norm": 0.01021300908178091,
      "learning_rate": 0.00041707622225073784,
      "loss": 0.0,
      "step": 25850
    },
    {
      "epoch": 1.661747722314898,
      "grad_norm": 0.009191160090267658,
      "learning_rate": 0.00041691582189144104,
      "loss": 0.0,
      "step": 25900
    },
    {
      "epoch": 1.664955729500834,
      "grad_norm": 0.004280391614884138,
      "learning_rate": 0.00041675542153214425,
      "loss": 0.0,
      "step": 25950
    },
    {
      "epoch": 1.66816373668677,
      "grad_norm": 0.019252577796578407,
      "learning_rate": 0.0004165950211728474,
      "loss": 0.0,
      "step": 26000
    },
    {
      "epoch": 1.6713717438727063,
      "grad_norm": 0.004672177601605654,
      "learning_rate": 0.00041643462081355066,
      "loss": 0.0,
      "step": 26050
    },
    {
      "epoch": 1.6745797510586424,
      "grad_norm": 0.007257366087287664,
      "learning_rate": 0.0004162742204542538,
      "loss": 0.0001,
      "step": 26100
    },
    {
      "epoch": 1.6777877582445786,
      "grad_norm": 0.026358744129538536,
      "learning_rate": 0.000416113820094957,
      "loss": 0.0,
      "step": 26150
    },
    {
      "epoch": 1.6809957654305145,
      "grad_norm": 0.019708532840013504,
      "learning_rate": 0.0004159534197356602,
      "loss": 0.0,
      "step": 26200
    },
    {
      "epoch": 1.6842037726164507,
      "grad_norm": 0.0063986629247665405,
      "learning_rate": 0.00041579301937636344,
      "loss": 0.0,
      "step": 26250
    },
    {
      "epoch": 1.6874117798023867,
      "grad_norm": 0.012006212025880814,
      "learning_rate": 0.0004156326190170666,
      "loss": 0.0,
      "step": 26300
    },
    {
      "epoch": 1.6906197869883228,
      "grad_norm": 0.018615037202835083,
      "learning_rate": 0.0004154722186577698,
      "loss": 0.0,
      "step": 26350
    },
    {
      "epoch": 1.693827794174259,
      "grad_norm": 0.008688176982104778,
      "learning_rate": 0.00041531181829847295,
      "loss": 0.0,
      "step": 26400
    },
    {
      "epoch": 1.6970358013601952,
      "grad_norm": 0.020585104823112488,
      "learning_rate": 0.0004151514179391762,
      "loss": 0.0,
      "step": 26450
    },
    {
      "epoch": 1.700243808546131,
      "grad_norm": 0.024866845458745956,
      "learning_rate": 0.0004149910175798794,
      "loss": 0.0001,
      "step": 26500
    },
    {
      "epoch": 1.7034518157320673,
      "grad_norm": 0.027759075164794922,
      "learning_rate": 0.00041483061722058257,
      "loss": 0.0,
      "step": 26550
    },
    {
      "epoch": 1.7066598229180032,
      "grad_norm": 0.00932740606367588,
      "learning_rate": 0.0004146702168612858,
      "loss": 0.0,
      "step": 26600
    },
    {
      "epoch": 1.7098678301039394,
      "grad_norm": 0.011559991165995598,
      "learning_rate": 0.000414509816501989,
      "loss": 0.0,
      "step": 26650
    },
    {
      "epoch": 1.7130758372898756,
      "grad_norm": 0.020091013982892036,
      "learning_rate": 0.0004143494161426922,
      "loss": 0.0,
      "step": 26700
    },
    {
      "epoch": 1.7162838444758117,
      "grad_norm": 0.02437407150864601,
      "learning_rate": 0.00041418901578339534,
      "loss": 0.0,
      "step": 26750
    },
    {
      "epoch": 1.7194918516617477,
      "grad_norm": 0.01007452979683876,
      "learning_rate": 0.00041402861542409855,
      "loss": 0.0,
      "step": 26800
    },
    {
      "epoch": 1.7226998588476838,
      "grad_norm": 0.04460136964917183,
      "learning_rate": 0.00041386821506480176,
      "loss": 0.0,
      "step": 26850
    },
    {
      "epoch": 1.7259078660336198,
      "grad_norm": 0.019683727994561195,
      "learning_rate": 0.00041370781470550496,
      "loss": 0.0,
      "step": 26900
    },
    {
      "epoch": 1.729115873219556,
      "grad_norm": 0.03407219797372818,
      "learning_rate": 0.0004135474143462081,
      "loss": 0.0,
      "step": 26950
    },
    {
      "epoch": 1.7323238804054921,
      "grad_norm": 0.018387669697403908,
      "learning_rate": 0.0004133870139869114,
      "loss": 0.0,
      "step": 27000
    },
    {
      "epoch": 1.7355318875914283,
      "grad_norm": 0.0024037943221628666,
      "learning_rate": 0.00041322661362761453,
      "loss": 0.0,
      "step": 27050
    },
    {
      "epoch": 1.7387398947773645,
      "grad_norm": 0.009212483651936054,
      "learning_rate": 0.00041306621326831774,
      "loss": 0.0,
      "step": 27100
    },
    {
      "epoch": 1.7419479019633004,
      "grad_norm": 0.021756956353783607,
      "learning_rate": 0.0004129058129090209,
      "loss": 0.0001,
      "step": 27150
    },
    {
      "epoch": 1.7451559091492364,
      "grad_norm": 0.045792125165462494,
      "learning_rate": 0.00041274541254972415,
      "loss": 0.0,
      "step": 27200
    },
    {
      "epoch": 1.7483639163351725,
      "grad_norm": 0.013289188966155052,
      "learning_rate": 0.0004125850121904273,
      "loss": 0.0,
      "step": 27250
    },
    {
      "epoch": 1.7515719235211087,
      "grad_norm": 0.02783150225877762,
      "learning_rate": 0.0004124246118311305,
      "loss": 0.0,
      "step": 27300
    },
    {
      "epoch": 1.7547799307070449,
      "grad_norm": 0.011633715592324734,
      "learning_rate": 0.00041226421147183366,
      "loss": 0.0,
      "step": 27350
    },
    {
      "epoch": 1.757987937892981,
      "grad_norm": 0.004621501080691814,
      "learning_rate": 0.0004121038111125369,
      "loss": 0.0,
      "step": 27400
    },
    {
      "epoch": 1.761195945078917,
      "grad_norm": 0.053757570683956146,
      "learning_rate": 0.0004119434107532401,
      "loss": 0.0,
      "step": 27450
    },
    {
      "epoch": 1.764403952264853,
      "grad_norm": 0.02271142229437828,
      "learning_rate": 0.0004117830103939433,
      "loss": 0.0,
      "step": 27500
    },
    {
      "epoch": 1.767611959450789,
      "grad_norm": 0.012823696248233318,
      "learning_rate": 0.00041162261003464644,
      "loss": 0.0,
      "step": 27550
    },
    {
      "epoch": 1.7708199666367253,
      "grad_norm": 0.020381009206175804,
      "learning_rate": 0.0004114622096753497,
      "loss": 0.0,
      "step": 27600
    },
    {
      "epoch": 1.7740279738226614,
      "grad_norm": 0.042032212018966675,
      "learning_rate": 0.00041130180931605285,
      "loss": 0.0,
      "step": 27650
    },
    {
      "epoch": 1.7772359810085976,
      "grad_norm": 0.043526869267225266,
      "learning_rate": 0.00041114140895675606,
      "loss": 0.0001,
      "step": 27700
    },
    {
      "epoch": 1.7804439881945335,
      "grad_norm": 0.028264876455068588,
      "learning_rate": 0.0004109810085974593,
      "loss": 0.0001,
      "step": 27750
    },
    {
      "epoch": 1.7836519953804697,
      "grad_norm": 0.01986582763493061,
      "learning_rate": 0.0004108206082381625,
      "loss": 0.0,
      "step": 27800
    },
    {
      "epoch": 1.7868600025664056,
      "grad_norm": 0.017591167241334915,
      "learning_rate": 0.0004106602078788657,
      "loss": 0.0001,
      "step": 27850
    },
    {
      "epoch": 1.7900680097523418,
      "grad_norm": 0.0211521927267313,
      "learning_rate": 0.00041049980751956883,
      "loss": 0.0,
      "step": 27900
    },
    {
      "epoch": 1.793276016938278,
      "grad_norm": 0.013562032952904701,
      "learning_rate": 0.0004103394071602721,
      "loss": 0.0,
      "step": 27950
    },
    {
      "epoch": 1.7964840241242142,
      "grad_norm": 0.02654021978378296,
      "learning_rate": 0.00041017900680097525,
      "loss": 0.0,
      "step": 28000
    },
    {
      "epoch": 1.79969203131015,
      "grad_norm": 0.015506915748119354,
      "learning_rate": 0.00041001860644167845,
      "loss": 0.0,
      "step": 28050
    },
    {
      "epoch": 1.8029000384960863,
      "grad_norm": 0.01318699773401022,
      "learning_rate": 0.0004098582060823816,
      "loss": 0.0,
      "step": 28100
    },
    {
      "epoch": 1.8061080456820222,
      "grad_norm": 0.011344607919454575,
      "learning_rate": 0.00040969780572308487,
      "loss": 0.0,
      "step": 28150
    },
    {
      "epoch": 1.8093160528679584,
      "grad_norm": 0.003591895569115877,
      "learning_rate": 0.000409537405363788,
      "loss": 0.0,
      "step": 28200
    },
    {
      "epoch": 1.8125240600538945,
      "grad_norm": 0.024938860908150673,
      "learning_rate": 0.00040937700500449123,
      "loss": 0.0,
      "step": 28250
    },
    {
      "epoch": 1.8157320672398307,
      "grad_norm": 0.010243238881230354,
      "learning_rate": 0.0004092166046451944,
      "loss": 0.0,
      "step": 28300
    },
    {
      "epoch": 1.8189400744257667,
      "grad_norm": 0.007456083782017231,
      "learning_rate": 0.00040905620428589764,
      "loss": 0.0,
      "step": 28350
    },
    {
      "epoch": 1.8221480816117028,
      "grad_norm": 0.01689486764371395,
      "learning_rate": 0.0004088958039266008,
      "loss": 0.0001,
      "step": 28400
    },
    {
      "epoch": 1.8253560887976388,
      "grad_norm": 0.009508066810667515,
      "learning_rate": 0.000408735403567304,
      "loss": 0.0001,
      "step": 28450
    },
    {
      "epoch": 1.828564095983575,
      "grad_norm": 0.019763456657528877,
      "learning_rate": 0.00040857500320800715,
      "loss": 0.0001,
      "step": 28500
    },
    {
      "epoch": 1.8317721031695111,
      "grad_norm": 0.0056946733966469765,
      "learning_rate": 0.0004084146028487104,
      "loss": 0.0,
      "step": 28550
    },
    {
      "epoch": 1.8349801103554473,
      "grad_norm": 0.01772553287446499,
      "learning_rate": 0.00040825420248941357,
      "loss": 0.0,
      "step": 28600
    },
    {
      "epoch": 1.8381881175413834,
      "grad_norm": 0.031079327687621117,
      "learning_rate": 0.0004080938021301168,
      "loss": 0.0,
      "step": 28650
    },
    {
      "epoch": 1.8413961247273194,
      "grad_norm": 0.006431609392166138,
      "learning_rate": 0.00040793340177082,
      "loss": 0.0,
      "step": 28700
    },
    {
      "epoch": 1.8446041319132553,
      "grad_norm": 0.007933424785733223,
      "learning_rate": 0.0004077730014115232,
      "loss": 0.0,
      "step": 28750
    },
    {
      "epoch": 1.8478121390991915,
      "grad_norm": 0.0032242753077298403,
      "learning_rate": 0.00040761260105222634,
      "loss": 0.0,
      "step": 28800
    },
    {
      "epoch": 1.8510201462851277,
      "grad_norm": 0.008900674991309643,
      "learning_rate": 0.00040745220069292955,
      "loss": 0.0,
      "step": 28850
    },
    {
      "epoch": 1.8542281534710638,
      "grad_norm": 0.030154187232255936,
      "learning_rate": 0.00040729180033363275,
      "loss": 0.0,
      "step": 28900
    },
    {
      "epoch": 1.857436160657,
      "grad_norm": 0.009755738079547882,
      "learning_rate": 0.00040713139997433596,
      "loss": 0.0,
      "step": 28950
    },
    {
      "epoch": 1.860644167842936,
      "grad_norm": 0.01902947388589382,
      "learning_rate": 0.0004069709996150391,
      "loss": 0.0,
      "step": 29000
    },
    {
      "epoch": 1.863852175028872,
      "grad_norm": 0.016514604911208153,
      "learning_rate": 0.0004068105992557423,
      "loss": 0.0,
      "step": 29050
    },
    {
      "epoch": 1.867060182214808,
      "grad_norm": 0.03276082128286362,
      "learning_rate": 0.0004066501988964456,
      "loss": 0.0,
      "step": 29100
    },
    {
      "epoch": 1.8702681894007442,
      "grad_norm": 0.0300283282995224,
      "learning_rate": 0.00040648979853714874,
      "loss": 0.0,
      "step": 29150
    },
    {
      "epoch": 1.8734761965866804,
      "grad_norm": 0.010997781530022621,
      "learning_rate": 0.00040632939817785194,
      "loss": 0.0,
      "step": 29200
    },
    {
      "epoch": 1.8766842037726166,
      "grad_norm": 0.021978206932544708,
      "learning_rate": 0.0004061689978185551,
      "loss": 0.0,
      "step": 29250
    },
    {
      "epoch": 1.8798922109585525,
      "grad_norm": 0.030819818377494812,
      "learning_rate": 0.00040600859745925836,
      "loss": 0.0,
      "step": 29300
    },
    {
      "epoch": 1.8831002181444887,
      "grad_norm": 0.01304661389440298,
      "learning_rate": 0.0004058481970999615,
      "loss": 0.0,
      "step": 29350
    },
    {
      "epoch": 1.8863082253304246,
      "grad_norm": 0.024300595745444298,
      "learning_rate": 0.0004056877967406647,
      "loss": 0.0,
      "step": 29400
    },
    {
      "epoch": 1.8895162325163608,
      "grad_norm": 0.047703247517347336,
      "learning_rate": 0.0004055273963813679,
      "loss": 0.0001,
      "step": 29450
    },
    {
      "epoch": 1.892724239702297,
      "grad_norm": 0.007822425104677677,
      "learning_rate": 0.00040536699602207113,
      "loss": 0.0001,
      "step": 29500
    },
    {
      "epoch": 1.8959322468882331,
      "grad_norm": 0.06114881858229637,
      "learning_rate": 0.0004052065956627743,
      "loss": 0.0,
      "step": 29550
    },
    {
      "epoch": 1.899140254074169,
      "grad_norm": 0.02261267602443695,
      "learning_rate": 0.0004050461953034775,
      "loss": 0.0,
      "step": 29600
    },
    {
      "epoch": 1.9023482612601053,
      "grad_norm": 0.022186266258358955,
      "learning_rate": 0.0004048857949441807,
      "loss": 0.0,
      "step": 29650
    },
    {
      "epoch": 1.9055562684460412,
      "grad_norm": 0.013339631259441376,
      "learning_rate": 0.0004047253945848839,
      "loss": 0.0,
      "step": 29700
    },
    {
      "epoch": 1.9087642756319774,
      "grad_norm": 0.0371321365237236,
      "learning_rate": 0.00040456499422558706,
      "loss": 0.0,
      "step": 29750
    },
    {
      "epoch": 1.9119722828179135,
      "grad_norm": 0.007946411147713661,
      "learning_rate": 0.00040440459386629026,
      "loss": 0.0,
      "step": 29800
    },
    {
      "epoch": 1.9151802900038497,
      "grad_norm": 0.018594926223158836,
      "learning_rate": 0.00040424419350699347,
      "loss": 0.0,
      "step": 29850
    },
    {
      "epoch": 1.9183882971897857,
      "grad_norm": 0.007607107982039452,
      "learning_rate": 0.0004040837931476967,
      "loss": 0.0,
      "step": 29900
    },
    {
      "epoch": 1.9215963043757218,
      "grad_norm": 0.008667634800076485,
      "learning_rate": 0.00040392339278839983,
      "loss": 0.0,
      "step": 29950
    },
    {
      "epoch": 1.9248043115616578,
      "grad_norm": 0.03404998779296875,
      "learning_rate": 0.00040376299242910304,
      "loss": 0.0,
      "step": 30000
    },
    {
      "epoch": 1.928012318747594,
      "grad_norm": 0.010371292009949684,
      "learning_rate": 0.00040360259206980624,
      "loss": 0.0,
      "step": 30050
    },
    {
      "epoch": 1.93122032593353,
      "grad_norm": 0.05014650151133537,
      "learning_rate": 0.00040344219171050945,
      "loss": 0.0,
      "step": 30100
    },
    {
      "epoch": 1.9344283331194663,
      "grad_norm": 0.03067471832036972,
      "learning_rate": 0.0004032817913512126,
      "loss": 0.0,
      "step": 30150
    },
    {
      "epoch": 1.9376363403054024,
      "grad_norm": 0.034115638583898544,
      "learning_rate": 0.0004031213909919158,
      "loss": 0.0,
      "step": 30200
    },
    {
      "epoch": 1.9408443474913384,
      "grad_norm": 0.01970476284623146,
      "learning_rate": 0.000402960990632619,
      "loss": 0.0001,
      "step": 30250
    },
    {
      "epoch": 1.9440523546772743,
      "grad_norm": 0.005821481347084045,
      "learning_rate": 0.0004028005902733222,
      "loss": 0.0,
      "step": 30300
    },
    {
      "epoch": 1.9472603618632105,
      "grad_norm": 0.017446067184209824,
      "learning_rate": 0.0004026401899140254,
      "loss": 0.0,
      "step": 30350
    },
    {
      "epoch": 1.9504683690491467,
      "grad_norm": 0.01713741011917591,
      "learning_rate": 0.00040247978955472864,
      "loss": 0.0,
      "step": 30400
    },
    {
      "epoch": 1.9536763762350828,
      "grad_norm": 0.04407334700226784,
      "learning_rate": 0.0004023193891954318,
      "loss": 0.0,
      "step": 30450
    },
    {
      "epoch": 1.956884383421019,
      "grad_norm": 0.010415490716695786,
      "learning_rate": 0.000402158988836135,
      "loss": 0.0,
      "step": 30500
    },
    {
      "epoch": 1.960092390606955,
      "grad_norm": 0.014662661589682102,
      "learning_rate": 0.0004019985884768382,
      "loss": 0.0,
      "step": 30550
    },
    {
      "epoch": 1.963300397792891,
      "grad_norm": 0.03168296813964844,
      "learning_rate": 0.0004018381881175414,
      "loss": 0.0,
      "step": 30600
    },
    {
      "epoch": 1.966508404978827,
      "grad_norm": 0.03255632892251015,
      "learning_rate": 0.0004016777877582446,
      "loss": 0.0,
      "step": 30650
    },
    {
      "epoch": 1.9697164121647632,
      "grad_norm": 0.008186847902834415,
      "learning_rate": 0.00040151738739894777,
      "loss": 0.0,
      "step": 30700
    },
    {
      "epoch": 1.9729244193506994,
      "grad_norm": 0.02009192854166031,
      "learning_rate": 0.000401356987039651,
      "loss": 0.0,
      "step": 30750
    },
    {
      "epoch": 1.9761324265366356,
      "grad_norm": 0.0176360122859478,
      "learning_rate": 0.0004011965866803542,
      "loss": 0.0,
      "step": 30800
    },
    {
      "epoch": 1.9793404337225715,
      "grad_norm": 0.047158434987068176,
      "learning_rate": 0.0004010361863210574,
      "loss": 0.0,
      "step": 30850
    },
    {
      "epoch": 1.9825484409085077,
      "grad_norm": 0.03309229761362076,
      "learning_rate": 0.00040087578596176055,
      "loss": 0.0001,
      "step": 30900
    },
    {
      "epoch": 1.9857564480944436,
      "grad_norm": 0.031813498586416245,
      "learning_rate": 0.00040071538560246375,
      "loss": 0.0,
      "step": 30950
    },
    {
      "epoch": 1.9889644552803798,
      "grad_norm": 0.012290417216718197,
      "learning_rate": 0.00040055498524316696,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 1.992172462466316,
      "grad_norm": 0.016961291432380676,
      "learning_rate": 0.00040039458488387017,
      "loss": 0.0,
      "step": 31050
    },
    {
      "epoch": 1.9953804696522521,
      "grad_norm": 0.008096273988485336,
      "learning_rate": 0.0004002341845245733,
      "loss": 0.0,
      "step": 31100
    },
    {
      "epoch": 1.998588476838188,
      "grad_norm": 0.009713374078273773,
      "learning_rate": 0.0004000737841652765,
      "loss": 0.0,
      "step": 31150
    },
    {
      "epoch": 2.001796484024124,
      "grad_norm": 0.021219003945589066,
      "learning_rate": 0.00039991338380597973,
      "loss": 0.0,
      "step": 31200
    },
    {
      "epoch": 2.00500449121006,
      "grad_norm": 0.03568968176841736,
      "learning_rate": 0.00039975298344668294,
      "loss": 0.0,
      "step": 31250
    },
    {
      "epoch": 2.0082124983959964,
      "grad_norm": 0.028933117166161537,
      "learning_rate": 0.0003995925830873861,
      "loss": 0.0,
      "step": 31300
    },
    {
      "epoch": 2.0114205055819325,
      "grad_norm": 0.027022462338209152,
      "learning_rate": 0.00039943218272808935,
      "loss": 0.0,
      "step": 31350
    },
    {
      "epoch": 2.0146285127678687,
      "grad_norm": 0.016384972259402275,
      "learning_rate": 0.0003992717823687925,
      "loss": 0.0001,
      "step": 31400
    },
    {
      "epoch": 2.017836519953805,
      "grad_norm": 0.009340094402432442,
      "learning_rate": 0.0003991113820094957,
      "loss": 0.0,
      "step": 31450
    },
    {
      "epoch": 2.0210445271397406,
      "grad_norm": 0.00999790895730257,
      "learning_rate": 0.00039895098165019887,
      "loss": 0.0,
      "step": 31500
    },
    {
      "epoch": 2.0242525343256768,
      "grad_norm": 0.0134780528023839,
      "learning_rate": 0.0003987905812909021,
      "loss": 0.0,
      "step": 31550
    },
    {
      "epoch": 2.027460541511613,
      "grad_norm": 0.00213862513191998,
      "learning_rate": 0.0003986301809316053,
      "loss": 0.0,
      "step": 31600
    },
    {
      "epoch": 2.030668548697549,
      "grad_norm": 0.009243199601769447,
      "learning_rate": 0.0003984697805723085,
      "loss": 0.0,
      "step": 31650
    },
    {
      "epoch": 2.0338765558834853,
      "grad_norm": 0.006217907648533583,
      "learning_rate": 0.00039830938021301164,
      "loss": 0.0,
      "step": 31700
    },
    {
      "epoch": 2.0370845630694214,
      "grad_norm": 0.022546738386154175,
      "learning_rate": 0.0003981489798537149,
      "loss": 0.0,
      "step": 31750
    },
    {
      "epoch": 2.0402925702553576,
      "grad_norm": 0.0179719477891922,
      "learning_rate": 0.00039798857949441805,
      "loss": 0.0,
      "step": 31800
    },
    {
      "epoch": 2.0435005774412933,
      "grad_norm": 0.03256244584918022,
      "learning_rate": 0.00039782817913512126,
      "loss": 0.0,
      "step": 31850
    },
    {
      "epoch": 2.0467085846272295,
      "grad_norm": 0.010539829730987549,
      "learning_rate": 0.00039766777877582447,
      "loss": 0.0001,
      "step": 31900
    },
    {
      "epoch": 2.0499165918131657,
      "grad_norm": 0.003589347703382373,
      "learning_rate": 0.0003975073784165277,
      "loss": 0.0,
      "step": 31950
    },
    {
      "epoch": 2.053124598999102,
      "grad_norm": 0.022874418646097183,
      "learning_rate": 0.0003973469780572309,
      "loss": 0.0,
      "step": 32000
    },
    {
      "epoch": 2.056332606185038,
      "grad_norm": 0.008626330643892288,
      "learning_rate": 0.00039718657769793403,
      "loss": 0.0,
      "step": 32050
    },
    {
      "epoch": 2.059540613370974,
      "grad_norm": 0.001721186563372612,
      "learning_rate": 0.0003970261773386373,
      "loss": 0.0,
      "step": 32100
    },
    {
      "epoch": 2.06274862055691,
      "grad_norm": 0.02507409267127514,
      "learning_rate": 0.00039686577697934045,
      "loss": 0.0,
      "step": 32150
    },
    {
      "epoch": 2.065956627742846,
      "grad_norm": 0.006196046248078346,
      "learning_rate": 0.00039670537662004365,
      "loss": 0.0,
      "step": 32200
    },
    {
      "epoch": 2.069164634928782,
      "grad_norm": 0.005679101217538118,
      "learning_rate": 0.0003965449762607468,
      "loss": 0.0,
      "step": 32250
    },
    {
      "epoch": 2.0723726421147184,
      "grad_norm": 0.02620951645076275,
      "learning_rate": 0.00039638457590145007,
      "loss": 0.0,
      "step": 32300
    },
    {
      "epoch": 2.0755806493006546,
      "grad_norm": 0.02748847007751465,
      "learning_rate": 0.0003962241755421532,
      "loss": 0.0,
      "step": 32350
    },
    {
      "epoch": 2.0787886564865907,
      "grad_norm": 0.014162622392177582,
      "learning_rate": 0.00039606377518285643,
      "loss": 0.0,
      "step": 32400
    },
    {
      "epoch": 2.0819966636725264,
      "grad_norm": 0.024130864068865776,
      "learning_rate": 0.0003959033748235596,
      "loss": 0.0,
      "step": 32450
    },
    {
      "epoch": 2.0852046708584626,
      "grad_norm": 0.020308196544647217,
      "learning_rate": 0.00039574297446426284,
      "loss": 0.0,
      "step": 32500
    },
    {
      "epoch": 2.088412678044399,
      "grad_norm": 0.029808323830366135,
      "learning_rate": 0.000395582574104966,
      "loss": 0.0,
      "step": 32550
    },
    {
      "epoch": 2.091620685230335,
      "grad_norm": 0.016314852982759476,
      "learning_rate": 0.0003954221737456692,
      "loss": 0.0,
      "step": 32600
    },
    {
      "epoch": 2.094828692416271,
      "grad_norm": 0.053201038390398026,
      "learning_rate": 0.00039526177338637235,
      "loss": 0.0001,
      "step": 32650
    },
    {
      "epoch": 2.0980366996022073,
      "grad_norm": 0.005391255486756563,
      "learning_rate": 0.0003951013730270756,
      "loss": 0.0,
      "step": 32700
    },
    {
      "epoch": 2.101244706788143,
      "grad_norm": 0.025032373145222664,
      "learning_rate": 0.00039494097266777877,
      "loss": 0.0,
      "step": 32750
    },
    {
      "epoch": 2.104452713974079,
      "grad_norm": 0.017051657661795616,
      "learning_rate": 0.000394780572308482,
      "loss": 0.0,
      "step": 32800
    },
    {
      "epoch": 2.1076607211600153,
      "grad_norm": 0.011123708449304104,
      "learning_rate": 0.00039462017194918513,
      "loss": 0.0,
      "step": 32850
    },
    {
      "epoch": 2.1108687283459515,
      "grad_norm": 0.02428933046758175,
      "learning_rate": 0.0003944597715898884,
      "loss": 0.0,
      "step": 32900
    },
    {
      "epoch": 2.1140767355318877,
      "grad_norm": 0.011335206218063831,
      "learning_rate": 0.00039429937123059154,
      "loss": 0.0,
      "step": 32950
    },
    {
      "epoch": 2.117284742717824,
      "grad_norm": 0.0106400391086936,
      "learning_rate": 0.00039413897087129475,
      "loss": 0.0,
      "step": 33000
    },
    {
      "epoch": 2.1204927499037596,
      "grad_norm": 0.012739704921841621,
      "learning_rate": 0.00039397857051199796,
      "loss": 0.0,
      "step": 33050
    },
    {
      "epoch": 2.1237007570896957,
      "grad_norm": 0.023938613012433052,
      "learning_rate": 0.00039381817015270116,
      "loss": 0.0,
      "step": 33100
    },
    {
      "epoch": 2.126908764275632,
      "grad_norm": 0.017898045480251312,
      "learning_rate": 0.0003936577697934043,
      "loss": 0.0,
      "step": 33150
    },
    {
      "epoch": 2.130116771461568,
      "grad_norm": 0.0220941174775362,
      "learning_rate": 0.0003934973694341075,
      "loss": 0.0,
      "step": 33200
    },
    {
      "epoch": 2.1333247786475042,
      "grad_norm": 0.035605017095804214,
      "learning_rate": 0.0003933369690748108,
      "loss": 0.0001,
      "step": 33250
    },
    {
      "epoch": 2.1365327858334404,
      "grad_norm": 0.011239014565944672,
      "learning_rate": 0.00039317656871551394,
      "loss": 0.0,
      "step": 33300
    },
    {
      "epoch": 2.139740793019376,
      "grad_norm": 0.019635362550616264,
      "learning_rate": 0.00039301616835621714,
      "loss": 0.0,
      "step": 33350
    },
    {
      "epoch": 2.1429488002053123,
      "grad_norm": 0.008336287923157215,
      "learning_rate": 0.0003928557679969203,
      "loss": 0.0,
      "step": 33400
    },
    {
      "epoch": 2.1461568073912485,
      "grad_norm": 0.010092330165207386,
      "learning_rate": 0.00039269536763762356,
      "loss": 0.0,
      "step": 33450
    },
    {
      "epoch": 2.1493648145771846,
      "grad_norm": 0.014520355500280857,
      "learning_rate": 0.0003925349672783267,
      "loss": 0.0,
      "step": 33500
    },
    {
      "epoch": 2.152572821763121,
      "grad_norm": 0.012941889464855194,
      "learning_rate": 0.0003923745669190299,
      "loss": 0.0,
      "step": 33550
    },
    {
      "epoch": 2.155780828949057,
      "grad_norm": 0.03989197686314583,
      "learning_rate": 0.00039221416655973307,
      "loss": 0.0001,
      "step": 33600
    },
    {
      "epoch": 2.158988836134993,
      "grad_norm": 0.01809437945485115,
      "learning_rate": 0.00039205376620043633,
      "loss": 0.0,
      "step": 33650
    },
    {
      "epoch": 2.162196843320929,
      "grad_norm": 0.0029674433171749115,
      "learning_rate": 0.0003918933658411395,
      "loss": 0.0,
      "step": 33700
    },
    {
      "epoch": 2.165404850506865,
      "grad_norm": 0.0177397970110178,
      "learning_rate": 0.0003917329654818427,
      "loss": 0.0,
      "step": 33750
    },
    {
      "epoch": 2.168612857692801,
      "grad_norm": 0.019017349928617477,
      "learning_rate": 0.0003915725651225459,
      "loss": 0.0,
      "step": 33800
    },
    {
      "epoch": 2.1718208648787374,
      "grad_norm": 0.01573382504284382,
      "learning_rate": 0.0003914121647632491,
      "loss": 0.0,
      "step": 33850
    },
    {
      "epoch": 2.1750288720646735,
      "grad_norm": 0.003181266598403454,
      "learning_rate": 0.00039125176440395226,
      "loss": 0.0,
      "step": 33900
    },
    {
      "epoch": 2.1782368792506097,
      "grad_norm": 0.006828230805695057,
      "learning_rate": 0.00039109136404465546,
      "loss": 0.0,
      "step": 33950
    },
    {
      "epoch": 2.1814448864365454,
      "grad_norm": 0.00730282673612237,
      "learning_rate": 0.00039093096368535867,
      "loss": 0.0,
      "step": 34000
    },
    {
      "epoch": 2.1846528936224816,
      "grad_norm": 0.0038629614282399416,
      "learning_rate": 0.0003907705633260619,
      "loss": 0.0,
      "step": 34050
    },
    {
      "epoch": 2.1878609008084178,
      "grad_norm": 0.017579663544893265,
      "learning_rate": 0.00039061016296676503,
      "loss": 0.0,
      "step": 34100
    },
    {
      "epoch": 2.191068907994354,
      "grad_norm": 0.004743786063045263,
      "learning_rate": 0.00039044976260746824,
      "loss": 0.0,
      "step": 34150
    },
    {
      "epoch": 2.19427691518029,
      "grad_norm": 0.0073910607025027275,
      "learning_rate": 0.00039028936224817144,
      "loss": 0.0,
      "step": 34200
    },
    {
      "epoch": 2.1974849223662263,
      "grad_norm": 0.005254733841866255,
      "learning_rate": 0.00039012896188887465,
      "loss": 0.0,
      "step": 34250
    },
    {
      "epoch": 2.200692929552162,
      "grad_norm": 0.013990447856485844,
      "learning_rate": 0.0003899685615295778,
      "loss": 0.0,
      "step": 34300
    },
    {
      "epoch": 2.203900936738098,
      "grad_norm": 0.029887065291404724,
      "learning_rate": 0.000389808161170281,
      "loss": 0.0,
      "step": 34350
    },
    {
      "epoch": 2.2071089439240343,
      "grad_norm": 0.010001816786825657,
      "learning_rate": 0.0003896477608109842,
      "loss": 0.0,
      "step": 34400
    },
    {
      "epoch": 2.2103169511099705,
      "grad_norm": 0.014854597859084606,
      "learning_rate": 0.0003894873604516874,
      "loss": 0.0,
      "step": 34450
    },
    {
      "epoch": 2.2135249582959067,
      "grad_norm": 0.03698276728391647,
      "learning_rate": 0.0003893269600923906,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 2.216732965481843,
      "grad_norm": 0.0360669381916523,
      "learning_rate": 0.0003891665597330938,
      "loss": 0.0001,
      "step": 34550
    },
    {
      "epoch": 2.2199409726677786,
      "grad_norm": 0.018452739343047142,
      "learning_rate": 0.00038900615937379705,
      "loss": 0.0,
      "step": 34600
    },
    {
      "epoch": 2.2231489798537147,
      "grad_norm": 0.026504376903176308,
      "learning_rate": 0.0003888457590145002,
      "loss": 0.0,
      "step": 34650
    },
    {
      "epoch": 2.226356987039651,
      "grad_norm": 0.012180193327367306,
      "learning_rate": 0.0003886853586552034,
      "loss": 0.0,
      "step": 34700
    },
    {
      "epoch": 2.229564994225587,
      "grad_norm": 0.016287626698613167,
      "learning_rate": 0.0003885249582959066,
      "loss": 0.0,
      "step": 34750
    },
    {
      "epoch": 2.2327730014115232,
      "grad_norm": 0.014529164880514145,
      "learning_rate": 0.0003883645579366098,
      "loss": 0.0,
      "step": 34800
    },
    {
      "epoch": 2.2359810085974594,
      "grad_norm": 0.024342965334653854,
      "learning_rate": 0.00038820415757731297,
      "loss": 0.0,
      "step": 34850
    },
    {
      "epoch": 2.2391890157833956,
      "grad_norm": 0.019227074459195137,
      "learning_rate": 0.0003880437572180162,
      "loss": 0.0,
      "step": 34900
    },
    {
      "epoch": 2.2423970229693313,
      "grad_norm": 0.007582670543342829,
      "learning_rate": 0.0003878833568587194,
      "loss": 0.0,
      "step": 34950
    },
    {
      "epoch": 2.2456050301552675,
      "grad_norm": 0.008364438079297543,
      "learning_rate": 0.0003877229564994226,
      "loss": 0.0,
      "step": 35000
    },
    {
      "epoch": 2.2488130373412036,
      "grad_norm": 0.0433962307870388,
      "learning_rate": 0.00038756255614012575,
      "loss": 0.0,
      "step": 35050
    },
    {
      "epoch": 2.25202104452714,
      "grad_norm": 0.0053907777182757854,
      "learning_rate": 0.00038740215578082895,
      "loss": 0.0,
      "step": 35100
    },
    {
      "epoch": 2.255229051713076,
      "grad_norm": 0.02253677509725094,
      "learning_rate": 0.00038724175542153216,
      "loss": 0.0,
      "step": 35150
    },
    {
      "epoch": 2.2584370588990117,
      "grad_norm": 0.027236144989728928,
      "learning_rate": 0.00038708135506223537,
      "loss": 0.0,
      "step": 35200
    },
    {
      "epoch": 2.261645066084948,
      "grad_norm": 0.02064507268369198,
      "learning_rate": 0.0003869209547029385,
      "loss": 0.0,
      "step": 35250
    },
    {
      "epoch": 2.264853073270884,
      "grad_norm": 0.031409118324518204,
      "learning_rate": 0.0003867605543436417,
      "loss": 0.0,
      "step": 35300
    },
    {
      "epoch": 2.26806108045682,
      "grad_norm": 0.03002609685063362,
      "learning_rate": 0.00038660015398434493,
      "loss": 0.0,
      "step": 35350
    },
    {
      "epoch": 2.2712690876427564,
      "grad_norm": 0.04246745631098747,
      "learning_rate": 0.00038643975362504814,
      "loss": 0.0,
      "step": 35400
    },
    {
      "epoch": 2.2744770948286925,
      "grad_norm": 0.007778015919029713,
      "learning_rate": 0.0003862793532657513,
      "loss": 0.0,
      "step": 35450
    },
    {
      "epoch": 2.2776851020146287,
      "grad_norm": 0.017440836876630783,
      "learning_rate": 0.00038611895290645455,
      "loss": 0.0,
      "step": 35500
    },
    {
      "epoch": 2.2808931092005644,
      "grad_norm": 0.021555675193667412,
      "learning_rate": 0.0003859585525471577,
      "loss": 0.0,
      "step": 35550
    },
    {
      "epoch": 2.2841011163865006,
      "grad_norm": 0.005316232331097126,
      "learning_rate": 0.0003857981521878609,
      "loss": 0.0,
      "step": 35600
    },
    {
      "epoch": 2.2873091235724368,
      "grad_norm": 0.008419161662459373,
      "learning_rate": 0.00038563775182856407,
      "loss": 0.0,
      "step": 35650
    },
    {
      "epoch": 2.290517130758373,
      "grad_norm": 0.006016105879098177,
      "learning_rate": 0.00038547735146926733,
      "loss": 0.0,
      "step": 35700
    },
    {
      "epoch": 2.293725137944309,
      "grad_norm": 0.02193201333284378,
      "learning_rate": 0.0003853169511099705,
      "loss": 0.0,
      "step": 35750
    },
    {
      "epoch": 2.2969331451302453,
      "grad_norm": 0.007347661070525646,
      "learning_rate": 0.0003851565507506737,
      "loss": 0.0,
      "step": 35800
    },
    {
      "epoch": 2.300141152316181,
      "grad_norm": 0.007921009324491024,
      "learning_rate": 0.00038499615039137684,
      "loss": 0.0,
      "step": 35850
    },
    {
      "epoch": 2.303349159502117,
      "grad_norm": 0.020514963194727898,
      "learning_rate": 0.0003848357500320801,
      "loss": 0.0,
      "step": 35900
    },
    {
      "epoch": 2.3065571666880533,
      "grad_norm": 0.006400551181286573,
      "learning_rate": 0.00038467534967278325,
      "loss": 0.0,
      "step": 35950
    },
    {
      "epoch": 2.3097651738739895,
      "grad_norm": 0.003612233093008399,
      "learning_rate": 0.00038451494931348646,
      "loss": 0.0,
      "step": 36000
    },
    {
      "epoch": 2.3129731810599257,
      "grad_norm": 0.02695045806467533,
      "learning_rate": 0.00038435454895418967,
      "loss": 0.0,
      "step": 36050
    },
    {
      "epoch": 2.316181188245862,
      "grad_norm": 0.03248979523777962,
      "learning_rate": 0.0003841941485948929,
      "loss": 0.0,
      "step": 36100
    },
    {
      "epoch": 2.319389195431798,
      "grad_norm": 0.0032649575732648373,
      "learning_rate": 0.0003840337482355961,
      "loss": 0.0,
      "step": 36150
    },
    {
      "epoch": 2.3225972026177337,
      "grad_norm": 0.011008513160049915,
      "learning_rate": 0.00038387334787629923,
      "loss": 0.0,
      "step": 36200
    },
    {
      "epoch": 2.32580520980367,
      "grad_norm": 0.024994686245918274,
      "learning_rate": 0.00038371294751700244,
      "loss": 0.0,
      "step": 36250
    },
    {
      "epoch": 2.329013216989606,
      "grad_norm": 0.013297054916620255,
      "learning_rate": 0.00038355254715770565,
      "loss": 0.0,
      "step": 36300
    },
    {
      "epoch": 2.3322212241755422,
      "grad_norm": 0.011917561292648315,
      "learning_rate": 0.00038339214679840886,
      "loss": 0.0,
      "step": 36350
    },
    {
      "epoch": 2.3354292313614784,
      "grad_norm": 0.038464948534965515,
      "learning_rate": 0.000383231746439112,
      "loss": 0.0001,
      "step": 36400
    },
    {
      "epoch": 2.338637238547414,
      "grad_norm": 0.00913381576538086,
      "learning_rate": 0.00038307134607981527,
      "loss": 0.0,
      "step": 36450
    },
    {
      "epoch": 2.3418452457333503,
      "grad_norm": 0.00870356522500515,
      "learning_rate": 0.0003829109457205184,
      "loss": 0.0,
      "step": 36500
    },
    {
      "epoch": 2.3450532529192865,
      "grad_norm": 0.004932771902531385,
      "learning_rate": 0.00038275054536122163,
      "loss": 0.0,
      "step": 36550
    },
    {
      "epoch": 2.3482612601052226,
      "grad_norm": 0.017219820991158485,
      "learning_rate": 0.0003825901450019248,
      "loss": 0.0,
      "step": 36600
    },
    {
      "epoch": 2.351469267291159,
      "grad_norm": 0.01690058968961239,
      "learning_rate": 0.00038242974464262804,
      "loss": 0.0,
      "step": 36650
    },
    {
      "epoch": 2.354677274477095,
      "grad_norm": 0.03179381415247917,
      "learning_rate": 0.0003822693442833312,
      "loss": 0.0,
      "step": 36700
    },
    {
      "epoch": 2.357885281663031,
      "grad_norm": 0.015046223066747189,
      "learning_rate": 0.0003821089439240344,
      "loss": 0.0,
      "step": 36750
    },
    {
      "epoch": 2.361093288848967,
      "grad_norm": 0.00823573675006628,
      "learning_rate": 0.00038194854356473756,
      "loss": 0.0,
      "step": 36800
    },
    {
      "epoch": 2.364301296034903,
      "grad_norm": 0.01998651586472988,
      "learning_rate": 0.0003817881432054408,
      "loss": 0.0,
      "step": 36850
    },
    {
      "epoch": 2.367509303220839,
      "grad_norm": 0.0363662913441658,
      "learning_rate": 0.00038162774284614397,
      "loss": 0.0,
      "step": 36900
    },
    {
      "epoch": 2.3707173104067754,
      "grad_norm": 0.03664163500070572,
      "learning_rate": 0.0003814673424868472,
      "loss": 0.0,
      "step": 36950
    },
    {
      "epoch": 2.3739253175927115,
      "grad_norm": 0.007306542247533798,
      "learning_rate": 0.00038130694212755033,
      "loss": 0.0,
      "step": 37000
    },
    {
      "epoch": 2.3771333247786477,
      "grad_norm": 0.01737004891037941,
      "learning_rate": 0.0003811465417682536,
      "loss": 0.0,
      "step": 37050
    },
    {
      "epoch": 2.3803413319645834,
      "grad_norm": 0.01889788545668125,
      "learning_rate": 0.00038098614140895674,
      "loss": 0.0,
      "step": 37100
    },
    {
      "epoch": 2.3835493391505196,
      "grad_norm": 0.011884588748216629,
      "learning_rate": 0.00038082574104965995,
      "loss": 0.0001,
      "step": 37150
    },
    {
      "epoch": 2.3867573463364558,
      "grad_norm": 0.018823277205228806,
      "learning_rate": 0.0003806653406903631,
      "loss": 0.0,
      "step": 37200
    },
    {
      "epoch": 2.389965353522392,
      "grad_norm": 0.006336897145956755,
      "learning_rate": 0.00038050494033106636,
      "loss": 0.0,
      "step": 37250
    },
    {
      "epoch": 2.393173360708328,
      "grad_norm": 0.020069580525159836,
      "learning_rate": 0.0003803445399717695,
      "loss": 0.0,
      "step": 37300
    },
    {
      "epoch": 2.3963813678942643,
      "grad_norm": 0.00856098998337984,
      "learning_rate": 0.0003801841396124727,
      "loss": 0.0,
      "step": 37350
    },
    {
      "epoch": 2.3995893750802004,
      "grad_norm": 0.02439139224588871,
      "learning_rate": 0.000380023739253176,
      "loss": 0.0,
      "step": 37400
    },
    {
      "epoch": 2.402797382266136,
      "grad_norm": 0.008065231144428253,
      "learning_rate": 0.00037986333889387914,
      "loss": 0.0,
      "step": 37450
    },
    {
      "epoch": 2.4060053894520723,
      "grad_norm": 0.0056738946586847305,
      "learning_rate": 0.00037970293853458234,
      "loss": 0.0,
      "step": 37500
    },
    {
      "epoch": 2.4092133966380085,
      "grad_norm": 0.028811246156692505,
      "learning_rate": 0.0003795425381752855,
      "loss": 0.0,
      "step": 37550
    },
    {
      "epoch": 2.4124214038239447,
      "grad_norm": 0.02626415155827999,
      "learning_rate": 0.00037938213781598876,
      "loss": 0.0,
      "step": 37600
    },
    {
      "epoch": 2.415629411009881,
      "grad_norm": 0.0069271414540708065,
      "learning_rate": 0.0003792217374566919,
      "loss": 0.0,
      "step": 37650
    },
    {
      "epoch": 2.4188374181958165,
      "grad_norm": 0.01644217036664486,
      "learning_rate": 0.0003790613370973951,
      "loss": 0.0,
      "step": 37700
    },
    {
      "epoch": 2.4220454253817527,
      "grad_norm": 0.0047096749767661095,
      "learning_rate": 0.00037890093673809827,
      "loss": 0.0,
      "step": 37750
    },
    {
      "epoch": 2.425253432567689,
      "grad_norm": 0.025797605514526367,
      "learning_rate": 0.00037874053637880153,
      "loss": 0.0,
      "step": 37800
    },
    {
      "epoch": 2.428461439753625,
      "grad_norm": 0.0229424349963665,
      "learning_rate": 0.0003785801360195047,
      "loss": 0.0,
      "step": 37850
    },
    {
      "epoch": 2.431669446939561,
      "grad_norm": 0.002694950671866536,
      "learning_rate": 0.0003784197356602079,
      "loss": 0.0,
      "step": 37900
    },
    {
      "epoch": 2.4348774541254974,
      "grad_norm": 0.014425263740122318,
      "learning_rate": 0.00037825933530091104,
      "loss": 0.0,
      "step": 37950
    },
    {
      "epoch": 2.4380854613114336,
      "grad_norm": 0.03526074439287186,
      "learning_rate": 0.0003780989349416143,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 2.4412934684973693,
      "grad_norm": 0.030618466436862946,
      "learning_rate": 0.00037793853458231746,
      "loss": 0.0,
      "step": 38050
    },
    {
      "epoch": 2.4445014756833054,
      "grad_norm": 0.032288193702697754,
      "learning_rate": 0.00037777813422302067,
      "loss": 0.0,
      "step": 38100
    },
    {
      "epoch": 2.4477094828692416,
      "grad_norm": 0.017384132370352745,
      "learning_rate": 0.00037761773386372387,
      "loss": 0.0,
      "step": 38150
    },
    {
      "epoch": 2.450917490055178,
      "grad_norm": 0.030356502160429955,
      "learning_rate": 0.0003774573335044271,
      "loss": 0.0,
      "step": 38200
    },
    {
      "epoch": 2.454125497241114,
      "grad_norm": 0.016922470182180405,
      "learning_rate": 0.00037729693314513023,
      "loss": 0.0,
      "step": 38250
    },
    {
      "epoch": 2.4573335044270497,
      "grad_norm": 0.021227223798632622,
      "learning_rate": 0.00037713653278583344,
      "loss": 0.0,
      "step": 38300
    },
    {
      "epoch": 2.460541511612986,
      "grad_norm": 0.023570910096168518,
      "learning_rate": 0.00037697613242653665,
      "loss": 0.0,
      "step": 38350
    },
    {
      "epoch": 2.463749518798922,
      "grad_norm": 0.007472035940736532,
      "learning_rate": 0.00037681573206723985,
      "loss": 0.0,
      "step": 38400
    },
    {
      "epoch": 2.466957525984858,
      "grad_norm": 0.018020709976553917,
      "learning_rate": 0.000376655331707943,
      "loss": 0.0,
      "step": 38450
    },
    {
      "epoch": 2.4701655331707943,
      "grad_norm": 0.013881458900868893,
      "learning_rate": 0.0003764949313486462,
      "loss": 0.0,
      "step": 38500
    },
    {
      "epoch": 2.4733735403567305,
      "grad_norm": 0.00719357468187809,
      "learning_rate": 0.0003763345309893494,
      "loss": 0.0,
      "step": 38550
    },
    {
      "epoch": 2.4765815475426667,
      "grad_norm": 0.032299984246492386,
      "learning_rate": 0.0003761741306300526,
      "loss": 0.0,
      "step": 38600
    },
    {
      "epoch": 2.4797895547286024,
      "grad_norm": 0.023470096290111542,
      "learning_rate": 0.0003760137302707558,
      "loss": 0.0,
      "step": 38650
    },
    {
      "epoch": 2.4829975619145386,
      "grad_norm": 0.018185514956712723,
      "learning_rate": 0.000375853329911459,
      "loss": 0.0,
      "step": 38700
    },
    {
      "epoch": 2.4862055691004747,
      "grad_norm": 0.01517408061772585,
      "learning_rate": 0.00037569292955216225,
      "loss": 0.0,
      "step": 38750
    },
    {
      "epoch": 2.489413576286411,
      "grad_norm": 0.007889569737017155,
      "learning_rate": 0.0003755325291928654,
      "loss": 0.0,
      "step": 38800
    },
    {
      "epoch": 2.492621583472347,
      "grad_norm": 0.031379446387290955,
      "learning_rate": 0.0003753721288335686,
      "loss": 0.0,
      "step": 38850
    },
    {
      "epoch": 2.4958295906582832,
      "grad_norm": 0.018198013305664062,
      "learning_rate": 0.00037521172847427176,
      "loss": 0.0,
      "step": 38900
    },
    {
      "epoch": 2.499037597844219,
      "grad_norm": 0.017611926421523094,
      "learning_rate": 0.000375051328114975,
      "loss": 0.0,
      "step": 38950
    },
    {
      "epoch": 2.502245605030155,
      "grad_norm": 0.013196895830333233,
      "learning_rate": 0.0003748909277556782,
      "loss": 0.0,
      "step": 39000
    },
    {
      "epoch": 2.5054536122160913,
      "grad_norm": 0.010383742861449718,
      "learning_rate": 0.0003747305273963814,
      "loss": 0.0,
      "step": 39050
    },
    {
      "epoch": 2.5086616194020275,
      "grad_norm": 0.011646630242466927,
      "learning_rate": 0.0003745701270370846,
      "loss": 0.0,
      "step": 39100
    },
    {
      "epoch": 2.5118696265879636,
      "grad_norm": 0.012553850188851357,
      "learning_rate": 0.0003744097266777878,
      "loss": 0.0,
      "step": 39150
    },
    {
      "epoch": 2.5150776337739,
      "grad_norm": 0.00655159167945385,
      "learning_rate": 0.00037424932631849095,
      "loss": 0.0,
      "step": 39200
    },
    {
      "epoch": 2.518285640959836,
      "grad_norm": 0.013497097417712212,
      "learning_rate": 0.00037408892595919415,
      "loss": 0.0,
      "step": 39250
    },
    {
      "epoch": 2.5214936481457717,
      "grad_norm": 0.013678588904440403,
      "learning_rate": 0.00037392852559989736,
      "loss": 0.0,
      "step": 39300
    },
    {
      "epoch": 2.524701655331708,
      "grad_norm": 0.0343705490231514,
      "learning_rate": 0.00037376812524060057,
      "loss": 0.0,
      "step": 39350
    },
    {
      "epoch": 2.527909662517644,
      "grad_norm": 0.011093749664723873,
      "learning_rate": 0.0003736077248813037,
      "loss": 0.0,
      "step": 39400
    },
    {
      "epoch": 2.53111766970358,
      "grad_norm": 0.006534963380545378,
      "learning_rate": 0.00037344732452200693,
      "loss": 0.0,
      "step": 39450
    },
    {
      "epoch": 2.5343256768895164,
      "grad_norm": 0.014148780144751072,
      "learning_rate": 0.00037328692416271013,
      "loss": 0.0,
      "step": 39500
    },
    {
      "epoch": 2.537533684075452,
      "grad_norm": 0.018580684438347816,
      "learning_rate": 0.00037312652380341334,
      "loss": 0.0,
      "step": 39550
    },
    {
      "epoch": 2.5407416912613883,
      "grad_norm": 0.007200786378234625,
      "learning_rate": 0.0003729661234441165,
      "loss": 0.0,
      "step": 39600
    },
    {
      "epoch": 2.5439496984473244,
      "grad_norm": 0.01597123220562935,
      "learning_rate": 0.0003728057230848197,
      "loss": 0.0,
      "step": 39650
    },
    {
      "epoch": 2.5471577056332606,
      "grad_norm": 0.006054268218576908,
      "learning_rate": 0.0003726453227255229,
      "loss": 0.0,
      "step": 39700
    },
    {
      "epoch": 2.5503657128191968,
      "grad_norm": 0.02412925288081169,
      "learning_rate": 0.0003724849223662261,
      "loss": 0.0,
      "step": 39750
    },
    {
      "epoch": 2.553573720005133,
      "grad_norm": 0.007635239977389574,
      "learning_rate": 0.00037232452200692927,
      "loss": 0.0,
      "step": 39800
    },
    {
      "epoch": 2.556781727191069,
      "grad_norm": 0.004093357361853123,
      "learning_rate": 0.00037216412164763253,
      "loss": 0.0,
      "step": 39850
    },
    {
      "epoch": 2.5599897343770053,
      "grad_norm": 0.023280784487724304,
      "learning_rate": 0.0003720037212883357,
      "loss": 0.0,
      "step": 39900
    },
    {
      "epoch": 2.563197741562941,
      "grad_norm": 0.0028537982143461704,
      "learning_rate": 0.0003718433209290389,
      "loss": 0.0,
      "step": 39950
    },
    {
      "epoch": 2.566405748748877,
      "grad_norm": 0.011454490013420582,
      "learning_rate": 0.00037168292056974204,
      "loss": 0.0,
      "step": 40000
    },
    {
      "epoch": 2.5696137559348133,
      "grad_norm": 0.013028000481426716,
      "learning_rate": 0.0003715225202104453,
      "loss": 0.0,
      "step": 40050
    },
    {
      "epoch": 2.5728217631207495,
      "grad_norm": 0.016055112704634666,
      "learning_rate": 0.0003713621198511485,
      "loss": 0.0,
      "step": 40100
    },
    {
      "epoch": 2.5760297703066852,
      "grad_norm": 0.008907120674848557,
      "learning_rate": 0.00037120171949185166,
      "loss": 0.0,
      "step": 40150
    },
    {
      "epoch": 2.5792377774926214,
      "grad_norm": 0.01233654748648405,
      "learning_rate": 0.00037104131913255487,
      "loss": 0.0,
      "step": 40200
    },
    {
      "epoch": 2.5824457846785576,
      "grad_norm": 0.01950586959719658,
      "learning_rate": 0.0003708809187732581,
      "loss": 0.0,
      "step": 40250
    },
    {
      "epoch": 2.5856537918644937,
      "grad_norm": 0.02947123907506466,
      "learning_rate": 0.0003707205184139613,
      "loss": 0.0,
      "step": 40300
    },
    {
      "epoch": 2.58886179905043,
      "grad_norm": 0.015612765215337276,
      "learning_rate": 0.00037056011805466444,
      "loss": 0.0,
      "step": 40350
    },
    {
      "epoch": 2.592069806236366,
      "grad_norm": 0.03022184409201145,
      "learning_rate": 0.00037039971769536764,
      "loss": 0.0,
      "step": 40400
    },
    {
      "epoch": 2.5952778134223022,
      "grad_norm": 0.014127570204436779,
      "learning_rate": 0.00037023931733607085,
      "loss": 0.0,
      "step": 40450
    },
    {
      "epoch": 2.5984858206082384,
      "grad_norm": 0.006074988748878241,
      "learning_rate": 0.00037007891697677406,
      "loss": 0.0,
      "step": 40500
    },
    {
      "epoch": 2.601693827794174,
      "grad_norm": 0.023887058719992638,
      "learning_rate": 0.0003699185166174772,
      "loss": 0.0,
      "step": 40550
    },
    {
      "epoch": 2.6049018349801103,
      "grad_norm": 0.005649708677083254,
      "learning_rate": 0.0003697581162581804,
      "loss": 0.0,
      "step": 40600
    },
    {
      "epoch": 2.6081098421660465,
      "grad_norm": 0.011789936572313309,
      "learning_rate": 0.0003695977158988836,
      "loss": 0.0,
      "step": 40650
    },
    {
      "epoch": 2.6113178493519826,
      "grad_norm": 0.011666600592434406,
      "learning_rate": 0.00036943731553958683,
      "loss": 0.0,
      "step": 40700
    },
    {
      "epoch": 2.614525856537919,
      "grad_norm": 0.01210401114076376,
      "learning_rate": 0.00036927691518029,
      "loss": 0.0,
      "step": 40750
    },
    {
      "epoch": 2.6177338637238545,
      "grad_norm": 0.005203903187066317,
      "learning_rate": 0.00036911651482099324,
      "loss": 0.0,
      "step": 40800
    },
    {
      "epoch": 2.6209418709097907,
      "grad_norm": 0.027699435129761696,
      "learning_rate": 0.0003689561144616964,
      "loss": 0.0,
      "step": 40850
    },
    {
      "epoch": 2.624149878095727,
      "grad_norm": 0.00996632594615221,
      "learning_rate": 0.0003687957141023996,
      "loss": 0.0,
      "step": 40900
    },
    {
      "epoch": 2.627357885281663,
      "grad_norm": 0.009921232238411903,
      "learning_rate": 0.00036863531374310276,
      "loss": 0.0,
      "step": 40950
    },
    {
      "epoch": 2.630565892467599,
      "grad_norm": 0.008475096896290779,
      "learning_rate": 0.000368474913383806,
      "loss": 0.0,
      "step": 41000
    },
    {
      "epoch": 2.6337738996535354,
      "grad_norm": 0.013275778852403164,
      "learning_rate": 0.00036831451302450917,
      "loss": 0.0,
      "step": 41050
    },
    {
      "epoch": 2.6369819068394715,
      "grad_norm": 0.023069215938448906,
      "learning_rate": 0.0003681541126652124,
      "loss": 0.0,
      "step": 41100
    },
    {
      "epoch": 2.6401899140254073,
      "grad_norm": 0.030935121700167656,
      "learning_rate": 0.00036799371230591553,
      "loss": 0.0,
      "step": 41150
    },
    {
      "epoch": 2.6433979212113434,
      "grad_norm": 0.0034688813611865044,
      "learning_rate": 0.0003678333119466188,
      "loss": 0.0,
      "step": 41200
    },
    {
      "epoch": 2.6466059283972796,
      "grad_norm": 0.003062974428758025,
      "learning_rate": 0.00036767291158732194,
      "loss": 0.0,
      "step": 41250
    },
    {
      "epoch": 2.6498139355832158,
      "grad_norm": 0.011113050393760204,
      "learning_rate": 0.00036751251122802515,
      "loss": 0.0,
      "step": 41300
    },
    {
      "epoch": 2.653021942769152,
      "grad_norm": 0.0071351658552885056,
      "learning_rate": 0.0003673521108687283,
      "loss": 0.0,
      "step": 41350
    },
    {
      "epoch": 2.6562299499550877,
      "grad_norm": 0.010238281451165676,
      "learning_rate": 0.00036719171050943156,
      "loss": 0.0,
      "step": 41400
    },
    {
      "epoch": 2.659437957141024,
      "grad_norm": 0.014428189024329185,
      "learning_rate": 0.00036703131015013477,
      "loss": 0.0,
      "step": 41450
    },
    {
      "epoch": 2.66264596432696,
      "grad_norm": 0.010325722396373749,
      "learning_rate": 0.0003668709097908379,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 2.665853971512896,
      "grad_norm": 0.021453358232975006,
      "learning_rate": 0.0003667105094315412,
      "loss": 0.0,
      "step": 41550
    },
    {
      "epoch": 2.6690619786988323,
      "grad_norm": 0.0058250706642866135,
      "learning_rate": 0.00036655010907224434,
      "loss": 0.0,
      "step": 41600
    },
    {
      "epoch": 2.6722699858847685,
      "grad_norm": 0.04618528485298157,
      "learning_rate": 0.00036638970871294755,
      "loss": 0.0,
      "step": 41650
    },
    {
      "epoch": 2.6754779930707047,
      "grad_norm": 0.028449812904000282,
      "learning_rate": 0.0003662293083536507,
      "loss": 0.0,
      "step": 41700
    },
    {
      "epoch": 2.678686000256641,
      "grad_norm": 0.010127485729753971,
      "learning_rate": 0.00036606890799435396,
      "loss": 0.0,
      "step": 41750
    },
    {
      "epoch": 2.6818940074425766,
      "grad_norm": 0.023908201605081558,
      "learning_rate": 0.0003659085076350571,
      "loss": 0.0,
      "step": 41800
    },
    {
      "epoch": 2.6851020146285127,
      "grad_norm": 0.007970794104039669,
      "learning_rate": 0.0003657481072757603,
      "loss": 0.0,
      "step": 41850
    },
    {
      "epoch": 2.688310021814449,
      "grad_norm": 0.013124149292707443,
      "learning_rate": 0.00036558770691646347,
      "loss": 0.0,
      "step": 41900
    },
    {
      "epoch": 2.691518029000385,
      "grad_norm": 0.015338270924985409,
      "learning_rate": 0.00036542730655716673,
      "loss": 0.0,
      "step": 41950
    },
    {
      "epoch": 2.694726036186321,
      "grad_norm": 0.030889082700014114,
      "learning_rate": 0.0003652669061978699,
      "loss": 0.0,
      "step": 42000
    },
    {
      "epoch": 2.697934043372257,
      "grad_norm": 0.024484002962708473,
      "learning_rate": 0.0003651065058385731,
      "loss": 0.0,
      "step": 42050
    },
    {
      "epoch": 2.701142050558193,
      "grad_norm": 0.022596247494220734,
      "learning_rate": 0.00036494610547927625,
      "loss": 0.0,
      "step": 42100
    },
    {
      "epoch": 2.7043500577441293,
      "grad_norm": 0.008535070344805717,
      "learning_rate": 0.0003647857051199795,
      "loss": 0.0,
      "step": 42150
    },
    {
      "epoch": 2.7075580649300655,
      "grad_norm": 0.03208252042531967,
      "learning_rate": 0.00036462530476068266,
      "loss": 0.0,
      "step": 42200
    },
    {
      "epoch": 2.7107660721160016,
      "grad_norm": 0.010437355376780033,
      "learning_rate": 0.00036446490440138587,
      "loss": 0.0,
      "step": 42250
    },
    {
      "epoch": 2.713974079301938,
      "grad_norm": 0.005864634644240141,
      "learning_rate": 0.000364304504042089,
      "loss": 0.0,
      "step": 42300
    },
    {
      "epoch": 2.717182086487874,
      "grad_norm": 0.0028857991565018892,
      "learning_rate": 0.0003641441036827923,
      "loss": 0.0,
      "step": 42350
    },
    {
      "epoch": 2.7203900936738097,
      "grad_norm": 0.005232800263911486,
      "learning_rate": 0.00036398370332349543,
      "loss": 0.0,
      "step": 42400
    },
    {
      "epoch": 2.723598100859746,
      "grad_norm": 0.02363819070160389,
      "learning_rate": 0.00036382330296419864,
      "loss": 0.0,
      "step": 42450
    },
    {
      "epoch": 2.726806108045682,
      "grad_norm": 0.01982635259628296,
      "learning_rate": 0.00036366290260490185,
      "loss": 0.0,
      "step": 42500
    },
    {
      "epoch": 2.730014115231618,
      "grad_norm": 0.00515716103836894,
      "learning_rate": 0.00036350250224560505,
      "loss": 0.0,
      "step": 42550
    },
    {
      "epoch": 2.7332221224175544,
      "grad_norm": 0.023032208904623985,
      "learning_rate": 0.0003633421018863082,
      "loss": 0.0,
      "step": 42600
    },
    {
      "epoch": 2.73643012960349,
      "grad_norm": 0.01732027530670166,
      "learning_rate": 0.0003631817015270114,
      "loss": 0.0,
      "step": 42650
    },
    {
      "epoch": 2.7396381367894262,
      "grad_norm": 0.020450739189982414,
      "learning_rate": 0.0003630213011677146,
      "loss": 0.0,
      "step": 42700
    },
    {
      "epoch": 2.7428461439753624,
      "grad_norm": 0.008078229613602161,
      "learning_rate": 0.00036286090080841783,
      "loss": 0.0,
      "step": 42750
    },
    {
      "epoch": 2.7460541511612986,
      "grad_norm": 0.02982613630592823,
      "learning_rate": 0.000362700500449121,
      "loss": 0.0,
      "step": 42800
    },
    {
      "epoch": 2.7492621583472348,
      "grad_norm": 0.01221423875540495,
      "learning_rate": 0.0003625401000898242,
      "loss": 0.0,
      "step": 42850
    },
    {
      "epoch": 2.752470165533171,
      "grad_norm": 0.008119168691337109,
      "learning_rate": 0.00036237969973052745,
      "loss": 0.0,
      "step": 42900
    },
    {
      "epoch": 2.755678172719107,
      "grad_norm": 0.008059016428887844,
      "learning_rate": 0.0003622192993712306,
      "loss": 0.0,
      "step": 42950
    },
    {
      "epoch": 2.7588861799050433,
      "grad_norm": 0.02743024379014969,
      "learning_rate": 0.0003620588990119338,
      "loss": 0.0,
      "step": 43000
    },
    {
      "epoch": 2.762094187090979,
      "grad_norm": 0.01251009851694107,
      "learning_rate": 0.00036189849865263696,
      "loss": 0.0,
      "step": 43050
    },
    {
      "epoch": 2.765302194276915,
      "grad_norm": 0.010689018294215202,
      "learning_rate": 0.0003617380982933402,
      "loss": 0.0,
      "step": 43100
    },
    {
      "epoch": 2.7685102014628513,
      "grad_norm": 0.020539751276373863,
      "learning_rate": 0.0003615776979340434,
      "loss": 0.0,
      "step": 43150
    },
    {
      "epoch": 2.7717182086487875,
      "grad_norm": 0.007048710249364376,
      "learning_rate": 0.0003614172975747466,
      "loss": 0.0,
      "step": 43200
    },
    {
      "epoch": 2.774926215834723,
      "grad_norm": 0.02569705620408058,
      "learning_rate": 0.00036125689721544973,
      "loss": 0.0,
      "step": 43250
    },
    {
      "epoch": 2.7781342230206594,
      "grad_norm": 0.01836458407342434,
      "learning_rate": 0.000361096496856153,
      "loss": 0.0,
      "step": 43300
    },
    {
      "epoch": 2.7813422302065955,
      "grad_norm": 0.027591969817876816,
      "learning_rate": 0.00036093609649685615,
      "loss": 0.0,
      "step": 43350
    },
    {
      "epoch": 2.7845502373925317,
      "grad_norm": 0.010844916105270386,
      "learning_rate": 0.00036077569613755935,
      "loss": 0.0,
      "step": 43400
    },
    {
      "epoch": 2.787758244578468,
      "grad_norm": 0.013354901224374771,
      "learning_rate": 0.00036061529577826256,
      "loss": 0.0,
      "step": 43450
    },
    {
      "epoch": 2.790966251764404,
      "grad_norm": 0.010761182755231857,
      "learning_rate": 0.00036045489541896577,
      "loss": 0.0,
      "step": 43500
    },
    {
      "epoch": 2.79417425895034,
      "grad_norm": 0.0158510971814394,
      "learning_rate": 0.0003602944950596689,
      "loss": 0.0,
      "step": 43550
    },
    {
      "epoch": 2.7973822661362764,
      "grad_norm": 0.01855717971920967,
      "learning_rate": 0.00036013409470037213,
      "loss": 0.0,
      "step": 43600
    },
    {
      "epoch": 2.800590273322212,
      "grad_norm": 0.01593376323580742,
      "learning_rate": 0.00035997369434107534,
      "loss": 0.0,
      "step": 43650
    },
    {
      "epoch": 2.8037982805081483,
      "grad_norm": 0.01891646720468998,
      "learning_rate": 0.00035981329398177854,
      "loss": 0.0,
      "step": 43700
    },
    {
      "epoch": 2.8070062876940844,
      "grad_norm": 0.00491380924358964,
      "learning_rate": 0.0003596528936224817,
      "loss": 0.0,
      "step": 43750
    },
    {
      "epoch": 2.8102142948800206,
      "grad_norm": 0.013087567873299122,
      "learning_rate": 0.0003594924932631849,
      "loss": 0.0,
      "step": 43800
    },
    {
      "epoch": 2.813422302065957,
      "grad_norm": 0.00612698495388031,
      "learning_rate": 0.0003593320929038881,
      "loss": 0.0,
      "step": 43850
    },
    {
      "epoch": 2.8166303092518925,
      "grad_norm": 0.006090898998081684,
      "learning_rate": 0.0003591716925445913,
      "loss": 0.0,
      "step": 43900
    },
    {
      "epoch": 2.8198383164378287,
      "grad_norm": 0.022757377475500107,
      "learning_rate": 0.00035901129218529447,
      "loss": 0.0,
      "step": 43950
    },
    {
      "epoch": 2.823046323623765,
      "grad_norm": 0.029354192316532135,
      "learning_rate": 0.0003588508918259977,
      "loss": 0.0,
      "step": 44000
    },
    {
      "epoch": 2.826254330809701,
      "grad_norm": 0.019458550959825516,
      "learning_rate": 0.0003586904914667009,
      "loss": 0.0,
      "step": 44050
    },
    {
      "epoch": 2.829462337995637,
      "grad_norm": 0.009339381940662861,
      "learning_rate": 0.0003585300911074041,
      "loss": 0.0,
      "step": 44100
    },
    {
      "epoch": 2.8326703451815733,
      "grad_norm": 0.039541635662317276,
      "learning_rate": 0.00035836969074810724,
      "loss": 0.0,
      "step": 44150
    },
    {
      "epoch": 2.8358783523675095,
      "grad_norm": 0.02450508251786232,
      "learning_rate": 0.0003582092903888105,
      "loss": 0.0,
      "step": 44200
    },
    {
      "epoch": 2.8390863595534452,
      "grad_norm": 0.009833506308495998,
      "learning_rate": 0.0003580488900295137,
      "loss": 0.0,
      "step": 44250
    },
    {
      "epoch": 2.8422943667393814,
      "grad_norm": 0.022264571860432625,
      "learning_rate": 0.00035788848967021686,
      "loss": 0.0,
      "step": 44300
    },
    {
      "epoch": 2.8455023739253176,
      "grad_norm": 0.013963311910629272,
      "learning_rate": 0.00035772808931092007,
      "loss": 0.0,
      "step": 44350
    },
    {
      "epoch": 2.8487103811112537,
      "grad_norm": 0.013182176277041435,
      "learning_rate": 0.0003575676889516233,
      "loss": 0.0,
      "step": 44400
    },
    {
      "epoch": 2.85191838829719,
      "grad_norm": 0.008948215283453465,
      "learning_rate": 0.0003574072885923265,
      "loss": 0.0,
      "step": 44450
    },
    {
      "epoch": 2.8551263954831256,
      "grad_norm": 0.004422953352332115,
      "learning_rate": 0.00035724688823302964,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 2.858334402669062,
      "grad_norm": 0.011612430214881897,
      "learning_rate": 0.00035708648787373284,
      "loss": 0.0,
      "step": 44550
    },
    {
      "epoch": 2.861542409854998,
      "grad_norm": 0.026087043806910515,
      "learning_rate": 0.00035692608751443605,
      "loss": 0.0,
      "step": 44600
    },
    {
      "epoch": 2.864750417040934,
      "grad_norm": 0.016194412484765053,
      "learning_rate": 0.00035676568715513926,
      "loss": 0.0,
      "step": 44650
    },
    {
      "epoch": 2.8679584242268703,
      "grad_norm": 0.022644443437457085,
      "learning_rate": 0.0003566052867958424,
      "loss": 0.0,
      "step": 44700
    },
    {
      "epoch": 2.8711664314128065,
      "grad_norm": 0.006099292542785406,
      "learning_rate": 0.0003564448864365456,
      "loss": 0.0,
      "step": 44750
    },
    {
      "epoch": 2.8743744385987426,
      "grad_norm": 0.025412559509277344,
      "learning_rate": 0.0003562844860772488,
      "loss": 0.0,
      "step": 44800
    },
    {
      "epoch": 2.877582445784679,
      "grad_norm": 0.00779585400596261,
      "learning_rate": 0.00035612408571795203,
      "loss": 0.0,
      "step": 44850
    },
    {
      "epoch": 2.8807904529706145,
      "grad_norm": 0.032928138971328735,
      "learning_rate": 0.0003559636853586552,
      "loss": 0.0,
      "step": 44900
    },
    {
      "epoch": 2.8839984601565507,
      "grad_norm": 0.016777334734797478,
      "learning_rate": 0.0003558032849993584,
      "loss": 0.0,
      "step": 44950
    },
    {
      "epoch": 2.887206467342487,
      "grad_norm": 0.007761291228234768,
      "learning_rate": 0.0003556428846400616,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 2.890414474528423,
      "grad_norm": 0.024420591071248055,
      "learning_rate": 0.0003554824842807648,
      "loss": 0.0,
      "step": 45050
    },
    {
      "epoch": 2.8936224817143588,
      "grad_norm": 0.02365739271044731,
      "learning_rate": 0.00035532208392146796,
      "loss": 0.0,
      "step": 45100
    },
    {
      "epoch": 2.896830488900295,
      "grad_norm": 0.004501595627516508,
      "learning_rate": 0.0003551616835621712,
      "loss": 0.0,
      "step": 45150
    },
    {
      "epoch": 2.900038496086231,
      "grad_norm": 0.008956948295235634,
      "learning_rate": 0.00035500128320287437,
      "loss": 0.0,
      "step": 45200
    },
    {
      "epoch": 2.9032465032721673,
      "grad_norm": 0.017394330352544785,
      "learning_rate": 0.0003548408828435776,
      "loss": 0.0,
      "step": 45250
    },
    {
      "epoch": 2.9064545104581034,
      "grad_norm": 0.008758079260587692,
      "learning_rate": 0.00035468048248428073,
      "loss": 0.0,
      "step": 45300
    },
    {
      "epoch": 2.9096625176440396,
      "grad_norm": 0.0012122635962441564,
      "learning_rate": 0.000354520082124984,
      "loss": 0.0,
      "step": 45350
    },
    {
      "epoch": 2.9128705248299758,
      "grad_norm": 0.012703334912657738,
      "learning_rate": 0.00035435968176568714,
      "loss": 0.0,
      "step": 45400
    },
    {
      "epoch": 2.916078532015912,
      "grad_norm": 0.014136554673314095,
      "learning_rate": 0.00035419928140639035,
      "loss": 0.0,
      "step": 45450
    },
    {
      "epoch": 2.9192865392018477,
      "grad_norm": 0.014774566516280174,
      "learning_rate": 0.0003540388810470935,
      "loss": 0.0,
      "step": 45500
    },
    {
      "epoch": 2.922494546387784,
      "grad_norm": 0.01632583700120449,
      "learning_rate": 0.00035387848068779677,
      "loss": 0.0,
      "step": 45550
    },
    {
      "epoch": 2.92570255357372,
      "grad_norm": 0.01955381967127323,
      "learning_rate": 0.00035371808032849997,
      "loss": 0.0,
      "step": 45600
    },
    {
      "epoch": 2.928910560759656,
      "grad_norm": 0.017885394394397736,
      "learning_rate": 0.0003535576799692031,
      "loss": 0.0,
      "step": 45650
    },
    {
      "epoch": 2.9321185679455923,
      "grad_norm": 0.01818620041012764,
      "learning_rate": 0.00035339727960990633,
      "loss": 0.0,
      "step": 45700
    },
    {
      "epoch": 2.935326575131528,
      "grad_norm": 0.006768271792680025,
      "learning_rate": 0.00035323687925060954,
      "loss": 0.0,
      "step": 45750
    },
    {
      "epoch": 2.9385345823174642,
      "grad_norm": 0.00788042787462473,
      "learning_rate": 0.00035307647889131275,
      "loss": 0.0,
      "step": 45800
    },
    {
      "epoch": 2.9417425895034004,
      "grad_norm": 0.0068936534225940704,
      "learning_rate": 0.0003529160785320159,
      "loss": 0.0,
      "step": 45850
    },
    {
      "epoch": 2.9449505966893366,
      "grad_norm": 0.022341230884194374,
      "learning_rate": 0.00035275567817271916,
      "loss": 0.0,
      "step": 45900
    },
    {
      "epoch": 2.9481586038752727,
      "grad_norm": 0.014146499335765839,
      "learning_rate": 0.0003525952778134223,
      "loss": 0.0,
      "step": 45950
    },
    {
      "epoch": 2.951366611061209,
      "grad_norm": 0.024437855929136276,
      "learning_rate": 0.0003524348774541255,
      "loss": 0.0,
      "step": 46000
    },
    {
      "epoch": 2.954574618247145,
      "grad_norm": 0.03299763798713684,
      "learning_rate": 0.00035227447709482867,
      "loss": 0.0,
      "step": 46050
    },
    {
      "epoch": 2.9577826254330812,
      "grad_norm": 0.02368335984647274,
      "learning_rate": 0.00035211407673553193,
      "loss": 0.0,
      "step": 46100
    },
    {
      "epoch": 2.960990632619017,
      "grad_norm": 0.012799634598195553,
      "learning_rate": 0.0003519536763762351,
      "loss": 0.0,
      "step": 46150
    },
    {
      "epoch": 2.964198639804953,
      "grad_norm": 0.012530690990388393,
      "learning_rate": 0.0003517932760169383,
      "loss": 0.0,
      "step": 46200
    },
    {
      "epoch": 2.9674066469908893,
      "grad_norm": 0.03055931068956852,
      "learning_rate": 0.00035163287565764145,
      "loss": 0.0,
      "step": 46250
    },
    {
      "epoch": 2.9706146541768255,
      "grad_norm": 0.011653797701001167,
      "learning_rate": 0.0003514724752983447,
      "loss": 0.0,
      "step": 46300
    },
    {
      "epoch": 2.973822661362761,
      "grad_norm": 0.02577962353825569,
      "learning_rate": 0.00035131207493904786,
      "loss": 0.0,
      "step": 46350
    },
    {
      "epoch": 2.9770306685486974,
      "grad_norm": 0.00988917425274849,
      "learning_rate": 0.00035115167457975107,
      "loss": 0.0,
      "step": 46400
    },
    {
      "epoch": 2.9802386757346335,
      "grad_norm": 0.014929569326341152,
      "learning_rate": 0.0003509912742204542,
      "loss": 0.0,
      "step": 46450
    },
    {
      "epoch": 2.9834466829205697,
      "grad_norm": 0.004267663694918156,
      "learning_rate": 0.0003508308738611575,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 2.986654690106506,
      "grad_norm": 0.005613685119897127,
      "learning_rate": 0.00035067047350186063,
      "loss": 0.0,
      "step": 46550
    },
    {
      "epoch": 2.989862697292442,
      "grad_norm": 0.004492464009672403,
      "learning_rate": 0.00035051007314256384,
      "loss": 0.0,
      "step": 46600
    },
    {
      "epoch": 2.993070704478378,
      "grad_norm": 0.013466401025652885,
      "learning_rate": 0.000350349672783267,
      "loss": 0.0,
      "step": 46650
    },
    {
      "epoch": 2.9962787116643144,
      "grad_norm": 0.0183819942176342,
      "learning_rate": 0.00035018927242397025,
      "loss": 0.0,
      "step": 46700
    },
    {
      "epoch": 2.99948671885025,
      "grad_norm": 0.008243474178016186,
      "learning_rate": 0.0003500288720646734,
      "loss": 0.0,
      "step": 46750
    },
    {
      "epoch": 3.0026947260361863,
      "grad_norm": 0.021151993423700333,
      "learning_rate": 0.0003498684717053766,
      "loss": 0.0,
      "step": 46800
    },
    {
      "epoch": 3.0059027332221224,
      "grad_norm": 0.021628722548484802,
      "learning_rate": 0.0003497080713460798,
      "loss": 0.0,
      "step": 46850
    },
    {
      "epoch": 3.0091107404080586,
      "grad_norm": 0.008733699098229408,
      "learning_rate": 0.00034954767098678303,
      "loss": 0.0,
      "step": 46900
    },
    {
      "epoch": 3.0123187475939948,
      "grad_norm": 0.010544277727603912,
      "learning_rate": 0.00034938727062748624,
      "loss": 0.0,
      "step": 46950
    },
    {
      "epoch": 3.0155267547799305,
      "grad_norm": 0.010981311090290546,
      "learning_rate": 0.0003492268702681894,
      "loss": 0.0,
      "step": 47000
    },
    {
      "epoch": 3.0187347619658667,
      "grad_norm": 0.013300899416208267,
      "learning_rate": 0.00034906646990889265,
      "loss": 0.0,
      "step": 47050
    },
    {
      "epoch": 3.021942769151803,
      "grad_norm": 0.006442129611968994,
      "learning_rate": 0.0003489060695495958,
      "loss": 0.0,
      "step": 47100
    },
    {
      "epoch": 3.025150776337739,
      "grad_norm": 0.014125827699899673,
      "learning_rate": 0.000348745669190299,
      "loss": 0.0,
      "step": 47150
    },
    {
      "epoch": 3.028358783523675,
      "grad_norm": 0.011394140310585499,
      "learning_rate": 0.00034858526883100216,
      "loss": 0.0,
      "step": 47200
    },
    {
      "epoch": 3.0315667907096113,
      "grad_norm": 0.010172098875045776,
      "learning_rate": 0.0003484248684717054,
      "loss": 0.0,
      "step": 47250
    },
    {
      "epoch": 3.0347747978955475,
      "grad_norm": 0.018719352781772614,
      "learning_rate": 0.0003482644681124086,
      "loss": 0.0,
      "step": 47300
    },
    {
      "epoch": 3.037982805081483,
      "grad_norm": 0.011463643051683903,
      "learning_rate": 0.0003481040677531118,
      "loss": 0.0,
      "step": 47350
    },
    {
      "epoch": 3.0411908122674194,
      "grad_norm": 0.019837448373436928,
      "learning_rate": 0.00034794366739381493,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 3.0443988194533556,
      "grad_norm": 0.022353651002049446,
      "learning_rate": 0.0003477832670345182,
      "loss": 0.0,
      "step": 47450
    },
    {
      "epoch": 3.0476068266392917,
      "grad_norm": 0.013372293673455715,
      "learning_rate": 0.00034762286667522135,
      "loss": 0.0,
      "step": 47500
    },
    {
      "epoch": 3.050814833825228,
      "grad_norm": 0.014491182751953602,
      "learning_rate": 0.00034746246631592456,
      "loss": 0.0,
      "step": 47550
    },
    {
      "epoch": 3.054022841011164,
      "grad_norm": 0.028369201347231865,
      "learning_rate": 0.00034730206595662776,
      "loss": 0.0,
      "step": 47600
    },
    {
      "epoch": 3.0572308481971,
      "grad_norm": 0.0069602057337760925,
      "learning_rate": 0.00034714166559733097,
      "loss": 0.0,
      "step": 47650
    },
    {
      "epoch": 3.060438855383036,
      "grad_norm": 0.01069791428744793,
      "learning_rate": 0.0003469812652380341,
      "loss": 0.0,
      "step": 47700
    },
    {
      "epoch": 3.063646862568972,
      "grad_norm": 0.010443293489515781,
      "learning_rate": 0.00034682086487873733,
      "loss": 0.0,
      "step": 47750
    },
    {
      "epoch": 3.0668548697549083,
      "grad_norm": 0.02865838259458542,
      "learning_rate": 0.00034666046451944054,
      "loss": 0.0,
      "step": 47800
    },
    {
      "epoch": 3.0700628769408445,
      "grad_norm": 0.00811487715691328,
      "learning_rate": 0.00034650006416014374,
      "loss": 0.0,
      "step": 47850
    },
    {
      "epoch": 3.0732708841267806,
      "grad_norm": 0.010040701366961002,
      "learning_rate": 0.0003463396638008469,
      "loss": 0.0,
      "step": 47900
    },
    {
      "epoch": 3.0764788913127163,
      "grad_norm": 0.01636037975549698,
      "learning_rate": 0.0003461792634415501,
      "loss": 0.0,
      "step": 47950
    },
    {
      "epoch": 3.0796868984986525,
      "grad_norm": 0.01924312487244606,
      "learning_rate": 0.0003460188630822533,
      "loss": 0.0,
      "step": 48000
    },
    {
      "epoch": 3.0828949056845887,
      "grad_norm": 0.01330530270934105,
      "learning_rate": 0.0003458584627229565,
      "loss": 0.0,
      "step": 48050
    },
    {
      "epoch": 3.086102912870525,
      "grad_norm": 0.016501354053616524,
      "learning_rate": 0.00034569806236365967,
      "loss": 0.0,
      "step": 48100
    },
    {
      "epoch": 3.089310920056461,
      "grad_norm": 0.008264070376753807,
      "learning_rate": 0.0003455376620043629,
      "loss": 0.0,
      "step": 48150
    },
    {
      "epoch": 3.092518927242397,
      "grad_norm": 0.006053571123629808,
      "learning_rate": 0.0003453772616450661,
      "loss": 0.0,
      "step": 48200
    },
    {
      "epoch": 3.095726934428333,
      "grad_norm": 0.01598387397825718,
      "learning_rate": 0.0003452168612857693,
      "loss": 0.0,
      "step": 48250
    },
    {
      "epoch": 3.098934941614269,
      "grad_norm": 0.02429681085050106,
      "learning_rate": 0.0003450564609264725,
      "loss": 0.0,
      "step": 48300
    },
    {
      "epoch": 3.1021429488002052,
      "grad_norm": 0.006247566547244787,
      "learning_rate": 0.00034489606056717565,
      "loss": 0.0,
      "step": 48350
    },
    {
      "epoch": 3.1053509559861414,
      "grad_norm": 0.006638156715780497,
      "learning_rate": 0.0003447356602078789,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 3.1085589631720776,
      "grad_norm": 0.010960393585264683,
      "learning_rate": 0.00034457525984858206,
      "loss": 0.0,
      "step": 48450
    },
    {
      "epoch": 3.1117669703580138,
      "grad_norm": 0.014710787683725357,
      "learning_rate": 0.00034441485948928527,
      "loss": 0.0,
      "step": 48500
    },
    {
      "epoch": 3.11497497754395,
      "grad_norm": 0.006854381412267685,
      "learning_rate": 0.0003442544591299885,
      "loss": 0.0,
      "step": 48550
    },
    {
      "epoch": 3.1181829847298856,
      "grad_norm": 0.021197309717535973,
      "learning_rate": 0.0003440940587706917,
      "loss": 0.0,
      "step": 48600
    },
    {
      "epoch": 3.121390991915822,
      "grad_norm": 0.020827773958444595,
      "learning_rate": 0.00034393365841139484,
      "loss": 0.0,
      "step": 48650
    },
    {
      "epoch": 3.124598999101758,
      "grad_norm": 0.004995179828256369,
      "learning_rate": 0.00034377325805209804,
      "loss": 0.0,
      "step": 48700
    },
    {
      "epoch": 3.127807006287694,
      "grad_norm": 0.017597408965229988,
      "learning_rate": 0.00034361285769280125,
      "loss": 0.0,
      "step": 48750
    },
    {
      "epoch": 3.1310150134736303,
      "grad_norm": 0.009533850476145744,
      "learning_rate": 0.00034345245733350446,
      "loss": 0.0,
      "step": 48800
    },
    {
      "epoch": 3.1342230206595665,
      "grad_norm": 0.032532766461372375,
      "learning_rate": 0.0003432920569742076,
      "loss": 0.0,
      "step": 48850
    },
    {
      "epoch": 3.137431027845502,
      "grad_norm": 0.01705465279519558,
      "learning_rate": 0.0003431316566149108,
      "loss": 0.0,
      "step": 48900
    },
    {
      "epoch": 3.1406390350314384,
      "grad_norm": 0.0027619791217148304,
      "learning_rate": 0.000342971256255614,
      "loss": 0.0,
      "step": 48950
    },
    {
      "epoch": 3.1438470422173745,
      "grad_norm": 0.009406977333128452,
      "learning_rate": 0.00034281085589631723,
      "loss": 0.0,
      "step": 49000
    },
    {
      "epoch": 3.1470550494033107,
      "grad_norm": 0.013730088248848915,
      "learning_rate": 0.0003426504555370204,
      "loss": 0.0,
      "step": 49050
    },
    {
      "epoch": 3.150263056589247,
      "grad_norm": 0.0051864199340343475,
      "learning_rate": 0.0003424900551777236,
      "loss": 0.0,
      "step": 49100
    },
    {
      "epoch": 3.153471063775183,
      "grad_norm": 0.016092276200652122,
      "learning_rate": 0.0003423296548184268,
      "loss": 0.0,
      "step": 49150
    },
    {
      "epoch": 3.1566790709611188,
      "grad_norm": 0.00967809185385704,
      "learning_rate": 0.00034216925445913,
      "loss": 0.0,
      "step": 49200
    },
    {
      "epoch": 3.159887078147055,
      "grad_norm": 0.007104165386408567,
      "learning_rate": 0.00034200885409983316,
      "loss": 0.0,
      "step": 49250
    },
    {
      "epoch": 3.163095085332991,
      "grad_norm": 0.022994190454483032,
      "learning_rate": 0.0003418484537405364,
      "loss": 0.0,
      "step": 49300
    },
    {
      "epoch": 3.1663030925189273,
      "grad_norm": 0.013654823414981365,
      "learning_rate": 0.00034168805338123957,
      "loss": 0.0,
      "step": 49350
    },
    {
      "epoch": 3.1695110997048634,
      "grad_norm": 0.0065172044560313225,
      "learning_rate": 0.0003415276530219428,
      "loss": 0.0,
      "step": 49400
    },
    {
      "epoch": 3.1727191068907996,
      "grad_norm": 0.023056408390402794,
      "learning_rate": 0.00034136725266264593,
      "loss": 0.0,
      "step": 49450
    },
    {
      "epoch": 3.1759271140767353,
      "grad_norm": 0.007451367564499378,
      "learning_rate": 0.0003412068523033492,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 3.1791351212626715,
      "grad_norm": 0.018841175362467766,
      "learning_rate": 0.00034104645194405235,
      "loss": 0.0,
      "step": 49550
    },
    {
      "epoch": 3.1823431284486077,
      "grad_norm": 0.005272017791867256,
      "learning_rate": 0.00034088605158475555,
      "loss": 0.0,
      "step": 49600
    },
    {
      "epoch": 3.185551135634544,
      "grad_norm": 0.010728913359344006,
      "learning_rate": 0.0003407256512254587,
      "loss": 0.0,
      "step": 49650
    },
    {
      "epoch": 3.18875914282048,
      "grad_norm": 0.01601419597864151,
      "learning_rate": 0.00034056525086616197,
      "loss": 0.0,
      "step": 49700
    },
    {
      "epoch": 3.191967150006416,
      "grad_norm": 0.014832044951617718,
      "learning_rate": 0.0003404048505068652,
      "loss": 0.0,
      "step": 49750
    },
    {
      "epoch": 3.1951751571923523,
      "grad_norm": 0.006668831221759319,
      "learning_rate": 0.0003402444501475683,
      "loss": 0.0,
      "step": 49800
    },
    {
      "epoch": 3.198383164378288,
      "grad_norm": 0.03997742384672165,
      "learning_rate": 0.00034008404978827153,
      "loss": 0.0,
      "step": 49850
    },
    {
      "epoch": 3.2015911715642242,
      "grad_norm": 0.012619261629879475,
      "learning_rate": 0.00033992364942897474,
      "loss": 0.0,
      "step": 49900
    },
    {
      "epoch": 3.2047991787501604,
      "grad_norm": 0.0173077043145895,
      "learning_rate": 0.00033976324906967795,
      "loss": 0.0,
      "step": 49950
    },
    {
      "epoch": 3.2080071859360966,
      "grad_norm": 0.00935082696378231,
      "learning_rate": 0.0003396028487103811,
      "loss": 0.0,
      "step": 50000
    },
    {
      "epoch": 3.2112151931220327,
      "grad_norm": 0.009263732470571995,
      "learning_rate": 0.0003394424483510843,
      "loss": 0.0,
      "step": 50050
    },
    {
      "epoch": 3.2144232003079685,
      "grad_norm": 0.011383354663848877,
      "learning_rate": 0.0003392820479917875,
      "loss": 0.0,
      "step": 50100
    },
    {
      "epoch": 3.2176312074939046,
      "grad_norm": 0.03102204203605652,
      "learning_rate": 0.0003391216476324907,
      "loss": 0.0,
      "step": 50150
    },
    {
      "epoch": 3.220839214679841,
      "grad_norm": 0.007382553070783615,
      "learning_rate": 0.0003389612472731939,
      "loss": 0.0,
      "step": 50200
    },
    {
      "epoch": 3.224047221865777,
      "grad_norm": 0.027001164853572845,
      "learning_rate": 0.00033880084691389713,
      "loss": 0.0,
      "step": 50250
    },
    {
      "epoch": 3.227255229051713,
      "grad_norm": 0.003930221777409315,
      "learning_rate": 0.0003386404465546003,
      "loss": 0.0,
      "step": 50300
    },
    {
      "epoch": 3.2304632362376493,
      "grad_norm": 0.019759684801101685,
      "learning_rate": 0.0003384800461953035,
      "loss": 0.0,
      "step": 50350
    },
    {
      "epoch": 3.2336712434235855,
      "grad_norm": 0.015441114082932472,
      "learning_rate": 0.00033831964583600665,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 3.236879250609521,
      "grad_norm": 0.010672297328710556,
      "learning_rate": 0.0003381592454767099,
      "loss": 0.0,
      "step": 50450
    },
    {
      "epoch": 3.2400872577954574,
      "grad_norm": 0.011445318348705769,
      "learning_rate": 0.00033799884511741306,
      "loss": 0.0,
      "step": 50500
    },
    {
      "epoch": 3.2432952649813935,
      "grad_norm": 0.005912866909056902,
      "learning_rate": 0.00033783844475811627,
      "loss": 0.0,
      "step": 50550
    },
    {
      "epoch": 3.2465032721673297,
      "grad_norm": 0.005338635761290789,
      "learning_rate": 0.0003376780443988194,
      "loss": 0.0,
      "step": 50600
    },
    {
      "epoch": 3.249711279353266,
      "grad_norm": 0.006386274471879005,
      "learning_rate": 0.0003375176440395227,
      "loss": 0.0,
      "step": 50650
    },
    {
      "epoch": 3.252919286539202,
      "grad_norm": 0.011743495240807533,
      "learning_rate": 0.00033735724368022583,
      "loss": 0.0,
      "step": 50700
    },
    {
      "epoch": 3.2561272937251378,
      "grad_norm": 0.011920501478016376,
      "learning_rate": 0.00033719684332092904,
      "loss": 0.0,
      "step": 50750
    },
    {
      "epoch": 3.259335300911074,
      "grad_norm": 0.02327309176325798,
      "learning_rate": 0.0003370364429616322,
      "loss": 0.0,
      "step": 50800
    },
    {
      "epoch": 3.26254330809701,
      "grad_norm": 0.007461227476596832,
      "learning_rate": 0.00033687604260233546,
      "loss": 0.0,
      "step": 50850
    },
    {
      "epoch": 3.2657513152829463,
      "grad_norm": 0.014196699485182762,
      "learning_rate": 0.0003367156422430386,
      "loss": 0.0,
      "step": 50900
    },
    {
      "epoch": 3.2689593224688824,
      "grad_norm": 0.009770957753062248,
      "learning_rate": 0.0003365552418837418,
      "loss": 0.0,
      "step": 50950
    },
    {
      "epoch": 3.2721673296548186,
      "grad_norm": 0.003218309720978141,
      "learning_rate": 0.00033639484152444497,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 3.2753753368407548,
      "grad_norm": 0.008966471068561077,
      "learning_rate": 0.00033623444116514823,
      "loss": 0.0,
      "step": 51050
    },
    {
      "epoch": 3.2785833440266905,
      "grad_norm": 0.011958306655287743,
      "learning_rate": 0.00033607404080585144,
      "loss": 0.0,
      "step": 51100
    },
    {
      "epoch": 3.2817913512126267,
      "grad_norm": 0.011460928246378899,
      "learning_rate": 0.0003359136404465546,
      "loss": 0.0,
      "step": 51150
    },
    {
      "epoch": 3.284999358398563,
      "grad_norm": 0.019808059558272362,
      "learning_rate": 0.00033575324008725785,
      "loss": 0.0,
      "step": 51200
    },
    {
      "epoch": 3.288207365584499,
      "grad_norm": 0.014847851358354092,
      "learning_rate": 0.000335592839727961,
      "loss": 0.0,
      "step": 51250
    },
    {
      "epoch": 3.291415372770435,
      "grad_norm": 0.025708891451358795,
      "learning_rate": 0.0003354324393686642,
      "loss": 0.0,
      "step": 51300
    },
    {
      "epoch": 3.294623379956371,
      "grad_norm": 0.006332239601761103,
      "learning_rate": 0.00033527203900936736,
      "loss": 0.0,
      "step": 51350
    },
    {
      "epoch": 3.297831387142307,
      "grad_norm": 0.012999624013900757,
      "learning_rate": 0.0003351116386500706,
      "loss": 0.0,
      "step": 51400
    },
    {
      "epoch": 3.3010393943282432,
      "grad_norm": 0.007111834362149239,
      "learning_rate": 0.0003349512382907738,
      "loss": 0.0,
      "step": 51450
    },
    {
      "epoch": 3.3042474015141794,
      "grad_norm": 0.01718953065574169,
      "learning_rate": 0.000334790837931477,
      "loss": 0.0,
      "step": 51500
    },
    {
      "epoch": 3.3074554087001156,
      "grad_norm": 0.012513820081949234,
      "learning_rate": 0.00033463043757218014,
      "loss": 0.0,
      "step": 51550
    },
    {
      "epoch": 3.3106634158860517,
      "grad_norm": 0.006884550675749779,
      "learning_rate": 0.0003344700372128834,
      "loss": 0.0,
      "step": 51600
    },
    {
      "epoch": 3.313871423071988,
      "grad_norm": 0.00900838989764452,
      "learning_rate": 0.00033430963685358655,
      "loss": 0.0,
      "step": 51650
    },
    {
      "epoch": 3.3170794302579236,
      "grad_norm": 0.002398497425019741,
      "learning_rate": 0.00033414923649428976,
      "loss": 0.0,
      "step": 51700
    },
    {
      "epoch": 3.32028743744386,
      "grad_norm": 0.016577081754803658,
      "learning_rate": 0.0003339888361349929,
      "loss": 0.0,
      "step": 51750
    },
    {
      "epoch": 3.323495444629796,
      "grad_norm": 0.0018586027435958385,
      "learning_rate": 0.00033382843577569617,
      "loss": 0.0,
      "step": 51800
    },
    {
      "epoch": 3.326703451815732,
      "grad_norm": 0.023316148668527603,
      "learning_rate": 0.0003336680354163993,
      "loss": 0.0,
      "step": 51850
    },
    {
      "epoch": 3.3299114590016683,
      "grad_norm": 0.009608183987438679,
      "learning_rate": 0.00033350763505710253,
      "loss": 0.0,
      "step": 51900
    },
    {
      "epoch": 3.333119466187604,
      "grad_norm": 0.016884643584489822,
      "learning_rate": 0.00033334723469780574,
      "loss": 0.0,
      "step": 51950
    },
    {
      "epoch": 3.33632747337354,
      "grad_norm": 0.010922122746706009,
      "learning_rate": 0.00033318683433850894,
      "loss": 0.0,
      "step": 52000
    },
    {
      "epoch": 3.3395354805594764,
      "grad_norm": 0.020040640607476234,
      "learning_rate": 0.0003330264339792121,
      "loss": 0.0,
      "step": 52050
    },
    {
      "epoch": 3.3427434877454125,
      "grad_norm": 0.03356495872139931,
      "learning_rate": 0.0003328660336199153,
      "loss": 0.0,
      "step": 52100
    },
    {
      "epoch": 3.3459514949313487,
      "grad_norm": 0.008357178419828415,
      "learning_rate": 0.0003327056332606185,
      "loss": 0.0,
      "step": 52150
    },
    {
      "epoch": 3.349159502117285,
      "grad_norm": 0.008533230051398277,
      "learning_rate": 0.0003325452329013217,
      "loss": 0.0,
      "step": 52200
    },
    {
      "epoch": 3.352367509303221,
      "grad_norm": 0.017434142529964447,
      "learning_rate": 0.00033238483254202487,
      "loss": 0.0,
      "step": 52250
    },
    {
      "epoch": 3.3555755164891568,
      "grad_norm": 0.010899204760789871,
      "learning_rate": 0.0003322244321827281,
      "loss": 0.0,
      "step": 52300
    },
    {
      "epoch": 3.358783523675093,
      "grad_norm": 0.01414352748543024,
      "learning_rate": 0.00033206403182343134,
      "loss": 0.0,
      "step": 52350
    },
    {
      "epoch": 3.361991530861029,
      "grad_norm": 0.00624728063121438,
      "learning_rate": 0.0003319036314641345,
      "loss": 0.0,
      "step": 52400
    },
    {
      "epoch": 3.3651995380469653,
      "grad_norm": 0.006209725979715586,
      "learning_rate": 0.0003317432311048377,
      "loss": 0.0,
      "step": 52450
    },
    {
      "epoch": 3.3684075452329014,
      "grad_norm": 0.007878501899540424,
      "learning_rate": 0.00033158283074554085,
      "loss": 0.0,
      "step": 52500
    },
    {
      "epoch": 3.3716155524188376,
      "grad_norm": 0.01705799251794815,
      "learning_rate": 0.0003314224303862441,
      "loss": 0.0,
      "step": 52550
    },
    {
      "epoch": 3.3748235596047733,
      "grad_norm": 0.006759439129382372,
      "learning_rate": 0.00033126203002694727,
      "loss": 0.0,
      "step": 52600
    },
    {
      "epoch": 3.3780315667907095,
      "grad_norm": 0.01579846628010273,
      "learning_rate": 0.00033110162966765047,
      "loss": 0.0,
      "step": 52650
    },
    {
      "epoch": 3.3812395739766457,
      "grad_norm": 0.01812121458351612,
      "learning_rate": 0.0003309412293083536,
      "loss": 0.0,
      "step": 52700
    },
    {
      "epoch": 3.384447581162582,
      "grad_norm": 0.01860155537724495,
      "learning_rate": 0.0003307808289490569,
      "loss": 0.0,
      "step": 52750
    },
    {
      "epoch": 3.387655588348518,
      "grad_norm": 0.016813572496175766,
      "learning_rate": 0.00033062042858976004,
      "loss": 0.0,
      "step": 52800
    },
    {
      "epoch": 3.390863595534454,
      "grad_norm": 0.019348589703440666,
      "learning_rate": 0.00033046002823046325,
      "loss": 0.0,
      "step": 52850
    },
    {
      "epoch": 3.3940716027203903,
      "grad_norm": 0.011715386994183064,
      "learning_rate": 0.00033029962787116645,
      "loss": 0.0,
      "step": 52900
    },
    {
      "epoch": 3.397279609906326,
      "grad_norm": 0.016010550782084465,
      "learning_rate": 0.00033013922751186966,
      "loss": 0.0,
      "step": 52950
    },
    {
      "epoch": 3.400487617092262,
      "grad_norm": 0.01588745228946209,
      "learning_rate": 0.0003299788271525728,
      "loss": 0.0,
      "step": 53000
    },
    {
      "epoch": 3.4036956242781984,
      "grad_norm": 0.013914655894041061,
      "learning_rate": 0.000329818426793276,
      "loss": 0.0,
      "step": 53050
    },
    {
      "epoch": 3.4069036314641346,
      "grad_norm": 0.006805810611695051,
      "learning_rate": 0.0003296580264339792,
      "loss": 0.0,
      "step": 53100
    },
    {
      "epoch": 3.4101116386500707,
      "grad_norm": 0.016827108338475227,
      "learning_rate": 0.00032949762607468243,
      "loss": 0.0,
      "step": 53150
    },
    {
      "epoch": 3.4133196458360064,
      "grad_norm": 0.0070829326286911964,
      "learning_rate": 0.0003293372257153856,
      "loss": 0.0,
      "step": 53200
    },
    {
      "epoch": 3.4165276530219426,
      "grad_norm": 0.006461013108491898,
      "learning_rate": 0.0003291768253560888,
      "loss": 0.0,
      "step": 53250
    },
    {
      "epoch": 3.419735660207879,
      "grad_norm": 0.01716618426144123,
      "learning_rate": 0.000329016424996792,
      "loss": 0.0,
      "step": 53300
    },
    {
      "epoch": 3.422943667393815,
      "grad_norm": 0.014855623245239258,
      "learning_rate": 0.0003288560246374952,
      "loss": 0.0,
      "step": 53350
    },
    {
      "epoch": 3.426151674579751,
      "grad_norm": 0.016837431117892265,
      "learning_rate": 0.00032869562427819836,
      "loss": 0.0,
      "step": 53400
    },
    {
      "epoch": 3.4293596817656873,
      "grad_norm": 0.03209736570715904,
      "learning_rate": 0.00032853522391890157,
      "loss": 0.0,
      "step": 53450
    },
    {
      "epoch": 3.4325676889516235,
      "grad_norm": 0.008737567812204361,
      "learning_rate": 0.0003283748235596048,
      "loss": 0.0,
      "step": 53500
    },
    {
      "epoch": 3.435775696137559,
      "grad_norm": 0.009700843133032322,
      "learning_rate": 0.000328214423200308,
      "loss": 0.0,
      "step": 53550
    },
    {
      "epoch": 3.4389837033234953,
      "grad_norm": 0.011160706169903278,
      "learning_rate": 0.00032805402284101113,
      "loss": 0.0,
      "step": 53600
    },
    {
      "epoch": 3.4421917105094315,
      "grad_norm": 0.00899417232722044,
      "learning_rate": 0.0003278936224817144,
      "loss": 0.0,
      "step": 53650
    },
    {
      "epoch": 3.4453997176953677,
      "grad_norm": 0.02035095915198326,
      "learning_rate": 0.00032773322212241755,
      "loss": 0.0,
      "step": 53700
    },
    {
      "epoch": 3.448607724881304,
      "grad_norm": 0.010951302945613861,
      "learning_rate": 0.00032757282176312075,
      "loss": 0.0,
      "step": 53750
    },
    {
      "epoch": 3.45181573206724,
      "grad_norm": 0.004715565592050552,
      "learning_rate": 0.00032741242140382396,
      "loss": 0.0,
      "step": 53800
    },
    {
      "epoch": 3.4550237392531757,
      "grad_norm": 0.00499541312456131,
      "learning_rate": 0.00032725202104452717,
      "loss": 0.0,
      "step": 53850
    },
    {
      "epoch": 3.458231746439112,
      "grad_norm": 0.006645777262747288,
      "learning_rate": 0.0003270916206852304,
      "loss": 0.0,
      "step": 53900
    },
    {
      "epoch": 3.461439753625048,
      "grad_norm": 0.02050669863820076,
      "learning_rate": 0.00032693122032593353,
      "loss": 0.0,
      "step": 53950
    },
    {
      "epoch": 3.4646477608109842,
      "grad_norm": 0.0053096553310751915,
      "learning_rate": 0.00032677081996663673,
      "loss": 0.0,
      "step": 54000
    },
    {
      "epoch": 3.4678557679969204,
      "grad_norm": 0.008319738321006298,
      "learning_rate": 0.00032661041960733994,
      "loss": 0.0,
      "step": 54050
    },
    {
      "epoch": 3.4710637751828566,
      "grad_norm": 0.00882778037339449,
      "learning_rate": 0.00032645001924804315,
      "loss": 0.0,
      "step": 54100
    },
    {
      "epoch": 3.4742717823687927,
      "grad_norm": 0.011627300642430782,
      "learning_rate": 0.0003262896188887463,
      "loss": 0.0,
      "step": 54150
    },
    {
      "epoch": 3.4774797895547285,
      "grad_norm": 0.019477108493447304,
      "learning_rate": 0.0003261292185294495,
      "loss": 0.0,
      "step": 54200
    },
    {
      "epoch": 3.4806877967406646,
      "grad_norm": 0.022825542837381363,
      "learning_rate": 0.0003259688181701527,
      "loss": 0.0,
      "step": 54250
    },
    {
      "epoch": 3.483895803926601,
      "grad_norm": 0.012071286328136921,
      "learning_rate": 0.0003258084178108559,
      "loss": 0.0,
      "step": 54300
    },
    {
      "epoch": 3.487103811112537,
      "grad_norm": 0.02732350118458271,
      "learning_rate": 0.0003256480174515591,
      "loss": 0.0,
      "step": 54350
    },
    {
      "epoch": 3.490311818298473,
      "grad_norm": 0.024687156081199646,
      "learning_rate": 0.0003254876170922623,
      "loss": 0.0,
      "step": 54400
    },
    {
      "epoch": 3.493519825484409,
      "grad_norm": 0.009893911890685558,
      "learning_rate": 0.0003253272167329655,
      "loss": 0.0,
      "step": 54450
    },
    {
      "epoch": 3.496727832670345,
      "grad_norm": 0.008484283462166786,
      "learning_rate": 0.0003251668163736687,
      "loss": 0.0,
      "step": 54500
    },
    {
      "epoch": 3.499935839856281,
      "grad_norm": 0.01040554977953434,
      "learning_rate": 0.00032500641601437185,
      "loss": 0.0,
      "step": 54550
    },
    {
      "epoch": 3.5031438470422174,
      "grad_norm": 0.022505104541778564,
      "learning_rate": 0.0003248460156550751,
      "loss": 0.0,
      "step": 54600
    },
    {
      "epoch": 3.5063518542281535,
      "grad_norm": 0.004197489004582167,
      "learning_rate": 0.00032468561529577826,
      "loss": 0.0,
      "step": 54650
    },
    {
      "epoch": 3.5095598614140897,
      "grad_norm": 0.014638219028711319,
      "learning_rate": 0.00032452521493648147,
      "loss": 0.0,
      "step": 54700
    },
    {
      "epoch": 3.512767868600026,
      "grad_norm": 0.03576334938406944,
      "learning_rate": 0.0003243648145771846,
      "loss": 0.0,
      "step": 54750
    },
    {
      "epoch": 3.5159758757859616,
      "grad_norm": 0.006801307667046785,
      "learning_rate": 0.0003242044142178879,
      "loss": 0.0,
      "step": 54800
    },
    {
      "epoch": 3.5191838829718978,
      "grad_norm": 0.003516347613185644,
      "learning_rate": 0.00032404401385859104,
      "loss": 0.0,
      "step": 54850
    },
    {
      "epoch": 3.522391890157834,
      "grad_norm": 0.013774586841464043,
      "learning_rate": 0.00032388361349929424,
      "loss": 0.0,
      "step": 54900
    },
    {
      "epoch": 3.52559989734377,
      "grad_norm": 0.002839107299223542,
      "learning_rate": 0.0003237232131399974,
      "loss": 0.0,
      "step": 54950
    },
    {
      "epoch": 3.5288079045297063,
      "grad_norm": 0.010683292523026466,
      "learning_rate": 0.00032356281278070066,
      "loss": 0.0,
      "step": 55000
    },
    {
      "epoch": 3.532015911715642,
      "grad_norm": 0.01025779265910387,
      "learning_rate": 0.0003234024124214038,
      "loss": 0.0,
      "step": 55050
    },
    {
      "epoch": 3.535223918901578,
      "grad_norm": 0.01058247685432434,
      "learning_rate": 0.000323242012062107,
      "loss": 0.0,
      "step": 55100
    },
    {
      "epoch": 3.5384319260875143,
      "grad_norm": 0.004509233869612217,
      "learning_rate": 0.0003230816117028102,
      "loss": 0.0,
      "step": 55150
    },
    {
      "epoch": 3.5416399332734505,
      "grad_norm": 0.010714175179600716,
      "learning_rate": 0.00032292121134351343,
      "loss": 0.0,
      "step": 55200
    },
    {
      "epoch": 3.5448479404593867,
      "grad_norm": 0.009666974656283855,
      "learning_rate": 0.00032276081098421664,
      "loss": 0.0,
      "step": 55250
    },
    {
      "epoch": 3.548055947645323,
      "grad_norm": 0.02089964598417282,
      "learning_rate": 0.0003226004106249198,
      "loss": 0.0,
      "step": 55300
    },
    {
      "epoch": 3.551263954831259,
      "grad_norm": 0.01737653836607933,
      "learning_rate": 0.00032244001026562305,
      "loss": 0.0,
      "step": 55350
    },
    {
      "epoch": 3.554471962017195,
      "grad_norm": 0.010442017577588558,
      "learning_rate": 0.0003222796099063262,
      "loss": 0.0,
      "step": 55400
    },
    {
      "epoch": 3.557679969203131,
      "grad_norm": 0.01467180997133255,
      "learning_rate": 0.0003221192095470294,
      "loss": 0.0,
      "step": 55450
    },
    {
      "epoch": 3.560887976389067,
      "grad_norm": 0.01744643598794937,
      "learning_rate": 0.00032195880918773256,
      "loss": 0.0,
      "step": 55500
    },
    {
      "epoch": 3.5640959835750032,
      "grad_norm": 0.0075093586929142475,
      "learning_rate": 0.0003217984088284358,
      "loss": 0.0,
      "step": 55550
    },
    {
      "epoch": 3.5673039907609394,
      "grad_norm": 0.007995152845978737,
      "learning_rate": 0.000321638008469139,
      "loss": 0.0,
      "step": 55600
    },
    {
      "epoch": 3.570511997946875,
      "grad_norm": 0.027155065909028053,
      "learning_rate": 0.0003214776081098422,
      "loss": 0.0,
      "step": 55650
    },
    {
      "epoch": 3.5737200051328113,
      "grad_norm": 0.014634928666055202,
      "learning_rate": 0.00032131720775054534,
      "loss": 0.0,
      "step": 55700
    },
    {
      "epoch": 3.5769280123187475,
      "grad_norm": 0.0225114356726408,
      "learning_rate": 0.0003211568073912486,
      "loss": 0.0,
      "step": 55750
    },
    {
      "epoch": 3.5801360195046836,
      "grad_norm": 0.005161785054951906,
      "learning_rate": 0.00032099640703195175,
      "loss": 0.0,
      "step": 55800
    },
    {
      "epoch": 3.58334402669062,
      "grad_norm": 0.01144328247755766,
      "learning_rate": 0.00032083600667265496,
      "loss": 0.0,
      "step": 55850
    },
    {
      "epoch": 3.586552033876556,
      "grad_norm": 0.026691412553191185,
      "learning_rate": 0.0003206756063133581,
      "loss": 0.0,
      "step": 55900
    },
    {
      "epoch": 3.589760041062492,
      "grad_norm": 0.01054862979799509,
      "learning_rate": 0.00032051520595406137,
      "loss": 0.0,
      "step": 55950
    },
    {
      "epoch": 3.5929680482484283,
      "grad_norm": 0.0075774770230054855,
      "learning_rate": 0.0003203548055947645,
      "loss": 0.0,
      "step": 56000
    },
    {
      "epoch": 3.596176055434364,
      "grad_norm": 0.007990743033587933,
      "learning_rate": 0.00032019440523546773,
      "loss": 0.0,
      "step": 56050
    },
    {
      "epoch": 3.5993840626203,
      "grad_norm": 0.0300294179469347,
      "learning_rate": 0.0003200340048761709,
      "loss": 0.0,
      "step": 56100
    },
    {
      "epoch": 3.6025920698062364,
      "grad_norm": 0.02282111532986164,
      "learning_rate": 0.00031987360451687415,
      "loss": 0.0,
      "step": 56150
    },
    {
      "epoch": 3.6058000769921725,
      "grad_norm": 0.022262776270508766,
      "learning_rate": 0.0003197132041575773,
      "loss": 0.0,
      "step": 56200
    },
    {
      "epoch": 3.6090080841781087,
      "grad_norm": 0.026925450190901756,
      "learning_rate": 0.0003195528037982805,
      "loss": 0.0,
      "step": 56250
    },
    {
      "epoch": 3.6122160913640444,
      "grad_norm": 0.008152998052537441,
      "learning_rate": 0.0003193924034389837,
      "loss": 0.0,
      "step": 56300
    },
    {
      "epoch": 3.6154240985499806,
      "grad_norm": 0.007062326651066542,
      "learning_rate": 0.0003192320030796869,
      "loss": 0.0,
      "step": 56350
    },
    {
      "epoch": 3.6186321057359168,
      "grad_norm": 0.008153479546308517,
      "learning_rate": 0.00031907160272039007,
      "loss": 0.0,
      "step": 56400
    },
    {
      "epoch": 3.621840112921853,
      "grad_norm": 0.004982935264706612,
      "learning_rate": 0.0003189112023610933,
      "loss": 0.0,
      "step": 56450
    },
    {
      "epoch": 3.625048120107789,
      "grad_norm": 0.01885794848203659,
      "learning_rate": 0.00031875080200179654,
      "loss": 0.0,
      "step": 56500
    },
    {
      "epoch": 3.6282561272937253,
      "grad_norm": 0.013342950493097305,
      "learning_rate": 0.0003185904016424997,
      "loss": 0.0,
      "step": 56550
    },
    {
      "epoch": 3.6314641344796614,
      "grad_norm": 0.017890730872750282,
      "learning_rate": 0.0003184300012832029,
      "loss": 0.0,
      "step": 56600
    },
    {
      "epoch": 3.6346721416655976,
      "grad_norm": 0.011965639889240265,
      "learning_rate": 0.00031826960092390605,
      "loss": 0.0,
      "step": 56650
    },
    {
      "epoch": 3.6378801488515333,
      "grad_norm": 0.026904942467808723,
      "learning_rate": 0.0003181092005646093,
      "loss": 0.0,
      "step": 56700
    },
    {
      "epoch": 3.6410881560374695,
      "grad_norm": 0.01772475428879261,
      "learning_rate": 0.00031794880020531247,
      "loss": 0.0,
      "step": 56750
    },
    {
      "epoch": 3.6442961632234057,
      "grad_norm": 0.015609323047101498,
      "learning_rate": 0.0003177883998460157,
      "loss": 0.0,
      "step": 56800
    },
    {
      "epoch": 3.647504170409342,
      "grad_norm": 0.016255274415016174,
      "learning_rate": 0.0003176279994867188,
      "loss": 0.0,
      "step": 56850
    },
    {
      "epoch": 3.6507121775952776,
      "grad_norm": 0.01996670849621296,
      "learning_rate": 0.0003174675991274221,
      "loss": 0.0,
      "step": 56900
    },
    {
      "epoch": 3.6539201847812137,
      "grad_norm": 0.006529844831675291,
      "learning_rate": 0.00031730719876812524,
      "loss": 0.0,
      "step": 56950
    },
    {
      "epoch": 3.65712819196715,
      "grad_norm": 0.006633502896875143,
      "learning_rate": 0.00031714679840882845,
      "loss": 0.0,
      "step": 57000
    },
    {
      "epoch": 3.660336199153086,
      "grad_norm": 0.01043032668530941,
      "learning_rate": 0.0003169863980495316,
      "loss": 0.0,
      "step": 57050
    },
    {
      "epoch": 3.6635442063390222,
      "grad_norm": 0.013440902344882488,
      "learning_rate": 0.00031682599769023486,
      "loss": 0.0,
      "step": 57100
    },
    {
      "epoch": 3.6667522135249584,
      "grad_norm": 0.006266042124480009,
      "learning_rate": 0.000316665597330938,
      "loss": 0.0,
      "step": 57150
    },
    {
      "epoch": 3.6699602207108946,
      "grad_norm": 0.013359094969928265,
      "learning_rate": 0.0003165051969716412,
      "loss": 0.0,
      "step": 57200
    },
    {
      "epoch": 3.6731682278968307,
      "grad_norm": 0.02263200841844082,
      "learning_rate": 0.0003163447966123444,
      "loss": 0.0,
      "step": 57250
    },
    {
      "epoch": 3.6763762350827665,
      "grad_norm": 0.012163075618445873,
      "learning_rate": 0.00031618439625304763,
      "loss": 0.0,
      "step": 57300
    },
    {
      "epoch": 3.6795842422687026,
      "grad_norm": 0.009835305623710155,
      "learning_rate": 0.0003160239958937508,
      "loss": 0.0,
      "step": 57350
    },
    {
      "epoch": 3.682792249454639,
      "grad_norm": 0.02112780697643757,
      "learning_rate": 0.000315863595534454,
      "loss": 0.0,
      "step": 57400
    },
    {
      "epoch": 3.686000256640575,
      "grad_norm": 0.016283687204122543,
      "learning_rate": 0.0003157031951751572,
      "loss": 0.0,
      "step": 57450
    },
    {
      "epoch": 3.689208263826511,
      "grad_norm": 0.012321144342422485,
      "learning_rate": 0.0003155427948158604,
      "loss": 0.0,
      "step": 57500
    },
    {
      "epoch": 3.692416271012447,
      "grad_norm": 0.019654009491205215,
      "learning_rate": 0.00031538239445656356,
      "loss": 0.0,
      "step": 57550
    },
    {
      "epoch": 3.695624278198383,
      "grad_norm": 0.012678966857492924,
      "learning_rate": 0.00031522199409726677,
      "loss": 0.0,
      "step": 57600
    },
    {
      "epoch": 3.698832285384319,
      "grad_norm": 0.006337088067084551,
      "learning_rate": 0.00031506159373797,
      "loss": 0.0,
      "step": 57650
    },
    {
      "epoch": 3.7020402925702554,
      "grad_norm": 0.028527116402983665,
      "learning_rate": 0.0003149011933786732,
      "loss": 0.0,
      "step": 57700
    },
    {
      "epoch": 3.7052482997561915,
      "grad_norm": 0.006903558038175106,
      "learning_rate": 0.00031474079301937633,
      "loss": 0.0,
      "step": 57750
    },
    {
      "epoch": 3.7084563069421277,
      "grad_norm": 0.008235045708715916,
      "learning_rate": 0.00031458039266007954,
      "loss": 0.0,
      "step": 57800
    },
    {
      "epoch": 3.711664314128064,
      "grad_norm": 0.012478223070502281,
      "learning_rate": 0.0003144199923007828,
      "loss": 0.0,
      "step": 57850
    },
    {
      "epoch": 3.7148723213139996,
      "grad_norm": 0.00927556212991476,
      "learning_rate": 0.00031425959194148595,
      "loss": 0.0,
      "step": 57900
    },
    {
      "epoch": 3.7180803284999357,
      "grad_norm": 0.008760001510381699,
      "learning_rate": 0.00031409919158218916,
      "loss": 0.0,
      "step": 57950
    },
    {
      "epoch": 3.721288335685872,
      "grad_norm": 0.022895021364092827,
      "learning_rate": 0.00031393879122289237,
      "loss": 0.0,
      "step": 58000
    },
    {
      "epoch": 3.724496342871808,
      "grad_norm": 0.00752612017095089,
      "learning_rate": 0.0003137783908635956,
      "loss": 0.0,
      "step": 58050
    },
    {
      "epoch": 3.7277043500577443,
      "grad_norm": 0.015675244852900505,
      "learning_rate": 0.00031361799050429873,
      "loss": 0.0,
      "step": 58100
    },
    {
      "epoch": 3.73091235724368,
      "grad_norm": 0.007306186947971582,
      "learning_rate": 0.00031345759014500194,
      "loss": 0.0,
      "step": 58150
    },
    {
      "epoch": 3.734120364429616,
      "grad_norm": 0.01220192201435566,
      "learning_rate": 0.00031329718978570514,
      "loss": 0.0,
      "step": 58200
    },
    {
      "epoch": 3.7373283716155523,
      "grad_norm": 0.006043888628482819,
      "learning_rate": 0.00031313678942640835,
      "loss": 0.0,
      "step": 58250
    },
    {
      "epoch": 3.7405363788014885,
      "grad_norm": 0.00585826626047492,
      "learning_rate": 0.0003129763890671115,
      "loss": 0.0,
      "step": 58300
    },
    {
      "epoch": 3.7437443859874246,
      "grad_norm": 0.028135886415839195,
      "learning_rate": 0.0003128159887078147,
      "loss": 0.0,
      "step": 58350
    },
    {
      "epoch": 3.746952393173361,
      "grad_norm": 0.005486068781465292,
      "learning_rate": 0.0003126555883485179,
      "loss": 0.0,
      "step": 58400
    },
    {
      "epoch": 3.750160400359297,
      "grad_norm": 0.018863357603549957,
      "learning_rate": 0.0003124951879892211,
      "loss": 0.0,
      "step": 58450
    },
    {
      "epoch": 3.753368407545233,
      "grad_norm": 0.01732194609940052,
      "learning_rate": 0.0003123347876299243,
      "loss": 0.0,
      "step": 58500
    },
    {
      "epoch": 3.756576414731169,
      "grad_norm": 0.020410802215337753,
      "learning_rate": 0.0003121743872706275,
      "loss": 0.0,
      "step": 58550
    },
    {
      "epoch": 3.759784421917105,
      "grad_norm": 0.012895244173705578,
      "learning_rate": 0.0003120139869113307,
      "loss": 0.0,
      "step": 58600
    },
    {
      "epoch": 3.762992429103041,
      "grad_norm": 0.0034343779552727938,
      "learning_rate": 0.0003118535865520339,
      "loss": 0.0,
      "step": 58650
    },
    {
      "epoch": 3.7662004362889774,
      "grad_norm": 0.012652470730245113,
      "learning_rate": 0.00031169318619273705,
      "loss": 0.0,
      "step": 58700
    },
    {
      "epoch": 3.769408443474913,
      "grad_norm": 0.0065096281468868256,
      "learning_rate": 0.00031153278583344026,
      "loss": 0.0,
      "step": 58750
    },
    {
      "epoch": 3.7726164506608493,
      "grad_norm": 0.028861697763204575,
      "learning_rate": 0.00031137238547414346,
      "loss": 0.0,
      "step": 58800
    },
    {
      "epoch": 3.7758244578467854,
      "grad_norm": 0.009978159330785275,
      "learning_rate": 0.00031121198511484667,
      "loss": 0.0,
      "step": 58850
    },
    {
      "epoch": 3.7790324650327216,
      "grad_norm": 0.004006039351224899,
      "learning_rate": 0.0003110515847555498,
      "loss": 0.0,
      "step": 58900
    },
    {
      "epoch": 3.782240472218658,
      "grad_norm": 0.02191910333931446,
      "learning_rate": 0.0003108911843962531,
      "loss": 0.0,
      "step": 58950
    },
    {
      "epoch": 3.785448479404594,
      "grad_norm": 0.0034167866688221693,
      "learning_rate": 0.00031073078403695624,
      "loss": 0.0,
      "step": 59000
    },
    {
      "epoch": 3.78865648659053,
      "grad_norm": 0.01186959259212017,
      "learning_rate": 0.00031057038367765944,
      "loss": 0.0,
      "step": 59050
    },
    {
      "epoch": 3.7918644937764663,
      "grad_norm": 0.005781553685665131,
      "learning_rate": 0.0003104099833183626,
      "loss": 0.0,
      "step": 59100
    },
    {
      "epoch": 3.795072500962402,
      "grad_norm": 0.004273700062185526,
      "learning_rate": 0.00031024958295906586,
      "loss": 0.0,
      "step": 59150
    },
    {
      "epoch": 3.798280508148338,
      "grad_norm": 0.017965413630008698,
      "learning_rate": 0.00031008918259976906,
      "loss": 0.0,
      "step": 59200
    },
    {
      "epoch": 3.8014885153342743,
      "grad_norm": 0.02649909444153309,
      "learning_rate": 0.0003099287822404722,
      "loss": 0.0,
      "step": 59250
    },
    {
      "epoch": 3.8046965225202105,
      "grad_norm": 0.00380853028036654,
      "learning_rate": 0.0003097683818811754,
      "loss": 0.0,
      "step": 59300
    },
    {
      "epoch": 3.8079045297061467,
      "grad_norm": 0.011831620708107948,
      "learning_rate": 0.00030960798152187863,
      "loss": 0.0,
      "step": 59350
    },
    {
      "epoch": 3.8111125368920824,
      "grad_norm": 0.005963164381682873,
      "learning_rate": 0.00030944758116258184,
      "loss": 0.0,
      "step": 59400
    },
    {
      "epoch": 3.8143205440780186,
      "grad_norm": 0.021646762266755104,
      "learning_rate": 0.000309287180803285,
      "loss": 0.0,
      "step": 59450
    },
    {
      "epoch": 3.8175285512639547,
      "grad_norm": 0.009828323498368263,
      "learning_rate": 0.0003091267804439882,
      "loss": 0.0,
      "step": 59500
    },
    {
      "epoch": 3.820736558449891,
      "grad_norm": 0.020191704854369164,
      "learning_rate": 0.0003089663800846914,
      "loss": 0.0,
      "step": 59550
    },
    {
      "epoch": 3.823944565635827,
      "grad_norm": 0.01893572323024273,
      "learning_rate": 0.0003088059797253946,
      "loss": 0.0,
      "step": 59600
    },
    {
      "epoch": 3.8271525728217632,
      "grad_norm": 0.011387525126338005,
      "learning_rate": 0.00030864557936609776,
      "loss": 0.0,
      "step": 59650
    },
    {
      "epoch": 3.8303605800076994,
      "grad_norm": 0.022600622847676277,
      "learning_rate": 0.000308485179006801,
      "loss": 0.0,
      "step": 59700
    },
    {
      "epoch": 3.8335685871936356,
      "grad_norm": 0.013629088178277016,
      "learning_rate": 0.0003083247786475042,
      "loss": 0.0,
      "step": 59750
    },
    {
      "epoch": 3.8367765943795713,
      "grad_norm": 0.021916944533586502,
      "learning_rate": 0.0003081643782882074,
      "loss": 0.0,
      "step": 59800
    },
    {
      "epoch": 3.8399846015655075,
      "grad_norm": 0.008967009373009205,
      "learning_rate": 0.00030800397792891054,
      "loss": 0.0,
      "step": 59850
    },
    {
      "epoch": 3.8431926087514436,
      "grad_norm": 0.015169956721365452,
      "learning_rate": 0.0003078435775696138,
      "loss": 0.0,
      "step": 59900
    },
    {
      "epoch": 3.84640061593738,
      "grad_norm": 0.028755517676472664,
      "learning_rate": 0.00030768317721031695,
      "loss": 0.0,
      "step": 59950
    },
    {
      "epoch": 3.8496086231233155,
      "grad_norm": 0.02236444503068924,
      "learning_rate": 0.00030752277685102016,
      "loss": 0.0,
      "step": 60000
    },
    {
      "epoch": 3.8528166303092517,
      "grad_norm": 0.007581564597785473,
      "learning_rate": 0.0003073623764917233,
      "loss": 0.0,
      "step": 60050
    },
    {
      "epoch": 3.856024637495188,
      "grad_norm": 0.014478731900453568,
      "learning_rate": 0.00030720197613242657,
      "loss": 0.0,
      "step": 60100
    },
    {
      "epoch": 3.859232644681124,
      "grad_norm": 0.011978053487837315,
      "learning_rate": 0.0003070415757731297,
      "loss": 0.0,
      "step": 60150
    },
    {
      "epoch": 3.86244065186706,
      "grad_norm": 0.007986702024936676,
      "learning_rate": 0.00030688117541383293,
      "loss": 0.0,
      "step": 60200
    },
    {
      "epoch": 3.8656486590529964,
      "grad_norm": 0.01642751321196556,
      "learning_rate": 0.0003067207750545361,
      "loss": 0.0,
      "step": 60250
    },
    {
      "epoch": 3.8688566662389325,
      "grad_norm": 0.00522867776453495,
      "learning_rate": 0.00030656037469523935,
      "loss": 0.0,
      "step": 60300
    },
    {
      "epoch": 3.8720646734248687,
      "grad_norm": 0.0132727837190032,
      "learning_rate": 0.0003063999743359425,
      "loss": 0.0,
      "step": 60350
    },
    {
      "epoch": 3.8752726806108044,
      "grad_norm": 0.02772393636405468,
      "learning_rate": 0.0003062395739766457,
      "loss": 0.0,
      "step": 60400
    },
    {
      "epoch": 3.8784806877967406,
      "grad_norm": 0.005735279992222786,
      "learning_rate": 0.00030607917361734886,
      "loss": 0.0,
      "step": 60450
    },
    {
      "epoch": 3.8816886949826768,
      "grad_norm": 0.02876247465610504,
      "learning_rate": 0.0003059187732580521,
      "loss": 0.0,
      "step": 60500
    },
    {
      "epoch": 3.884896702168613,
      "grad_norm": 0.02584015019237995,
      "learning_rate": 0.00030575837289875527,
      "loss": 0.0,
      "step": 60550
    },
    {
      "epoch": 3.888104709354549,
      "grad_norm": 0.0018758238293230534,
      "learning_rate": 0.0003055979725394585,
      "loss": 0.0,
      "step": 60600
    },
    {
      "epoch": 3.891312716540485,
      "grad_norm": 0.020080851390957832,
      "learning_rate": 0.00030543757218016174,
      "loss": 0.0,
      "step": 60650
    },
    {
      "epoch": 3.894520723726421,
      "grad_norm": 0.009805652312934399,
      "learning_rate": 0.0003052771718208649,
      "loss": 0.0,
      "step": 60700
    },
    {
      "epoch": 3.897728730912357,
      "grad_norm": 0.004732721950858831,
      "learning_rate": 0.0003051167714615681,
      "loss": 0.0,
      "step": 60750
    },
    {
      "epoch": 3.9009367380982933,
      "grad_norm": 0.006320433225482702,
      "learning_rate": 0.00030495637110227125,
      "loss": 0.0,
      "step": 60800
    },
    {
      "epoch": 3.9041447452842295,
      "grad_norm": 0.0076280939392745495,
      "learning_rate": 0.0003047959707429745,
      "loss": 0.0,
      "step": 60850
    },
    {
      "epoch": 3.9073527524701657,
      "grad_norm": 0.004563266411423683,
      "learning_rate": 0.00030463557038367767,
      "loss": 0.0,
      "step": 60900
    },
    {
      "epoch": 3.910560759656102,
      "grad_norm": 0.007424547802656889,
      "learning_rate": 0.0003044751700243809,
      "loss": 0.0,
      "step": 60950
    },
    {
      "epoch": 3.9137687668420376,
      "grad_norm": 0.00918116606771946,
      "learning_rate": 0.000304314769665084,
      "loss": 0.0,
      "step": 61000
    },
    {
      "epoch": 3.9169767740279737,
      "grad_norm": 0.018270615488290787,
      "learning_rate": 0.0003041543693057873,
      "loss": 0.0,
      "step": 61050
    },
    {
      "epoch": 3.92018478121391,
      "grad_norm": 0.011597472243010998,
      "learning_rate": 0.00030399396894649044,
      "loss": 0.0,
      "step": 61100
    },
    {
      "epoch": 3.923392788399846,
      "grad_norm": 0.02008955366909504,
      "learning_rate": 0.00030383356858719365,
      "loss": 0.0,
      "step": 61150
    },
    {
      "epoch": 3.9266007955857822,
      "grad_norm": 0.010929861105978489,
      "learning_rate": 0.0003036731682278968,
      "loss": 0.0,
      "step": 61200
    },
    {
      "epoch": 3.929808802771718,
      "grad_norm": 0.012383894994854927,
      "learning_rate": 0.00030351276786860006,
      "loss": 0.0,
      "step": 61250
    },
    {
      "epoch": 3.933016809957654,
      "grad_norm": 0.011580218560993671,
      "learning_rate": 0.0003033523675093032,
      "loss": 0.0,
      "step": 61300
    },
    {
      "epoch": 3.9362248171435903,
      "grad_norm": 0.02453063428401947,
      "learning_rate": 0.0003031919671500064,
      "loss": 0.0,
      "step": 61350
    },
    {
      "epoch": 3.9394328243295265,
      "grad_norm": 0.0031527436804026365,
      "learning_rate": 0.00030303156679070963,
      "loss": 0.0,
      "step": 61400
    },
    {
      "epoch": 3.9426408315154626,
      "grad_norm": 0.00337244407273829,
      "learning_rate": 0.00030287116643141283,
      "loss": 0.0,
      "step": 61450
    },
    {
      "epoch": 3.945848838701399,
      "grad_norm": 0.004578420892357826,
      "learning_rate": 0.000302710766072116,
      "loss": 0.0,
      "step": 61500
    },
    {
      "epoch": 3.949056845887335,
      "grad_norm": 0.01627432554960251,
      "learning_rate": 0.0003025503657128192,
      "loss": 0.0,
      "step": 61550
    },
    {
      "epoch": 3.952264853073271,
      "grad_norm": 0.012140676379203796,
      "learning_rate": 0.0003023899653535224,
      "loss": 0.0,
      "step": 61600
    },
    {
      "epoch": 3.955472860259207,
      "grad_norm": 0.01354830153286457,
      "learning_rate": 0.0003022295649942256,
      "loss": 0.0,
      "step": 61650
    },
    {
      "epoch": 3.958680867445143,
      "grad_norm": 0.022253500297665596,
      "learning_rate": 0.00030206916463492876,
      "loss": 0.0,
      "step": 61700
    },
    {
      "epoch": 3.961888874631079,
      "grad_norm": 0.024982791393995285,
      "learning_rate": 0.00030190876427563197,
      "loss": 0.0,
      "step": 61750
    },
    {
      "epoch": 3.9650968818170154,
      "grad_norm": 0.01348753273487091,
      "learning_rate": 0.0003017483639163352,
      "loss": 0.0,
      "step": 61800
    },
    {
      "epoch": 3.9683048890029515,
      "grad_norm": 0.014511928893625736,
      "learning_rate": 0.0003015879635570384,
      "loss": 0.0,
      "step": 61850
    },
    {
      "epoch": 3.9715128961888873,
      "grad_norm": 0.007767773699015379,
      "learning_rate": 0.00030142756319774153,
      "loss": 0.0,
      "step": 61900
    },
    {
      "epoch": 3.9747209033748234,
      "grad_norm": 0.009898838587105274,
      "learning_rate": 0.00030126716283844474,
      "loss": 0.0,
      "step": 61950
    },
    {
      "epoch": 3.9779289105607596,
      "grad_norm": 0.01918811909854412,
      "learning_rate": 0.000301106762479148,
      "loss": 0.0,
      "step": 62000
    },
    {
      "epoch": 3.9811369177466958,
      "grad_norm": 0.005003537051379681,
      "learning_rate": 0.00030094636211985116,
      "loss": 0.0,
      "step": 62050
    },
    {
      "epoch": 3.984344924932632,
      "grad_norm": 0.011451877653598785,
      "learning_rate": 0.00030078596176055436,
      "loss": 0.0,
      "step": 62100
    },
    {
      "epoch": 3.987552932118568,
      "grad_norm": 0.010203148238360882,
      "learning_rate": 0.0003006255614012575,
      "loss": 0.0,
      "step": 62150
    },
    {
      "epoch": 3.9907609393045043,
      "grad_norm": 0.012324267998337746,
      "learning_rate": 0.0003004651610419608,
      "loss": 0.0,
      "step": 62200
    },
    {
      "epoch": 3.99396894649044,
      "grad_norm": 0.008015372790396214,
      "learning_rate": 0.00030030476068266393,
      "loss": 0.0,
      "step": 62250
    },
    {
      "epoch": 3.997176953676376,
      "grad_norm": 0.004335049074143171,
      "learning_rate": 0.00030014436032336714,
      "loss": 0.0,
      "step": 62300
    },
    {
      "epoch": 4.000384960862313,
      "grad_norm": 0.005374328698962927,
      "learning_rate": 0.00029998395996407034,
      "loss": 0.0,
      "step": 62350
    },
    {
      "epoch": 4.003592968048248,
      "grad_norm": 0.02009662427008152,
      "learning_rate": 0.00029982355960477355,
      "loss": 0.0,
      "step": 62400
    },
    {
      "epoch": 4.006800975234184,
      "grad_norm": 0.0166021641343832,
      "learning_rate": 0.0002996631592454767,
      "loss": 0.0,
      "step": 62450
    },
    {
      "epoch": 4.01000898242012,
      "grad_norm": 0.028157131746411324,
      "learning_rate": 0.0002995027588861799,
      "loss": 0.0,
      "step": 62500
    },
    {
      "epoch": 4.0132169896060566,
      "grad_norm": 0.009490062482655048,
      "learning_rate": 0.0002993423585268831,
      "loss": 0.0,
      "step": 62550
    },
    {
      "epoch": 4.016424996791993,
      "grad_norm": 0.025194985792040825,
      "learning_rate": 0.0002991819581675863,
      "loss": 0.0,
      "step": 62600
    },
    {
      "epoch": 4.019633003977929,
      "grad_norm": 0.006030970253050327,
      "learning_rate": 0.0002990215578082895,
      "loss": 0.0,
      "step": 62650
    },
    {
      "epoch": 4.022841011163865,
      "grad_norm": 0.03013378195464611,
      "learning_rate": 0.0002988611574489927,
      "loss": 0.0,
      "step": 62700
    },
    {
      "epoch": 4.026049018349801,
      "grad_norm": 0.014735018834471703,
      "learning_rate": 0.0002987007570896959,
      "loss": 0.0,
      "step": 62750
    },
    {
      "epoch": 4.029257025535737,
      "grad_norm": 0.0144080501049757,
      "learning_rate": 0.0002985403567303991,
      "loss": 0.0,
      "step": 62800
    },
    {
      "epoch": 4.032465032721674,
      "grad_norm": 0.0035344536881893873,
      "learning_rate": 0.00029837995637110225,
      "loss": 0.0,
      "step": 62850
    },
    {
      "epoch": 4.03567303990761,
      "grad_norm": 0.009861352853477001,
      "learning_rate": 0.00029821955601180546,
      "loss": 0.0,
      "step": 62900
    },
    {
      "epoch": 4.038881047093546,
      "grad_norm": 0.015530179254710674,
      "learning_rate": 0.00029805915565250866,
      "loss": 0.0,
      "step": 62950
    },
    {
      "epoch": 4.042089054279481,
      "grad_norm": 0.0009291571332141757,
      "learning_rate": 0.00029789875529321187,
      "loss": 0.0,
      "step": 63000
    },
    {
      "epoch": 4.045297061465417,
      "grad_norm": 0.003290430875495076,
      "learning_rate": 0.000297738354933915,
      "loss": 0.0,
      "step": 63050
    },
    {
      "epoch": 4.0485050686513535,
      "grad_norm": 0.007068178150802851,
      "learning_rate": 0.00029757795457461823,
      "loss": 0.0,
      "step": 63100
    },
    {
      "epoch": 4.05171307583729,
      "grad_norm": 0.013317268341779709,
      "learning_rate": 0.00029741755421532144,
      "loss": 0.0,
      "step": 63150
    },
    {
      "epoch": 4.054921083023226,
      "grad_norm": 0.01213799323886633,
      "learning_rate": 0.00029725715385602464,
      "loss": 0.0,
      "step": 63200
    },
    {
      "epoch": 4.058129090209162,
      "grad_norm": 0.043443478643894196,
      "learning_rate": 0.0002970967534967278,
      "loss": 0.0,
      "step": 63250
    },
    {
      "epoch": 4.061337097395098,
      "grad_norm": 0.008294347673654556,
      "learning_rate": 0.00029693635313743106,
      "loss": 0.0,
      "step": 63300
    },
    {
      "epoch": 4.064545104581034,
      "grad_norm": 0.01205974817276001,
      "learning_rate": 0.00029677595277813427,
      "loss": 0.0,
      "step": 63350
    },
    {
      "epoch": 4.0677531117669705,
      "grad_norm": 0.043551355600357056,
      "learning_rate": 0.0002966155524188374,
      "loss": 0.0,
      "step": 63400
    },
    {
      "epoch": 4.070961118952907,
      "grad_norm": 0.010952950455248356,
      "learning_rate": 0.0002964551520595406,
      "loss": 0.0,
      "step": 63450
    },
    {
      "epoch": 4.074169126138843,
      "grad_norm": 0.0068705142475664616,
      "learning_rate": 0.00029629475170024383,
      "loss": 0.0,
      "step": 63500
    },
    {
      "epoch": 4.077377133324779,
      "grad_norm": 0.010786090977489948,
      "learning_rate": 0.00029613435134094704,
      "loss": 0.0,
      "step": 63550
    },
    {
      "epoch": 4.080585140510715,
      "grad_norm": 0.01307095866650343,
      "learning_rate": 0.0002959739509816502,
      "loss": 0.0,
      "step": 63600
    },
    {
      "epoch": 4.0837931476966505,
      "grad_norm": 0.026288723573088646,
      "learning_rate": 0.0002958135506223534,
      "loss": 0.0,
      "step": 63650
    },
    {
      "epoch": 4.087001154882587,
      "grad_norm": 0.004731621593236923,
      "learning_rate": 0.0002956531502630566,
      "loss": 0.0,
      "step": 63700
    },
    {
      "epoch": 4.090209162068523,
      "grad_norm": 0.010867124423384666,
      "learning_rate": 0.0002954927499037598,
      "loss": 0.0,
      "step": 63750
    },
    {
      "epoch": 4.093417169254459,
      "grad_norm": 0.005362373776733875,
      "learning_rate": 0.00029533234954446297,
      "loss": 0.0,
      "step": 63800
    },
    {
      "epoch": 4.096625176440395,
      "grad_norm": 0.003523806808516383,
      "learning_rate": 0.00029517194918516617,
      "loss": 0.0,
      "step": 63850
    },
    {
      "epoch": 4.099833183626331,
      "grad_norm": 0.007884437218308449,
      "learning_rate": 0.0002950115488258694,
      "loss": 0.0,
      "step": 63900
    },
    {
      "epoch": 4.1030411908122675,
      "grad_norm": 0.015244384296238422,
      "learning_rate": 0.0002948511484665726,
      "loss": 0.0,
      "step": 63950
    },
    {
      "epoch": 4.106249197998204,
      "grad_norm": 0.009230240248143673,
      "learning_rate": 0.00029469074810727574,
      "loss": 0.0,
      "step": 64000
    },
    {
      "epoch": 4.10945720518414,
      "grad_norm": 0.009987772442400455,
      "learning_rate": 0.000294530347747979,
      "loss": 0.0,
      "step": 64050
    },
    {
      "epoch": 4.112665212370076,
      "grad_norm": 0.01365329883992672,
      "learning_rate": 0.00029436994738868215,
      "loss": 0.0,
      "step": 64100
    },
    {
      "epoch": 4.115873219556012,
      "grad_norm": 0.0015416474780067801,
      "learning_rate": 0.00029420954702938536,
      "loss": 0.0,
      "step": 64150
    },
    {
      "epoch": 4.119081226741948,
      "grad_norm": 0.005302701145410538,
      "learning_rate": 0.0002940491466700885,
      "loss": 0.0,
      "step": 64200
    },
    {
      "epoch": 4.122289233927884,
      "grad_norm": 0.029041673988103867,
      "learning_rate": 0.0002938887463107918,
      "loss": 0.0,
      "step": 64250
    },
    {
      "epoch": 4.12549724111382,
      "grad_norm": 0.018262552097439766,
      "learning_rate": 0.0002937283459514949,
      "loss": 0.0,
      "step": 64300
    },
    {
      "epoch": 4.128705248299756,
      "grad_norm": 0.012752358801662922,
      "learning_rate": 0.00029356794559219813,
      "loss": 0.0,
      "step": 64350
    },
    {
      "epoch": 4.131913255485692,
      "grad_norm": 0.0301672276109457,
      "learning_rate": 0.0002934075452329013,
      "loss": 0.0,
      "step": 64400
    },
    {
      "epoch": 4.135121262671628,
      "grad_norm": 0.003934320528060198,
      "learning_rate": 0.00029324714487360455,
      "loss": 0.0,
      "step": 64450
    },
    {
      "epoch": 4.138329269857564,
      "grad_norm": 0.020502883940935135,
      "learning_rate": 0.0002930867445143077,
      "loss": 0.0,
      "step": 64500
    },
    {
      "epoch": 4.141537277043501,
      "grad_norm": 0.012766808271408081,
      "learning_rate": 0.0002929263441550109,
      "loss": 0.0,
      "step": 64550
    },
    {
      "epoch": 4.144745284229437,
      "grad_norm": 0.007930200546979904,
      "learning_rate": 0.00029276594379571406,
      "loss": 0.0,
      "step": 64600
    },
    {
      "epoch": 4.147953291415373,
      "grad_norm": 0.012591917999088764,
      "learning_rate": 0.0002926055434364173,
      "loss": 0.0,
      "step": 64650
    },
    {
      "epoch": 4.151161298601309,
      "grad_norm": 0.007441912777721882,
      "learning_rate": 0.00029244514307712053,
      "loss": 0.0,
      "step": 64700
    },
    {
      "epoch": 4.154369305787245,
      "grad_norm": 0.008550317957997322,
      "learning_rate": 0.0002922847427178237,
      "loss": 0.0,
      "step": 64750
    },
    {
      "epoch": 4.1575773129731814,
      "grad_norm": 0.017980774864554405,
      "learning_rate": 0.0002921243423585269,
      "loss": 0.0,
      "step": 64800
    },
    {
      "epoch": 4.160785320159117,
      "grad_norm": 0.004627144429832697,
      "learning_rate": 0.0002919639419992301,
      "loss": 0.0,
      "step": 64850
    },
    {
      "epoch": 4.163993327345053,
      "grad_norm": 0.001489712973125279,
      "learning_rate": 0.0002918035416399333,
      "loss": 0.0,
      "step": 64900
    },
    {
      "epoch": 4.167201334530989,
      "grad_norm": 0.0075250412337481976,
      "learning_rate": 0.00029164314128063645,
      "loss": 0.0,
      "step": 64950
    },
    {
      "epoch": 4.170409341716925,
      "grad_norm": 0.007940346375107765,
      "learning_rate": 0.0002914827409213397,
      "loss": 0.0,
      "step": 65000
    },
    {
      "epoch": 4.173617348902861,
      "grad_norm": 0.027984078973531723,
      "learning_rate": 0.00029132234056204287,
      "loss": 0.0,
      "step": 65050
    },
    {
      "epoch": 4.176825356088798,
      "grad_norm": 0.013769615441560745,
      "learning_rate": 0.0002911619402027461,
      "loss": 0.0,
      "step": 65100
    },
    {
      "epoch": 4.180033363274734,
      "grad_norm": 0.007375533692538738,
      "learning_rate": 0.00029100153984344923,
      "loss": 0.0,
      "step": 65150
    },
    {
      "epoch": 4.18324137046067,
      "grad_norm": 0.006447233259677887,
      "learning_rate": 0.0002908411394841525,
      "loss": 0.0,
      "step": 65200
    },
    {
      "epoch": 4.186449377646606,
      "grad_norm": 0.022393060848116875,
      "learning_rate": 0.00029068073912485564,
      "loss": 0.0,
      "step": 65250
    },
    {
      "epoch": 4.189657384832542,
      "grad_norm": 0.014487468637526035,
      "learning_rate": 0.00029052033876555885,
      "loss": 0.0,
      "step": 65300
    },
    {
      "epoch": 4.192865392018478,
      "grad_norm": 0.0040628849528729916,
      "learning_rate": 0.000290359938406262,
      "loss": 0.0,
      "step": 65350
    },
    {
      "epoch": 4.196073399204415,
      "grad_norm": 0.008041920140385628,
      "learning_rate": 0.00029019953804696526,
      "loss": 0.0,
      "step": 65400
    },
    {
      "epoch": 4.19928140639035,
      "grad_norm": 0.01051148772239685,
      "learning_rate": 0.0002900391376876684,
      "loss": 0.0,
      "step": 65450
    },
    {
      "epoch": 4.202489413576286,
      "grad_norm": 0.00796592514961958,
      "learning_rate": 0.0002898787373283716,
      "loss": 0.0,
      "step": 65500
    },
    {
      "epoch": 4.205697420762222,
      "grad_norm": 0.03215751424431801,
      "learning_rate": 0.0002897183369690748,
      "loss": 0.0,
      "step": 65550
    },
    {
      "epoch": 4.208905427948158,
      "grad_norm": 0.01680535450577736,
      "learning_rate": 0.00028955793660977804,
      "loss": 0.0,
      "step": 65600
    },
    {
      "epoch": 4.2121134351340945,
      "grad_norm": 0.021689053624868393,
      "learning_rate": 0.0002893975362504812,
      "loss": 0.0,
      "step": 65650
    },
    {
      "epoch": 4.215321442320031,
      "grad_norm": 0.012481938116252422,
      "learning_rate": 0.0002892371358911844,
      "loss": 0.0,
      "step": 65700
    },
    {
      "epoch": 4.218529449505967,
      "grad_norm": 0.01697242632508278,
      "learning_rate": 0.0002890767355318876,
      "loss": 0.0,
      "step": 65750
    },
    {
      "epoch": 4.221737456691903,
      "grad_norm": 0.018386859446763992,
      "learning_rate": 0.0002889163351725908,
      "loss": 0.0,
      "step": 65800
    },
    {
      "epoch": 4.224945463877839,
      "grad_norm": 0.0067758322693407536,
      "learning_rate": 0.00028875593481329396,
      "loss": 0.0,
      "step": 65850
    },
    {
      "epoch": 4.228153471063775,
      "grad_norm": 0.003610148560255766,
      "learning_rate": 0.00028859553445399717,
      "loss": 0.0,
      "step": 65900
    },
    {
      "epoch": 4.2313614782497115,
      "grad_norm": 0.006893296726047993,
      "learning_rate": 0.0002884351340947004,
      "loss": 0.0,
      "step": 65950
    },
    {
      "epoch": 4.234569485435648,
      "grad_norm": 0.011294502764940262,
      "learning_rate": 0.0002882747337354036,
      "loss": 0.0,
      "step": 66000
    },
    {
      "epoch": 4.237777492621584,
      "grad_norm": 0.012120471335947514,
      "learning_rate": 0.0002881143333761068,
      "loss": 0.0,
      "step": 66050
    },
    {
      "epoch": 4.240985499807519,
      "grad_norm": 0.014702125452458858,
      "learning_rate": 0.00028795393301680994,
      "loss": 0.0,
      "step": 66100
    },
    {
      "epoch": 4.244193506993455,
      "grad_norm": 0.017843512818217278,
      "learning_rate": 0.0002877935326575132,
      "loss": 0.0,
      "step": 66150
    },
    {
      "epoch": 4.2474015141793915,
      "grad_norm": 0.020569337531924248,
      "learning_rate": 0.00028763313229821636,
      "loss": 0.0,
      "step": 66200
    },
    {
      "epoch": 4.250609521365328,
      "grad_norm": 0.005855300463736057,
      "learning_rate": 0.00028747273193891956,
      "loss": 0.0,
      "step": 66250
    },
    {
      "epoch": 4.253817528551264,
      "grad_norm": 0.010108872316777706,
      "learning_rate": 0.0002873123315796227,
      "loss": 0.0,
      "step": 66300
    },
    {
      "epoch": 4.2570255357372,
      "grad_norm": 0.010189702734351158,
      "learning_rate": 0.000287151931220326,
      "loss": 0.0,
      "step": 66350
    },
    {
      "epoch": 4.260233542923136,
      "grad_norm": 0.0048859333619475365,
      "learning_rate": 0.00028699153086102913,
      "loss": 0.0,
      "step": 66400
    },
    {
      "epoch": 4.263441550109072,
      "grad_norm": 0.0060782781802117825,
      "learning_rate": 0.00028683113050173234,
      "loss": 0.0,
      "step": 66450
    },
    {
      "epoch": 4.2666495572950085,
      "grad_norm": 0.015191318467259407,
      "learning_rate": 0.0002866707301424355,
      "loss": 0.0,
      "step": 66500
    },
    {
      "epoch": 4.269857564480945,
      "grad_norm": 0.011473054997622967,
      "learning_rate": 0.00028651032978313875,
      "loss": 0.0,
      "step": 66550
    },
    {
      "epoch": 4.273065571666881,
      "grad_norm": 0.0043730344623327255,
      "learning_rate": 0.0002863499294238419,
      "loss": 0.0,
      "step": 66600
    },
    {
      "epoch": 4.276273578852817,
      "grad_norm": 0.010737068019807339,
      "learning_rate": 0.0002861895290645451,
      "loss": 0.0,
      "step": 66650
    },
    {
      "epoch": 4.279481586038752,
      "grad_norm": 0.01906779035925865,
      "learning_rate": 0.0002860291287052483,
      "loss": 0.0,
      "step": 66700
    },
    {
      "epoch": 4.2826895932246885,
      "grad_norm": 0.015582029707729816,
      "learning_rate": 0.0002858687283459515,
      "loss": 0.0,
      "step": 66750
    },
    {
      "epoch": 4.285897600410625,
      "grad_norm": 0.018907196819782257,
      "learning_rate": 0.0002857083279866547,
      "loss": 0.0,
      "step": 66800
    },
    {
      "epoch": 4.289105607596561,
      "grad_norm": 0.03799596056342125,
      "learning_rate": 0.0002855479276273579,
      "loss": 0.0,
      "step": 66850
    },
    {
      "epoch": 4.292313614782497,
      "grad_norm": 0.0026187582407146692,
      "learning_rate": 0.0002853875272680611,
      "loss": 0.0,
      "step": 66900
    },
    {
      "epoch": 4.295521621968433,
      "grad_norm": 0.010028282180428505,
      "learning_rate": 0.0002852271269087643,
      "loss": 0.0,
      "step": 66950
    },
    {
      "epoch": 4.298729629154369,
      "grad_norm": 0.012491093017160892,
      "learning_rate": 0.00028506672654946745,
      "loss": 0.0,
      "step": 67000
    },
    {
      "epoch": 4.3019376363403055,
      "grad_norm": 0.006807004567235708,
      "learning_rate": 0.00028490632619017066,
      "loss": 0.0,
      "step": 67050
    },
    {
      "epoch": 4.305145643526242,
      "grad_norm": 0.008997398428618908,
      "learning_rate": 0.00028474592583087386,
      "loss": 0.0,
      "step": 67100
    },
    {
      "epoch": 4.308353650712178,
      "grad_norm": 0.01817391999065876,
      "learning_rate": 0.00028458552547157707,
      "loss": 0.0,
      "step": 67150
    },
    {
      "epoch": 4.311561657898114,
      "grad_norm": 0.012354479171335697,
      "learning_rate": 0.0002844251251122802,
      "loss": 0.0,
      "step": 67200
    },
    {
      "epoch": 4.31476966508405,
      "grad_norm": 0.005368944723159075,
      "learning_rate": 0.00028426472475298343,
      "loss": 0.0,
      "step": 67250
    },
    {
      "epoch": 4.317977672269986,
      "grad_norm": 0.01567688025534153,
      "learning_rate": 0.00028410432439368664,
      "loss": 0.0,
      "step": 67300
    },
    {
      "epoch": 4.321185679455922,
      "grad_norm": 0.004857607185840607,
      "learning_rate": 0.00028394392403438985,
      "loss": 0.0,
      "step": 67350
    },
    {
      "epoch": 4.324393686641858,
      "grad_norm": 0.015799324959516525,
      "learning_rate": 0.000283783523675093,
      "loss": 0.0,
      "step": 67400
    },
    {
      "epoch": 4.327601693827794,
      "grad_norm": 0.0041415016166865826,
      "learning_rate": 0.00028362312331579626,
      "loss": 0.0,
      "step": 67450
    },
    {
      "epoch": 4.33080970101373,
      "grad_norm": 0.018782716244459152,
      "learning_rate": 0.00028346272295649947,
      "loss": 0.0,
      "step": 67500
    },
    {
      "epoch": 4.334017708199666,
      "grad_norm": 0.018842462450265884,
      "learning_rate": 0.0002833023225972026,
      "loss": 0.0,
      "step": 67550
    },
    {
      "epoch": 4.337225715385602,
      "grad_norm": 0.02062091790139675,
      "learning_rate": 0.0002831419222379058,
      "loss": 0.0,
      "step": 67600
    },
    {
      "epoch": 4.340433722571539,
      "grad_norm": 0.015496754087507725,
      "learning_rate": 0.00028298152187860903,
      "loss": 0.0,
      "step": 67650
    },
    {
      "epoch": 4.343641729757475,
      "grad_norm": 0.008008155971765518,
      "learning_rate": 0.00028282112151931224,
      "loss": 0.0,
      "step": 67700
    },
    {
      "epoch": 4.346849736943411,
      "grad_norm": 0.005432340782135725,
      "learning_rate": 0.0002826607211600154,
      "loss": 0.0,
      "step": 67750
    },
    {
      "epoch": 4.350057744129347,
      "grad_norm": 0.004123525228351355,
      "learning_rate": 0.0002825003208007186,
      "loss": 0.0,
      "step": 67800
    },
    {
      "epoch": 4.353265751315283,
      "grad_norm": 0.004442465957254171,
      "learning_rate": 0.0002823399204414218,
      "loss": 0.0,
      "step": 67850
    },
    {
      "epoch": 4.356473758501219,
      "grad_norm": 0.006099725142121315,
      "learning_rate": 0.000282179520082125,
      "loss": 0.0,
      "step": 67900
    },
    {
      "epoch": 4.359681765687155,
      "grad_norm": 0.004864184185862541,
      "learning_rate": 0.00028201911972282817,
      "loss": 0.0,
      "step": 67950
    },
    {
      "epoch": 4.362889772873091,
      "grad_norm": 0.018054252490401268,
      "learning_rate": 0.0002818587193635314,
      "loss": 0.0,
      "step": 68000
    },
    {
      "epoch": 4.366097780059027,
      "grad_norm": 0.012646193616092205,
      "learning_rate": 0.0002816983190042346,
      "loss": 0.0,
      "step": 68050
    },
    {
      "epoch": 4.369305787244963,
      "grad_norm": 0.024297233670949936,
      "learning_rate": 0.0002815379186449378,
      "loss": 0.0,
      "step": 68100
    },
    {
      "epoch": 4.372513794430899,
      "grad_norm": 0.017555711790919304,
      "learning_rate": 0.00028137751828564094,
      "loss": 0.0,
      "step": 68150
    },
    {
      "epoch": 4.3757218016168355,
      "grad_norm": 0.003986738156527281,
      "learning_rate": 0.00028121711792634415,
      "loss": 0.0,
      "step": 68200
    },
    {
      "epoch": 4.378929808802772,
      "grad_norm": 0.008037787862122059,
      "learning_rate": 0.00028105671756704735,
      "loss": 0.0,
      "step": 68250
    },
    {
      "epoch": 4.382137815988708,
      "grad_norm": 0.009379926137626171,
      "learning_rate": 0.00028089631720775056,
      "loss": 0.0,
      "step": 68300
    },
    {
      "epoch": 4.385345823174644,
      "grad_norm": 0.0050387256778776646,
      "learning_rate": 0.0002807359168484537,
      "loss": 0.0,
      "step": 68350
    },
    {
      "epoch": 4.38855383036058,
      "grad_norm": 0.013771358877420425,
      "learning_rate": 0.000280575516489157,
      "loss": 0.0,
      "step": 68400
    },
    {
      "epoch": 4.391761837546516,
      "grad_norm": 0.010324379429221153,
      "learning_rate": 0.00028041511612986013,
      "loss": 0.0,
      "step": 68450
    },
    {
      "epoch": 4.394969844732453,
      "grad_norm": 0.02072806842625141,
      "learning_rate": 0.00028025471577056333,
      "loss": 0.0,
      "step": 68500
    },
    {
      "epoch": 4.398177851918389,
      "grad_norm": 0.008723316714167595,
      "learning_rate": 0.0002800943154112665,
      "loss": 0.0,
      "step": 68550
    },
    {
      "epoch": 4.401385859104324,
      "grad_norm": 0.0069769262336194515,
      "learning_rate": 0.00027993391505196975,
      "loss": 0.0,
      "step": 68600
    },
    {
      "epoch": 4.40459386629026,
      "grad_norm": 0.00868544913828373,
      "learning_rate": 0.0002797735146926729,
      "loss": 0.0,
      "step": 68650
    },
    {
      "epoch": 4.407801873476196,
      "grad_norm": 0.013987204059958458,
      "learning_rate": 0.0002796131143333761,
      "loss": 0.0,
      "step": 68700
    },
    {
      "epoch": 4.4110098806621325,
      "grad_norm": 0.009407319128513336,
      "learning_rate": 0.00027945271397407926,
      "loss": 0.0,
      "step": 68750
    },
    {
      "epoch": 4.414217887848069,
      "grad_norm": 0.005817921832203865,
      "learning_rate": 0.0002792923136147825,
      "loss": 0.0,
      "step": 68800
    },
    {
      "epoch": 4.417425895034005,
      "grad_norm": 0.007618478965014219,
      "learning_rate": 0.00027913191325548573,
      "loss": 0.0,
      "step": 68850
    },
    {
      "epoch": 4.420633902219941,
      "grad_norm": 0.011689037084579468,
      "learning_rate": 0.0002789715128961889,
      "loss": 0.0,
      "step": 68900
    },
    {
      "epoch": 4.423841909405877,
      "grad_norm": 0.006939512211829424,
      "learning_rate": 0.0002788111125368921,
      "loss": 0.0,
      "step": 68950
    },
    {
      "epoch": 4.427049916591813,
      "grad_norm": 0.00798032246530056,
      "learning_rate": 0.0002786507121775953,
      "loss": 0.0,
      "step": 69000
    },
    {
      "epoch": 4.4302579237777495,
      "grad_norm": 0.018603641539812088,
      "learning_rate": 0.0002784903118182985,
      "loss": 0.0,
      "step": 69050
    },
    {
      "epoch": 4.433465930963686,
      "grad_norm": 0.011715851724147797,
      "learning_rate": 0.00027832991145900165,
      "loss": 0.0,
      "step": 69100
    },
    {
      "epoch": 4.436673938149622,
      "grad_norm": 0.01138118002563715,
      "learning_rate": 0.00027816951109970486,
      "loss": 0.0,
      "step": 69150
    },
    {
      "epoch": 4.439881945335557,
      "grad_norm": 0.005193349905312061,
      "learning_rate": 0.00027800911074040807,
      "loss": 0.0,
      "step": 69200
    },
    {
      "epoch": 4.443089952521493,
      "grad_norm": 0.008790112100541592,
      "learning_rate": 0.0002778487103811113,
      "loss": 0.0,
      "step": 69250
    },
    {
      "epoch": 4.4462979597074295,
      "grad_norm": 0.020557871088385582,
      "learning_rate": 0.00027768831002181443,
      "loss": 0.0,
      "step": 69300
    },
    {
      "epoch": 4.449505966893366,
      "grad_norm": 0.011904068291187286,
      "learning_rate": 0.0002775279096625177,
      "loss": 0.0,
      "step": 69350
    },
    {
      "epoch": 4.452713974079302,
      "grad_norm": 0.007721080910414457,
      "learning_rate": 0.00027736750930322084,
      "loss": 0.0,
      "step": 69400
    },
    {
      "epoch": 4.455921981265238,
      "grad_norm": 0.009870205074548721,
      "learning_rate": 0.00027720710894392405,
      "loss": 0.0,
      "step": 69450
    },
    {
      "epoch": 4.459129988451174,
      "grad_norm": 0.029168978333473206,
      "learning_rate": 0.0002770467085846272,
      "loss": 0.0,
      "step": 69500
    },
    {
      "epoch": 4.46233799563711,
      "grad_norm": 0.007483662571758032,
      "learning_rate": 0.00027688630822533046,
      "loss": 0.0,
      "step": 69550
    },
    {
      "epoch": 4.4655460028230465,
      "grad_norm": 0.0058454908430576324,
      "learning_rate": 0.0002767259078660336,
      "loss": 0.0,
      "step": 69600
    },
    {
      "epoch": 4.468754010008983,
      "grad_norm": 0.012028557248413563,
      "learning_rate": 0.0002765655075067368,
      "loss": 0.0,
      "step": 69650
    },
    {
      "epoch": 4.471962017194919,
      "grad_norm": 0.008571126498281956,
      "learning_rate": 0.00027640510714744,
      "loss": 0.0,
      "step": 69700
    },
    {
      "epoch": 4.475170024380855,
      "grad_norm": 0.017826030030846596,
      "learning_rate": 0.00027624470678814324,
      "loss": 0.0,
      "step": 69750
    },
    {
      "epoch": 4.478378031566791,
      "grad_norm": 0.011296888813376427,
      "learning_rate": 0.0002760843064288464,
      "loss": 0.0,
      "step": 69800
    },
    {
      "epoch": 4.481586038752726,
      "grad_norm": 0.0272412970662117,
      "learning_rate": 0.0002759239060695496,
      "loss": 0.0,
      "step": 69850
    },
    {
      "epoch": 4.484794045938663,
      "grad_norm": 0.02924519032239914,
      "learning_rate": 0.00027576350571025275,
      "loss": 0.0,
      "step": 69900
    },
    {
      "epoch": 4.488002053124599,
      "grad_norm": 0.011286664754152298,
      "learning_rate": 0.000275603105350956,
      "loss": 0.0,
      "step": 69950
    },
    {
      "epoch": 4.491210060310535,
      "grad_norm": 0.00682070991024375,
      "learning_rate": 0.00027544270499165916,
      "loss": 0.0,
      "step": 70000
    },
    {
      "epoch": 4.494418067496471,
      "grad_norm": 0.011984744109213352,
      "learning_rate": 0.00027528230463236237,
      "loss": 0.0,
      "step": 70050
    },
    {
      "epoch": 4.497626074682407,
      "grad_norm": 0.01189845148473978,
      "learning_rate": 0.0002751219042730656,
      "loss": 0.0,
      "step": 70100
    },
    {
      "epoch": 4.500834081868343,
      "grad_norm": 0.003960495349019766,
      "learning_rate": 0.0002749615039137688,
      "loss": 0.0,
      "step": 70150
    },
    {
      "epoch": 4.50404208905428,
      "grad_norm": 0.007650662213563919,
      "learning_rate": 0.000274801103554472,
      "loss": 0.0,
      "step": 70200
    },
    {
      "epoch": 4.507250096240216,
      "grad_norm": 0.02769942209124565,
      "learning_rate": 0.00027464070319517514,
      "loss": 0.0,
      "step": 70250
    },
    {
      "epoch": 4.510458103426152,
      "grad_norm": 0.0175417959690094,
      "learning_rate": 0.0002744803028358784,
      "loss": 0.0,
      "step": 70300
    },
    {
      "epoch": 4.513666110612088,
      "grad_norm": 0.009809992276132107,
      "learning_rate": 0.00027431990247658156,
      "loss": 0.0,
      "step": 70350
    },
    {
      "epoch": 4.516874117798023,
      "grad_norm": 0.01189133245497942,
      "learning_rate": 0.00027415950211728476,
      "loss": 0.0,
      "step": 70400
    },
    {
      "epoch": 4.52008212498396,
      "grad_norm": 0.011426422744989395,
      "learning_rate": 0.0002739991017579879,
      "loss": 0.0,
      "step": 70450
    },
    {
      "epoch": 4.523290132169896,
      "grad_norm": 0.024860674515366554,
      "learning_rate": 0.0002738387013986912,
      "loss": 0.0,
      "step": 70500
    },
    {
      "epoch": 4.526498139355832,
      "grad_norm": 0.0055976989679038525,
      "learning_rate": 0.00027367830103939433,
      "loss": 0.0,
      "step": 70550
    },
    {
      "epoch": 4.529706146541768,
      "grad_norm": 0.022395191714167595,
      "learning_rate": 0.00027351790068009754,
      "loss": 0.0,
      "step": 70600
    },
    {
      "epoch": 4.532914153727704,
      "grad_norm": 0.009058013558387756,
      "learning_rate": 0.0002733575003208007,
      "loss": 0.0,
      "step": 70650
    },
    {
      "epoch": 4.53612216091364,
      "grad_norm": 0.006761273369193077,
      "learning_rate": 0.00027319709996150395,
      "loss": 0.0,
      "step": 70700
    },
    {
      "epoch": 4.539330168099577,
      "grad_norm": 0.02093220315873623,
      "learning_rate": 0.0002730366996022071,
      "loss": 0.0,
      "step": 70750
    },
    {
      "epoch": 4.542538175285513,
      "grad_norm": 0.01533040963113308,
      "learning_rate": 0.0002728762992429103,
      "loss": 0.0,
      "step": 70800
    },
    {
      "epoch": 4.545746182471449,
      "grad_norm": 0.007056778762489557,
      "learning_rate": 0.00027271589888361346,
      "loss": 0.0,
      "step": 70850
    },
    {
      "epoch": 4.548954189657385,
      "grad_norm": 0.014155703596770763,
      "learning_rate": 0.0002725554985243167,
      "loss": 0.0,
      "step": 70900
    },
    {
      "epoch": 4.552162196843321,
      "grad_norm": 0.0022566586267203093,
      "learning_rate": 0.0002723950981650199,
      "loss": 0.0,
      "step": 70950
    },
    {
      "epoch": 4.555370204029257,
      "grad_norm": 0.011969107203185558,
      "learning_rate": 0.0002722346978057231,
      "loss": 0.0,
      "step": 71000
    },
    {
      "epoch": 4.558578211215194,
      "grad_norm": 0.020770102739334106,
      "learning_rate": 0.0002720742974464263,
      "loss": 0.0,
      "step": 71050
    },
    {
      "epoch": 4.561786218401129,
      "grad_norm": 0.010688481852412224,
      "learning_rate": 0.0002719138970871295,
      "loss": 0.0,
      "step": 71100
    },
    {
      "epoch": 4.564994225587065,
      "grad_norm": 0.006254754960536957,
      "learning_rate": 0.00027175349672783265,
      "loss": 0.0,
      "step": 71150
    },
    {
      "epoch": 4.568202232773001,
      "grad_norm": 0.01262183953076601,
      "learning_rate": 0.00027159309636853586,
      "loss": 0.0,
      "step": 71200
    },
    {
      "epoch": 4.571410239958937,
      "grad_norm": 0.01701321080327034,
      "learning_rate": 0.00027143269600923907,
      "loss": 0.0,
      "step": 71250
    },
    {
      "epoch": 4.5746182471448735,
      "grad_norm": 0.036053288727998734,
      "learning_rate": 0.00027127229564994227,
      "loss": 0.0,
      "step": 71300
    },
    {
      "epoch": 4.57782625433081,
      "grad_norm": 0.012752213515341282,
      "learning_rate": 0.0002711118952906454,
      "loss": 0.0,
      "step": 71350
    },
    {
      "epoch": 4.581034261516746,
      "grad_norm": 0.014171021059155464,
      "learning_rate": 0.00027095149493134863,
      "loss": 0.0,
      "step": 71400
    },
    {
      "epoch": 4.584242268702682,
      "grad_norm": 0.006890672724694014,
      "learning_rate": 0.00027079109457205184,
      "loss": 0.0,
      "step": 71450
    },
    {
      "epoch": 4.587450275888618,
      "grad_norm": 0.04858297109603882,
      "learning_rate": 0.00027063069421275505,
      "loss": 0.0,
      "step": 71500
    },
    {
      "epoch": 4.590658283074554,
      "grad_norm": 0.013555203564465046,
      "learning_rate": 0.00027047029385345825,
      "loss": 0.0,
      "step": 71550
    },
    {
      "epoch": 4.5938662902604905,
      "grad_norm": 0.01910487934947014,
      "learning_rate": 0.0002703098934941614,
      "loss": 0.0,
      "step": 71600
    },
    {
      "epoch": 4.597074297446426,
      "grad_norm": 0.006025043316185474,
      "learning_rate": 0.00027014949313486467,
      "loss": 0.0,
      "step": 71650
    },
    {
      "epoch": 4.600282304632362,
      "grad_norm": 0.005546151660382748,
      "learning_rate": 0.0002699890927755678,
      "loss": 0.0,
      "step": 71700
    },
    {
      "epoch": 4.603490311818298,
      "grad_norm": 0.007610464468598366,
      "learning_rate": 0.000269828692416271,
      "loss": 0.0,
      "step": 71750
    },
    {
      "epoch": 4.606698319004234,
      "grad_norm": 0.018943537026643753,
      "learning_rate": 0.00026966829205697423,
      "loss": 0.0,
      "step": 71800
    },
    {
      "epoch": 4.6099063261901705,
      "grad_norm": 0.00884925201535225,
      "learning_rate": 0.00026950789169767744,
      "loss": 0.0,
      "step": 71850
    },
    {
      "epoch": 4.613114333376107,
      "grad_norm": 0.004700998309999704,
      "learning_rate": 0.0002693474913383806,
      "loss": 0.0,
      "step": 71900
    },
    {
      "epoch": 4.616322340562043,
      "grad_norm": 0.013157835230231285,
      "learning_rate": 0.0002691870909790838,
      "loss": 0.0,
      "step": 71950
    },
    {
      "epoch": 4.619530347747979,
      "grad_norm": 0.017100805416703224,
      "learning_rate": 0.000269026690619787,
      "loss": 0.0,
      "step": 72000
    },
    {
      "epoch": 4.622738354933915,
      "grad_norm": 0.00827752985060215,
      "learning_rate": 0.0002688662902604902,
      "loss": 0.0,
      "step": 72050
    },
    {
      "epoch": 4.625946362119851,
      "grad_norm": 0.0073311058804392815,
      "learning_rate": 0.00026870588990119337,
      "loss": 0.0,
      "step": 72100
    },
    {
      "epoch": 4.6291543693057875,
      "grad_norm": 0.00818570889532566,
      "learning_rate": 0.0002685454895418966,
      "loss": 0.0,
      "step": 72150
    },
    {
      "epoch": 4.632362376491724,
      "grad_norm": 0.0036330525763332844,
      "learning_rate": 0.0002683850891825998,
      "loss": 0.0,
      "step": 72200
    },
    {
      "epoch": 4.63557038367766,
      "grad_norm": 0.0073595657013356686,
      "learning_rate": 0.000268224688823303,
      "loss": 0.0,
      "step": 72250
    },
    {
      "epoch": 4.638778390863596,
      "grad_norm": 0.003473408753052354,
      "learning_rate": 0.00026806428846400614,
      "loss": 0.0,
      "step": 72300
    },
    {
      "epoch": 4.641986398049531,
      "grad_norm": 0.0095541812479496,
      "learning_rate": 0.00026790388810470935,
      "loss": 0.0,
      "step": 72350
    },
    {
      "epoch": 4.6451944052354674,
      "grad_norm": 0.002896105870604515,
      "learning_rate": 0.00026774348774541255,
      "loss": 0.0,
      "step": 72400
    },
    {
      "epoch": 4.648402412421404,
      "grad_norm": 0.02661396749317646,
      "learning_rate": 0.00026758308738611576,
      "loss": 0.0,
      "step": 72450
    },
    {
      "epoch": 4.65161041960734,
      "grad_norm": 0.012138886377215385,
      "learning_rate": 0.0002674226870268189,
      "loss": 0.0,
      "step": 72500
    },
    {
      "epoch": 4.654818426793276,
      "grad_norm": 0.00907661858946085,
      "learning_rate": 0.0002672622866675221,
      "loss": 0.0,
      "step": 72550
    },
    {
      "epoch": 4.658026433979212,
      "grad_norm": 0.018827572464942932,
      "learning_rate": 0.00026710188630822533,
      "loss": 0.0,
      "step": 72600
    },
    {
      "epoch": 4.661234441165148,
      "grad_norm": 0.013492175377905369,
      "learning_rate": 0.00026694148594892854,
      "loss": 0.0,
      "step": 72650
    },
    {
      "epoch": 4.6644424483510845,
      "grad_norm": 0.013521606102585793,
      "learning_rate": 0.0002667810855896317,
      "loss": 0.0,
      "step": 72700
    },
    {
      "epoch": 4.667650455537021,
      "grad_norm": 0.007034566719084978,
      "learning_rate": 0.00026662068523033495,
      "loss": 0.0,
      "step": 72750
    },
    {
      "epoch": 4.670858462722957,
      "grad_norm": 0.00489604938775301,
      "learning_rate": 0.0002664602848710381,
      "loss": 0.0,
      "step": 72800
    },
    {
      "epoch": 4.674066469908893,
      "grad_norm": 0.005031155422329903,
      "learning_rate": 0.0002662998845117413,
      "loss": 0.0,
      "step": 72850
    },
    {
      "epoch": 4.677274477094828,
      "grad_norm": 0.013352105394005775,
      "learning_rate": 0.0002661394841524445,
      "loss": 0.0,
      "step": 72900
    },
    {
      "epoch": 4.680482484280764,
      "grad_norm": 0.012153919786214828,
      "learning_rate": 0.0002659790837931477,
      "loss": 0.0,
      "step": 72950
    },
    {
      "epoch": 4.683690491466701,
      "grad_norm": 0.006461549084633589,
      "learning_rate": 0.00026581868343385093,
      "loss": 0.0,
      "step": 73000
    },
    {
      "epoch": 4.686898498652637,
      "grad_norm": 0.015617827884852886,
      "learning_rate": 0.0002656582830745541,
      "loss": 0.0,
      "step": 73050
    },
    {
      "epoch": 4.690106505838573,
      "grad_norm": 0.008367153815925121,
      "learning_rate": 0.0002654978827152573,
      "loss": 0.0,
      "step": 73100
    },
    {
      "epoch": 4.693314513024509,
      "grad_norm": 0.01465174276381731,
      "learning_rate": 0.0002653374823559605,
      "loss": 0.0,
      "step": 73150
    },
    {
      "epoch": 4.696522520210445,
      "grad_norm": 0.0061483182944357395,
      "learning_rate": 0.0002651770819966637,
      "loss": 0.0,
      "step": 73200
    },
    {
      "epoch": 4.699730527396381,
      "grad_norm": 0.019516093656420708,
      "learning_rate": 0.00026501668163736686,
      "loss": 0.0,
      "step": 73250
    },
    {
      "epoch": 4.702938534582318,
      "grad_norm": 0.0034441521856933832,
      "learning_rate": 0.00026485628127807006,
      "loss": 0.0,
      "step": 73300
    },
    {
      "epoch": 4.706146541768254,
      "grad_norm": 0.021372845396399498,
      "learning_rate": 0.00026469588091877327,
      "loss": 0.0,
      "step": 73350
    },
    {
      "epoch": 4.70935454895419,
      "grad_norm": 0.010297906585037708,
      "learning_rate": 0.0002645354805594765,
      "loss": 0.0,
      "step": 73400
    },
    {
      "epoch": 4.712562556140126,
      "grad_norm": 0.010022821836173534,
      "learning_rate": 0.00026437508020017963,
      "loss": 0.0,
      "step": 73450
    },
    {
      "epoch": 4.715770563326062,
      "grad_norm": 0.006800292059779167,
      "learning_rate": 0.0002642146798408829,
      "loss": 0.0,
      "step": 73500
    },
    {
      "epoch": 4.718978570511998,
      "grad_norm": 0.005894111469388008,
      "learning_rate": 0.00026405427948158604,
      "loss": 0.0,
      "step": 73550
    },
    {
      "epoch": 4.722186577697934,
      "grad_norm": 0.00739733362570405,
      "learning_rate": 0.00026389387912228925,
      "loss": 0.0,
      "step": 73600
    },
    {
      "epoch": 4.72539458488387,
      "grad_norm": 0.011320787481963634,
      "learning_rate": 0.0002637334787629924,
      "loss": 0.0,
      "step": 73650
    },
    {
      "epoch": 4.728602592069806,
      "grad_norm": 0.012842196971178055,
      "learning_rate": 0.00026357307840369566,
      "loss": 0.0,
      "step": 73700
    },
    {
      "epoch": 4.731810599255742,
      "grad_norm": 0.013120295479893684,
      "learning_rate": 0.0002634126780443988,
      "loss": 0.0,
      "step": 73750
    },
    {
      "epoch": 4.735018606441678,
      "grad_norm": 0.018597545102238655,
      "learning_rate": 0.000263252277685102,
      "loss": 0.0,
      "step": 73800
    },
    {
      "epoch": 4.7382266136276145,
      "grad_norm": 0.015419798903167248,
      "learning_rate": 0.0002630918773258052,
      "loss": 0.0,
      "step": 73850
    },
    {
      "epoch": 4.741434620813551,
      "grad_norm": 0.01512815710157156,
      "learning_rate": 0.00026293147696650844,
      "loss": 0.0,
      "step": 73900
    },
    {
      "epoch": 4.744642627999487,
      "grad_norm": 0.00374964764341712,
      "learning_rate": 0.0002627710766072116,
      "loss": 0.0,
      "step": 73950
    },
    {
      "epoch": 4.747850635185423,
      "grad_norm": 0.007117048837244511,
      "learning_rate": 0.0002626106762479148,
      "loss": 0.0,
      "step": 74000
    },
    {
      "epoch": 4.751058642371359,
      "grad_norm": 0.0033797763753682375,
      "learning_rate": 0.00026245027588861795,
      "loss": 0.0,
      "step": 74050
    },
    {
      "epoch": 4.754266649557295,
      "grad_norm": 0.00860462337732315,
      "learning_rate": 0.0002622898755293212,
      "loss": 0.0,
      "step": 74100
    },
    {
      "epoch": 4.757474656743231,
      "grad_norm": 0.014743959531188011,
      "learning_rate": 0.00026212947517002436,
      "loss": 0.0,
      "step": 74150
    },
    {
      "epoch": 4.760682663929167,
      "grad_norm": 0.0021293433383107185,
      "learning_rate": 0.00026196907481072757,
      "loss": 0.0,
      "step": 74200
    },
    {
      "epoch": 4.763890671115103,
      "grad_norm": 0.003602482844144106,
      "learning_rate": 0.0002618086744514307,
      "loss": 0.0,
      "step": 74250
    },
    {
      "epoch": 4.767098678301039,
      "grad_norm": 0.0008950239280238748,
      "learning_rate": 0.000261648274092134,
      "loss": 0.0,
      "step": 74300
    },
    {
      "epoch": 4.770306685486975,
      "grad_norm": 0.01820029318332672,
      "learning_rate": 0.0002614878737328372,
      "loss": 0.0,
      "step": 74350
    },
    {
      "epoch": 4.7735146926729115,
      "grad_norm": 0.020894113928079605,
      "learning_rate": 0.00026132747337354034,
      "loss": 0.0,
      "step": 74400
    },
    {
      "epoch": 4.776722699858848,
      "grad_norm": 0.02845076657831669,
      "learning_rate": 0.0002611670730142436,
      "loss": 0.0,
      "step": 74450
    },
    {
      "epoch": 4.779930707044784,
      "grad_norm": 0.004101718310266733,
      "learning_rate": 0.00026100667265494676,
      "loss": 0.0,
      "step": 74500
    },
    {
      "epoch": 4.78313871423072,
      "grad_norm": 0.010185728780925274,
      "learning_rate": 0.00026084627229564997,
      "loss": 0.0,
      "step": 74550
    },
    {
      "epoch": 4.786346721416656,
      "grad_norm": 0.004805178381502628,
      "learning_rate": 0.0002606858719363531,
      "loss": 0.0,
      "step": 74600
    },
    {
      "epoch": 4.789554728602592,
      "grad_norm": 0.010825494304299355,
      "learning_rate": 0.0002605254715770564,
      "loss": 0.0,
      "step": 74650
    },
    {
      "epoch": 4.7927627357885285,
      "grad_norm": 0.020293228328227997,
      "learning_rate": 0.00026036507121775953,
      "loss": 0.0,
      "step": 74700
    },
    {
      "epoch": 4.795970742974465,
      "grad_norm": 0.015693021938204765,
      "learning_rate": 0.00026020467085846274,
      "loss": 0.0,
      "step": 74750
    },
    {
      "epoch": 4.799178750160401,
      "grad_norm": 0.021928204223513603,
      "learning_rate": 0.0002600442704991659,
      "loss": 0.0,
      "step": 74800
    },
    {
      "epoch": 4.802386757346336,
      "grad_norm": 0.016921769827604294,
      "learning_rate": 0.00025988387013986915,
      "loss": 0.0,
      "step": 74850
    },
    {
      "epoch": 4.805594764532272,
      "grad_norm": 0.004279394168406725,
      "learning_rate": 0.0002597234697805723,
      "loss": 0.0,
      "step": 74900
    },
    {
      "epoch": 4.8088027717182085,
      "grad_norm": 0.011291412636637688,
      "learning_rate": 0.0002595630694212755,
      "loss": 0.0,
      "step": 74950
    },
    {
      "epoch": 4.812010778904145,
      "grad_norm": 0.008493217639625072,
      "learning_rate": 0.00025940266906197867,
      "loss": 0.0,
      "step": 75000
    },
    {
      "epoch": 4.815218786090081,
      "grad_norm": 0.016944415867328644,
      "learning_rate": 0.0002592422687026819,
      "loss": 0.0,
      "step": 75050
    },
    {
      "epoch": 4.818426793276017,
      "grad_norm": 0.013752308674156666,
      "learning_rate": 0.0002590818683433851,
      "loss": 0.0,
      "step": 75100
    },
    {
      "epoch": 4.821634800461953,
      "grad_norm": 0.017617452889680862,
      "learning_rate": 0.0002589214679840883,
      "loss": 0.0,
      "step": 75150
    },
    {
      "epoch": 4.824842807647889,
      "grad_norm": 0.019109921529889107,
      "learning_rate": 0.00025876106762479144,
      "loss": 0.0,
      "step": 75200
    },
    {
      "epoch": 4.8280508148338255,
      "grad_norm": 0.005227112211287022,
      "learning_rate": 0.0002586006672654947,
      "loss": 0.0,
      "step": 75250
    },
    {
      "epoch": 4.831258822019762,
      "grad_norm": 0.02268947847187519,
      "learning_rate": 0.00025844026690619785,
      "loss": 0.0,
      "step": 75300
    },
    {
      "epoch": 4.834466829205697,
      "grad_norm": 0.0036181623581796885,
      "learning_rate": 0.00025827986654690106,
      "loss": 0.0,
      "step": 75350
    },
    {
      "epoch": 4.837674836391633,
      "grad_norm": 0.006038850639015436,
      "learning_rate": 0.00025811946618760427,
      "loss": 0.0,
      "step": 75400
    },
    {
      "epoch": 4.840882843577569,
      "grad_norm": 0.005294509697705507,
      "learning_rate": 0.0002579590658283075,
      "loss": 0.0,
      "step": 75450
    },
    {
      "epoch": 4.844090850763505,
      "grad_norm": 0.017517905682325363,
      "learning_rate": 0.0002577986654690106,
      "loss": 0.0,
      "step": 75500
    },
    {
      "epoch": 4.847298857949442,
      "grad_norm": 0.006620998028665781,
      "learning_rate": 0.00025763826510971383,
      "loss": 0.0,
      "step": 75550
    },
    {
      "epoch": 4.850506865135378,
      "grad_norm": 0.011664383113384247,
      "learning_rate": 0.0002574778647504171,
      "loss": 0.0,
      "step": 75600
    },
    {
      "epoch": 4.853714872321314,
      "grad_norm": 0.00762640917673707,
      "learning_rate": 0.00025731746439112025,
      "loss": 0.0,
      "step": 75650
    },
    {
      "epoch": 4.85692287950725,
      "grad_norm": 0.003481329185888171,
      "learning_rate": 0.00025715706403182345,
      "loss": 0.0,
      "step": 75700
    },
    {
      "epoch": 4.860130886693186,
      "grad_norm": 0.006777811795473099,
      "learning_rate": 0.0002569966636725266,
      "loss": 0.0,
      "step": 75750
    },
    {
      "epoch": 4.863338893879122,
      "grad_norm": 0.010331920348107815,
      "learning_rate": 0.00025683626331322987,
      "loss": 0.0,
      "step": 75800
    },
    {
      "epoch": 4.866546901065059,
      "grad_norm": 0.025387557223439217,
      "learning_rate": 0.000256675862953933,
      "loss": 0.0,
      "step": 75850
    },
    {
      "epoch": 4.869754908250995,
      "grad_norm": 0.006871892139315605,
      "learning_rate": 0.00025651546259463623,
      "loss": 0.0,
      "step": 75900
    },
    {
      "epoch": 4.872962915436931,
      "grad_norm": 0.009434194304049015,
      "learning_rate": 0.0002563550622353394,
      "loss": 0.0,
      "step": 75950
    },
    {
      "epoch": 4.876170922622867,
      "grad_norm": 0.012019531801342964,
      "learning_rate": 0.00025619466187604264,
      "loss": 0.0,
      "step": 76000
    },
    {
      "epoch": 4.879378929808802,
      "grad_norm": 0.01015252061188221,
      "learning_rate": 0.0002560342615167458,
      "loss": 0.0,
      "step": 76050
    },
    {
      "epoch": 4.882586936994739,
      "grad_norm": 0.01805655099451542,
      "learning_rate": 0.000255873861157449,
      "loss": 0.0,
      "step": 76100
    },
    {
      "epoch": 4.885794944180675,
      "grad_norm": 0.020917559042572975,
      "learning_rate": 0.0002557134607981522,
      "loss": 0.0,
      "step": 76150
    },
    {
      "epoch": 4.889002951366611,
      "grad_norm": 0.0022268190514296293,
      "learning_rate": 0.0002555530604388554,
      "loss": 0.0,
      "step": 76200
    },
    {
      "epoch": 4.892210958552547,
      "grad_norm": 0.017054177820682526,
      "learning_rate": 0.00025539266007955857,
      "loss": 0.0,
      "step": 76250
    },
    {
      "epoch": 4.895418965738483,
      "grad_norm": 0.006376692559570074,
      "learning_rate": 0.0002552322597202618,
      "loss": 0.0,
      "step": 76300
    },
    {
      "epoch": 4.898626972924419,
      "grad_norm": 0.005254948511719704,
      "learning_rate": 0.000255071859360965,
      "loss": 0.0,
      "step": 76350
    },
    {
      "epoch": 4.901834980110356,
      "grad_norm": 0.015834517776966095,
      "learning_rate": 0.0002549114590016682,
      "loss": 0.0,
      "step": 76400
    },
    {
      "epoch": 4.905042987296292,
      "grad_norm": 0.00311585096642375,
      "learning_rate": 0.00025475105864237134,
      "loss": 0.0,
      "step": 76450
    },
    {
      "epoch": 4.908250994482228,
      "grad_norm": 0.010036389343440533,
      "learning_rate": 0.00025459065828307455,
      "loss": 0.0,
      "step": 76500
    },
    {
      "epoch": 4.911459001668164,
      "grad_norm": 0.01647982746362686,
      "learning_rate": 0.00025443025792377776,
      "loss": 0.0,
      "step": 76550
    },
    {
      "epoch": 4.914667008854099,
      "grad_norm": 0.013545106165111065,
      "learning_rate": 0.00025426985756448096,
      "loss": 0.0,
      "step": 76600
    },
    {
      "epoch": 4.9178750160400355,
      "grad_norm": 0.005654233507812023,
      "learning_rate": 0.0002541094572051841,
      "loss": 0.0,
      "step": 76650
    },
    {
      "epoch": 4.921083023225972,
      "grad_norm": 0.028061626479029655,
      "learning_rate": 0.0002539490568458873,
      "loss": 0.0,
      "step": 76700
    },
    {
      "epoch": 4.924291030411908,
      "grad_norm": 0.009537260979413986,
      "learning_rate": 0.00025378865648659053,
      "loss": 0.0,
      "step": 76750
    },
    {
      "epoch": 4.927499037597844,
      "grad_norm": 0.016712237149477005,
      "learning_rate": 0.00025362825612729374,
      "loss": 0.0,
      "step": 76800
    },
    {
      "epoch": 4.93070704478378,
      "grad_norm": 0.0034480683971196413,
      "learning_rate": 0.0002534678557679969,
      "loss": 0.0,
      "step": 76850
    },
    {
      "epoch": 4.933915051969716,
      "grad_norm": 0.015374034643173218,
      "learning_rate": 0.0002533074554087001,
      "loss": 0.0,
      "step": 76900
    },
    {
      "epoch": 4.9371230591556525,
      "grad_norm": 0.019142452627420425,
      "learning_rate": 0.0002531470550494033,
      "loss": 0.0,
      "step": 76950
    },
    {
      "epoch": 4.940331066341589,
      "grad_norm": 0.010121768340468407,
      "learning_rate": 0.0002529866546901065,
      "loss": 0.0,
      "step": 77000
    },
    {
      "epoch": 4.943539073527525,
      "grad_norm": 0.0026904731057584286,
      "learning_rate": 0.0002528262543308097,
      "loss": 0.0,
      "step": 77050
    },
    {
      "epoch": 4.946747080713461,
      "grad_norm": 0.022747645154595375,
      "learning_rate": 0.0002526658539715129,
      "loss": 0.0,
      "step": 77100
    },
    {
      "epoch": 4.949955087899397,
      "grad_norm": 0.011270411312580109,
      "learning_rate": 0.00025250545361221613,
      "loss": 0.0,
      "step": 77150
    },
    {
      "epoch": 4.953163095085333,
      "grad_norm": 0.008960169740021229,
      "learning_rate": 0.0002523450532529193,
      "loss": 0.0,
      "step": 77200
    },
    {
      "epoch": 4.9563711022712695,
      "grad_norm": 0.006838175002485514,
      "learning_rate": 0.0002521846528936225,
      "loss": 0.0,
      "step": 77250
    },
    {
      "epoch": 4.959579109457205,
      "grad_norm": 0.016574984416365623,
      "learning_rate": 0.0002520242525343257,
      "loss": 0.0,
      "step": 77300
    },
    {
      "epoch": 4.962787116643141,
      "grad_norm": 0.007687180768698454,
      "learning_rate": 0.0002518638521750289,
      "loss": 0.0,
      "step": 77350
    },
    {
      "epoch": 4.965995123829077,
      "grad_norm": 0.007254901807755232,
      "learning_rate": 0.00025170345181573206,
      "loss": 0.0,
      "step": 77400
    },
    {
      "epoch": 4.969203131015013,
      "grad_norm": 0.012837537564337254,
      "learning_rate": 0.00025154305145643526,
      "loss": 0.0,
      "step": 77450
    },
    {
      "epoch": 4.9724111382009495,
      "grad_norm": 0.00639015156775713,
      "learning_rate": 0.00025138265109713847,
      "loss": 0.0,
      "step": 77500
    },
    {
      "epoch": 4.975619145386886,
      "grad_norm": 0.009688188321888447,
      "learning_rate": 0.0002512222507378417,
      "loss": 0.0,
      "step": 77550
    },
    {
      "epoch": 4.978827152572822,
      "grad_norm": 0.003485988825559616,
      "learning_rate": 0.00025106185037854483,
      "loss": 0.0,
      "step": 77600
    },
    {
      "epoch": 4.982035159758758,
      "grad_norm": 0.01617366075515747,
      "learning_rate": 0.00025090145001924804,
      "loss": 0.0,
      "step": 77650
    },
    {
      "epoch": 4.985243166944694,
      "grad_norm": 0.009921181946992874,
      "learning_rate": 0.00025074104965995124,
      "loss": 0.0,
      "step": 77700
    },
    {
      "epoch": 4.98845117413063,
      "grad_norm": 0.015501406043767929,
      "learning_rate": 0.00025058064930065445,
      "loss": 0.0,
      "step": 77750
    },
    {
      "epoch": 4.9916591813165665,
      "grad_norm": 0.008257326669991016,
      "learning_rate": 0.0002504202489413576,
      "loss": 0.0,
      "step": 77800
    },
    {
      "epoch": 4.994867188502502,
      "grad_norm": 0.011534993536770344,
      "learning_rate": 0.00025025984858206087,
      "loss": 0.0,
      "step": 77850
    },
    {
      "epoch": 4.998075195688438,
      "grad_norm": 0.00722391065210104,
      "learning_rate": 0.000250099448222764,
      "loss": 0.0,
      "step": 77900
    },
    {
      "epoch": 5.001283202874374,
      "grad_norm": 0.018890270963311195,
      "learning_rate": 0.0002499390478634672,
      "loss": 0.0,
      "step": 77950
    },
    {
      "epoch": 5.00449121006031,
      "grad_norm": 0.005552831571549177,
      "learning_rate": 0.00024977864750417043,
      "loss": 0.0,
      "step": 78000
    },
    {
      "epoch": 5.0076992172462464,
      "grad_norm": 0.0019068154506385326,
      "learning_rate": 0.0002496182471448736,
      "loss": 0.0,
      "step": 78050
    },
    {
      "epoch": 5.010907224432183,
      "grad_norm": 0.013427904807031155,
      "learning_rate": 0.0002494578467855768,
      "loss": 0.0,
      "step": 78100
    },
    {
      "epoch": 5.014115231618119,
      "grad_norm": 0.02151251956820488,
      "learning_rate": 0.00024929744642628,
      "loss": 0.0,
      "step": 78150
    },
    {
      "epoch": 5.017323238804055,
      "grad_norm": 0.00907523650676012,
      "learning_rate": 0.0002491370460669832,
      "loss": 0.0,
      "step": 78200
    },
    {
      "epoch": 5.020531245989991,
      "grad_norm": 0.020409589633345604,
      "learning_rate": 0.00024897664570768636,
      "loss": 0.0,
      "step": 78250
    },
    {
      "epoch": 5.023739253175927,
      "grad_norm": 0.033457837998867035,
      "learning_rate": 0.00024881624534838957,
      "loss": 0.0,
      "step": 78300
    },
    {
      "epoch": 5.0269472603618635,
      "grad_norm": 0.004854556173086166,
      "learning_rate": 0.00024865584498909277,
      "loss": 0.0,
      "step": 78350
    },
    {
      "epoch": 5.0301552675478,
      "grad_norm": 0.02273526042699814,
      "learning_rate": 0.000248495444629796,
      "loss": 0.0,
      "step": 78400
    },
    {
      "epoch": 5.033363274733736,
      "grad_norm": 0.01538918912410736,
      "learning_rate": 0.0002483350442704992,
      "loss": 0.0,
      "step": 78450
    },
    {
      "epoch": 5.036571281919671,
      "grad_norm": 0.007671347353607416,
      "learning_rate": 0.0002481746439112024,
      "loss": 0.0,
      "step": 78500
    },
    {
      "epoch": 5.039779289105607,
      "grad_norm": 0.0052811275236308575,
      "learning_rate": 0.00024801424355190555,
      "loss": 0.0,
      "step": 78550
    },
    {
      "epoch": 5.042987296291543,
      "grad_norm": 0.011556691490113735,
      "learning_rate": 0.00024785384319260875,
      "loss": 0.0,
      "step": 78600
    },
    {
      "epoch": 5.04619530347748,
      "grad_norm": 0.004064098000526428,
      "learning_rate": 0.00024769344283331196,
      "loss": 0.0,
      "step": 78650
    },
    {
      "epoch": 5.049403310663416,
      "grad_norm": 0.015485568903386593,
      "learning_rate": 0.00024753304247401517,
      "loss": 0.0,
      "step": 78700
    },
    {
      "epoch": 5.052611317849352,
      "grad_norm": 0.01502815168350935,
      "learning_rate": 0.0002473726421147184,
      "loss": 0.0,
      "step": 78750
    },
    {
      "epoch": 5.055819325035288,
      "grad_norm": 0.0050179739482700825,
      "learning_rate": 0.0002472122417554215,
      "loss": 0.0,
      "step": 78800
    },
    {
      "epoch": 5.059027332221224,
      "grad_norm": 0.016375351697206497,
      "learning_rate": 0.00024705184139612473,
      "loss": 0.0,
      "step": 78850
    },
    {
      "epoch": 5.06223533940716,
      "grad_norm": 0.011750171892344952,
      "learning_rate": 0.00024689144103682794,
      "loss": 0.0,
      "step": 78900
    },
    {
      "epoch": 5.065443346593097,
      "grad_norm": 0.014898859895765781,
      "learning_rate": 0.00024673104067753115,
      "loss": 0.0,
      "step": 78950
    },
    {
      "epoch": 5.068651353779033,
      "grad_norm": 0.005011263303458691,
      "learning_rate": 0.0002465706403182343,
      "loss": 0.0,
      "step": 79000
    },
    {
      "epoch": 5.071859360964969,
      "grad_norm": 0.015806615352630615,
      "learning_rate": 0.0002464102399589375,
      "loss": 0.0,
      "step": 79050
    },
    {
      "epoch": 5.075067368150905,
      "grad_norm": 0.021262452006340027,
      "learning_rate": 0.0002462498395996407,
      "loss": 0.0,
      "step": 79100
    },
    {
      "epoch": 5.07827537533684,
      "grad_norm": 0.020508766174316406,
      "learning_rate": 0.0002460894392403439,
      "loss": 0.0,
      "step": 79150
    },
    {
      "epoch": 5.0814833825227765,
      "grad_norm": 0.003006734186783433,
      "learning_rate": 0.0002459290388810471,
      "loss": 0.0,
      "step": 79200
    },
    {
      "epoch": 5.084691389708713,
      "grad_norm": 0.009668306447565556,
      "learning_rate": 0.0002457686385217503,
      "loss": 0.0,
      "step": 79250
    },
    {
      "epoch": 5.087899396894649,
      "grad_norm": 0.010525346733629704,
      "learning_rate": 0.0002456082381624535,
      "loss": 0.0,
      "step": 79300
    },
    {
      "epoch": 5.091107404080585,
      "grad_norm": 0.003051221836358309,
      "learning_rate": 0.0002454478378031567,
      "loss": 0.0,
      "step": 79350
    },
    {
      "epoch": 5.094315411266521,
      "grad_norm": 0.009682576172053814,
      "learning_rate": 0.00024528743744385985,
      "loss": 0.0,
      "step": 79400
    },
    {
      "epoch": 5.097523418452457,
      "grad_norm": 0.007193546276539564,
      "learning_rate": 0.00024512703708456305,
      "loss": 0.0,
      "step": 79450
    },
    {
      "epoch": 5.1007314256383935,
      "grad_norm": 0.01170593872666359,
      "learning_rate": 0.00024496663672526626,
      "loss": 0.0,
      "step": 79500
    },
    {
      "epoch": 5.10393943282433,
      "grad_norm": 0.0036195095162838697,
      "learning_rate": 0.00024480623636596947,
      "loss": 0.0,
      "step": 79550
    },
    {
      "epoch": 5.107147440010266,
      "grad_norm": 0.0149146793410182,
      "learning_rate": 0.0002446458360066727,
      "loss": 0.0,
      "step": 79600
    },
    {
      "epoch": 5.110355447196202,
      "grad_norm": 0.010748209431767464,
      "learning_rate": 0.00024448543564737583,
      "loss": 0.0,
      "step": 79650
    },
    {
      "epoch": 5.113563454382138,
      "grad_norm": 0.031960826367139816,
      "learning_rate": 0.0002443250352880791,
      "loss": 0.0,
      "step": 79700
    },
    {
      "epoch": 5.1167714615680735,
      "grad_norm": 0.02076813206076622,
      "learning_rate": 0.00024416463492878224,
      "loss": 0.0,
      "step": 79750
    },
    {
      "epoch": 5.11997946875401,
      "grad_norm": 0.005711584817618132,
      "learning_rate": 0.00024400423456948545,
      "loss": 0.0,
      "step": 79800
    },
    {
      "epoch": 5.123187475939946,
      "grad_norm": 0.01402283739298582,
      "learning_rate": 0.00024384383421018863,
      "loss": 0.0,
      "step": 79850
    },
    {
      "epoch": 5.126395483125882,
      "grad_norm": 0.01874529756605625,
      "learning_rate": 0.00024368343385089184,
      "loss": 0.0,
      "step": 79900
    },
    {
      "epoch": 5.129603490311818,
      "grad_norm": 0.007986378856003284,
      "learning_rate": 0.00024352303349159501,
      "loss": 0.0,
      "step": 79950
    },
    {
      "epoch": 5.132811497497754,
      "grad_norm": 0.014157728292047977,
      "learning_rate": 0.00024336263313229822,
      "loss": 0.0,
      "step": 80000
    },
    {
      "epoch": 5.1360195046836905,
      "grad_norm": 0.011805851012468338,
      "learning_rate": 0.0002432022327730014,
      "loss": 0.0,
      "step": 80050
    },
    {
      "epoch": 5.139227511869627,
      "grad_norm": 0.012783828191459179,
      "learning_rate": 0.0002430418324137046,
      "loss": 0.0,
      "step": 80100
    },
    {
      "epoch": 5.142435519055563,
      "grad_norm": 0.007279236800968647,
      "learning_rate": 0.0002428814320544078,
      "loss": 0.0,
      "step": 80150
    },
    {
      "epoch": 5.145643526241499,
      "grad_norm": 0.00807899422943592,
      "learning_rate": 0.000242721031695111,
      "loss": 0.0,
      "step": 80200
    },
    {
      "epoch": 5.148851533427435,
      "grad_norm": 0.023630844429135323,
      "learning_rate": 0.00024256063133581418,
      "loss": 0.0,
      "step": 80250
    },
    {
      "epoch": 5.152059540613371,
      "grad_norm": 0.001209730515256524,
      "learning_rate": 0.00024240023097651738,
      "loss": 0.0,
      "step": 80300
    },
    {
      "epoch": 5.155267547799307,
      "grad_norm": 0.015104757621884346,
      "learning_rate": 0.00024223983061722056,
      "loss": 0.0,
      "step": 80350
    },
    {
      "epoch": 5.158475554985243,
      "grad_norm": 0.007729855831712484,
      "learning_rate": 0.0002420794302579238,
      "loss": 0.0,
      "step": 80400
    },
    {
      "epoch": 5.161683562171179,
      "grad_norm": 0.006531229708343744,
      "learning_rate": 0.000241919029898627,
      "loss": 0.0,
      "step": 80450
    },
    {
      "epoch": 5.164891569357115,
      "grad_norm": 0.008360288105905056,
      "learning_rate": 0.00024175862953933018,
      "loss": 0.0,
      "step": 80500
    },
    {
      "epoch": 5.168099576543051,
      "grad_norm": 0.018455173820257187,
      "learning_rate": 0.0002415982291800334,
      "loss": 0.0,
      "step": 80550
    },
    {
      "epoch": 5.1713075837289875,
      "grad_norm": 0.0051124426536262035,
      "learning_rate": 0.00024143782882073657,
      "loss": 0.0,
      "step": 80600
    },
    {
      "epoch": 5.174515590914924,
      "grad_norm": 0.022711768746376038,
      "learning_rate": 0.00024127742846143978,
      "loss": 0.0,
      "step": 80650
    },
    {
      "epoch": 5.17772359810086,
      "grad_norm": 0.0066667539067566395,
      "learning_rate": 0.00024111702810214296,
      "loss": 0.0,
      "step": 80700
    },
    {
      "epoch": 5.180931605286796,
      "grad_norm": 0.011704152449965477,
      "learning_rate": 0.00024095662774284616,
      "loss": 0.0,
      "step": 80750
    },
    {
      "epoch": 5.184139612472732,
      "grad_norm": 0.005336804315447807,
      "learning_rate": 0.00024079622738354934,
      "loss": 0.0,
      "step": 80800
    },
    {
      "epoch": 5.187347619658668,
      "grad_norm": 0.0016275863163173199,
      "learning_rate": 0.00024063582702425255,
      "loss": 0.0,
      "step": 80850
    },
    {
      "epoch": 5.1905556268446045,
      "grad_norm": 0.025220122188329697,
      "learning_rate": 0.00024047542666495573,
      "loss": 0.0,
      "step": 80900
    },
    {
      "epoch": 5.193763634030541,
      "grad_norm": 0.009467029012739658,
      "learning_rate": 0.00024031502630565894,
      "loss": 0.0,
      "step": 80950
    },
    {
      "epoch": 5.196971641216476,
      "grad_norm": 0.0038958590012043715,
      "learning_rate": 0.00024015462594636212,
      "loss": 0.0,
      "step": 81000
    },
    {
      "epoch": 5.200179648402412,
      "grad_norm": 0.008880382403731346,
      "learning_rate": 0.00023999422558706532,
      "loss": 0.0,
      "step": 81050
    },
    {
      "epoch": 5.203387655588348,
      "grad_norm": 0.00826188549399376,
      "learning_rate": 0.0002398338252277685,
      "loss": 0.0,
      "step": 81100
    },
    {
      "epoch": 5.206595662774284,
      "grad_norm": 0.004799161572009325,
      "learning_rate": 0.0002396734248684717,
      "loss": 0.0,
      "step": 81150
    },
    {
      "epoch": 5.209803669960221,
      "grad_norm": 0.01368297915905714,
      "learning_rate": 0.0002395130245091749,
      "loss": 0.0,
      "step": 81200
    },
    {
      "epoch": 5.213011677146157,
      "grad_norm": 0.0025000248569995165,
      "learning_rate": 0.0002393526241498781,
      "loss": 0.0,
      "step": 81250
    },
    {
      "epoch": 5.216219684332093,
      "grad_norm": 0.003232280258089304,
      "learning_rate": 0.0002391922237905813,
      "loss": 0.0,
      "step": 81300
    },
    {
      "epoch": 5.219427691518029,
      "grad_norm": 0.004976852331310511,
      "learning_rate": 0.00023903182343128448,
      "loss": 0.0,
      "step": 81350
    },
    {
      "epoch": 5.222635698703965,
      "grad_norm": 0.006679864134639502,
      "learning_rate": 0.0002388714230719877,
      "loss": 0.0,
      "step": 81400
    },
    {
      "epoch": 5.225843705889901,
      "grad_norm": 0.004060913342982531,
      "learning_rate": 0.00023871102271269087,
      "loss": 0.0,
      "step": 81450
    },
    {
      "epoch": 5.229051713075838,
      "grad_norm": 0.00306243309751153,
      "learning_rate": 0.00023855062235339408,
      "loss": 0.0,
      "step": 81500
    },
    {
      "epoch": 5.232259720261774,
      "grad_norm": 0.022544559091329575,
      "learning_rate": 0.00023839022199409726,
      "loss": 0.0,
      "step": 81550
    },
    {
      "epoch": 5.235467727447709,
      "grad_norm": 0.019006801769137383,
      "learning_rate": 0.00023822982163480046,
      "loss": 0.0,
      "step": 81600
    },
    {
      "epoch": 5.238675734633645,
      "grad_norm": 0.012501989491283894,
      "learning_rate": 0.00023806942127550364,
      "loss": 0.0,
      "step": 81650
    },
    {
      "epoch": 5.241883741819581,
      "grad_norm": 0.008009020239114761,
      "learning_rate": 0.00023790902091620685,
      "loss": 0.0,
      "step": 81700
    },
    {
      "epoch": 5.245091749005518,
      "grad_norm": 0.024022528901696205,
      "learning_rate": 0.00023774862055691003,
      "loss": 0.0,
      "step": 81750
    },
    {
      "epoch": 5.248299756191454,
      "grad_norm": 0.022923629730939865,
      "learning_rate": 0.00023758822019761327,
      "loss": 0.0,
      "step": 81800
    },
    {
      "epoch": 5.25150776337739,
      "grad_norm": 0.008348916657269001,
      "learning_rate": 0.00023742781983831645,
      "loss": 0.0,
      "step": 81850
    },
    {
      "epoch": 5.254715770563326,
      "grad_norm": 0.010257357731461525,
      "learning_rate": 0.00023726741947901965,
      "loss": 0.0,
      "step": 81900
    },
    {
      "epoch": 5.257923777749262,
      "grad_norm": 0.006216204259544611,
      "learning_rate": 0.00023710701911972283,
      "loss": 0.0,
      "step": 81950
    },
    {
      "epoch": 5.261131784935198,
      "grad_norm": 0.00908361654728651,
      "learning_rate": 0.00023694661876042604,
      "loss": 0.0,
      "step": 82000
    },
    {
      "epoch": 5.264339792121135,
      "grad_norm": 0.011593836359679699,
      "learning_rate": 0.00023678621840112922,
      "loss": 0.0,
      "step": 82050
    },
    {
      "epoch": 5.267547799307071,
      "grad_norm": 0.012476577423512936,
      "learning_rate": 0.00023662581804183243,
      "loss": 0.0,
      "step": 82100
    },
    {
      "epoch": 5.270755806493007,
      "grad_norm": 0.004598408471792936,
      "learning_rate": 0.00023646541768253563,
      "loss": 0.0,
      "step": 82150
    },
    {
      "epoch": 5.273963813678943,
      "grad_norm": 0.02476555109024048,
      "learning_rate": 0.0002363050173232388,
      "loss": 0.0,
      "step": 82200
    },
    {
      "epoch": 5.277171820864878,
      "grad_norm": 0.008318556472659111,
      "learning_rate": 0.00023614461696394202,
      "loss": 0.0,
      "step": 82250
    },
    {
      "epoch": 5.2803798280508145,
      "grad_norm": 0.016148842871189117,
      "learning_rate": 0.0002359842166046452,
      "loss": 0.0,
      "step": 82300
    },
    {
      "epoch": 5.283587835236751,
      "grad_norm": 0.010126660577952862,
      "learning_rate": 0.0002358238162453484,
      "loss": 0.0,
      "step": 82350
    },
    {
      "epoch": 5.286795842422687,
      "grad_norm": 0.005795956589281559,
      "learning_rate": 0.00023566341588605159,
      "loss": 0.0,
      "step": 82400
    },
    {
      "epoch": 5.290003849608623,
      "grad_norm": 0.008935605175793171,
      "learning_rate": 0.0002355030155267548,
      "loss": 0.0,
      "step": 82450
    },
    {
      "epoch": 5.293211856794559,
      "grad_norm": 0.0019529465353116393,
      "learning_rate": 0.00023534261516745797,
      "loss": 0.0,
      "step": 82500
    },
    {
      "epoch": 5.296419863980495,
      "grad_norm": 0.013749866746366024,
      "learning_rate": 0.00023518221480816118,
      "loss": 0.0,
      "step": 82550
    },
    {
      "epoch": 5.2996278711664315,
      "grad_norm": 0.004790838807821274,
      "learning_rate": 0.00023502181444886436,
      "loss": 0.0,
      "step": 82600
    },
    {
      "epoch": 5.302835878352368,
      "grad_norm": 0.013601664453744888,
      "learning_rate": 0.00023486141408956757,
      "loss": 0.0,
      "step": 82650
    },
    {
      "epoch": 5.306043885538304,
      "grad_norm": 0.014108519069850445,
      "learning_rate": 0.00023470101373027075,
      "loss": 0.0,
      "step": 82700
    },
    {
      "epoch": 5.30925189272424,
      "grad_norm": 0.009767813608050346,
      "learning_rate": 0.00023454061337097395,
      "loss": 0.0,
      "step": 82750
    },
    {
      "epoch": 5.312459899910176,
      "grad_norm": 0.0007668229518458247,
      "learning_rate": 0.00023438021301167713,
      "loss": 0.0,
      "step": 82800
    },
    {
      "epoch": 5.3156679070961115,
      "grad_norm": 0.00877887662500143,
      "learning_rate": 0.00023421981265238034,
      "loss": 0.0,
      "step": 82850
    },
    {
      "epoch": 5.318875914282048,
      "grad_norm": 0.005840668920427561,
      "learning_rate": 0.00023405941229308352,
      "loss": 0.0,
      "step": 82900
    },
    {
      "epoch": 5.322083921467984,
      "grad_norm": 0.0036083711311221123,
      "learning_rate": 0.00023389901193378673,
      "loss": 0.0,
      "step": 82950
    },
    {
      "epoch": 5.32529192865392,
      "grad_norm": 0.012541725300252438,
      "learning_rate": 0.00023373861157448993,
      "loss": 0.0,
      "step": 83000
    },
    {
      "epoch": 5.328499935839856,
      "grad_norm": 0.006748270243406296,
      "learning_rate": 0.00023357821121519311,
      "loss": 0.0,
      "step": 83050
    },
    {
      "epoch": 5.331707943025792,
      "grad_norm": 0.003227939596399665,
      "learning_rate": 0.00023341781085589632,
      "loss": 0.0,
      "step": 83100
    },
    {
      "epoch": 5.3349159502117285,
      "grad_norm": 0.013179508037865162,
      "learning_rate": 0.00023325741049659953,
      "loss": 0.0,
      "step": 83150
    },
    {
      "epoch": 5.338123957397665,
      "grad_norm": 0.013523886911571026,
      "learning_rate": 0.00023309701013730273,
      "loss": 0.0,
      "step": 83200
    },
    {
      "epoch": 5.341331964583601,
      "grad_norm": 0.003951506223529577,
      "learning_rate": 0.00023293660977800591,
      "loss": 0.0,
      "step": 83250
    },
    {
      "epoch": 5.344539971769537,
      "grad_norm": 0.008925446309149265,
      "learning_rate": 0.00023277620941870912,
      "loss": 0.0,
      "step": 83300
    },
    {
      "epoch": 5.347747978955473,
      "grad_norm": 0.011839155107736588,
      "learning_rate": 0.0002326158090594123,
      "loss": 0.0,
      "step": 83350
    },
    {
      "epoch": 5.350955986141409,
      "grad_norm": 0.013259310275316238,
      "learning_rate": 0.0002324554087001155,
      "loss": 0.0,
      "step": 83400
    },
    {
      "epoch": 5.3541639933273455,
      "grad_norm": 0.0038544845301657915,
      "learning_rate": 0.0002322950083408187,
      "loss": 0.0,
      "step": 83450
    },
    {
      "epoch": 5.357372000513281,
      "grad_norm": 0.005862140562385321,
      "learning_rate": 0.0002321346079815219,
      "loss": 0.0,
      "step": 83500
    },
    {
      "epoch": 5.360580007699217,
      "grad_norm": 0.020791059359908104,
      "learning_rate": 0.00023197420762222508,
      "loss": 0.0,
      "step": 83550
    },
    {
      "epoch": 5.363788014885153,
      "grad_norm": 0.009848082438111305,
      "learning_rate": 0.00023181380726292828,
      "loss": 0.0,
      "step": 83600
    },
    {
      "epoch": 5.366996022071089,
      "grad_norm": 0.003739582607522607,
      "learning_rate": 0.00023165340690363146,
      "loss": 0.0,
      "step": 83650
    },
    {
      "epoch": 5.3702040292570254,
      "grad_norm": 0.007357788272202015,
      "learning_rate": 0.00023149300654433467,
      "loss": 0.0,
      "step": 83700
    },
    {
      "epoch": 5.373412036442962,
      "grad_norm": 0.015688659623265266,
      "learning_rate": 0.00023133260618503785,
      "loss": 0.0,
      "step": 83750
    },
    {
      "epoch": 5.376620043628898,
      "grad_norm": 0.016252214089035988,
      "learning_rate": 0.00023117220582574106,
      "loss": 0.0,
      "step": 83800
    },
    {
      "epoch": 5.379828050814834,
      "grad_norm": 0.007192239630967379,
      "learning_rate": 0.00023101180546644424,
      "loss": 0.0,
      "step": 83850
    },
    {
      "epoch": 5.38303605800077,
      "grad_norm": 0.017896000295877457,
      "learning_rate": 0.00023085140510714744,
      "loss": 0.0,
      "step": 83900
    },
    {
      "epoch": 5.386244065186706,
      "grad_norm": 0.006958935875445604,
      "learning_rate": 0.00023069100474785065,
      "loss": 0.0,
      "step": 83950
    },
    {
      "epoch": 5.3894520723726425,
      "grad_norm": 0.01536043081432581,
      "learning_rate": 0.00023053060438855383,
      "loss": 0.0,
      "step": 84000
    },
    {
      "epoch": 5.392660079558579,
      "grad_norm": 0.020400866866111755,
      "learning_rate": 0.00023037020402925704,
      "loss": 0.0,
      "step": 84050
    },
    {
      "epoch": 5.395868086744514,
      "grad_norm": 0.02039767988026142,
      "learning_rate": 0.00023020980366996022,
      "loss": 0.0,
      "step": 84100
    },
    {
      "epoch": 5.39907609393045,
      "grad_norm": 0.006049818824976683,
      "learning_rate": 0.00023004940331066342,
      "loss": 0.0,
      "step": 84150
    },
    {
      "epoch": 5.402284101116386,
      "grad_norm": 0.012522915378212929,
      "learning_rate": 0.0002298890029513666,
      "loss": 0.0,
      "step": 84200
    },
    {
      "epoch": 5.405492108302322,
      "grad_norm": 0.0033789181616157293,
      "learning_rate": 0.0002297286025920698,
      "loss": 0.0,
      "step": 84250
    },
    {
      "epoch": 5.408700115488259,
      "grad_norm": 0.005659886170178652,
      "learning_rate": 0.000229568202232773,
      "loss": 0.0,
      "step": 84300
    },
    {
      "epoch": 5.411908122674195,
      "grad_norm": 0.009303227998316288,
      "learning_rate": 0.0002294078018734762,
      "loss": 0.0,
      "step": 84350
    },
    {
      "epoch": 5.415116129860131,
      "grad_norm": 0.007007181644439697,
      "learning_rate": 0.00022924740151417938,
      "loss": 0.0,
      "step": 84400
    },
    {
      "epoch": 5.418324137046067,
      "grad_norm": 0.013627508655190468,
      "learning_rate": 0.00022908700115488258,
      "loss": 0.0,
      "step": 84450
    },
    {
      "epoch": 5.421532144232003,
      "grad_norm": 0.00920652225613594,
      "learning_rate": 0.00022892660079558576,
      "loss": 0.0,
      "step": 84500
    },
    {
      "epoch": 5.424740151417939,
      "grad_norm": 0.01383537519723177,
      "learning_rate": 0.000228766200436289,
      "loss": 0.0,
      "step": 84550
    },
    {
      "epoch": 5.427948158603876,
      "grad_norm": 0.016571534797549248,
      "learning_rate": 0.00022860580007699218,
      "loss": 0.0,
      "step": 84600
    },
    {
      "epoch": 5.431156165789812,
      "grad_norm": 0.026933075860142708,
      "learning_rate": 0.00022844539971769538,
      "loss": 0.0,
      "step": 84650
    },
    {
      "epoch": 5.434364172975748,
      "grad_norm": 0.01300665270537138,
      "learning_rate": 0.00022828499935839856,
      "loss": 0.0,
      "step": 84700
    },
    {
      "epoch": 5.437572180161683,
      "grad_norm": 0.0063733612187206745,
      "learning_rate": 0.00022812459899910177,
      "loss": 0.0,
      "step": 84750
    },
    {
      "epoch": 5.440780187347619,
      "grad_norm": 0.021134400740265846,
      "learning_rate": 0.00022796419863980498,
      "loss": 0.0,
      "step": 84800
    },
    {
      "epoch": 5.4439881945335555,
      "grad_norm": 0.006739850156009197,
      "learning_rate": 0.00022780379828050816,
      "loss": 0.0,
      "step": 84850
    },
    {
      "epoch": 5.447196201719492,
      "grad_norm": 0.010348613373935223,
      "learning_rate": 0.00022764339792121136,
      "loss": 0.0,
      "step": 84900
    },
    {
      "epoch": 5.450404208905428,
      "grad_norm": 0.007036278024315834,
      "learning_rate": 0.00022748299756191454,
      "loss": 0.0,
      "step": 84950
    },
    {
      "epoch": 5.453612216091364,
      "grad_norm": 0.0034763882867991924,
      "learning_rate": 0.00022732259720261775,
      "loss": 0.0,
      "step": 85000
    },
    {
      "epoch": 5.4568202232773,
      "grad_norm": 0.006710200570523739,
      "learning_rate": 0.00022716219684332093,
      "loss": 0.0,
      "step": 85050
    },
    {
      "epoch": 5.460028230463236,
      "grad_norm": 0.006890178192406893,
      "learning_rate": 0.00022700179648402414,
      "loss": 0.0,
      "step": 85100
    },
    {
      "epoch": 5.4632362376491725,
      "grad_norm": 0.014742217026650906,
      "learning_rate": 0.00022684139612472732,
      "loss": 0.0,
      "step": 85150
    },
    {
      "epoch": 5.466444244835109,
      "grad_norm": 0.014652114361524582,
      "learning_rate": 0.00022668099576543052,
      "loss": 0.0,
      "step": 85200
    },
    {
      "epoch": 5.469652252021045,
      "grad_norm": 0.02001461386680603,
      "learning_rate": 0.0002265205954061337,
      "loss": 0.0,
      "step": 85250
    },
    {
      "epoch": 5.47286025920698,
      "grad_norm": 0.016254905611276627,
      "learning_rate": 0.0002263601950468369,
      "loss": 0.0,
      "step": 85300
    },
    {
      "epoch": 5.476068266392916,
      "grad_norm": 0.013050916604697704,
      "learning_rate": 0.0002261997946875401,
      "loss": 0.0,
      "step": 85350
    },
    {
      "epoch": 5.4792762735788525,
      "grad_norm": 0.010181648656725883,
      "learning_rate": 0.0002260393943282433,
      "loss": 0.0,
      "step": 85400
    },
    {
      "epoch": 5.482484280764789,
      "grad_norm": 0.006520232185721397,
      "learning_rate": 0.00022587899396894648,
      "loss": 0.0,
      "step": 85450
    },
    {
      "epoch": 5.485692287950725,
      "grad_norm": 0.023012148216366768,
      "learning_rate": 0.00022571859360964969,
      "loss": 0.0,
      "step": 85500
    },
    {
      "epoch": 5.488900295136661,
      "grad_norm": 0.008032097481191158,
      "learning_rate": 0.00022555819325035287,
      "loss": 0.0,
      "step": 85550
    },
    {
      "epoch": 5.492108302322597,
      "grad_norm": 0.009915747679769993,
      "learning_rate": 0.00022539779289105607,
      "loss": 0.0,
      "step": 85600
    },
    {
      "epoch": 5.495316309508533,
      "grad_norm": 0.0008251425460912287,
      "learning_rate": 0.00022523739253175928,
      "loss": 0.0,
      "step": 85650
    },
    {
      "epoch": 5.4985243166944695,
      "grad_norm": 0.013831095770001411,
      "learning_rate": 0.00022507699217246246,
      "loss": 0.0,
      "step": 85700
    },
    {
      "epoch": 5.501732323880406,
      "grad_norm": 0.0076017603278160095,
      "learning_rate": 0.00022491659181316567,
      "loss": 0.0,
      "step": 85750
    },
    {
      "epoch": 5.504940331066342,
      "grad_norm": 0.010244067758321762,
      "learning_rate": 0.00022475619145386885,
      "loss": 0.0,
      "step": 85800
    },
    {
      "epoch": 5.508148338252278,
      "grad_norm": 0.01332418154925108,
      "learning_rate": 0.00022459579109457208,
      "loss": 0.0,
      "step": 85850
    },
    {
      "epoch": 5.511356345438214,
      "grad_norm": 0.014569655060768127,
      "learning_rate": 0.00022443539073527526,
      "loss": 0.0,
      "step": 85900
    },
    {
      "epoch": 5.51456435262415,
      "grad_norm": 0.025680728256702423,
      "learning_rate": 0.00022427499037597847,
      "loss": 0.0,
      "step": 85950
    },
    {
      "epoch": 5.517772359810086,
      "grad_norm": 0.014413182623684406,
      "learning_rate": 0.00022411459001668165,
      "loss": 0.0,
      "step": 86000
    },
    {
      "epoch": 5.520980366996022,
      "grad_norm": 0.009418410249054432,
      "learning_rate": 0.00022395418965738485,
      "loss": 0.0,
      "step": 86050
    },
    {
      "epoch": 5.524188374181958,
      "grad_norm": 0.015420433133840561,
      "learning_rate": 0.00022379378929808803,
      "loss": 0.0,
      "step": 86100
    },
    {
      "epoch": 5.527396381367894,
      "grad_norm": 0.012841785326600075,
      "learning_rate": 0.00022363338893879124,
      "loss": 0.0,
      "step": 86150
    },
    {
      "epoch": 5.53060438855383,
      "grad_norm": 0.0017341511556878686,
      "learning_rate": 0.00022347298857949442,
      "loss": 0.0,
      "step": 86200
    },
    {
      "epoch": 5.5338123957397665,
      "grad_norm": 0.013646547682583332,
      "learning_rate": 0.00022331258822019763,
      "loss": 0.0,
      "step": 86250
    },
    {
      "epoch": 5.537020402925703,
      "grad_norm": 0.005063413176685572,
      "learning_rate": 0.0002231521878609008,
      "loss": 0.0,
      "step": 86300
    },
    {
      "epoch": 5.540228410111639,
      "grad_norm": 0.006940273102372885,
      "learning_rate": 0.00022299178750160401,
      "loss": 0.0,
      "step": 86350
    },
    {
      "epoch": 5.543436417297575,
      "grad_norm": 0.004812152124941349,
      "learning_rate": 0.0002228313871423072,
      "loss": 0.0,
      "step": 86400
    },
    {
      "epoch": 5.546644424483511,
      "grad_norm": 0.005753282457590103,
      "learning_rate": 0.0002226709867830104,
      "loss": 0.0,
      "step": 86450
    },
    {
      "epoch": 5.549852431669447,
      "grad_norm": 0.01061145681887865,
      "learning_rate": 0.0002225105864237136,
      "loss": 0.0,
      "step": 86500
    },
    {
      "epoch": 5.553060438855383,
      "grad_norm": 0.0031061694025993347,
      "learning_rate": 0.0002223501860644168,
      "loss": 0.0,
      "step": 86550
    },
    {
      "epoch": 5.556268446041319,
      "grad_norm": 0.010563491843640804,
      "learning_rate": 0.00022218978570512,
      "loss": 0.0,
      "step": 86600
    },
    {
      "epoch": 5.559476453227255,
      "grad_norm": 0.006630884949117899,
      "learning_rate": 0.00022202938534582317,
      "loss": 0.0,
      "step": 86650
    },
    {
      "epoch": 5.562684460413191,
      "grad_norm": 0.017115850001573563,
      "learning_rate": 0.00022186898498652638,
      "loss": 0.0,
      "step": 86700
    },
    {
      "epoch": 5.565892467599127,
      "grad_norm": 0.002776707988232374,
      "learning_rate": 0.00022170858462722956,
      "loss": 0.0,
      "step": 86750
    },
    {
      "epoch": 5.569100474785063,
      "grad_norm": 0.007243018597364426,
      "learning_rate": 0.00022154818426793277,
      "loss": 0.0,
      "step": 86800
    },
    {
      "epoch": 5.572308481971,
      "grad_norm": 0.005230553448200226,
      "learning_rate": 0.00022138778390863595,
      "loss": 0.0,
      "step": 86850
    },
    {
      "epoch": 5.575516489156936,
      "grad_norm": 0.014890684746205807,
      "learning_rate": 0.00022122738354933915,
      "loss": 0.0,
      "step": 86900
    },
    {
      "epoch": 5.578724496342872,
      "grad_norm": 0.010928197763860226,
      "learning_rate": 0.00022106698319004233,
      "loss": 0.0,
      "step": 86950
    },
    {
      "epoch": 5.581932503528808,
      "grad_norm": 0.00718407379463315,
      "learning_rate": 0.00022090658283074554,
      "loss": 0.0,
      "step": 87000
    },
    {
      "epoch": 5.585140510714744,
      "grad_norm": 0.009597638621926308,
      "learning_rate": 0.00022074618247144872,
      "loss": 0.0,
      "step": 87050
    },
    {
      "epoch": 5.58834851790068,
      "grad_norm": 0.0040711769834160805,
      "learning_rate": 0.00022058578211215193,
      "loss": 0.0,
      "step": 87100
    },
    {
      "epoch": 5.591556525086617,
      "grad_norm": 0.011736642569303513,
      "learning_rate": 0.0002204253817528551,
      "loss": 0.0,
      "step": 87150
    },
    {
      "epoch": 5.594764532272553,
      "grad_norm": 0.010807592421770096,
      "learning_rate": 0.00022026498139355831,
      "loss": 0.0,
      "step": 87200
    },
    {
      "epoch": 5.597972539458488,
      "grad_norm": 0.002896111225709319,
      "learning_rate": 0.00022010458103426152,
      "loss": 0.0,
      "step": 87250
    },
    {
      "epoch": 5.601180546644424,
      "grad_norm": 0.010815875604748726,
      "learning_rate": 0.00021994418067496473,
      "loss": 0.0,
      "step": 87300
    },
    {
      "epoch": 5.60438855383036,
      "grad_norm": 0.005725347436964512,
      "learning_rate": 0.00021978378031566794,
      "loss": 0.0,
      "step": 87350
    },
    {
      "epoch": 5.6075965610162966,
      "grad_norm": 0.01171900611370802,
      "learning_rate": 0.00021962337995637112,
      "loss": 0.0,
      "step": 87400
    },
    {
      "epoch": 5.610804568202233,
      "grad_norm": 0.013415392488241196,
      "learning_rate": 0.00021946297959707432,
      "loss": 0.0,
      "step": 87450
    },
    {
      "epoch": 5.614012575388169,
      "grad_norm": 0.008175871334969997,
      "learning_rate": 0.0002193025792377775,
      "loss": 0.0,
      "step": 87500
    },
    {
      "epoch": 5.617220582574105,
      "grad_norm": 0.005444415379315615,
      "learning_rate": 0.0002191421788784807,
      "loss": 0.0,
      "step": 87550
    },
    {
      "epoch": 5.620428589760041,
      "grad_norm": 0.006369051057845354,
      "learning_rate": 0.0002189817785191839,
      "loss": 0.0,
      "step": 87600
    },
    {
      "epoch": 5.623636596945977,
      "grad_norm": 0.02166653238236904,
      "learning_rate": 0.0002188213781598871,
      "loss": 0.0,
      "step": 87650
    },
    {
      "epoch": 5.626844604131914,
      "grad_norm": 0.0051951780915260315,
      "learning_rate": 0.00021866097780059028,
      "loss": 0.0,
      "step": 87700
    },
    {
      "epoch": 5.63005261131785,
      "grad_norm": 0.007894149981439114,
      "learning_rate": 0.00021850057744129348,
      "loss": 0.0,
      "step": 87750
    },
    {
      "epoch": 5.633260618503785,
      "grad_norm": 0.0018473919481039047,
      "learning_rate": 0.00021834017708199666,
      "loss": 0.0,
      "step": 87800
    },
    {
      "epoch": 5.636468625689721,
      "grad_norm": 0.008205769583582878,
      "learning_rate": 0.00021817977672269987,
      "loss": 0.0,
      "step": 87850
    },
    {
      "epoch": 5.639676632875657,
      "grad_norm": 0.012641113251447678,
      "learning_rate": 0.00021801937636340305,
      "loss": 0.0,
      "step": 87900
    },
    {
      "epoch": 5.6428846400615935,
      "grad_norm": 0.00828786101192236,
      "learning_rate": 0.00021785897600410626,
      "loss": 0.0,
      "step": 87950
    },
    {
      "epoch": 5.64609264724753,
      "grad_norm": 0.007473226636648178,
      "learning_rate": 0.00021769857564480944,
      "loss": 0.0,
      "step": 88000
    },
    {
      "epoch": 5.649300654433466,
      "grad_norm": 0.02616596594452858,
      "learning_rate": 0.00021753817528551264,
      "loss": 0.0,
      "step": 88050
    },
    {
      "epoch": 5.652508661619402,
      "grad_norm": 0.01202276349067688,
      "learning_rate": 0.00021737777492621582,
      "loss": 0.0,
      "step": 88100
    },
    {
      "epoch": 5.655716668805338,
      "grad_norm": 0.004733572714030743,
      "learning_rate": 0.00021721737456691903,
      "loss": 0.0,
      "step": 88150
    },
    {
      "epoch": 5.658924675991274,
      "grad_norm": 0.008549811318516731,
      "learning_rate": 0.00021705697420762224,
      "loss": 0.0,
      "step": 88200
    },
    {
      "epoch": 5.6621326831772105,
      "grad_norm": 0.00831310823559761,
      "learning_rate": 0.00021689657384832542,
      "loss": 0.0,
      "step": 88250
    },
    {
      "epoch": 5.665340690363147,
      "grad_norm": 0.003575436072424054,
      "learning_rate": 0.00021673617348902862,
      "loss": 0.0,
      "step": 88300
    },
    {
      "epoch": 5.668548697549083,
      "grad_norm": 0.019536133855581284,
      "learning_rate": 0.0002165757731297318,
      "loss": 0.0,
      "step": 88350
    },
    {
      "epoch": 5.671756704735019,
      "grad_norm": 0.014062370173633099,
      "learning_rate": 0.000216415372770435,
      "loss": 0.0,
      "step": 88400
    },
    {
      "epoch": 5.674964711920955,
      "grad_norm": 0.007944595068693161,
      "learning_rate": 0.0002162549724111382,
      "loss": 0.0,
      "step": 88450
    },
    {
      "epoch": 5.6781727191068905,
      "grad_norm": 0.017220662906765938,
      "learning_rate": 0.0002160945720518414,
      "loss": 0.0,
      "step": 88500
    },
    {
      "epoch": 5.681380726292827,
      "grad_norm": 0.009567253291606903,
      "learning_rate": 0.00021593417169254458,
      "loss": 0.0,
      "step": 88550
    },
    {
      "epoch": 5.684588733478763,
      "grad_norm": 0.006923885550349951,
      "learning_rate": 0.0002157737713332478,
      "loss": 0.0,
      "step": 88600
    },
    {
      "epoch": 5.687796740664699,
      "grad_norm": 0.00979629997164011,
      "learning_rate": 0.000215613370973951,
      "loss": 0.0,
      "step": 88650
    },
    {
      "epoch": 5.691004747850635,
      "grad_norm": 0.031157948076725006,
      "learning_rate": 0.0002154529706146542,
      "loss": 0.0,
      "step": 88700
    },
    {
      "epoch": 5.694212755036571,
      "grad_norm": 0.003921548370271921,
      "learning_rate": 0.00021529257025535738,
      "loss": 0.0,
      "step": 88750
    },
    {
      "epoch": 5.6974207622225075,
      "grad_norm": 0.007597820833325386,
      "learning_rate": 0.00021513216989606058,
      "loss": 0.0,
      "step": 88800
    },
    {
      "epoch": 5.700628769408444,
      "grad_norm": 0.01347130537033081,
      "learning_rate": 0.00021497176953676376,
      "loss": 0.0,
      "step": 88850
    },
    {
      "epoch": 5.70383677659438,
      "grad_norm": 0.011747896671295166,
      "learning_rate": 0.00021481136917746697,
      "loss": 0.0,
      "step": 88900
    },
    {
      "epoch": 5.707044783780316,
      "grad_norm": 0.008416581898927689,
      "learning_rate": 0.00021465096881817015,
      "loss": 0.0,
      "step": 88950
    },
    {
      "epoch": 5.710252790966251,
      "grad_norm": 0.019212892279028893,
      "learning_rate": 0.00021449056845887336,
      "loss": 0.0,
      "step": 89000
    },
    {
      "epoch": 5.713460798152187,
      "grad_norm": 0.003671434009447694,
      "learning_rate": 0.00021433016809957657,
      "loss": 0.0,
      "step": 89050
    },
    {
      "epoch": 5.716668805338124,
      "grad_norm": 0.010253150947391987,
      "learning_rate": 0.00021416976774027975,
      "loss": 0.0,
      "step": 89100
    },
    {
      "epoch": 5.71987681252406,
      "grad_norm": 0.019384125247597694,
      "learning_rate": 0.00021400936738098295,
      "loss": 0.0,
      "step": 89150
    },
    {
      "epoch": 5.723084819709996,
      "grad_norm": 0.009903647005558014,
      "learning_rate": 0.00021384896702168613,
      "loss": 0.0,
      "step": 89200
    },
    {
      "epoch": 5.726292826895932,
      "grad_norm": 0.009615371003746986,
      "learning_rate": 0.00021368856666238934,
      "loss": 0.0,
      "step": 89250
    },
    {
      "epoch": 5.729500834081868,
      "grad_norm": 0.022207019850611687,
      "learning_rate": 0.00021352816630309252,
      "loss": 0.0,
      "step": 89300
    },
    {
      "epoch": 5.7327088412678044,
      "grad_norm": 0.005403977818787098,
      "learning_rate": 0.00021336776594379573,
      "loss": 0.0,
      "step": 89350
    },
    {
      "epoch": 5.735916848453741,
      "grad_norm": 0.0171392560005188,
      "learning_rate": 0.0002132073655844989,
      "loss": 0.0,
      "step": 89400
    },
    {
      "epoch": 5.739124855639677,
      "grad_norm": 0.0035958995576947927,
      "learning_rate": 0.0002130469652252021,
      "loss": 0.0,
      "step": 89450
    },
    {
      "epoch": 5.742332862825613,
      "grad_norm": 0.00512517336755991,
      "learning_rate": 0.0002128865648659053,
      "loss": 0.0,
      "step": 89500
    },
    {
      "epoch": 5.745540870011549,
      "grad_norm": 0.01467194315046072,
      "learning_rate": 0.0002127261645066085,
      "loss": 0.0,
      "step": 89550
    },
    {
      "epoch": 5.748748877197485,
      "grad_norm": 0.012077958323061466,
      "learning_rate": 0.00021256576414731168,
      "loss": 0.0,
      "step": 89600
    },
    {
      "epoch": 5.7519568843834215,
      "grad_norm": 0.006799767259508371,
      "learning_rate": 0.00021240536378801489,
      "loss": 0.0,
      "step": 89650
    },
    {
      "epoch": 5.755164891569357,
      "grad_norm": 0.0028991338331252337,
      "learning_rate": 0.00021224496342871807,
      "loss": 0.0,
      "step": 89700
    },
    {
      "epoch": 5.758372898755293,
      "grad_norm": 0.016031350940465927,
      "learning_rate": 0.00021208456306942127,
      "loss": 0.0,
      "step": 89750
    },
    {
      "epoch": 5.761580905941229,
      "grad_norm": 0.009503561072051525,
      "learning_rate": 0.00021192416271012445,
      "loss": 0.0,
      "step": 89800
    },
    {
      "epoch": 5.764788913127165,
      "grad_norm": 0.016851382330060005,
      "learning_rate": 0.00021176376235082766,
      "loss": 0.0,
      "step": 89850
    },
    {
      "epoch": 5.767996920313101,
      "grad_norm": 0.014933993108570576,
      "learning_rate": 0.00021160336199153084,
      "loss": 0.0,
      "step": 89900
    },
    {
      "epoch": 5.771204927499038,
      "grad_norm": 0.006983138155192137,
      "learning_rate": 0.00021144296163223405,
      "loss": 0.0,
      "step": 89950
    },
    {
      "epoch": 5.774412934684974,
      "grad_norm": 0.003328392980620265,
      "learning_rate": 0.00021128256127293728,
      "loss": 0.0,
      "step": 90000
    },
    {
      "epoch": 5.77762094187091,
      "grad_norm": 0.007692729122936726,
      "learning_rate": 0.00021112216091364046,
      "loss": 0.0,
      "step": 90050
    },
    {
      "epoch": 5.780828949056846,
      "grad_norm": 0.007767905481159687,
      "learning_rate": 0.00021096176055434367,
      "loss": 0.0,
      "step": 90100
    },
    {
      "epoch": 5.784036956242782,
      "grad_norm": 0.0067909699864685535,
      "learning_rate": 0.00021080136019504685,
      "loss": 0.0,
      "step": 90150
    },
    {
      "epoch": 5.787244963428718,
      "grad_norm": 0.009847655892372131,
      "learning_rate": 0.00021064095983575005,
      "loss": 0.0,
      "step": 90200
    },
    {
      "epoch": 5.790452970614654,
      "grad_norm": 0.0072578489780426025,
      "learning_rate": 0.00021048055947645323,
      "loss": 0.0,
      "step": 90250
    },
    {
      "epoch": 5.79366097780059,
      "grad_norm": 0.0050169662572443485,
      "learning_rate": 0.00021032015911715644,
      "loss": 0.0,
      "step": 90300
    },
    {
      "epoch": 5.796868984986526,
      "grad_norm": 0.010364674963057041,
      "learning_rate": 0.00021015975875785962,
      "loss": 0.0,
      "step": 90350
    },
    {
      "epoch": 5.800076992172462,
      "grad_norm": 0.005817960947751999,
      "learning_rate": 0.00020999935839856283,
      "loss": 0.0,
      "step": 90400
    },
    {
      "epoch": 5.803284999358398,
      "grad_norm": 0.01969481259584427,
      "learning_rate": 0.000209838958039266,
      "loss": 0.0,
      "step": 90450
    },
    {
      "epoch": 5.8064930065443345,
      "grad_norm": 0.01625286415219307,
      "learning_rate": 0.00020967855767996921,
      "loss": 0.0,
      "step": 90500
    },
    {
      "epoch": 5.809701013730271,
      "grad_norm": 0.008541066199541092,
      "learning_rate": 0.0002095181573206724,
      "loss": 0.0,
      "step": 90550
    },
    {
      "epoch": 5.812909020916207,
      "grad_norm": 0.009829403832554817,
      "learning_rate": 0.0002093577569613756,
      "loss": 0.0,
      "step": 90600
    },
    {
      "epoch": 5.816117028102143,
      "grad_norm": 0.012953052297234535,
      "learning_rate": 0.00020919735660207878,
      "loss": 0.0,
      "step": 90650
    },
    {
      "epoch": 5.819325035288079,
      "grad_norm": 0.0016562293749302626,
      "learning_rate": 0.000209036956242782,
      "loss": 0.0,
      "step": 90700
    },
    {
      "epoch": 5.822533042474015,
      "grad_norm": 0.013047748245298862,
      "learning_rate": 0.00020887655588348517,
      "loss": 0.0,
      "step": 90750
    },
    {
      "epoch": 5.8257410496599515,
      "grad_norm": 0.00644974410533905,
      "learning_rate": 0.00020871615552418837,
      "loss": 0.0,
      "step": 90800
    },
    {
      "epoch": 5.828949056845888,
      "grad_norm": 0.005764191970229149,
      "learning_rate": 0.00020855575516489158,
      "loss": 0.0,
      "step": 90850
    },
    {
      "epoch": 5.832157064031824,
      "grad_norm": 0.005646174773573875,
      "learning_rate": 0.00020839535480559476,
      "loss": 0.0,
      "step": 90900
    },
    {
      "epoch": 5.835365071217759,
      "grad_norm": 0.009246818721294403,
      "learning_rate": 0.00020823495444629797,
      "loss": 0.0,
      "step": 90950
    },
    {
      "epoch": 5.838573078403695,
      "grad_norm": 0.008352917619049549,
      "learning_rate": 0.00020807455408700115,
      "loss": 0.0,
      "step": 91000
    },
    {
      "epoch": 5.8417810855896315,
      "grad_norm": 0.004007698968052864,
      "learning_rate": 0.00020791415372770436,
      "loss": 0.0,
      "step": 91050
    },
    {
      "epoch": 5.844989092775568,
      "grad_norm": 0.015308883972465992,
      "learning_rate": 0.00020775375336840754,
      "loss": 0.0,
      "step": 91100
    },
    {
      "epoch": 5.848197099961504,
      "grad_norm": 0.009354752488434315,
      "learning_rate": 0.00020759335300911074,
      "loss": 0.0,
      "step": 91150
    },
    {
      "epoch": 5.85140510714744,
      "grad_norm": 0.008507306687533855,
      "learning_rate": 0.00020743295264981392,
      "loss": 0.0,
      "step": 91200
    },
    {
      "epoch": 5.854613114333376,
      "grad_norm": 0.005421673879027367,
      "learning_rate": 0.00020727255229051713,
      "loss": 0.0,
      "step": 91250
    },
    {
      "epoch": 5.857821121519312,
      "grad_norm": 0.0073956032283604145,
      "learning_rate": 0.0002071121519312203,
      "loss": 0.0,
      "step": 91300
    },
    {
      "epoch": 5.8610291287052485,
      "grad_norm": 0.012292972765862942,
      "learning_rate": 0.00020695175157192354,
      "loss": 0.0,
      "step": 91350
    },
    {
      "epoch": 5.864237135891185,
      "grad_norm": 0.004995448514819145,
      "learning_rate": 0.00020679135121262672,
      "loss": 0.0,
      "step": 91400
    },
    {
      "epoch": 5.867445143077121,
      "grad_norm": 0.015164464712142944,
      "learning_rate": 0.00020663095085332993,
      "loss": 0.0,
      "step": 91450
    },
    {
      "epoch": 5.870653150263056,
      "grad_norm": 0.011612622998654842,
      "learning_rate": 0.0002064705504940331,
      "loss": 0.0,
      "step": 91500
    },
    {
      "epoch": 5.873861157448992,
      "grad_norm": 0.014798982068896294,
      "learning_rate": 0.00020631015013473632,
      "loss": 0.0,
      "step": 91550
    },
    {
      "epoch": 5.8770691646349285,
      "grad_norm": 0.012083975598216057,
      "learning_rate": 0.0002061497497754395,
      "loss": 0.0,
      "step": 91600
    },
    {
      "epoch": 5.880277171820865,
      "grad_norm": 0.009600934572517872,
      "learning_rate": 0.0002059893494161427,
      "loss": 0.0,
      "step": 91650
    },
    {
      "epoch": 5.883485179006801,
      "grad_norm": 0.004546556156128645,
      "learning_rate": 0.0002058289490568459,
      "loss": 0.0,
      "step": 91700
    },
    {
      "epoch": 5.886693186192737,
      "grad_norm": 0.003284002188593149,
      "learning_rate": 0.0002056685486975491,
      "loss": 0.0,
      "step": 91750
    },
    {
      "epoch": 5.889901193378673,
      "grad_norm": 0.014238777570426464,
      "learning_rate": 0.0002055081483382523,
      "loss": 0.0,
      "step": 91800
    },
    {
      "epoch": 5.893109200564609,
      "grad_norm": 0.006231081206351519,
      "learning_rate": 0.00020534774797895548,
      "loss": 0.0,
      "step": 91850
    },
    {
      "epoch": 5.8963172077505455,
      "grad_norm": 0.005533069837838411,
      "learning_rate": 0.00020518734761965868,
      "loss": 0.0,
      "step": 91900
    },
    {
      "epoch": 5.899525214936482,
      "grad_norm": 0.014790905639529228,
      "learning_rate": 0.00020502694726036186,
      "loss": 0.0,
      "step": 91950
    },
    {
      "epoch": 5.902733222122418,
      "grad_norm": 0.0030261045321822166,
      "learning_rate": 0.00020486654690106507,
      "loss": 0.0,
      "step": 92000
    },
    {
      "epoch": 5.905941229308354,
      "grad_norm": 0.007318300660699606,
      "learning_rate": 0.00020470614654176825,
      "loss": 0.0,
      "step": 92050
    },
    {
      "epoch": 5.90914923649429,
      "grad_norm": 0.0037580966018140316,
      "learning_rate": 0.00020454574618247146,
      "loss": 0.0,
      "step": 92100
    },
    {
      "epoch": 5.912357243680226,
      "grad_norm": 0.0015597679885104299,
      "learning_rate": 0.00020438534582317464,
      "loss": 0.0,
      "step": 92150
    },
    {
      "epoch": 5.915565250866162,
      "grad_norm": 0.01451567467302084,
      "learning_rate": 0.00020422494546387784,
      "loss": 0.0,
      "step": 92200
    },
    {
      "epoch": 5.918773258052098,
      "grad_norm": 0.006796596106141806,
      "learning_rate": 0.00020406454510458102,
      "loss": 0.0,
      "step": 92250
    },
    {
      "epoch": 5.921981265238034,
      "grad_norm": 0.0157383531332016,
      "learning_rate": 0.00020390414474528423,
      "loss": 0.0,
      "step": 92300
    },
    {
      "epoch": 5.92518927242397,
      "grad_norm": 0.013784713111817837,
      "learning_rate": 0.0002037437443859874,
      "loss": 0.0,
      "step": 92350
    },
    {
      "epoch": 5.928397279609906,
      "grad_norm": 0.011813275516033173,
      "learning_rate": 0.00020358334402669062,
      "loss": 0.0,
      "step": 92400
    },
    {
      "epoch": 5.931605286795842,
      "grad_norm": 0.005991488695144653,
      "learning_rate": 0.0002034229436673938,
      "loss": 0.0,
      "step": 92450
    },
    {
      "epoch": 5.934813293981779,
      "grad_norm": 0.01314136665314436,
      "learning_rate": 0.000203262543308097,
      "loss": 0.0,
      "step": 92500
    },
    {
      "epoch": 5.938021301167715,
      "grad_norm": 0.0046578203327953815,
      "learning_rate": 0.0002031021429488002,
      "loss": 0.0,
      "step": 92550
    },
    {
      "epoch": 5.941229308353651,
      "grad_norm": 0.0176539346575737,
      "learning_rate": 0.0002029417425895034,
      "loss": 0.0,
      "step": 92600
    },
    {
      "epoch": 5.944437315539587,
      "grad_norm": 0.013090130873024464,
      "learning_rate": 0.0002027813422302066,
      "loss": 0.0,
      "step": 92650
    },
    {
      "epoch": 5.947645322725523,
      "grad_norm": 0.0042869155295193195,
      "learning_rate": 0.00020262094187090978,
      "loss": 0.0,
      "step": 92700
    },
    {
      "epoch": 5.9508533299114585,
      "grad_norm": 0.01564142107963562,
      "learning_rate": 0.000202460541511613,
      "loss": 0.0,
      "step": 92750
    },
    {
      "epoch": 5.954061337097395,
      "grad_norm": 0.00888008065521717,
      "learning_rate": 0.0002023001411523162,
      "loss": 0.0,
      "step": 92800
    },
    {
      "epoch": 5.957269344283331,
      "grad_norm": 0.008828088641166687,
      "learning_rate": 0.0002021397407930194,
      "loss": 0.0,
      "step": 92850
    },
    {
      "epoch": 5.960477351469267,
      "grad_norm": 0.011422768235206604,
      "learning_rate": 0.00020197934043372258,
      "loss": 0.0,
      "step": 92900
    },
    {
      "epoch": 5.963685358655203,
      "grad_norm": 0.0070170084945857525,
      "learning_rate": 0.00020181894007442579,
      "loss": 0.0,
      "step": 92950
    },
    {
      "epoch": 5.966893365841139,
      "grad_norm": 0.0029828364495187998,
      "learning_rate": 0.00020165853971512897,
      "loss": 0.0,
      "step": 93000
    },
    {
      "epoch": 5.9701013730270756,
      "grad_norm": 0.004774677101522684,
      "learning_rate": 0.00020149813935583217,
      "loss": 0.0,
      "step": 93050
    },
    {
      "epoch": 5.973309380213012,
      "grad_norm": 0.012282461859285831,
      "learning_rate": 0.00020133773899653535,
      "loss": 0.0,
      "step": 93100
    },
    {
      "epoch": 5.976517387398948,
      "grad_norm": 0.013817641884088516,
      "learning_rate": 0.00020117733863723856,
      "loss": 0.0,
      "step": 93150
    },
    {
      "epoch": 5.979725394584884,
      "grad_norm": 0.010792230255901814,
      "learning_rate": 0.00020101693827794174,
      "loss": 0.0,
      "step": 93200
    },
    {
      "epoch": 5.98293340177082,
      "grad_norm": 0.012801731936633587,
      "learning_rate": 0.00020085653791864495,
      "loss": 0.0,
      "step": 93250
    },
    {
      "epoch": 5.986141408956756,
      "grad_norm": 0.011987471953034401,
      "learning_rate": 0.00020069613755934813,
      "loss": 0.0,
      "step": 93300
    },
    {
      "epoch": 5.989349416142693,
      "grad_norm": 0.005915961693972349,
      "learning_rate": 0.00020053573720005133,
      "loss": 0.0,
      "step": 93350
    },
    {
      "epoch": 5.992557423328629,
      "grad_norm": 0.004508999176323414,
      "learning_rate": 0.00020037533684075454,
      "loss": 0.0,
      "step": 93400
    },
    {
      "epoch": 5.995765430514564,
      "grad_norm": 0.006081594619899988,
      "learning_rate": 0.00020021493648145772,
      "loss": 0.0,
      "step": 93450
    },
    {
      "epoch": 5.9989734377005,
      "grad_norm": 0.011489909142255783,
      "learning_rate": 0.00020005453612216093,
      "loss": 0.0,
      "step": 93500
    },
    {
      "epoch": 6.002181444886436,
      "grad_norm": 0.004748541861772537,
      "learning_rate": 0.0001998941357628641,
      "loss": 0.0,
      "step": 93550
    },
    {
      "epoch": 6.0053894520723725,
      "grad_norm": 0.007453446742147207,
      "learning_rate": 0.00019973373540356731,
      "loss": 0.0,
      "step": 93600
    },
    {
      "epoch": 6.008597459258309,
      "grad_norm": 0.008386597968637943,
      "learning_rate": 0.0001995733350442705,
      "loss": 0.0,
      "step": 93650
    },
    {
      "epoch": 6.011805466444245,
      "grad_norm": 0.011469833552837372,
      "learning_rate": 0.0001994129346849737,
      "loss": 0.0,
      "step": 93700
    },
    {
      "epoch": 6.015013473630181,
      "grad_norm": 0.022234756499528885,
      "learning_rate": 0.00019925253432567688,
      "loss": 0.0,
      "step": 93750
    },
    {
      "epoch": 6.018221480816117,
      "grad_norm": 0.016639288514852524,
      "learning_rate": 0.0001990921339663801,
      "loss": 0.0,
      "step": 93800
    },
    {
      "epoch": 6.021429488002053,
      "grad_norm": 0.00620765658095479,
      "learning_rate": 0.00019893173360708327,
      "loss": 0.0,
      "step": 93850
    },
    {
      "epoch": 6.0246374951879895,
      "grad_norm": 0.005745660979300737,
      "learning_rate": 0.00019877133324778647,
      "loss": 0.0,
      "step": 93900
    },
    {
      "epoch": 6.027845502373926,
      "grad_norm": 0.004454591311514378,
      "learning_rate": 0.00019861093288848965,
      "loss": 0.0,
      "step": 93950
    },
    {
      "epoch": 6.031053509559861,
      "grad_norm": 0.00961173977702856,
      "learning_rate": 0.00019845053252919286,
      "loss": 0.0,
      "step": 94000
    },
    {
      "epoch": 6.034261516745797,
      "grad_norm": 0.00920644961297512,
      "learning_rate": 0.00019829013216989604,
      "loss": 0.0,
      "step": 94050
    },
    {
      "epoch": 6.037469523931733,
      "grad_norm": 0.0014771745773032308,
      "learning_rate": 0.00019812973181059927,
      "loss": 0.0,
      "step": 94100
    },
    {
      "epoch": 6.0406775311176695,
      "grad_norm": 0.016337204724550247,
      "learning_rate": 0.00019796933145130245,
      "loss": 0.0,
      "step": 94150
    },
    {
      "epoch": 6.043885538303606,
      "grad_norm": 0.00549091212451458,
      "learning_rate": 0.00019780893109200566,
      "loss": 0.0,
      "step": 94200
    },
    {
      "epoch": 6.047093545489542,
      "grad_norm": 0.015317508019506931,
      "learning_rate": 0.00019764853073270887,
      "loss": 0.0,
      "step": 94250
    },
    {
      "epoch": 6.050301552675478,
      "grad_norm": 0.01554133277386427,
      "learning_rate": 0.00019748813037341205,
      "loss": 0.0,
      "step": 94300
    },
    {
      "epoch": 6.053509559861414,
      "grad_norm": 0.004796367604285479,
      "learning_rate": 0.00019732773001411526,
      "loss": 0.0,
      "step": 94350
    },
    {
      "epoch": 6.05671756704735,
      "grad_norm": 0.004756562411785126,
      "learning_rate": 0.00019716732965481844,
      "loss": 0.0,
      "step": 94400
    },
    {
      "epoch": 6.0599255742332865,
      "grad_norm": 0.01755681075155735,
      "learning_rate": 0.00019700692929552164,
      "loss": 0.0,
      "step": 94450
    },
    {
      "epoch": 6.063133581419223,
      "grad_norm": 0.003493531374260783,
      "learning_rate": 0.00019684652893622482,
      "loss": 0.0,
      "step": 94500
    },
    {
      "epoch": 6.066341588605159,
      "grad_norm": 0.004738321993499994,
      "learning_rate": 0.00019668612857692803,
      "loss": 0.0,
      "step": 94550
    },
    {
      "epoch": 6.069549595791095,
      "grad_norm": 0.008699511177837849,
      "learning_rate": 0.0001965257282176312,
      "loss": 0.0,
      "step": 94600
    },
    {
      "epoch": 6.07275760297703,
      "grad_norm": 0.009444648399949074,
      "learning_rate": 0.00019636532785833442,
      "loss": 0.0,
      "step": 94650
    },
    {
      "epoch": 6.075965610162966,
      "grad_norm": 0.0078038740903139114,
      "learning_rate": 0.0001962049274990376,
      "loss": 0.0,
      "step": 94700
    },
    {
      "epoch": 6.079173617348903,
      "grad_norm": 0.013644200749695301,
      "learning_rate": 0.0001960445271397408,
      "loss": 0.0,
      "step": 94750
    },
    {
      "epoch": 6.082381624534839,
      "grad_norm": 0.010532774031162262,
      "learning_rate": 0.00019588412678044398,
      "loss": 0.0,
      "step": 94800
    },
    {
      "epoch": 6.085589631720775,
      "grad_norm": 0.022164329886436462,
      "learning_rate": 0.0001957237264211472,
      "loss": 0.0,
      "step": 94850
    },
    {
      "epoch": 6.088797638906711,
      "grad_norm": 0.009883199818432331,
      "learning_rate": 0.00019556332606185037,
      "loss": 0.0,
      "step": 94900
    },
    {
      "epoch": 6.092005646092647,
      "grad_norm": 0.011904430575668812,
      "learning_rate": 0.00019540292570255358,
      "loss": 0.0,
      "step": 94950
    },
    {
      "epoch": 6.095213653278583,
      "grad_norm": 0.0027272035367786884,
      "learning_rate": 0.00019524252534325676,
      "loss": 0.0,
      "step": 95000
    },
    {
      "epoch": 6.09842166046452,
      "grad_norm": 0.007914887741208076,
      "learning_rate": 0.00019508212498395996,
      "loss": 0.0,
      "step": 95050
    },
    {
      "epoch": 6.101629667650456,
      "grad_norm": 0.009151438251137733,
      "learning_rate": 0.00019492172462466317,
      "loss": 0.0,
      "step": 95100
    },
    {
      "epoch": 6.104837674836392,
      "grad_norm": 0.015488911420106888,
      "learning_rate": 0.00019476132426536635,
      "loss": 0.0,
      "step": 95150
    },
    {
      "epoch": 6.108045682022328,
      "grad_norm": 0.0038838875479996204,
      "learning_rate": 0.00019460092390606956,
      "loss": 0.0,
      "step": 95200
    },
    {
      "epoch": 6.111253689208263,
      "grad_norm": 0.00610552029684186,
      "learning_rate": 0.00019444052354677274,
      "loss": 0.0,
      "step": 95250
    },
    {
      "epoch": 6.1144616963942,
      "grad_norm": 0.012119613587856293,
      "learning_rate": 0.00019428012318747594,
      "loss": 0.0,
      "step": 95300
    },
    {
      "epoch": 6.117669703580136,
      "grad_norm": 0.018847225233912468,
      "learning_rate": 0.00019411972282817912,
      "loss": 0.0,
      "step": 95350
    },
    {
      "epoch": 6.120877710766072,
      "grad_norm": 0.0035692499950528145,
      "learning_rate": 0.00019395932246888233,
      "loss": 0.0,
      "step": 95400
    },
    {
      "epoch": 6.124085717952008,
      "grad_norm": 0.007657583802938461,
      "learning_rate": 0.00019379892210958554,
      "loss": 0.0,
      "step": 95450
    },
    {
      "epoch": 6.127293725137944,
      "grad_norm": 0.002231849357485771,
      "learning_rate": 0.00019363852175028874,
      "loss": 0.0,
      "step": 95500
    },
    {
      "epoch": 6.13050173232388,
      "grad_norm": 0.011539563536643982,
      "learning_rate": 0.00019347812139099192,
      "loss": 0.0,
      "step": 95550
    },
    {
      "epoch": 6.133709739509817,
      "grad_norm": 0.003000311553478241,
      "learning_rate": 0.00019331772103169513,
      "loss": 0.0,
      "step": 95600
    },
    {
      "epoch": 6.136917746695753,
      "grad_norm": 0.004898338112980127,
      "learning_rate": 0.0001931573206723983,
      "loss": 0.0,
      "step": 95650
    },
    {
      "epoch": 6.140125753881689,
      "grad_norm": 0.011086839251220226,
      "learning_rate": 0.00019299692031310152,
      "loss": 0.0,
      "step": 95700
    },
    {
      "epoch": 6.143333761067625,
      "grad_norm": 0.009038511663675308,
      "learning_rate": 0.0001928365199538047,
      "loss": 0.0,
      "step": 95750
    },
    {
      "epoch": 6.146541768253561,
      "grad_norm": 0.015246041119098663,
      "learning_rate": 0.0001926761195945079,
      "loss": 0.0,
      "step": 95800
    },
    {
      "epoch": 6.149749775439497,
      "grad_norm": 0.020729824900627136,
      "learning_rate": 0.00019251571923521108,
      "loss": 0.0,
      "step": 95850
    },
    {
      "epoch": 6.152957782625433,
      "grad_norm": 0.015421990305185318,
      "learning_rate": 0.0001923553188759143,
      "loss": 0.0,
      "step": 95900
    },
    {
      "epoch": 6.156165789811369,
      "grad_norm": 0.005332705099135637,
      "learning_rate": 0.00019219491851661747,
      "loss": 0.0,
      "step": 95950
    },
    {
      "epoch": 6.159373796997305,
      "grad_norm": 0.024524016305804253,
      "learning_rate": 0.00019203451815732068,
      "loss": 0.0,
      "step": 96000
    },
    {
      "epoch": 6.162581804183241,
      "grad_norm": 0.014771630056202412,
      "learning_rate": 0.00019187411779802388,
      "loss": 0.0,
      "step": 96050
    },
    {
      "epoch": 6.165789811369177,
      "grad_norm": 0.006811844650655985,
      "learning_rate": 0.00019171371743872706,
      "loss": 0.0,
      "step": 96100
    },
    {
      "epoch": 6.1689978185551135,
      "grad_norm": 0.004668358247727156,
      "learning_rate": 0.00019155331707943027,
      "loss": 0.0,
      "step": 96150
    },
    {
      "epoch": 6.17220582574105,
      "grad_norm": 0.008940831758081913,
      "learning_rate": 0.00019139291672013345,
      "loss": 0.0,
      "step": 96200
    },
    {
      "epoch": 6.175413832926986,
      "grad_norm": 0.021605735644698143,
      "learning_rate": 0.00019123251636083666,
      "loss": 0.0,
      "step": 96250
    },
    {
      "epoch": 6.178621840112922,
      "grad_norm": 0.003913366701453924,
      "learning_rate": 0.00019107211600153984,
      "loss": 0.0,
      "step": 96300
    },
    {
      "epoch": 6.181829847298858,
      "grad_norm": 0.015008972957730293,
      "learning_rate": 0.00019091171564224305,
      "loss": 0.0,
      "step": 96350
    },
    {
      "epoch": 6.185037854484794,
      "grad_norm": 0.01181888859719038,
      "learning_rate": 0.00019075131528294623,
      "loss": 0.0,
      "step": 96400
    },
    {
      "epoch": 6.1882458616707305,
      "grad_norm": 0.014967700466513634,
      "learning_rate": 0.00019059091492364943,
      "loss": 0.0,
      "step": 96450
    },
    {
      "epoch": 6.191453868856666,
      "grad_norm": 0.0075135244987905025,
      "learning_rate": 0.0001904305145643526,
      "loss": 0.0,
      "step": 96500
    },
    {
      "epoch": 6.194661876042602,
      "grad_norm": 0.008366091176867485,
      "learning_rate": 0.00019027011420505582,
      "loss": 0.0,
      "step": 96550
    },
    {
      "epoch": 6.197869883228538,
      "grad_norm": 0.010014760307967663,
      "learning_rate": 0.000190109713845759,
      "loss": 0.0,
      "step": 96600
    },
    {
      "epoch": 6.201077890414474,
      "grad_norm": 0.019947612658143044,
      "learning_rate": 0.0001899493134864622,
      "loss": 0.0,
      "step": 96650
    },
    {
      "epoch": 6.2042858976004105,
      "grad_norm": 0.0035985433496534824,
      "learning_rate": 0.00018978891312716539,
      "loss": 0.0,
      "step": 96700
    },
    {
      "epoch": 6.207493904786347,
      "grad_norm": 0.009102785028517246,
      "learning_rate": 0.0001896285127678686,
      "loss": 0.0,
      "step": 96750
    },
    {
      "epoch": 6.210701911972283,
      "grad_norm": 0.009733476676046848,
      "learning_rate": 0.00018946811240857177,
      "loss": 0.0,
      "step": 96800
    },
    {
      "epoch": 6.213909919158219,
      "grad_norm": 0.0025607876013964415,
      "learning_rate": 0.000189307712049275,
      "loss": 0.0,
      "step": 96850
    },
    {
      "epoch": 6.217117926344155,
      "grad_norm": 0.0063291206024587154,
      "learning_rate": 0.0001891473116899782,
      "loss": 0.0,
      "step": 96900
    },
    {
      "epoch": 6.220325933530091,
      "grad_norm": 0.00870641227811575,
      "learning_rate": 0.0001889869113306814,
      "loss": 0.0,
      "step": 96950
    },
    {
      "epoch": 6.2235339407160275,
      "grad_norm": 0.010265829972922802,
      "learning_rate": 0.0001888265109713846,
      "loss": 0.0,
      "step": 97000
    },
    {
      "epoch": 6.226741947901964,
      "grad_norm": 0.00543684558942914,
      "learning_rate": 0.00018866611061208778,
      "loss": 0.0,
      "step": 97050
    },
    {
      "epoch": 6.2299499550879,
      "grad_norm": 0.01532970741391182,
      "learning_rate": 0.000188505710252791,
      "loss": 0.0,
      "step": 97100
    },
    {
      "epoch": 6.233157962273835,
      "grad_norm": 0.004193366505205631,
      "learning_rate": 0.00018834530989349417,
      "loss": 0.0,
      "step": 97150
    },
    {
      "epoch": 6.236365969459771,
      "grad_norm": 0.006192730739712715,
      "learning_rate": 0.00018818490953419737,
      "loss": 0.0,
      "step": 97200
    },
    {
      "epoch": 6.2395739766457075,
      "grad_norm": 0.004399767145514488,
      "learning_rate": 0.00018802450917490055,
      "loss": 0.0,
      "step": 97250
    },
    {
      "epoch": 6.242781983831644,
      "grad_norm": 0.003594065783545375,
      "learning_rate": 0.00018786410881560376,
      "loss": 0.0,
      "step": 97300
    },
    {
      "epoch": 6.24598999101758,
      "grad_norm": 0.011988257989287376,
      "learning_rate": 0.00018770370845630694,
      "loss": 0.0,
      "step": 97350
    },
    {
      "epoch": 6.249197998203516,
      "grad_norm": 0.004867388401180506,
      "learning_rate": 0.00018754330809701015,
      "loss": 0.0,
      "step": 97400
    },
    {
      "epoch": 6.252406005389452,
      "grad_norm": 0.01286347582936287,
      "learning_rate": 0.00018738290773771333,
      "loss": 0.0,
      "step": 97450
    },
    {
      "epoch": 6.255614012575388,
      "grad_norm": 0.008879859000444412,
      "learning_rate": 0.00018722250737841653,
      "loss": 0.0,
      "step": 97500
    },
    {
      "epoch": 6.2588220197613245,
      "grad_norm": 0.008914637379348278,
      "learning_rate": 0.00018706210701911971,
      "loss": 0.0,
      "step": 97550
    },
    {
      "epoch": 6.262030026947261,
      "grad_norm": 0.0049591632559895515,
      "learning_rate": 0.00018690170665982292,
      "loss": 0.0,
      "step": 97600
    },
    {
      "epoch": 6.265238034133197,
      "grad_norm": 0.0046554612927138805,
      "learning_rate": 0.0001867413063005261,
      "loss": 0.0,
      "step": 97650
    },
    {
      "epoch": 6.268446041319133,
      "grad_norm": 0.003311370499432087,
      "learning_rate": 0.0001865809059412293,
      "loss": 0.0,
      "step": 97700
    },
    {
      "epoch": 6.271654048505068,
      "grad_norm": 0.006843145936727524,
      "learning_rate": 0.00018642050558193251,
      "loss": 0.0,
      "step": 97750
    },
    {
      "epoch": 6.274862055691004,
      "grad_norm": 0.011175727471709251,
      "learning_rate": 0.0001862601052226357,
      "loss": 0.0,
      "step": 97800
    },
    {
      "epoch": 6.278070062876941,
      "grad_norm": 0.01313562598079443,
      "learning_rate": 0.0001860997048633389,
      "loss": 0.0,
      "step": 97850
    },
    {
      "epoch": 6.281278070062877,
      "grad_norm": 0.008360344916582108,
      "learning_rate": 0.00018593930450404208,
      "loss": 0.0,
      "step": 97900
    },
    {
      "epoch": 6.284486077248813,
      "grad_norm": 0.010166601277887821,
      "learning_rate": 0.0001857789041447453,
      "loss": 0.0,
      "step": 97950
    },
    {
      "epoch": 6.287694084434749,
      "grad_norm": 0.019601954147219658,
      "learning_rate": 0.00018561850378544847,
      "loss": 0.0,
      "step": 98000
    },
    {
      "epoch": 6.290902091620685,
      "grad_norm": 0.018174901604652405,
      "learning_rate": 0.00018545810342615167,
      "loss": 0.0,
      "step": 98050
    },
    {
      "epoch": 6.294110098806621,
      "grad_norm": 0.007684641983360052,
      "learning_rate": 0.00018529770306685485,
      "loss": 0.0,
      "step": 98100
    },
    {
      "epoch": 6.297318105992558,
      "grad_norm": 0.005068853963166475,
      "learning_rate": 0.00018513730270755806,
      "loss": 0.0,
      "step": 98150
    },
    {
      "epoch": 6.300526113178494,
      "grad_norm": 0.010298646986484528,
      "learning_rate": 0.00018497690234826127,
      "loss": 0.0,
      "step": 98200
    },
    {
      "epoch": 6.30373412036443,
      "grad_norm": 0.006103032734245062,
      "learning_rate": 0.00018481650198896448,
      "loss": 0.0,
      "step": 98250
    },
    {
      "epoch": 6.306942127550366,
      "grad_norm": 0.005127742420881987,
      "learning_rate": 0.00018465610162966766,
      "loss": 0.0,
      "step": 98300
    },
    {
      "epoch": 6.310150134736302,
      "grad_norm": 0.02018967643380165,
      "learning_rate": 0.00018449570127037086,
      "loss": 0.0,
      "step": 98350
    },
    {
      "epoch": 6.3133581419222375,
      "grad_norm": 0.007667833939194679,
      "learning_rate": 0.00018433530091107404,
      "loss": 0.0,
      "step": 98400
    },
    {
      "epoch": 6.316566149108174,
      "grad_norm": 0.008662550710141659,
      "learning_rate": 0.00018417490055177725,
      "loss": 0.0,
      "step": 98450
    },
    {
      "epoch": 6.31977415629411,
      "grad_norm": 0.00632035918533802,
      "learning_rate": 0.00018401450019248043,
      "loss": 0.0,
      "step": 98500
    },
    {
      "epoch": 6.322982163480046,
      "grad_norm": 0.007363977842032909,
      "learning_rate": 0.00018385409983318364,
      "loss": 0.0,
      "step": 98550
    },
    {
      "epoch": 6.326190170665982,
      "grad_norm": 0.015415350906550884,
      "learning_rate": 0.00018369369947388684,
      "loss": 0.0,
      "step": 98600
    },
    {
      "epoch": 6.329398177851918,
      "grad_norm": 0.010563590563833714,
      "learning_rate": 0.00018353329911459002,
      "loss": 0.0,
      "step": 98650
    },
    {
      "epoch": 6.3326061850378546,
      "grad_norm": 0.003573416732251644,
      "learning_rate": 0.00018337289875529323,
      "loss": 0.0,
      "step": 98700
    },
    {
      "epoch": 6.335814192223791,
      "grad_norm": 0.008642017841339111,
      "learning_rate": 0.0001832124983959964,
      "loss": 0.0,
      "step": 98750
    },
    {
      "epoch": 6.339022199409727,
      "grad_norm": 0.004031743388622999,
      "learning_rate": 0.00018305209803669962,
      "loss": 0.0,
      "step": 98800
    },
    {
      "epoch": 6.342230206595663,
      "grad_norm": 0.013096464797854424,
      "learning_rate": 0.0001828916976774028,
      "loss": 0.0,
      "step": 98850
    },
    {
      "epoch": 6.345438213781599,
      "grad_norm": 0.012246339581906796,
      "learning_rate": 0.000182731297318106,
      "loss": 0.0,
      "step": 98900
    },
    {
      "epoch": 6.3486462209675345,
      "grad_norm": 0.0036129173822700977,
      "learning_rate": 0.00018257089695880918,
      "loss": 0.0,
      "step": 98950
    },
    {
      "epoch": 6.351854228153471,
      "grad_norm": 0.0006076170830056071,
      "learning_rate": 0.0001824104965995124,
      "loss": 0.0,
      "step": 99000
    },
    {
      "epoch": 6.355062235339407,
      "grad_norm": 0.004061252344399691,
      "learning_rate": 0.00018225009624021557,
      "loss": 0.0,
      "step": 99050
    },
    {
      "epoch": 6.358270242525343,
      "grad_norm": 0.0034468115773051977,
      "learning_rate": 0.00018208969588091878,
      "loss": 0.0,
      "step": 99100
    },
    {
      "epoch": 6.361478249711279,
      "grad_norm": 0.017618432641029358,
      "learning_rate": 0.00018192929552162196,
      "loss": 0.0,
      "step": 99150
    },
    {
      "epoch": 6.364686256897215,
      "grad_norm": 0.013859597966074944,
      "learning_rate": 0.00018176889516232516,
      "loss": 0.0,
      "step": 99200
    },
    {
      "epoch": 6.3678942640831515,
      "grad_norm": 0.013630632311105728,
      "learning_rate": 0.00018160849480302834,
      "loss": 0.0,
      "step": 99250
    },
    {
      "epoch": 6.371102271269088,
      "grad_norm": 0.007001505699008703,
      "learning_rate": 0.00018144809444373155,
      "loss": 0.0,
      "step": 99300
    },
    {
      "epoch": 6.374310278455024,
      "grad_norm": 0.007358715869486332,
      "learning_rate": 0.00018128769408443473,
      "loss": 0.0,
      "step": 99350
    },
    {
      "epoch": 6.37751828564096,
      "grad_norm": 0.013506848365068436,
      "learning_rate": 0.00018112729372513794,
      "loss": 0.0,
      "step": 99400
    },
    {
      "epoch": 6.380726292826896,
      "grad_norm": 0.008229204453527927,
      "learning_rate": 0.00018096689336584114,
      "loss": 0.0,
      "step": 99450
    },
    {
      "epoch": 6.383934300012832,
      "grad_norm": 0.015606606379151344,
      "learning_rate": 0.00018080649300654432,
      "loss": 0.0,
      "step": 99500
    },
    {
      "epoch": 6.3871423071987685,
      "grad_norm": 0.005441686138510704,
      "learning_rate": 0.00018064609264724756,
      "loss": 0.0,
      "step": 99550
    },
    {
      "epoch": 6.390350314384705,
      "grad_norm": 0.005834860261529684,
      "learning_rate": 0.00018048569228795074,
      "loss": 0.0,
      "step": 99600
    },
    {
      "epoch": 6.39355832157064,
      "grad_norm": 0.0034506688825786114,
      "learning_rate": 0.00018032529192865394,
      "loss": 0.0,
      "step": 99650
    },
    {
      "epoch": 6.396766328756576,
      "grad_norm": 0.0032845058012753725,
      "learning_rate": 0.00018016489156935712,
      "loss": 0.0,
      "step": 99700
    },
    {
      "epoch": 6.399974335942512,
      "grad_norm": 0.00943036936223507,
      "learning_rate": 0.00018000449121006033,
      "loss": 0.0,
      "step": 99750
    },
    {
      "epoch": 6.4031823431284485,
      "grad_norm": 0.025584286078810692,
      "learning_rate": 0.0001798440908507635,
      "loss": 0.0,
      "step": 99800
    },
    {
      "epoch": 6.406390350314385,
      "grad_norm": 0.001415560836903751,
      "learning_rate": 0.00017968369049146672,
      "loss": 0.0,
      "step": 99850
    },
    {
      "epoch": 6.409598357500321,
      "grad_norm": 0.006644013803452253,
      "learning_rate": 0.0001795232901321699,
      "loss": 0.0,
      "step": 99900
    },
    {
      "epoch": 6.412806364686257,
      "grad_norm": 0.002957954304292798,
      "learning_rate": 0.0001793628897728731,
      "loss": 0.0,
      "step": 99950
    },
    {
      "epoch": 6.416014371872193,
      "grad_norm": 0.004476349335163832,
      "learning_rate": 0.00017920248941357629,
      "loss": 0.0,
      "step": 100000
    },
    {
      "epoch": 6.419222379058129,
      "grad_norm": 0.002813017461448908,
      "learning_rate": 0.0001790420890542795,
      "loss": 0.0,
      "step": 100050
    },
    {
      "epoch": 6.4224303862440655,
      "grad_norm": 0.0066101932898163795,
      "learning_rate": 0.00017888168869498267,
      "loss": 0.0,
      "step": 100100
    },
    {
      "epoch": 6.425638393430002,
      "grad_norm": 0.0084804967045784,
      "learning_rate": 0.00017872128833568588,
      "loss": 0.0,
      "step": 100150
    },
    {
      "epoch": 6.428846400615937,
      "grad_norm": 0.013633254915475845,
      "learning_rate": 0.00017856088797638906,
      "loss": 0.0,
      "step": 100200
    },
    {
      "epoch": 6.432054407801873,
      "grad_norm": 0.00321608642116189,
      "learning_rate": 0.00017840048761709227,
      "loss": 0.0,
      "step": 100250
    },
    {
      "epoch": 6.435262414987809,
      "grad_norm": 0.015201764181256294,
      "learning_rate": 0.00017824008725779547,
      "loss": 0.0,
      "step": 100300
    },
    {
      "epoch": 6.438470422173745,
      "grad_norm": 0.010394121520221233,
      "learning_rate": 0.00017807968689849865,
      "loss": 0.0,
      "step": 100350
    },
    {
      "epoch": 6.441678429359682,
      "grad_norm": 0.008232435211539268,
      "learning_rate": 0.00017791928653920186,
      "loss": 0.0,
      "step": 100400
    },
    {
      "epoch": 6.444886436545618,
      "grad_norm": 0.010354570113122463,
      "learning_rate": 0.00017775888617990504,
      "loss": 0.0,
      "step": 100450
    },
    {
      "epoch": 6.448094443731554,
      "grad_norm": 0.010915485210716724,
      "learning_rate": 0.00017759848582060825,
      "loss": 0.0,
      "step": 100500
    },
    {
      "epoch": 6.45130245091749,
      "grad_norm": 0.0063377730548381805,
      "learning_rate": 0.00017743808546131143,
      "loss": 0.0,
      "step": 100550
    },
    {
      "epoch": 6.454510458103426,
      "grad_norm": 0.005868334788829088,
      "learning_rate": 0.00017727768510201463,
      "loss": 0.0,
      "step": 100600
    },
    {
      "epoch": 6.457718465289362,
      "grad_norm": 0.0028409170918166637,
      "learning_rate": 0.0001771172847427178,
      "loss": 0.0,
      "step": 100650
    },
    {
      "epoch": 6.460926472475299,
      "grad_norm": 0.010884612798690796,
      "learning_rate": 0.00017695688438342102,
      "loss": 0.0,
      "step": 100700
    },
    {
      "epoch": 6.464134479661235,
      "grad_norm": 0.005050697363913059,
      "learning_rate": 0.0001767964840241242,
      "loss": 0.0,
      "step": 100750
    },
    {
      "epoch": 6.467342486847171,
      "grad_norm": 0.012580733746290207,
      "learning_rate": 0.0001766360836648274,
      "loss": 0.0,
      "step": 100800
    },
    {
      "epoch": 6.470550494033106,
      "grad_norm": 0.014001481235027313,
      "learning_rate": 0.0001764756833055306,
      "loss": 0.0,
      "step": 100850
    },
    {
      "epoch": 6.473758501219042,
      "grad_norm": 0.0011321899946779013,
      "learning_rate": 0.00017631528294623382,
      "loss": 0.0,
      "step": 100900
    },
    {
      "epoch": 6.476966508404979,
      "grad_norm": 0.0026945348363369703,
      "learning_rate": 0.000176154882586937,
      "loss": 0.0,
      "step": 100950
    },
    {
      "epoch": 6.480174515590915,
      "grad_norm": 0.007886560633778572,
      "learning_rate": 0.0001759944822276402,
      "loss": 0.0,
      "step": 101000
    },
    {
      "epoch": 6.483382522776851,
      "grad_norm": 0.011377173475921154,
      "learning_rate": 0.0001758340818683434,
      "loss": 0.0,
      "step": 101050
    },
    {
      "epoch": 6.486590529962787,
      "grad_norm": 0.0019490711856633425,
      "learning_rate": 0.0001756736815090466,
      "loss": 0.0,
      "step": 101100
    },
    {
      "epoch": 6.489798537148723,
      "grad_norm": 0.004643468651920557,
      "learning_rate": 0.0001755132811497498,
      "loss": 0.0,
      "step": 101150
    },
    {
      "epoch": 6.493006544334659,
      "grad_norm": 0.008288980461657047,
      "learning_rate": 0.00017535288079045298,
      "loss": 0.0,
      "step": 101200
    },
    {
      "epoch": 6.496214551520596,
      "grad_norm": 0.002978196367621422,
      "learning_rate": 0.0001751924804311562,
      "loss": 0.0,
      "step": 101250
    },
    {
      "epoch": 6.499422558706532,
      "grad_norm": 0.004379278048872948,
      "learning_rate": 0.00017503208007185937,
      "loss": 0.0,
      "step": 101300
    },
    {
      "epoch": 6.502630565892468,
      "grad_norm": 0.004887609276920557,
      "learning_rate": 0.00017487167971256257,
      "loss": 0.0,
      "step": 101350
    },
    {
      "epoch": 6.505838573078404,
      "grad_norm": 0.012193121947348118,
      "learning_rate": 0.00017471127935326575,
      "loss": 0.0,
      "step": 101400
    },
    {
      "epoch": 6.509046580264339,
      "grad_norm": 0.0037679746747016907,
      "learning_rate": 0.00017455087899396896,
      "loss": 0.0,
      "step": 101450
    },
    {
      "epoch": 6.5122545874502755,
      "grad_norm": 0.009045232087373734,
      "learning_rate": 0.00017439047863467214,
      "loss": 0.0,
      "step": 101500
    },
    {
      "epoch": 6.515462594636212,
      "grad_norm": 0.011156355030834675,
      "learning_rate": 0.00017423007827537535,
      "loss": 0.0,
      "step": 101550
    },
    {
      "epoch": 6.518670601822148,
      "grad_norm": 0.0038132788613438606,
      "learning_rate": 0.00017406967791607853,
      "loss": 0.0,
      "step": 101600
    },
    {
      "epoch": 6.521878609008084,
      "grad_norm": 0.011119100265204906,
      "learning_rate": 0.00017390927755678174,
      "loss": 0.0,
      "step": 101650
    },
    {
      "epoch": 6.52508661619402,
      "grad_norm": 0.005214356351643801,
      "learning_rate": 0.00017374887719748491,
      "loss": 0.0,
      "step": 101700
    },
    {
      "epoch": 6.528294623379956,
      "grad_norm": 0.005960196256637573,
      "learning_rate": 0.00017358847683818812,
      "loss": 0.0,
      "step": 101750
    },
    {
      "epoch": 6.5315026305658925,
      "grad_norm": 0.008323526941239834,
      "learning_rate": 0.0001734280764788913,
      "loss": 0.0,
      "step": 101800
    },
    {
      "epoch": 6.534710637751829,
      "grad_norm": 0.005916748661547899,
      "learning_rate": 0.0001732676761195945,
      "loss": 0.0,
      "step": 101850
    },
    {
      "epoch": 6.537918644937765,
      "grad_norm": 0.0057602315209805965,
      "learning_rate": 0.0001731072757602977,
      "loss": 0.0,
      "step": 101900
    },
    {
      "epoch": 6.541126652123701,
      "grad_norm": 0.009322056546807289,
      "learning_rate": 0.0001729468754010009,
      "loss": 0.0,
      "step": 101950
    },
    {
      "epoch": 6.544334659309637,
      "grad_norm": 0.00431090360507369,
      "learning_rate": 0.00017278647504170408,
      "loss": 0.0,
      "step": 102000
    },
    {
      "epoch": 6.547542666495573,
      "grad_norm": 0.005752363242208958,
      "learning_rate": 0.00017262607468240728,
      "loss": 0.0,
      "step": 102050
    },
    {
      "epoch": 6.5507506736815095,
      "grad_norm": 0.012412812560796738,
      "learning_rate": 0.0001724656743231105,
      "loss": 0.0,
      "step": 102100
    },
    {
      "epoch": 6.553958680867445,
      "grad_norm": 0.009660597890615463,
      "learning_rate": 0.00017230527396381367,
      "loss": 0.0,
      "step": 102150
    },
    {
      "epoch": 6.557166688053381,
      "grad_norm": 0.0070261405780911446,
      "learning_rate": 0.00017214487360451688,
      "loss": 0.0,
      "step": 102200
    },
    {
      "epoch": 6.560374695239317,
      "grad_norm": 0.0031859837472438812,
      "learning_rate": 0.00017198447324522006,
      "loss": 0.0,
      "step": 102250
    },
    {
      "epoch": 6.563582702425253,
      "grad_norm": 0.01201265212148428,
      "learning_rate": 0.0001718240728859233,
      "loss": 0.0,
      "step": 102300
    },
    {
      "epoch": 6.5667907096111895,
      "grad_norm": 0.02188383787870407,
      "learning_rate": 0.00017166367252662647,
      "loss": 0.0,
      "step": 102350
    },
    {
      "epoch": 6.569998716797126,
      "grad_norm": 0.004087089095264673,
      "learning_rate": 0.00017150327216732968,
      "loss": 0.0,
      "step": 102400
    },
    {
      "epoch": 6.573206723983062,
      "grad_norm": 0.0043538655154407024,
      "learning_rate": 0.00017134287180803286,
      "loss": 0.0,
      "step": 102450
    },
    {
      "epoch": 6.576414731168998,
      "grad_norm": 0.01429536659270525,
      "learning_rate": 0.00017118247144873606,
      "loss": 0.0,
      "step": 102500
    },
    {
      "epoch": 6.579622738354934,
      "grad_norm": 0.005371591541916132,
      "learning_rate": 0.00017102207108943924,
      "loss": 0.0,
      "step": 102550
    },
    {
      "epoch": 6.58283074554087,
      "grad_norm": 0.011906825937330723,
      "learning_rate": 0.00017086167073014245,
      "loss": 0.0,
      "step": 102600
    },
    {
      "epoch": 6.586038752726806,
      "grad_norm": 0.01648215390741825,
      "learning_rate": 0.00017070127037084563,
      "loss": 0.0,
      "step": 102650
    },
    {
      "epoch": 6.589246759912742,
      "grad_norm": 0.008738319389522076,
      "learning_rate": 0.00017054087001154884,
      "loss": 0.0,
      "step": 102700
    },
    {
      "epoch": 6.592454767098678,
      "grad_norm": 0.0032790456898510456,
      "learning_rate": 0.00017038046965225202,
      "loss": 0.0,
      "step": 102750
    },
    {
      "epoch": 6.595662774284614,
      "grad_norm": 0.01441992912441492,
      "learning_rate": 0.00017022006929295522,
      "loss": 0.0,
      "step": 102800
    },
    {
      "epoch": 6.59887078147055,
      "grad_norm": 0.008025952614843845,
      "learning_rate": 0.0001700596689336584,
      "loss": 0.0,
      "step": 102850
    },
    {
      "epoch": 6.6020787886564865,
      "grad_norm": 0.005861863028258085,
      "learning_rate": 0.0001698992685743616,
      "loss": 0.0,
      "step": 102900
    },
    {
      "epoch": 6.605286795842423,
      "grad_norm": 0.003140268614515662,
      "learning_rate": 0.00016973886821506482,
      "loss": 0.0,
      "step": 102950
    },
    {
      "epoch": 6.608494803028359,
      "grad_norm": 0.0029139562975615263,
      "learning_rate": 0.000169578467855768,
      "loss": 0.0,
      "step": 103000
    },
    {
      "epoch": 6.611702810214295,
      "grad_norm": 0.010848433710634708,
      "learning_rate": 0.0001694180674964712,
      "loss": 0.0,
      "step": 103050
    },
    {
      "epoch": 6.614910817400231,
      "grad_norm": 0.0048510292544960976,
      "learning_rate": 0.00016925766713717438,
      "loss": 0.0,
      "step": 103100
    },
    {
      "epoch": 6.618118824586167,
      "grad_norm": 0.005813112016767263,
      "learning_rate": 0.0001690972667778776,
      "loss": 0.0,
      "step": 103150
    },
    {
      "epoch": 6.6213268317721035,
      "grad_norm": 0.01680372655391693,
      "learning_rate": 0.00016893686641858077,
      "loss": 0.0,
      "step": 103200
    },
    {
      "epoch": 6.62453483895804,
      "grad_norm": 0.003569744061678648,
      "learning_rate": 0.00016877646605928398,
      "loss": 0.0,
      "step": 103250
    },
    {
      "epoch": 6.627742846143976,
      "grad_norm": 0.012823719531297684,
      "learning_rate": 0.00016861606569998716,
      "loss": 0.0,
      "step": 103300
    },
    {
      "epoch": 6.630950853329911,
      "grad_norm": 0.0070715537294745445,
      "learning_rate": 0.00016845566534069036,
      "loss": 0.0,
      "step": 103350
    },
    {
      "epoch": 6.634158860515847,
      "grad_norm": 0.001598428119905293,
      "learning_rate": 0.00016829526498139354,
      "loss": 0.0,
      "step": 103400
    },
    {
      "epoch": 6.637366867701783,
      "grad_norm": 0.005346118472516537,
      "learning_rate": 0.00016813486462209675,
      "loss": 0.0,
      "step": 103450
    },
    {
      "epoch": 6.64057487488772,
      "grad_norm": 0.006912949029356241,
      "learning_rate": 0.00016797446426279993,
      "loss": 0.0,
      "step": 103500
    },
    {
      "epoch": 6.643782882073656,
      "grad_norm": 0.007345481310039759,
      "learning_rate": 0.00016781406390350314,
      "loss": 0.0,
      "step": 103550
    },
    {
      "epoch": 6.646990889259592,
      "grad_norm": 0.0026350540574640036,
      "learning_rate": 0.00016765366354420632,
      "loss": 0.0,
      "step": 103600
    },
    {
      "epoch": 6.650198896445528,
      "grad_norm": 0.007651910185813904,
      "learning_rate": 0.00016749326318490955,
      "loss": 0.0,
      "step": 103650
    },
    {
      "epoch": 6.653406903631464,
      "grad_norm": 0.01413098257035017,
      "learning_rate": 0.00016733286282561273,
      "loss": 0.0,
      "step": 103700
    },
    {
      "epoch": 6.6566149108174,
      "grad_norm": 0.007828069850802422,
      "learning_rate": 0.00016717246246631594,
      "loss": 0.0,
      "step": 103750
    },
    {
      "epoch": 6.659822918003337,
      "grad_norm": 0.0024604753125458956,
      "learning_rate": 0.00016701206210701915,
      "loss": 0.0,
      "step": 103800
    },
    {
      "epoch": 6.663030925189273,
      "grad_norm": 0.01499170996248722,
      "learning_rate": 0.00016685166174772233,
      "loss": 0.0,
      "step": 103850
    },
    {
      "epoch": 6.666238932375208,
      "grad_norm": 0.010966995730996132,
      "learning_rate": 0.00016669126138842553,
      "loss": 0.0,
      "step": 103900
    },
    {
      "epoch": 6.669446939561144,
      "grad_norm": 0.013190802186727524,
      "learning_rate": 0.0001665308610291287,
      "loss": 0.0,
      "step": 103950
    },
    {
      "epoch": 6.67265494674708,
      "grad_norm": 0.010688886977732182,
      "learning_rate": 0.00016637046066983192,
      "loss": 0.0,
      "step": 104000
    },
    {
      "epoch": 6.6758629539330165,
      "grad_norm": 0.004046913702040911,
      "learning_rate": 0.0001662100603105351,
      "loss": 0.0,
      "step": 104050
    },
    {
      "epoch": 6.679070961118953,
      "grad_norm": 0.007268283981829882,
      "learning_rate": 0.0001660496599512383,
      "loss": 0.0,
      "step": 104100
    },
    {
      "epoch": 6.682278968304889,
      "grad_norm": 0.009285188280045986,
      "learning_rate": 0.00016588925959194149,
      "loss": 0.0,
      "step": 104150
    },
    {
      "epoch": 6.685486975490825,
      "grad_norm": 0.01039897371083498,
      "learning_rate": 0.0001657288592326447,
      "loss": 0.0,
      "step": 104200
    },
    {
      "epoch": 6.688694982676761,
      "grad_norm": 0.015399179421365261,
      "learning_rate": 0.00016556845887334787,
      "loss": 0.0,
      "step": 104250
    },
    {
      "epoch": 6.691902989862697,
      "grad_norm": 0.008511597290635109,
      "learning_rate": 0.00016540805851405108,
      "loss": 0.0,
      "step": 104300
    },
    {
      "epoch": 6.6951109970486335,
      "grad_norm": 0.010963022708892822,
      "learning_rate": 0.00016524765815475426,
      "loss": 0.0,
      "step": 104350
    },
    {
      "epoch": 6.69831900423457,
      "grad_norm": 0.009938153438270092,
      "learning_rate": 0.00016508725779545747,
      "loss": 0.0,
      "step": 104400
    },
    {
      "epoch": 6.701527011420506,
      "grad_norm": 0.004382283892482519,
      "learning_rate": 0.00016492685743616065,
      "loss": 0.0,
      "step": 104450
    },
    {
      "epoch": 6.704735018606442,
      "grad_norm": 0.007656085770577192,
      "learning_rate": 0.00016476645707686385,
      "loss": 0.0,
      "step": 104500
    },
    {
      "epoch": 6.707943025792378,
      "grad_norm": 0.017035869881510735,
      "learning_rate": 0.00016460605671756703,
      "loss": 0.0,
      "step": 104550
    },
    {
      "epoch": 6.7111510329783135,
      "grad_norm": 0.005959153175354004,
      "learning_rate": 0.00016444565635827024,
      "loss": 0.0,
      "step": 104600
    },
    {
      "epoch": 6.71435904016425,
      "grad_norm": 0.003724731970578432,
      "learning_rate": 0.00016428525599897345,
      "loss": 0.0,
      "step": 104650
    },
    {
      "epoch": 6.717567047350186,
      "grad_norm": 0.014548588544130325,
      "learning_rate": 0.00016412485563967663,
      "loss": 0.0,
      "step": 104700
    },
    {
      "epoch": 6.720775054536122,
      "grad_norm": 0.004800167866051197,
      "learning_rate": 0.00016396445528037983,
      "loss": 0.0,
      "step": 104750
    },
    {
      "epoch": 6.723983061722058,
      "grad_norm": 0.015994271263480186,
      "learning_rate": 0.00016380405492108301,
      "loss": 0.0,
      "step": 104800
    },
    {
      "epoch": 6.727191068907994,
      "grad_norm": 0.013864556327462196,
      "learning_rate": 0.00016364365456178622,
      "loss": 0.0,
      "step": 104850
    },
    {
      "epoch": 6.7303990760939305,
      "grad_norm": 0.005076615139842033,
      "learning_rate": 0.0001634832542024894,
      "loss": 0.0,
      "step": 104900
    },
    {
      "epoch": 6.733607083279867,
      "grad_norm": 0.004226168617606163,
      "learning_rate": 0.0001633228538431926,
      "loss": 0.0,
      "step": 104950
    },
    {
      "epoch": 6.736815090465803,
      "grad_norm": 0.0029285496566444635,
      "learning_rate": 0.0001631624534838958,
      "loss": 0.0,
      "step": 105000
    },
    {
      "epoch": 6.740023097651739,
      "grad_norm": 0.0016450720140710473,
      "learning_rate": 0.00016300205312459902,
      "loss": 0.0,
      "step": 105050
    },
    {
      "epoch": 6.743231104837675,
      "grad_norm": 0.004954067524522543,
      "learning_rate": 0.0001628416527653022,
      "loss": 0.0,
      "step": 105100
    },
    {
      "epoch": 6.7464391120236105,
      "grad_norm": 0.007612043060362339,
      "learning_rate": 0.0001626812524060054,
      "loss": 0.0,
      "step": 105150
    },
    {
      "epoch": 6.749647119209547,
      "grad_norm": 0.016200534999370575,
      "learning_rate": 0.0001625208520467086,
      "loss": 0.0,
      "step": 105200
    },
    {
      "epoch": 6.752855126395483,
      "grad_norm": 0.005127749405801296,
      "learning_rate": 0.0001623604516874118,
      "loss": 0.0,
      "step": 105250
    },
    {
      "epoch": 6.756063133581419,
      "grad_norm": 0.011898244731128216,
      "learning_rate": 0.00016220005132811497,
      "loss": 0.0,
      "step": 105300
    },
    {
      "epoch": 6.759271140767355,
      "grad_norm": 0.01606990024447441,
      "learning_rate": 0.00016203965096881818,
      "loss": 0.0,
      "step": 105350
    },
    {
      "epoch": 6.762479147953291,
      "grad_norm": 0.006111361086368561,
      "learning_rate": 0.00016187925060952136,
      "loss": 0.0,
      "step": 105400
    },
    {
      "epoch": 6.7656871551392275,
      "grad_norm": 0.024097077548503876,
      "learning_rate": 0.00016171885025022457,
      "loss": 0.0,
      "step": 105450
    },
    {
      "epoch": 6.768895162325164,
      "grad_norm": 0.00862010195851326,
      "learning_rate": 0.00016155844989092778,
      "loss": 0.0,
      "step": 105500
    },
    {
      "epoch": 6.7721031695111,
      "grad_norm": 0.0026009303983300924,
      "learning_rate": 0.00016139804953163096,
      "loss": 0.0,
      "step": 105550
    },
    {
      "epoch": 6.775311176697036,
      "grad_norm": 0.004875866696238518,
      "learning_rate": 0.00016123764917233416,
      "loss": 0.0,
      "step": 105600
    },
    {
      "epoch": 6.778519183882972,
      "grad_norm": 0.0111493906006217,
      "learning_rate": 0.00016107724881303734,
      "loss": 0.0,
      "step": 105650
    },
    {
      "epoch": 6.781727191068908,
      "grad_norm": 0.015673553571105003,
      "learning_rate": 0.00016091684845374055,
      "loss": 0.0,
      "step": 105700
    },
    {
      "epoch": 6.7849351982548445,
      "grad_norm": 0.011225657537579536,
      "learning_rate": 0.00016075644809444373,
      "loss": 0.0,
      "step": 105750
    },
    {
      "epoch": 6.788143205440781,
      "grad_norm": 0.006714357528835535,
      "learning_rate": 0.00016059604773514694,
      "loss": 0.0,
      "step": 105800
    },
    {
      "epoch": 6.791351212626716,
      "grad_norm": 0.015240938402712345,
      "learning_rate": 0.00016043564737585012,
      "loss": 0.0,
      "step": 105850
    },
    {
      "epoch": 6.794559219812652,
      "grad_norm": 0.005755506455898285,
      "learning_rate": 0.00016027524701655332,
      "loss": 0.0,
      "step": 105900
    },
    {
      "epoch": 6.797767226998588,
      "grad_norm": 0.006849647033959627,
      "learning_rate": 0.0001601148466572565,
      "loss": 0.0,
      "step": 105950
    },
    {
      "epoch": 6.800975234184524,
      "grad_norm": 0.009956760331988335,
      "learning_rate": 0.0001599544462979597,
      "loss": 0.0,
      "step": 106000
    },
    {
      "epoch": 6.804183241370461,
      "grad_norm": 0.007119548041373491,
      "learning_rate": 0.0001597940459386629,
      "loss": 0.0,
      "step": 106050
    },
    {
      "epoch": 6.807391248556397,
      "grad_norm": 0.0029731213580816984,
      "learning_rate": 0.0001596336455793661,
      "loss": 0.0,
      "step": 106100
    },
    {
      "epoch": 6.810599255742333,
      "grad_norm": 0.020057057961821556,
      "learning_rate": 0.00015947324522006928,
      "loss": 0.0,
      "step": 106150
    },
    {
      "epoch": 6.813807262928269,
      "grad_norm": 0.013014980591833591,
      "learning_rate": 0.00015931284486077248,
      "loss": 0.0,
      "step": 106200
    },
    {
      "epoch": 6.817015270114205,
      "grad_norm": 0.01601994037628174,
      "learning_rate": 0.00015915244450147566,
      "loss": 0.0,
      "step": 106250
    },
    {
      "epoch": 6.820223277300141,
      "grad_norm": 0.0025818031281232834,
      "learning_rate": 0.00015899204414217887,
      "loss": 0.0,
      "step": 106300
    },
    {
      "epoch": 6.823431284486078,
      "grad_norm": 0.004902553744614124,
      "learning_rate": 0.00015883164378288208,
      "loss": 0.0,
      "step": 106350
    },
    {
      "epoch": 6.826639291672013,
      "grad_norm": 0.015697387978434563,
      "learning_rate": 0.00015867124342358528,
      "loss": 0.0,
      "step": 106400
    },
    {
      "epoch": 6.829847298857949,
      "grad_norm": 0.009230825118720531,
      "learning_rate": 0.0001585108430642885,
      "loss": 0.0,
      "step": 106450
    },
    {
      "epoch": 6.833055306043885,
      "grad_norm": 0.016968274489045143,
      "learning_rate": 0.00015835044270499167,
      "loss": 0.0,
      "step": 106500
    },
    {
      "epoch": 6.836263313229821,
      "grad_norm": 0.004842360503971577,
      "learning_rate": 0.00015819004234569488,
      "loss": 0.0,
      "step": 106550
    },
    {
      "epoch": 6.839471320415758,
      "grad_norm": 0.007239318918436766,
      "learning_rate": 0.00015802964198639806,
      "loss": 0.0,
      "step": 106600
    },
    {
      "epoch": 6.842679327601694,
      "grad_norm": 0.009350023232400417,
      "learning_rate": 0.00015786924162710126,
      "loss": 0.0,
      "step": 106650
    },
    {
      "epoch": 6.84588733478763,
      "grad_norm": 0.012150069698691368,
      "learning_rate": 0.00015770884126780444,
      "loss": 0.0,
      "step": 106700
    },
    {
      "epoch": 6.849095341973566,
      "grad_norm": 0.004499603994190693,
      "learning_rate": 0.00015754844090850765,
      "loss": 0.0,
      "step": 106750
    },
    {
      "epoch": 6.852303349159502,
      "grad_norm": 0.013869032263755798,
      "learning_rate": 0.00015738804054921083,
      "loss": 0.0,
      "step": 106800
    },
    {
      "epoch": 6.855511356345438,
      "grad_norm": 0.008121016435325146,
      "learning_rate": 0.00015722764018991404,
      "loss": 0.0,
      "step": 106850
    },
    {
      "epoch": 6.858719363531375,
      "grad_norm": 0.0104847252368927,
      "learning_rate": 0.00015706723983061722,
      "loss": 0.0,
      "step": 106900
    },
    {
      "epoch": 6.861927370717311,
      "grad_norm": 0.00647581834346056,
      "learning_rate": 0.00015690683947132042,
      "loss": 0.0,
      "step": 106950
    },
    {
      "epoch": 6.865135377903247,
      "grad_norm": 0.007369738072156906,
      "learning_rate": 0.0001567464391120236,
      "loss": 0.0,
      "step": 107000
    },
    {
      "epoch": 6.868343385089183,
      "grad_norm": 0.006600890774279833,
      "learning_rate": 0.0001565860387527268,
      "loss": 0.0,
      "step": 107050
    },
    {
      "epoch": 6.871551392275118,
      "grad_norm": 0.00566702987998724,
      "learning_rate": 0.00015642563839343,
      "loss": 0.0,
      "step": 107100
    },
    {
      "epoch": 6.8747593994610545,
      "grad_norm": 0.0032462417148053646,
      "learning_rate": 0.0001562652380341332,
      "loss": 0.0,
      "step": 107150
    },
    {
      "epoch": 6.877967406646991,
      "grad_norm": 0.0044524092227220535,
      "learning_rate": 0.0001561048376748364,
      "loss": 0.0,
      "step": 107200
    },
    {
      "epoch": 6.881175413832927,
      "grad_norm": 0.014067324809730053,
      "learning_rate": 0.00015594443731553959,
      "loss": 0.0,
      "step": 107250
    },
    {
      "epoch": 6.884383421018863,
      "grad_norm": 0.005296087823808193,
      "learning_rate": 0.0001557840369562428,
      "loss": 0.0,
      "step": 107300
    },
    {
      "epoch": 6.887591428204799,
      "grad_norm": 0.010935199446976185,
      "learning_rate": 0.00015562363659694597,
      "loss": 0.0,
      "step": 107350
    },
    {
      "epoch": 6.890799435390735,
      "grad_norm": 0.003692739177495241,
      "learning_rate": 0.00015546323623764918,
      "loss": 0.0,
      "step": 107400
    },
    {
      "epoch": 6.8940074425766715,
      "grad_norm": 0.008359277620911598,
      "learning_rate": 0.00015530283587835236,
      "loss": 0.0,
      "step": 107450
    },
    {
      "epoch": 6.897215449762608,
      "grad_norm": 0.010456044226884842,
      "learning_rate": 0.00015514243551905557,
      "loss": 0.0,
      "step": 107500
    },
    {
      "epoch": 6.900423456948544,
      "grad_norm": 0.0029570702463388443,
      "learning_rate": 0.00015498203515975875,
      "loss": 0.0,
      "step": 107550
    },
    {
      "epoch": 6.90363146413448,
      "grad_norm": 0.001782344887033105,
      "learning_rate": 0.00015482163480046195,
      "loss": 0.0,
      "step": 107600
    },
    {
      "epoch": 6.906839471320415,
      "grad_norm": 0.006484910845756531,
      "learning_rate": 0.00015466123444116513,
      "loss": 0.0,
      "step": 107650
    },
    {
      "epoch": 6.9100474785063515,
      "grad_norm": 0.009207542985677719,
      "learning_rate": 0.00015450083408186834,
      "loss": 0.0,
      "step": 107700
    },
    {
      "epoch": 6.913255485692288,
      "grad_norm": 0.015024393796920776,
      "learning_rate": 0.00015434043372257155,
      "loss": 0.0,
      "step": 107750
    },
    {
      "epoch": 6.916463492878224,
      "grad_norm": 0.011185871437191963,
      "learning_rate": 0.00015418003336327475,
      "loss": 0.0,
      "step": 107800
    },
    {
      "epoch": 6.91967150006416,
      "grad_norm": 0.004066202789545059,
      "learning_rate": 0.00015401963300397793,
      "loss": 0.0,
      "step": 107850
    },
    {
      "epoch": 6.922879507250096,
      "grad_norm": 0.011885186657309532,
      "learning_rate": 0.00015385923264468114,
      "loss": 0.0,
      "step": 107900
    },
    {
      "epoch": 6.926087514436032,
      "grad_norm": 0.02047097496688366,
      "learning_rate": 0.00015369883228538432,
      "loss": 0.0,
      "step": 107950
    },
    {
      "epoch": 6.9292955216219685,
      "grad_norm": 0.008410440757870674,
      "learning_rate": 0.00015353843192608753,
      "loss": 0.0,
      "step": 108000
    },
    {
      "epoch": 6.932503528807905,
      "grad_norm": 0.0014739568578079343,
      "learning_rate": 0.00015337803156679073,
      "loss": 0.0,
      "step": 108050
    },
    {
      "epoch": 6.935711535993841,
      "grad_norm": 0.006046107970178127,
      "learning_rate": 0.0001532176312074939,
      "loss": 0.0,
      "step": 108100
    },
    {
      "epoch": 6.938919543179777,
      "grad_norm": 0.010670327581465244,
      "learning_rate": 0.00015305723084819712,
      "loss": 0.0,
      "step": 108150
    },
    {
      "epoch": 6.942127550365713,
      "grad_norm": 0.010855486616492271,
      "learning_rate": 0.0001528968304889003,
      "loss": 0.0,
      "step": 108200
    },
    {
      "epoch": 6.945335557551649,
      "grad_norm": 0.007134660147130489,
      "learning_rate": 0.0001527364301296035,
      "loss": 0.0,
      "step": 108250
    },
    {
      "epoch": 6.9485435647375855,
      "grad_norm": 0.006674173288047314,
      "learning_rate": 0.0001525760297703067,
      "loss": 0.0,
      "step": 108300
    },
    {
      "epoch": 6.951751571923521,
      "grad_norm": 0.0034447298385202885,
      "learning_rate": 0.0001524156294110099,
      "loss": 0.0,
      "step": 108350
    },
    {
      "epoch": 6.954959579109457,
      "grad_norm": 0.010200340300798416,
      "learning_rate": 0.00015225522905171307,
      "loss": 0.0,
      "step": 108400
    },
    {
      "epoch": 6.958167586295393,
      "grad_norm": 0.005338406655937433,
      "learning_rate": 0.00015209482869241628,
      "loss": 0.0,
      "step": 108450
    },
    {
      "epoch": 6.961375593481329,
      "grad_norm": 0.008183437399566174,
      "learning_rate": 0.00015193442833311946,
      "loss": 0.0,
      "step": 108500
    },
    {
      "epoch": 6.9645836006672655,
      "grad_norm": 0.003473317716270685,
      "learning_rate": 0.00015177402797382267,
      "loss": 0.0,
      "step": 108550
    },
    {
      "epoch": 6.967791607853202,
      "grad_norm": 0.011728557758033276,
      "learning_rate": 0.00015161362761452585,
      "loss": 0.0,
      "step": 108600
    },
    {
      "epoch": 6.970999615039138,
      "grad_norm": 0.014415771700441837,
      "learning_rate": 0.00015145322725522905,
      "loss": 0.0,
      "step": 108650
    },
    {
      "epoch": 6.974207622225074,
      "grad_norm": 0.002425152575597167,
      "learning_rate": 0.00015129282689593223,
      "loss": 0.0,
      "step": 108700
    },
    {
      "epoch": 6.97741562941101,
      "grad_norm": 0.0037747235037386417,
      "learning_rate": 0.00015113242653663544,
      "loss": 0.0,
      "step": 108750
    },
    {
      "epoch": 6.980623636596946,
      "grad_norm": 0.012124983593821526,
      "learning_rate": 0.00015097202617733862,
      "loss": 0.0,
      "step": 108800
    },
    {
      "epoch": 6.9838316437828825,
      "grad_norm": 0.0055588106624782085,
      "learning_rate": 0.00015081162581804183,
      "loss": 0.0,
      "step": 108850
    },
    {
      "epoch": 6.987039650968818,
      "grad_norm": 0.009278585202991962,
      "learning_rate": 0.000150651225458745,
      "loss": 0.0,
      "step": 108900
    },
    {
      "epoch": 6.990247658154754,
      "grad_norm": 0.010217469185590744,
      "learning_rate": 0.00015049082509944821,
      "loss": 0.0,
      "step": 108950
    },
    {
      "epoch": 6.99345566534069,
      "grad_norm": 0.003977846819907427,
      "learning_rate": 0.00015033042474015142,
      "loss": 0.0,
      "step": 109000
    },
    {
      "epoch": 6.996663672526626,
      "grad_norm": 0.008799872361123562,
      "learning_rate": 0.0001501700243808546,
      "loss": 0.0,
      "step": 109050
    },
    {
      "epoch": 6.999871679712562,
      "grad_norm": 0.00418445048853755,
      "learning_rate": 0.00015000962402155784,
      "loss": 0.0,
      "step": 109100
    },
    {
      "epoch": 7.003079686898499,
      "grad_norm": 0.0075758639723062515,
      "learning_rate": 0.00014984922366226102,
      "loss": 0.0,
      "step": 109150
    },
    {
      "epoch": 7.006287694084435,
      "grad_norm": 0.004655311815440655,
      "learning_rate": 0.00014968882330296422,
      "loss": 0.0,
      "step": 109200
    },
    {
      "epoch": 7.009495701270371,
      "grad_norm": 0.005770691204816103,
      "learning_rate": 0.0001495284229436674,
      "loss": 0.0,
      "step": 109250
    },
    {
      "epoch": 7.012703708456307,
      "grad_norm": 0.01276764553040266,
      "learning_rate": 0.0001493680225843706,
      "loss": 0.0,
      "step": 109300
    },
    {
      "epoch": 7.015911715642243,
      "grad_norm": 0.006554572843015194,
      "learning_rate": 0.0001492076222250738,
      "loss": 0.0,
      "step": 109350
    },
    {
      "epoch": 7.019119722828179,
      "grad_norm": 0.019189903512597084,
      "learning_rate": 0.000149047221865777,
      "loss": 0.0,
      "step": 109400
    },
    {
      "epoch": 7.022327730014116,
      "grad_norm": 0.007087781559675932,
      "learning_rate": 0.00014888682150648018,
      "loss": 0.0,
      "step": 109450
    },
    {
      "epoch": 7.025535737200052,
      "grad_norm": 0.01281523797661066,
      "learning_rate": 0.00014872642114718338,
      "loss": 0.0,
      "step": 109500
    },
    {
      "epoch": 7.028743744385987,
      "grad_norm": 0.004417817573994398,
      "learning_rate": 0.00014856602078788656,
      "loss": 0.0,
      "step": 109550
    },
    {
      "epoch": 7.031951751571923,
      "grad_norm": 0.0064169010147452354,
      "learning_rate": 0.00014840562042858977,
      "loss": 0.0,
      "step": 109600
    },
    {
      "epoch": 7.035159758757859,
      "grad_norm": 0.015383888967335224,
      "learning_rate": 0.00014824522006929295,
      "loss": 0.0,
      "step": 109650
    },
    {
      "epoch": 7.0383677659437955,
      "grad_norm": 0.005534812342375517,
      "learning_rate": 0.00014808481970999616,
      "loss": 0.0,
      "step": 109700
    },
    {
      "epoch": 7.041575773129732,
      "grad_norm": 0.0024938632268458605,
      "learning_rate": 0.00014792441935069934,
      "loss": 0.0,
      "step": 109750
    },
    {
      "epoch": 7.044783780315668,
      "grad_norm": 0.005925729405134916,
      "learning_rate": 0.00014776401899140254,
      "loss": 0.0,
      "step": 109800
    },
    {
      "epoch": 7.047991787501604,
      "grad_norm": 0.004277324303984642,
      "learning_rate": 0.00014760361863210575,
      "loss": 0.0,
      "step": 109850
    },
    {
      "epoch": 7.05119979468754,
      "grad_norm": 0.006057120393961668,
      "learning_rate": 0.00014744321827280893,
      "loss": 0.0,
      "step": 109900
    },
    {
      "epoch": 7.054407801873476,
      "grad_norm": 0.00974833220243454,
      "learning_rate": 0.00014728281791351214,
      "loss": 0.0,
      "step": 109950
    },
    {
      "epoch": 7.0576158090594125,
      "grad_norm": 0.006693229544907808,
      "learning_rate": 0.00014712241755421532,
      "loss": 0.0,
      "step": 110000
    },
    {
      "epoch": 7.060823816245349,
      "grad_norm": 0.007964269258081913,
      "learning_rate": 0.00014696201719491852,
      "loss": 0.0,
      "step": 110050
    },
    {
      "epoch": 7.064031823431285,
      "grad_norm": 0.005443088710308075,
      "learning_rate": 0.0001468016168356217,
      "loss": 0.0,
      "step": 110100
    },
    {
      "epoch": 7.06723983061722,
      "grad_norm": 0.008571064099669456,
      "learning_rate": 0.0001466412164763249,
      "loss": 0.0,
      "step": 110150
    },
    {
      "epoch": 7.070447837803156,
      "grad_norm": 0.008215381763875484,
      "learning_rate": 0.0001464808161170281,
      "loss": 0.0,
      "step": 110200
    },
    {
      "epoch": 7.0736558449890925,
      "grad_norm": 0.005030888598412275,
      "learning_rate": 0.0001463204157577313,
      "loss": 0.0,
      "step": 110250
    },
    {
      "epoch": 7.076863852175029,
      "grad_norm": 0.01812691241502762,
      "learning_rate": 0.00014616001539843448,
      "loss": 0.0,
      "step": 110300
    },
    {
      "epoch": 7.080071859360965,
      "grad_norm": 0.006330362521111965,
      "learning_rate": 0.00014599961503913768,
      "loss": 0.0,
      "step": 110350
    },
    {
      "epoch": 7.083279866546901,
      "grad_norm": 0.0029217698611319065,
      "learning_rate": 0.00014583921467984086,
      "loss": 0.0,
      "step": 110400
    },
    {
      "epoch": 7.086487873732837,
      "grad_norm": 0.007138639688491821,
      "learning_rate": 0.00014567881432054407,
      "loss": 0.0,
      "step": 110450
    },
    {
      "epoch": 7.089695880918773,
      "grad_norm": 0.007507536560297012,
      "learning_rate": 0.00014551841396124728,
      "loss": 0.0,
      "step": 110500
    },
    {
      "epoch": 7.0929038881047095,
      "grad_norm": 0.009977511130273342,
      "learning_rate": 0.00014535801360195048,
      "loss": 0.0,
      "step": 110550
    },
    {
      "epoch": 7.096111895290646,
      "grad_norm": 0.018013643100857735,
      "learning_rate": 0.00014519761324265366,
      "loss": 0.0,
      "step": 110600
    },
    {
      "epoch": 7.099319902476582,
      "grad_norm": 0.00526748551055789,
      "learning_rate": 0.00014503721288335687,
      "loss": 0.0,
      "step": 110650
    },
    {
      "epoch": 7.102527909662518,
      "grad_norm": 0.00798148475587368,
      "learning_rate": 0.00014487681252406008,
      "loss": 0.0,
      "step": 110700
    },
    {
      "epoch": 7.105735916848454,
      "grad_norm": 0.013268881477415562,
      "learning_rate": 0.00014471641216476326,
      "loss": 0.0,
      "step": 110750
    },
    {
      "epoch": 7.1089439240343895,
      "grad_norm": 0.004990900866687298,
      "learning_rate": 0.00014455601180546647,
      "loss": 0.0,
      "step": 110800
    },
    {
      "epoch": 7.112151931220326,
      "grad_norm": 0.014792601577937603,
      "learning_rate": 0.00014439561144616965,
      "loss": 0.0,
      "step": 110850
    },
    {
      "epoch": 7.115359938406262,
      "grad_norm": 0.0059240153059363365,
      "learning_rate": 0.00014423521108687285,
      "loss": 0.0,
      "step": 110900
    },
    {
      "epoch": 7.118567945592198,
      "grad_norm": 0.008182208053767681,
      "learning_rate": 0.00014407481072757603,
      "loss": 0.0,
      "step": 110950
    },
    {
      "epoch": 7.121775952778134,
      "grad_norm": 0.010715351440012455,
      "learning_rate": 0.00014391441036827924,
      "loss": 0.0,
      "step": 111000
    },
    {
      "epoch": 7.12498395996407,
      "grad_norm": 0.008270704187452793,
      "learning_rate": 0.00014375401000898242,
      "loss": 0.0,
      "step": 111050
    },
    {
      "epoch": 7.1281919671500065,
      "grad_norm": 0.010391024872660637,
      "learning_rate": 0.00014359360964968563,
      "loss": 0.0,
      "step": 111100
    },
    {
      "epoch": 7.131399974335943,
      "grad_norm": 0.009208488278090954,
      "learning_rate": 0.0001434332092903888,
      "loss": 0.0,
      "step": 111150
    },
    {
      "epoch": 7.134607981521879,
      "grad_norm": 0.0077523887157440186,
      "learning_rate": 0.000143272808931092,
      "loss": 0.0,
      "step": 111200
    },
    {
      "epoch": 7.137815988707815,
      "grad_norm": 0.003540690988302231,
      "learning_rate": 0.0001431124085717952,
      "loss": 0.0,
      "step": 111250
    },
    {
      "epoch": 7.141023995893751,
      "grad_norm": 0.00459371879696846,
      "learning_rate": 0.0001429520082124984,
      "loss": 0.0,
      "step": 111300
    },
    {
      "epoch": 7.144232003079687,
      "grad_norm": 0.004721565172076225,
      "learning_rate": 0.00014279160785320158,
      "loss": 0.0,
      "step": 111350
    },
    {
      "epoch": 7.147440010265623,
      "grad_norm": 0.016687095165252686,
      "learning_rate": 0.00014263120749390479,
      "loss": 0.0,
      "step": 111400
    },
    {
      "epoch": 7.150648017451559,
      "grad_norm": 0.011920529417693615,
      "learning_rate": 0.00014247080713460797,
      "loss": 0.0,
      "step": 111450
    },
    {
      "epoch": 7.153856024637495,
      "grad_norm": 0.008371821604669094,
      "learning_rate": 0.00014231040677531117,
      "loss": 0.0,
      "step": 111500
    },
    {
      "epoch": 7.157064031823431,
      "grad_norm": 0.0032555789221078157,
      "learning_rate": 0.00014215000641601438,
      "loss": 0.0,
      "step": 111550
    },
    {
      "epoch": 7.160272039009367,
      "grad_norm": 0.008741103112697601,
      "learning_rate": 0.00014198960605671756,
      "loss": 0.0,
      "step": 111600
    },
    {
      "epoch": 7.163480046195303,
      "grad_norm": 0.00749580841511488,
      "learning_rate": 0.00014182920569742077,
      "loss": 0.0,
      "step": 111650
    },
    {
      "epoch": 7.16668805338124,
      "grad_norm": 0.010135850869119167,
      "learning_rate": 0.00014166880533812395,
      "loss": 0.0,
      "step": 111700
    },
    {
      "epoch": 7.169896060567176,
      "grad_norm": 0.009572161361575127,
      "learning_rate": 0.00014150840497882715,
      "loss": 0.0,
      "step": 111750
    },
    {
      "epoch": 7.173104067753112,
      "grad_norm": 0.014171996153891087,
      "learning_rate": 0.00014134800461953033,
      "loss": 0.0,
      "step": 111800
    },
    {
      "epoch": 7.176312074939048,
      "grad_norm": 0.009819853119552135,
      "learning_rate": 0.00014118760426023357,
      "loss": 0.0,
      "step": 111850
    },
    {
      "epoch": 7.179520082124984,
      "grad_norm": 0.02069033868610859,
      "learning_rate": 0.00014102720390093675,
      "loss": 0.0,
      "step": 111900
    },
    {
      "epoch": 7.18272808931092,
      "grad_norm": 0.008206981234252453,
      "learning_rate": 0.00014086680354163995,
      "loss": 0.0,
      "step": 111950
    },
    {
      "epoch": 7.185936096496857,
      "grad_norm": 0.014573885127902031,
      "learning_rate": 0.00014070640318234313,
      "loss": 0.0,
      "step": 112000
    },
    {
      "epoch": 7.189144103682792,
      "grad_norm": 0.006837578024715185,
      "learning_rate": 0.00014054600282304634,
      "loss": 0.0,
      "step": 112050
    },
    {
      "epoch": 7.192352110868728,
      "grad_norm": 0.014054547064006329,
      "learning_rate": 0.00014038560246374952,
      "loss": 0.0,
      "step": 112100
    },
    {
      "epoch": 7.195560118054664,
      "grad_norm": 0.002864498645067215,
      "learning_rate": 0.00014022520210445273,
      "loss": 0.0,
      "step": 112150
    },
    {
      "epoch": 7.1987681252406,
      "grad_norm": 0.000924956810194999,
      "learning_rate": 0.0001400648017451559,
      "loss": 0.0,
      "step": 112200
    },
    {
      "epoch": 7.201976132426537,
      "grad_norm": 0.011632559821009636,
      "learning_rate": 0.00013990440138585911,
      "loss": 0.0,
      "step": 112250
    },
    {
      "epoch": 7.205184139612473,
      "grad_norm": 0.014313516207039356,
      "learning_rate": 0.0001397440010265623,
      "loss": 0.0,
      "step": 112300
    },
    {
      "epoch": 7.208392146798409,
      "grad_norm": 0.012939533218741417,
      "learning_rate": 0.0001395836006672655,
      "loss": 0.0,
      "step": 112350
    },
    {
      "epoch": 7.211600153984345,
      "grad_norm": 0.005372494459152222,
      "learning_rate": 0.0001394232003079687,
      "loss": 0.0,
      "step": 112400
    },
    {
      "epoch": 7.214808161170281,
      "grad_norm": 0.009426714852452278,
      "learning_rate": 0.0001392627999486719,
      "loss": 0.0,
      "step": 112450
    },
    {
      "epoch": 7.218016168356217,
      "grad_norm": 0.007930148392915726,
      "learning_rate": 0.0001391023995893751,
      "loss": 0.0,
      "step": 112500
    },
    {
      "epoch": 7.221224175542154,
      "grad_norm": 0.021256595849990845,
      "learning_rate": 0.00013894199923007827,
      "loss": 0.0,
      "step": 112550
    },
    {
      "epoch": 7.22443218272809,
      "grad_norm": 0.004770275205373764,
      "learning_rate": 0.00013878159887078148,
      "loss": 0.0,
      "step": 112600
    },
    {
      "epoch": 7.227640189914025,
      "grad_norm": 0.011754326522350311,
      "learning_rate": 0.00013862119851148466,
      "loss": 0.0,
      "step": 112650
    },
    {
      "epoch": 7.230848197099961,
      "grad_norm": 0.01255620177835226,
      "learning_rate": 0.00013846079815218787,
      "loss": 0.0,
      "step": 112700
    },
    {
      "epoch": 7.234056204285897,
      "grad_norm": 0.011789865791797638,
      "learning_rate": 0.00013830039779289105,
      "loss": 0.0,
      "step": 112750
    },
    {
      "epoch": 7.2372642114718335,
      "grad_norm": 0.007017642259597778,
      "learning_rate": 0.00013813999743359426,
      "loss": 0.0,
      "step": 112800
    },
    {
      "epoch": 7.24047221865777,
      "grad_norm": 0.004744849167764187,
      "learning_rate": 0.00013797959707429744,
      "loss": 0.0,
      "step": 112850
    },
    {
      "epoch": 7.243680225843706,
      "grad_norm": 0.00423032371327281,
      "learning_rate": 0.00013781919671500064,
      "loss": 0.0,
      "step": 112900
    },
    {
      "epoch": 7.246888233029642,
      "grad_norm": 0.008274582214653492,
      "learning_rate": 0.00013765879635570382,
      "loss": 0.0,
      "step": 112950
    },
    {
      "epoch": 7.250096240215578,
      "grad_norm": 0.00578296696767211,
      "learning_rate": 0.00013749839599640703,
      "loss": 0.0,
      "step": 113000
    },
    {
      "epoch": 7.253304247401514,
      "grad_norm": 0.018546855077147484,
      "learning_rate": 0.0001373379956371102,
      "loss": 0.0,
      "step": 113050
    },
    {
      "epoch": 7.2565122545874505,
      "grad_norm": 0.005510650109499693,
      "learning_rate": 0.00013717759527781342,
      "loss": 0.0,
      "step": 113100
    },
    {
      "epoch": 7.259720261773387,
      "grad_norm": 0.01506705954670906,
      "learning_rate": 0.0001370171949185166,
      "loss": 0.0,
      "step": 113150
    },
    {
      "epoch": 7.262928268959323,
      "grad_norm": 0.00539172301068902,
      "learning_rate": 0.0001368567945592198,
      "loss": 0.0,
      "step": 113200
    },
    {
      "epoch": 7.266136276145259,
      "grad_norm": 0.008433416485786438,
      "learning_rate": 0.00013669639419992304,
      "loss": 0.0,
      "step": 113250
    },
    {
      "epoch": 7.269344283331194,
      "grad_norm": 0.005539280362427235,
      "learning_rate": 0.00013653599384062622,
      "loss": 0.0,
      "step": 113300
    },
    {
      "epoch": 7.2725522905171305,
      "grad_norm": 0.014179231598973274,
      "learning_rate": 0.00013637559348132942,
      "loss": 0.0,
      "step": 113350
    },
    {
      "epoch": 7.275760297703067,
      "grad_norm": 0.01311294361948967,
      "learning_rate": 0.0001362151931220326,
      "loss": 0.0,
      "step": 113400
    },
    {
      "epoch": 7.278968304889003,
      "grad_norm": 0.0049643320962786674,
      "learning_rate": 0.0001360547927627358,
      "loss": 0.0,
      "step": 113450
    },
    {
      "epoch": 7.282176312074939,
      "grad_norm": 0.002985633909702301,
      "learning_rate": 0.000135894392403439,
      "loss": 0.0,
      "step": 113500
    },
    {
      "epoch": 7.285384319260875,
      "grad_norm": 0.005107948090881109,
      "learning_rate": 0.0001357339920441422,
      "loss": 0.0,
      "step": 113550
    },
    {
      "epoch": 7.288592326446811,
      "grad_norm": 0.0035453583113849163,
      "learning_rate": 0.00013557359168484538,
      "loss": 0.0,
      "step": 113600
    },
    {
      "epoch": 7.2918003336327475,
      "grad_norm": 0.010007200762629509,
      "learning_rate": 0.00013541319132554858,
      "loss": 0.0,
      "step": 113650
    },
    {
      "epoch": 7.295008340818684,
      "grad_norm": 0.004252091981470585,
      "learning_rate": 0.00013525279096625176,
      "loss": 0.0,
      "step": 113700
    },
    {
      "epoch": 7.29821634800462,
      "grad_norm": 0.012927486561238766,
      "learning_rate": 0.00013509239060695497,
      "loss": 0.0,
      "step": 113750
    },
    {
      "epoch": 7.301424355190556,
      "grad_norm": 0.01670675165951252,
      "learning_rate": 0.00013493199024765815,
      "loss": 0.0,
      "step": 113800
    },
    {
      "epoch": 7.304632362376491,
      "grad_norm": 0.008782762102782726,
      "learning_rate": 0.00013477158988836136,
      "loss": 0.0,
      "step": 113850
    },
    {
      "epoch": 7.307840369562427,
      "grad_norm": 0.0136515311896801,
      "learning_rate": 0.00013461118952906454,
      "loss": 0.0,
      "step": 113900
    },
    {
      "epoch": 7.311048376748364,
      "grad_norm": 0.003327409503981471,
      "learning_rate": 0.00013445078916976774,
      "loss": 0.0,
      "step": 113950
    },
    {
      "epoch": 7.3142563839343,
      "grad_norm": 0.001781055354513228,
      "learning_rate": 0.00013429038881047092,
      "loss": 0.0,
      "step": 114000
    },
    {
      "epoch": 7.317464391120236,
      "grad_norm": 0.005734747275710106,
      "learning_rate": 0.00013412998845117413,
      "loss": 0.0,
      "step": 114050
    },
    {
      "epoch": 7.320672398306172,
      "grad_norm": 0.0028682651463896036,
      "learning_rate": 0.00013396958809187734,
      "loss": 0.0,
      "step": 114100
    },
    {
      "epoch": 7.323880405492108,
      "grad_norm": 0.011888399720191956,
      "learning_rate": 0.00013380918773258052,
      "loss": 0.0,
      "step": 114150
    },
    {
      "epoch": 7.3270884126780444,
      "grad_norm": 0.008186370134353638,
      "learning_rate": 0.00013364878737328372,
      "loss": 0.0,
      "step": 114200
    },
    {
      "epoch": 7.330296419863981,
      "grad_norm": 0.01548987627029419,
      "learning_rate": 0.0001334883870139869,
      "loss": 0.0,
      "step": 114250
    },
    {
      "epoch": 7.333504427049917,
      "grad_norm": 0.004852755926549435,
      "learning_rate": 0.0001333279866546901,
      "loss": 0.0,
      "step": 114300
    },
    {
      "epoch": 7.336712434235853,
      "grad_norm": 0.011135246604681015,
      "learning_rate": 0.0001331675862953933,
      "loss": 0.0,
      "step": 114350
    },
    {
      "epoch": 7.339920441421789,
      "grad_norm": 0.012482874095439911,
      "learning_rate": 0.0001330071859360965,
      "loss": 0.0,
      "step": 114400
    },
    {
      "epoch": 7.343128448607725,
      "grad_norm": 0.00663155410438776,
      "learning_rate": 0.00013284678557679968,
      "loss": 0.0,
      "step": 114450
    },
    {
      "epoch": 7.346336455793661,
      "grad_norm": 0.003208605805411935,
      "learning_rate": 0.00013268638521750289,
      "loss": 0.0,
      "step": 114500
    },
    {
      "epoch": 7.349544462979597,
      "grad_norm": 0.009812567383050919,
      "learning_rate": 0.00013252598485820606,
      "loss": 0.0,
      "step": 114550
    },
    {
      "epoch": 7.352752470165533,
      "grad_norm": 0.002983827842399478,
      "learning_rate": 0.0001323655844989093,
      "loss": 0.0,
      "step": 114600
    },
    {
      "epoch": 7.355960477351469,
      "grad_norm": 0.0064101628959178925,
      "learning_rate": 0.00013220518413961248,
      "loss": 0.0,
      "step": 114650
    },
    {
      "epoch": 7.359168484537405,
      "grad_norm": 0.013369237072765827,
      "learning_rate": 0.00013204478378031569,
      "loss": 0.0,
      "step": 114700
    },
    {
      "epoch": 7.362376491723341,
      "grad_norm": 0.012967517599463463,
      "learning_rate": 0.00013188438342101887,
      "loss": 0.0,
      "step": 114750
    },
    {
      "epoch": 7.365584498909278,
      "grad_norm": 0.006081718951463699,
      "learning_rate": 0.00013172398306172207,
      "loss": 0.0,
      "step": 114800
    },
    {
      "epoch": 7.368792506095214,
      "grad_norm": 0.005847445223480463,
      "learning_rate": 0.00013156358270242525,
      "loss": 0.0,
      "step": 114850
    },
    {
      "epoch": 7.37200051328115,
      "grad_norm": 0.012678592465817928,
      "learning_rate": 0.00013140318234312846,
      "loss": 0.0,
      "step": 114900
    },
    {
      "epoch": 7.375208520467086,
      "grad_norm": 0.014083925634622574,
      "learning_rate": 0.00013124278198383164,
      "loss": 0.0,
      "step": 114950
    },
    {
      "epoch": 7.378416527653022,
      "grad_norm": 0.004744472447782755,
      "learning_rate": 0.00013108238162453485,
      "loss": 0.0,
      "step": 115000
    },
    {
      "epoch": 7.381624534838958,
      "grad_norm": 0.005772549193352461,
      "learning_rate": 0.00013092198126523805,
      "loss": 0.0,
      "step": 115050
    },
    {
      "epoch": 7.384832542024894,
      "grad_norm": 0.011219698004424572,
      "learning_rate": 0.00013076158090594123,
      "loss": 0.0,
      "step": 115100
    },
    {
      "epoch": 7.38804054921083,
      "grad_norm": 0.017003562301397324,
      "learning_rate": 0.00013060118054664444,
      "loss": 0.0,
      "step": 115150
    },
    {
      "epoch": 7.391248556396766,
      "grad_norm": 0.0068687270395457745,
      "learning_rate": 0.00013044078018734762,
      "loss": 0.0,
      "step": 115200
    },
    {
      "epoch": 7.394456563582702,
      "grad_norm": 0.003132767044007778,
      "learning_rate": 0.00013028037982805083,
      "loss": 0.0,
      "step": 115250
    },
    {
      "epoch": 7.397664570768638,
      "grad_norm": 0.006039035972207785,
      "learning_rate": 0.000130119979468754,
      "loss": 0.0,
      "step": 115300
    },
    {
      "epoch": 7.4008725779545745,
      "grad_norm": 0.003857268951833248,
      "learning_rate": 0.0001299595791094572,
      "loss": 0.0,
      "step": 115350
    },
    {
      "epoch": 7.404080585140511,
      "grad_norm": 0.006069704424589872,
      "learning_rate": 0.0001297991787501604,
      "loss": 0.0,
      "step": 115400
    },
    {
      "epoch": 7.407288592326447,
      "grad_norm": 0.007364419288933277,
      "learning_rate": 0.0001296387783908636,
      "loss": 0.0,
      "step": 115450
    },
    {
      "epoch": 7.410496599512383,
      "grad_norm": 0.0025264660362154245,
      "learning_rate": 0.00012947837803156678,
      "loss": 0.0,
      "step": 115500
    },
    {
      "epoch": 7.413704606698319,
      "grad_norm": 0.0016245967708528042,
      "learning_rate": 0.00012931797767227,
      "loss": 0.0,
      "step": 115550
    },
    {
      "epoch": 7.416912613884255,
      "grad_norm": 0.0028566892724484205,
      "learning_rate": 0.00012915757731297317,
      "loss": 0.0,
      "step": 115600
    },
    {
      "epoch": 7.4201206210701915,
      "grad_norm": 0.005852804984897375,
      "learning_rate": 0.00012899717695367637,
      "loss": 0.0,
      "step": 115650
    },
    {
      "epoch": 7.423328628256128,
      "grad_norm": 0.009755154140293598,
      "learning_rate": 0.00012883677659437955,
      "loss": 0.0,
      "step": 115700
    },
    {
      "epoch": 7.426536635442063,
      "grad_norm": 0.005876678973436356,
      "learning_rate": 0.00012867637623508276,
      "loss": 0.0,
      "step": 115750
    },
    {
      "epoch": 7.429744642627999,
      "grad_norm": 0.0045188432559370995,
      "learning_rate": 0.00012851597587578594,
      "loss": 0.0,
      "step": 115800
    },
    {
      "epoch": 7.432952649813935,
      "grad_norm": 0.01575939916074276,
      "learning_rate": 0.00012835557551648915,
      "loss": 0.0,
      "step": 115850
    },
    {
      "epoch": 7.4361606569998715,
      "grad_norm": 0.012884603813290596,
      "learning_rate": 0.00012819517515719235,
      "loss": 0.0,
      "step": 115900
    },
    {
      "epoch": 7.439368664185808,
      "grad_norm": 0.008614810183644295,
      "learning_rate": 0.00012803477479789556,
      "loss": 0.0,
      "step": 115950
    },
    {
      "epoch": 7.442576671371744,
      "grad_norm": 0.0051498813554644585,
      "learning_rate": 0.00012787437443859877,
      "loss": 0.0,
      "step": 116000
    },
    {
      "epoch": 7.44578467855768,
      "grad_norm": 0.007437463384121656,
      "learning_rate": 0.00012771397407930195,
      "loss": 0.0,
      "step": 116050
    },
    {
      "epoch": 7.448992685743616,
      "grad_norm": 0.004081196617335081,
      "learning_rate": 0.00012755357372000516,
      "loss": 0.0,
      "step": 116100
    },
    {
      "epoch": 7.452200692929552,
      "grad_norm": 0.01186011079698801,
      "learning_rate": 0.00012739317336070833,
      "loss": 0.0,
      "step": 116150
    },
    {
      "epoch": 7.4554087001154885,
      "grad_norm": 0.006397249177098274,
      "learning_rate": 0.00012723277300141154,
      "loss": 0.0,
      "step": 116200
    },
    {
      "epoch": 7.458616707301425,
      "grad_norm": 0.006875626277178526,
      "learning_rate": 0.00012707237264211472,
      "loss": 0.0,
      "step": 116250
    },
    {
      "epoch": 7.461824714487361,
      "grad_norm": 0.004463173449039459,
      "learning_rate": 0.00012691197228281793,
      "loss": 0.0,
      "step": 116300
    },
    {
      "epoch": 7.465032721673296,
      "grad_norm": 0.010499791242182255,
      "learning_rate": 0.0001267515719235211,
      "loss": 0.0,
      "step": 116350
    },
    {
      "epoch": 7.468240728859232,
      "grad_norm": 0.00428110221400857,
      "learning_rate": 0.00012659117156422432,
      "loss": 0.0,
      "step": 116400
    },
    {
      "epoch": 7.4714487360451685,
      "grad_norm": 0.007267990615218878,
      "learning_rate": 0.0001264307712049275,
      "loss": 0.0,
      "step": 116450
    },
    {
      "epoch": 7.474656743231105,
      "grad_norm": 0.009020403027534485,
      "learning_rate": 0.0001262703708456307,
      "loss": 0.0,
      "step": 116500
    },
    {
      "epoch": 7.477864750417041,
      "grad_norm": 0.0012188185937702656,
      "learning_rate": 0.00012610997048633388,
      "loss": 0.0,
      "step": 116550
    },
    {
      "epoch": 7.481072757602977,
      "grad_norm": 0.008536522276699543,
      "learning_rate": 0.0001259495701270371,
      "loss": 0.0,
      "step": 116600
    },
    {
      "epoch": 7.484280764788913,
      "grad_norm": 0.012445504777133465,
      "learning_rate": 0.00012578916976774027,
      "loss": 0.0,
      "step": 116650
    },
    {
      "epoch": 7.487488771974849,
      "grad_norm": 0.0033459493424743414,
      "learning_rate": 0.00012562876940844348,
      "loss": 0.0,
      "step": 116700
    },
    {
      "epoch": 7.4906967791607855,
      "grad_norm": 0.0022776671685278416,
      "learning_rate": 0.00012546836904914668,
      "loss": 0.0,
      "step": 116750
    },
    {
      "epoch": 7.493904786346722,
      "grad_norm": 0.01812065951526165,
      "learning_rate": 0.00012530796868984986,
      "loss": 0.0,
      "step": 116800
    },
    {
      "epoch": 7.497112793532658,
      "grad_norm": 0.0029989220201969147,
      "learning_rate": 0.00012514756833055307,
      "loss": 0.0,
      "step": 116850
    },
    {
      "epoch": 7.500320800718594,
      "grad_norm": 0.019844388589262962,
      "learning_rate": 0.00012498716797125625,
      "loss": 0.0,
      "step": 116900
    },
    {
      "epoch": 7.50352880790453,
      "grad_norm": 0.007782652974128723,
      "learning_rate": 0.00012482676761195946,
      "loss": 0.0,
      "step": 116950
    },
    {
      "epoch": 7.506736815090465,
      "grad_norm": 0.005985928699374199,
      "learning_rate": 0.00012466636725266264,
      "loss": 0.0,
      "step": 117000
    },
    {
      "epoch": 7.509944822276402,
      "grad_norm": 0.007055474445223808,
      "learning_rate": 0.00012450596689336584,
      "loss": 0.0,
      "step": 117050
    },
    {
      "epoch": 7.513152829462338,
      "grad_norm": 0.008266584016382694,
      "learning_rate": 0.00012434556653406902,
      "loss": 0.0,
      "step": 117100
    },
    {
      "epoch": 7.516360836648274,
      "grad_norm": 0.004784021060913801,
      "learning_rate": 0.00012418516617477223,
      "loss": 0.0,
      "step": 117150
    },
    {
      "epoch": 7.51956884383421,
      "grad_norm": 0.003504191990941763,
      "learning_rate": 0.00012402476581547544,
      "loss": 0.0,
      "step": 117200
    },
    {
      "epoch": 7.522776851020146,
      "grad_norm": 0.003778661834076047,
      "learning_rate": 0.00012386436545617862,
      "loss": 0.0,
      "step": 117250
    },
    {
      "epoch": 7.525984858206082,
      "grad_norm": 0.009083561599254608,
      "learning_rate": 0.00012370396509688182,
      "loss": 0.0,
      "step": 117300
    },
    {
      "epoch": 7.529192865392019,
      "grad_norm": 0.0036051059141755104,
      "learning_rate": 0.00012354356473758503,
      "loss": 0.0,
      "step": 117350
    },
    {
      "epoch": 7.532400872577955,
      "grad_norm": 0.014476841315627098,
      "learning_rate": 0.0001233831643782882,
      "loss": 0.0,
      "step": 117400
    },
    {
      "epoch": 7.535608879763891,
      "grad_norm": 0.004526252392679453,
      "learning_rate": 0.00012322276401899142,
      "loss": 0.0,
      "step": 117450
    },
    {
      "epoch": 7.538816886949827,
      "grad_norm": 0.0025778261478990316,
      "learning_rate": 0.0001230623636596946,
      "loss": 0.0,
      "step": 117500
    },
    {
      "epoch": 7.542024894135762,
      "grad_norm": 0.019827870652079582,
      "learning_rate": 0.0001229019633003978,
      "loss": 0.0,
      "step": 117550
    },
    {
      "epoch": 7.5452329013216985,
      "grad_norm": 0.002204058924689889,
      "learning_rate": 0.00012274156294110098,
      "loss": 0.0,
      "step": 117600
    },
    {
      "epoch": 7.548440908507635,
      "grad_norm": 0.00483943335711956,
      "learning_rate": 0.0001225811625818042,
      "loss": 0.0,
      "step": 117650
    },
    {
      "epoch": 7.551648915693571,
      "grad_norm": 0.007358248345553875,
      "learning_rate": 0.00012242076222250737,
      "loss": 0.0,
      "step": 117700
    },
    {
      "epoch": 7.554856922879507,
      "grad_norm": 0.0022206611465662718,
      "learning_rate": 0.00012226036186321058,
      "loss": 0.0,
      "step": 117750
    },
    {
      "epoch": 7.558064930065443,
      "grad_norm": 0.004068607930094004,
      "learning_rate": 0.00012209996150391376,
      "loss": 0.0,
      "step": 117800
    },
    {
      "epoch": 7.561272937251379,
      "grad_norm": 0.006139606703072786,
      "learning_rate": 0.00012193956114461696,
      "loss": 0.0,
      "step": 117850
    },
    {
      "epoch": 7.564480944437316,
      "grad_norm": 0.007607202976942062,
      "learning_rate": 0.00012177916078532016,
      "loss": 0.0,
      "step": 117900
    },
    {
      "epoch": 7.567688951623252,
      "grad_norm": 0.003989433404058218,
      "learning_rate": 0.00012161876042602335,
      "loss": 0.0,
      "step": 117950
    },
    {
      "epoch": 7.570896958809188,
      "grad_norm": 0.010421082377433777,
      "learning_rate": 0.00012145836006672656,
      "loss": 0.0,
      "step": 118000
    },
    {
      "epoch": 7.574104965995124,
      "grad_norm": 0.0016116279875859618,
      "learning_rate": 0.00012129795970742975,
      "loss": 0.0,
      "step": 118050
    },
    {
      "epoch": 7.57731297318106,
      "grad_norm": 0.004336175974458456,
      "learning_rate": 0.00012113755934813295,
      "loss": 0.0,
      "step": 118100
    },
    {
      "epoch": 7.580520980366996,
      "grad_norm": 0.006972119677811861,
      "learning_rate": 0.00012097715898883614,
      "loss": 0.0,
      "step": 118150
    },
    {
      "epoch": 7.583728987552933,
      "grad_norm": 0.00725700706243515,
      "learning_rate": 0.00012081675862953933,
      "loss": 0.0,
      "step": 118200
    },
    {
      "epoch": 7.586936994738868,
      "grad_norm": 0.004795759916305542,
      "learning_rate": 0.00012065635827024253,
      "loss": 0.0,
      "step": 118250
    },
    {
      "epoch": 7.590145001924804,
      "grad_norm": 0.003526640823110938,
      "learning_rate": 0.00012049595791094572,
      "loss": 0.0,
      "step": 118300
    },
    {
      "epoch": 7.59335300911074,
      "grad_norm": 0.004469163715839386,
      "learning_rate": 0.00012033555755164893,
      "loss": 0.0,
      "step": 118350
    },
    {
      "epoch": 7.596561016296676,
      "grad_norm": 0.0060244593769311905,
      "learning_rate": 0.00012017515719235212,
      "loss": 0.0,
      "step": 118400
    },
    {
      "epoch": 7.5997690234826125,
      "grad_norm": 0.018603799864649773,
      "learning_rate": 0.00012001475683305531,
      "loss": 0.0,
      "step": 118450
    },
    {
      "epoch": 7.602977030668549,
      "grad_norm": 0.0022282812278717756,
      "learning_rate": 0.0001198543564737585,
      "loss": 0.0,
      "step": 118500
    },
    {
      "epoch": 7.606185037854485,
      "grad_norm": 0.005616773385554552,
      "learning_rate": 0.0001196939561144617,
      "loss": 0.0,
      "step": 118550
    },
    {
      "epoch": 7.609393045040421,
      "grad_norm": 0.004223428666591644,
      "learning_rate": 0.00011953355575516489,
      "loss": 0.0,
      "step": 118600
    },
    {
      "epoch": 7.612601052226357,
      "grad_norm": 0.010366027243435383,
      "learning_rate": 0.00011937315539586809,
      "loss": 0.0,
      "step": 118650
    },
    {
      "epoch": 7.615809059412293,
      "grad_norm": 0.007842413149774075,
      "learning_rate": 0.00011921275503657128,
      "loss": 0.0,
      "step": 118700
    },
    {
      "epoch": 7.6190170665982295,
      "grad_norm": 0.007058664225041866,
      "learning_rate": 0.00011905235467727447,
      "loss": 0.0,
      "step": 118750
    },
    {
      "epoch": 7.622225073784165,
      "grad_norm": 0.00940141174942255,
      "learning_rate": 0.00011889195431797767,
      "loss": 0.0,
      "step": 118800
    },
    {
      "epoch": 7.625433080970101,
      "grad_norm": 0.006907516159117222,
      "learning_rate": 0.00011873155395868087,
      "loss": 0.0,
      "step": 118850
    },
    {
      "epoch": 7.628641088156037,
      "grad_norm": 0.004394644405692816,
      "learning_rate": 0.00011857115359938407,
      "loss": 0.0,
      "step": 118900
    },
    {
      "epoch": 7.631849095341973,
      "grad_norm": 0.014801343902945518,
      "learning_rate": 0.00011841075324008726,
      "loss": 0.0,
      "step": 118950
    },
    {
      "epoch": 7.6350571025279095,
      "grad_norm": 0.00703479303047061,
      "learning_rate": 0.00011825035288079045,
      "loss": 0.0,
      "step": 119000
    },
    {
      "epoch": 7.638265109713846,
      "grad_norm": 0.019043590873479843,
      "learning_rate": 0.00011808995252149366,
      "loss": 0.0,
      "step": 119050
    },
    {
      "epoch": 7.641473116899782,
      "grad_norm": 0.008107644505798817,
      "learning_rate": 0.00011792955216219685,
      "loss": 0.0,
      "step": 119100
    },
    {
      "epoch": 7.644681124085718,
      "grad_norm": 0.005773101467639208,
      "learning_rate": 0.00011776915180290005,
      "loss": 0.0,
      "step": 119150
    },
    {
      "epoch": 7.647889131271654,
      "grad_norm": 0.007435582112520933,
      "learning_rate": 0.00011760875144360324,
      "loss": 0.0,
      "step": 119200
    },
    {
      "epoch": 7.65109713845759,
      "grad_norm": 0.01788889430463314,
      "learning_rate": 0.00011744835108430643,
      "loss": 0.0,
      "step": 119250
    },
    {
      "epoch": 7.6543051456435265,
      "grad_norm": 0.00575766758993268,
      "learning_rate": 0.00011728795072500963,
      "loss": 0.0,
      "step": 119300
    },
    {
      "epoch": 7.657513152829463,
      "grad_norm": 0.005632251035422087,
      "learning_rate": 0.00011712755036571282,
      "loss": 0.0,
      "step": 119350
    },
    {
      "epoch": 7.660721160015399,
      "grad_norm": 0.006556185428053141,
      "learning_rate": 0.00011696715000641601,
      "loss": 0.0,
      "step": 119400
    },
    {
      "epoch": 7.663929167201335,
      "grad_norm": 0.004772454500198364,
      "learning_rate": 0.00011680674964711921,
      "loss": 0.0,
      "step": 119450
    },
    {
      "epoch": 7.66713717438727,
      "grad_norm": 0.0031409896910190582,
      "learning_rate": 0.0001166463492878224,
      "loss": 0.0,
      "step": 119500
    },
    {
      "epoch": 7.670345181573206,
      "grad_norm": 0.0017201502341777086,
      "learning_rate": 0.0001164859489285256,
      "loss": 0.0,
      "step": 119550
    },
    {
      "epoch": 7.673553188759143,
      "grad_norm": 0.0015616550808772445,
      "learning_rate": 0.00011632554856922879,
      "loss": 0.0,
      "step": 119600
    },
    {
      "epoch": 7.676761195945079,
      "grad_norm": 0.008731210604310036,
      "learning_rate": 0.00011616514820993198,
      "loss": 0.0,
      "step": 119650
    },
    {
      "epoch": 7.679969203131015,
      "grad_norm": 0.016317127272486687,
      "learning_rate": 0.00011600474785063517,
      "loss": 0.0,
      "step": 119700
    },
    {
      "epoch": 7.683177210316951,
      "grad_norm": 0.006587374489754438,
      "learning_rate": 0.0001158443474913384,
      "loss": 0.0,
      "step": 119750
    },
    {
      "epoch": 7.686385217502887,
      "grad_norm": 0.004467817023396492,
      "learning_rate": 0.00011568394713204159,
      "loss": 0.0,
      "step": 119800
    },
    {
      "epoch": 7.6895932246888234,
      "grad_norm": 0.008839772082865238,
      "learning_rate": 0.00011552354677274478,
      "loss": 0.0,
      "step": 119850
    },
    {
      "epoch": 7.69280123187476,
      "grad_norm": 0.008887622505426407,
      "learning_rate": 0.00011536314641344798,
      "loss": 0.0,
      "step": 119900
    },
    {
      "epoch": 7.696009239060696,
      "grad_norm": 0.005656986031681299,
      "learning_rate": 0.00011520274605415117,
      "loss": 0.0,
      "step": 119950
    },
    {
      "epoch": 7.699217246246632,
      "grad_norm": 0.002261214889585972,
      "learning_rate": 0.00011504234569485436,
      "loss": 0.0,
      "step": 120000
    },
    {
      "epoch": 7.702425253432567,
      "grad_norm": 0.005393298342823982,
      "learning_rate": 0.00011488194533555756,
      "loss": 0.0,
      "step": 120050
    },
    {
      "epoch": 7.705633260618503,
      "grad_norm": 0.0026721309404820204,
      "learning_rate": 0.00011472154497626075,
      "loss": 0.0,
      "step": 120100
    },
    {
      "epoch": 7.70884126780444,
      "grad_norm": 0.014613503590226173,
      "learning_rate": 0.00011456114461696394,
      "loss": 0.0,
      "step": 120150
    },
    {
      "epoch": 7.712049274990376,
      "grad_norm": 0.004954723175615072,
      "learning_rate": 0.00011440074425766714,
      "loss": 0.0,
      "step": 120200
    },
    {
      "epoch": 7.715257282176312,
      "grad_norm": 0.006297207437455654,
      "learning_rate": 0.00011424034389837033,
      "loss": 0.0,
      "step": 120250
    },
    {
      "epoch": 7.718465289362248,
      "grad_norm": 0.0078605767339468,
      "learning_rate": 0.00011407994353907352,
      "loss": 0.0,
      "step": 120300
    },
    {
      "epoch": 7.721673296548184,
      "grad_norm": 0.009564867243170738,
      "learning_rate": 0.00011391954317977672,
      "loss": 0.0,
      "step": 120350
    },
    {
      "epoch": 7.72488130373412,
      "grad_norm": 0.00861922837793827,
      "learning_rate": 0.00011375914282047992,
      "loss": 0.0,
      "step": 120400
    },
    {
      "epoch": 7.728089310920057,
      "grad_norm": 0.006187800783663988,
      "learning_rate": 0.00011359874246118312,
      "loss": 0.0,
      "step": 120450
    },
    {
      "epoch": 7.731297318105993,
      "grad_norm": 0.008928599767386913,
      "learning_rate": 0.00011343834210188631,
      "loss": 0.0,
      "step": 120500
    },
    {
      "epoch": 7.734505325291929,
      "grad_norm": 0.009286939166486263,
      "learning_rate": 0.0001132779417425895,
      "loss": 0.0,
      "step": 120550
    },
    {
      "epoch": 7.737713332477865,
      "grad_norm": 0.0034799862187355757,
      "learning_rate": 0.00011311754138329271,
      "loss": 0.0,
      "step": 120600
    },
    {
      "epoch": 7.740921339663801,
      "grad_norm": 0.0020249506924301386,
      "learning_rate": 0.0001129571410239959,
      "loss": 0.0,
      "step": 120650
    },
    {
      "epoch": 7.744129346849737,
      "grad_norm": 0.00884007103741169,
      "learning_rate": 0.0001127967406646991,
      "loss": 0.0,
      "step": 120700
    },
    {
      "epoch": 7.747337354035673,
      "grad_norm": 0.011093645356595516,
      "learning_rate": 0.00011263634030540229,
      "loss": 0.0,
      "step": 120750
    },
    {
      "epoch": 7.750545361221609,
      "grad_norm": 0.008020936511456966,
      "learning_rate": 0.00011247593994610548,
      "loss": 0.0,
      "step": 120800
    },
    {
      "epoch": 7.753753368407545,
      "grad_norm": 0.004610789939761162,
      "learning_rate": 0.00011231553958680868,
      "loss": 0.0,
      "step": 120850
    },
    {
      "epoch": 7.756961375593481,
      "grad_norm": 0.020122850313782692,
      "learning_rate": 0.00011215513922751187,
      "loss": 0.0,
      "step": 120900
    },
    {
      "epoch": 7.760169382779417,
      "grad_norm": 0.011769650503993034,
      "learning_rate": 0.00011199473886821506,
      "loss": 0.0,
      "step": 120950
    },
    {
      "epoch": 7.7633773899653535,
      "grad_norm": 0.0052860495634377,
      "learning_rate": 0.00011183433850891826,
      "loss": 0.0,
      "step": 121000
    },
    {
      "epoch": 7.76658539715129,
      "grad_norm": 0.003679045708850026,
      "learning_rate": 0.00011167393814962145,
      "loss": 0.0,
      "step": 121050
    },
    {
      "epoch": 7.769793404337226,
      "grad_norm": 0.009063007310032845,
      "learning_rate": 0.00011151353779032466,
      "loss": 0.0,
      "step": 121100
    },
    {
      "epoch": 7.773001411523162,
      "grad_norm": 0.01646358333528042,
      "learning_rate": 0.00011135313743102785,
      "loss": 0.0,
      "step": 121150
    },
    {
      "epoch": 7.776209418709098,
      "grad_norm": 0.0015764603158459067,
      "learning_rate": 0.00011119273707173104,
      "loss": 0.0,
      "step": 121200
    },
    {
      "epoch": 7.779417425895034,
      "grad_norm": 0.010184635408222675,
      "learning_rate": 0.00011103233671243424,
      "loss": 0.0,
      "step": 121250
    },
    {
      "epoch": 7.78262543308097,
      "grad_norm": 0.007401053793728352,
      "learning_rate": 0.00011087193635313743,
      "loss": 0.0,
      "step": 121300
    },
    {
      "epoch": 7.785833440266906,
      "grad_norm": 0.008280293084681034,
      "learning_rate": 0.00011071153599384062,
      "loss": 0.0,
      "step": 121350
    },
    {
      "epoch": 7.789041447452842,
      "grad_norm": 0.0029479251243174076,
      "learning_rate": 0.00011055113563454382,
      "loss": 0.0,
      "step": 121400
    },
    {
      "epoch": 7.792249454638778,
      "grad_norm": 0.007445327937602997,
      "learning_rate": 0.00011039073527524702,
      "loss": 0.0,
      "step": 121450
    },
    {
      "epoch": 7.795457461824714,
      "grad_norm": 0.007515871897339821,
      "learning_rate": 0.00011023033491595022,
      "loss": 0.0,
      "step": 121500
    },
    {
      "epoch": 7.7986654690106505,
      "grad_norm": 0.007209431380033493,
      "learning_rate": 0.00011006993455665341,
      "loss": 0.0,
      "step": 121550
    },
    {
      "epoch": 7.801873476196587,
      "grad_norm": 0.004358375910669565,
      "learning_rate": 0.0001099095341973566,
      "loss": 0.0,
      "step": 121600
    },
    {
      "epoch": 7.805081483382523,
      "grad_norm": 0.0025665489956736565,
      "learning_rate": 0.0001097491338380598,
      "loss": 0.0,
      "step": 121650
    },
    {
      "epoch": 7.808289490568459,
      "grad_norm": 0.0048240795731544495,
      "learning_rate": 0.00010958873347876299,
      "loss": 0.0,
      "step": 121700
    },
    {
      "epoch": 7.811497497754395,
      "grad_norm": 0.004685284104198217,
      "learning_rate": 0.0001094283331194662,
      "loss": 0.0,
      "step": 121750
    },
    {
      "epoch": 7.814705504940331,
      "grad_norm": 0.0022450671531260014,
      "learning_rate": 0.00010926793276016939,
      "loss": 0.0,
      "step": 121800
    },
    {
      "epoch": 7.8179135121262675,
      "grad_norm": 0.002870517550036311,
      "learning_rate": 0.00010910753240087259,
      "loss": 0.0,
      "step": 121850
    },
    {
      "epoch": 7.821121519312204,
      "grad_norm": 0.0028279265388846397,
      "learning_rate": 0.00010894713204157578,
      "loss": 0.0,
      "step": 121900
    },
    {
      "epoch": 7.82432952649814,
      "grad_norm": 0.007506732363253832,
      "learning_rate": 0.00010878673168227897,
      "loss": 0.0,
      "step": 121950
    },
    {
      "epoch": 7.827537533684075,
      "grad_norm": 0.004008068237453699,
      "learning_rate": 0.00010862633132298217,
      "loss": 0.0,
      "step": 122000
    },
    {
      "epoch": 7.830745540870011,
      "grad_norm": 0.005197365768253803,
      "learning_rate": 0.00010846593096368536,
      "loss": 0.0,
      "step": 122050
    },
    {
      "epoch": 7.8339535480559475,
      "grad_norm": 0.014540325850248337,
      "learning_rate": 0.00010830553060438855,
      "loss": 0.0,
      "step": 122100
    },
    {
      "epoch": 7.837161555241884,
      "grad_norm": 0.0034443438053131104,
      "learning_rate": 0.00010814513024509175,
      "loss": 0.0,
      "step": 122150
    },
    {
      "epoch": 7.84036956242782,
      "grad_norm": 0.004594468977302313,
      "learning_rate": 0.00010798472988579494,
      "loss": 0.0,
      "step": 122200
    },
    {
      "epoch": 7.843577569613756,
      "grad_norm": 0.007978108711540699,
      "learning_rate": 0.00010782432952649813,
      "loss": 0.0,
      "step": 122250
    },
    {
      "epoch": 7.846785576799692,
      "grad_norm": 0.002975414739921689,
      "learning_rate": 0.00010766392916720133,
      "loss": 0.0,
      "step": 122300
    },
    {
      "epoch": 7.849993583985628,
      "grad_norm": 0.010688436217606068,
      "learning_rate": 0.00010750352880790453,
      "loss": 0.0,
      "step": 122350
    },
    {
      "epoch": 7.8532015911715645,
      "grad_norm": 0.004130002576857805,
      "learning_rate": 0.00010734312844860773,
      "loss": 0.0,
      "step": 122400
    },
    {
      "epoch": 7.856409598357501,
      "grad_norm": 0.005555614363402128,
      "learning_rate": 0.00010718272808931093,
      "loss": 0.0,
      "step": 122450
    },
    {
      "epoch": 7.859617605543437,
      "grad_norm": 0.00644831545650959,
      "learning_rate": 0.00010702232773001413,
      "loss": 0.0,
      "step": 122500
    },
    {
      "epoch": 7.862825612729372,
      "grad_norm": 0.014257334172725677,
      "learning_rate": 0.00010686192737071732,
      "loss": 0.0,
      "step": 122550
    },
    {
      "epoch": 7.866033619915308,
      "grad_norm": 0.006025279406458139,
      "learning_rate": 0.00010670152701142051,
      "loss": 0.0,
      "step": 122600
    },
    {
      "epoch": 7.869241627101244,
      "grad_norm": 0.009022800251841545,
      "learning_rate": 0.00010654112665212371,
      "loss": 0.0,
      "step": 122650
    },
    {
      "epoch": 7.872449634287181,
      "grad_norm": 0.00851509440690279,
      "learning_rate": 0.0001063807262928269,
      "loss": 0.0,
      "step": 122700
    },
    {
      "epoch": 7.875657641473117,
      "grad_norm": 0.00855083018541336,
      "learning_rate": 0.0001062203259335301,
      "loss": 0.0,
      "step": 122750
    },
    {
      "epoch": 7.878865648659053,
      "grad_norm": 0.0019035408040508628,
      "learning_rate": 0.00010605992557423329,
      "loss": 0.0,
      "step": 122800
    },
    {
      "epoch": 7.882073655844989,
      "grad_norm": 0.008973918855190277,
      "learning_rate": 0.00010589952521493648,
      "loss": 0.0,
      "step": 122850
    },
    {
      "epoch": 7.885281663030925,
      "grad_norm": 0.0010770189110189676,
      "learning_rate": 0.00010573912485563967,
      "loss": 0.0,
      "step": 122900
    },
    {
      "epoch": 7.888489670216861,
      "grad_norm": 0.003031698754057288,
      "learning_rate": 0.00010557872449634287,
      "loss": 0.0,
      "step": 122950
    },
    {
      "epoch": 7.891697677402798,
      "grad_norm": 0.0059354607947170734,
      "learning_rate": 0.00010541832413704606,
      "loss": 0.0,
      "step": 123000
    },
    {
      "epoch": 7.894905684588734,
      "grad_norm": 0.010471968911588192,
      "learning_rate": 0.00010525792377774925,
      "loss": 0.0,
      "step": 123050
    },
    {
      "epoch": 7.89811369177467,
      "grad_norm": 0.007348345126956701,
      "learning_rate": 0.00010509752341845245,
      "loss": 0.0,
      "step": 123100
    },
    {
      "epoch": 7.901321698960606,
      "grad_norm": 0.0037704992573708296,
      "learning_rate": 0.00010493712305915565,
      "loss": 0.0,
      "step": 123150
    },
    {
      "epoch": 7.904529706146542,
      "grad_norm": 0.004426690749824047,
      "learning_rate": 0.00010477672269985886,
      "loss": 0.0,
      "step": 123200
    },
    {
      "epoch": 7.9077377133324775,
      "grad_norm": 0.005268459673970938,
      "learning_rate": 0.00010461632234056205,
      "loss": 0.0,
      "step": 123250
    },
    {
      "epoch": 7.910945720518414,
      "grad_norm": 0.005440919194370508,
      "learning_rate": 0.00010445592198126525,
      "loss": 0.0,
      "step": 123300
    },
    {
      "epoch": 7.91415372770435,
      "grad_norm": 0.007333504501730204,
      "learning_rate": 0.00010429552162196844,
      "loss": 0.0,
      "step": 123350
    },
    {
      "epoch": 7.917361734890286,
      "grad_norm": 0.005396106280386448,
      "learning_rate": 0.00010413512126267163,
      "loss": 0.0,
      "step": 123400
    },
    {
      "epoch": 7.920569742076222,
      "grad_norm": 0.006729757878929377,
      "learning_rate": 0.00010397472090337483,
      "loss": 0.0,
      "step": 123450
    },
    {
      "epoch": 7.923777749262158,
      "grad_norm": 0.005865216720849276,
      "learning_rate": 0.00010381432054407802,
      "loss": 0.0,
      "step": 123500
    },
    {
      "epoch": 7.9269857564480946,
      "grad_norm": 0.014959064312279224,
      "learning_rate": 0.00010365392018478122,
      "loss": 0.0,
      "step": 123550
    },
    {
      "epoch": 7.930193763634031,
      "grad_norm": 0.004544373601675034,
      "learning_rate": 0.00010349351982548441,
      "loss": 0.0,
      "step": 123600
    },
    {
      "epoch": 7.933401770819967,
      "grad_norm": 0.005305734928697348,
      "learning_rate": 0.0001033331194661876,
      "loss": 0.0,
      "step": 123650
    },
    {
      "epoch": 7.936609778005903,
      "grad_norm": 0.009800601750612259,
      "learning_rate": 0.0001031727191068908,
      "loss": 0.0,
      "step": 123700
    },
    {
      "epoch": 7.939817785191838,
      "grad_norm": 0.014270124025642872,
      "learning_rate": 0.00010301231874759399,
      "loss": 0.0,
      "step": 123750
    },
    {
      "epoch": 7.9430257923777745,
      "grad_norm": 0.008808151818811893,
      "learning_rate": 0.00010285191838829718,
      "loss": 0.0,
      "step": 123800
    },
    {
      "epoch": 7.946233799563711,
      "grad_norm": 0.003546570660546422,
      "learning_rate": 0.00010269151802900039,
      "loss": 0.0,
      "step": 123850
    },
    {
      "epoch": 7.949441806749647,
      "grad_norm": 0.004500470589846373,
      "learning_rate": 0.00010253111766970358,
      "loss": 0.0,
      "step": 123900
    },
    {
      "epoch": 7.952649813935583,
      "grad_norm": 0.005876626819372177,
      "learning_rate": 0.00010237071731040678,
      "loss": 0.0,
      "step": 123950
    },
    {
      "epoch": 7.955857821121519,
      "grad_norm": 0.0036673671565949917,
      "learning_rate": 0.00010221031695110997,
      "loss": 0.0,
      "step": 124000
    },
    {
      "epoch": 7.959065828307455,
      "grad_norm": 0.010099275968968868,
      "learning_rate": 0.00010204991659181318,
      "loss": 0.0,
      "step": 124050
    },
    {
      "epoch": 7.9622738354933915,
      "grad_norm": 0.004876032937318087,
      "learning_rate": 0.00010188951623251637,
      "loss": 0.0,
      "step": 124100
    },
    {
      "epoch": 7.965481842679328,
      "grad_norm": 0.004168851301074028,
      "learning_rate": 0.00010172911587321956,
      "loss": 0.0,
      "step": 124150
    },
    {
      "epoch": 7.968689849865264,
      "grad_norm": 0.017317986115813255,
      "learning_rate": 0.00010156871551392276,
      "loss": 0.0,
      "step": 124200
    },
    {
      "epoch": 7.9718978570512,
      "grad_norm": 0.0055822632275521755,
      "learning_rate": 0.00010140831515462595,
      "loss": 0.0,
      "step": 124250
    },
    {
      "epoch": 7.975105864237136,
      "grad_norm": 0.007577106822282076,
      "learning_rate": 0.00010124791479532914,
      "loss": 0.0,
      "step": 124300
    },
    {
      "epoch": 7.978313871423072,
      "grad_norm": 0.01240195706486702,
      "learning_rate": 0.00010108751443603234,
      "loss": 0.0,
      "step": 124350
    },
    {
      "epoch": 7.9815218786090085,
      "grad_norm": 0.006793216802179813,
      "learning_rate": 0.00010092711407673553,
      "loss": 0.0,
      "step": 124400
    },
    {
      "epoch": 7.984729885794944,
      "grad_norm": 0.00966601725667715,
      "learning_rate": 0.00010076671371743872,
      "loss": 0.0,
      "step": 124450
    },
    {
      "epoch": 7.98793789298088,
      "grad_norm": 0.00717827258631587,
      "learning_rate": 0.00010060631335814193,
      "loss": 0.0,
      "step": 124500
    },
    {
      "epoch": 7.991145900166816,
      "grad_norm": 0.005619628820568323,
      "learning_rate": 0.00010044591299884512,
      "loss": 0.0,
      "step": 124550
    },
    {
      "epoch": 7.994353907352752,
      "grad_norm": 0.005877356510609388,
      "learning_rate": 0.00010028551263954832,
      "loss": 0.0,
      "step": 124600
    },
    {
      "epoch": 7.9975619145386885,
      "grad_norm": 0.006179517135024071,
      "learning_rate": 0.00010012511228025151,
      "loss": 0.0,
      "step": 124650
    },
    {
      "epoch": 8.000769921724626,
      "grad_norm": 0.018365953117609024,
      "learning_rate": 9.99647119209547e-05,
      "loss": 0.0,
      "step": 124700
    },
    {
      "epoch": 8.00397792891056,
      "grad_norm": 0.01796356774866581,
      "learning_rate": 9.98043115616579e-05,
      "loss": 0.0,
      "step": 124750
    },
    {
      "epoch": 8.007185936096496,
      "grad_norm": 0.01098989974707365,
      "learning_rate": 9.964391120236109e-05,
      "loss": 0.0,
      "step": 124800
    },
    {
      "epoch": 8.010393943282432,
      "grad_norm": 0.001913144369609654,
      "learning_rate": 9.948351084306428e-05,
      "loss": 0.0,
      "step": 124850
    },
    {
      "epoch": 8.013601950468368,
      "grad_norm": 0.012699127197265625,
      "learning_rate": 9.932311048376749e-05,
      "loss": 0.0,
      "step": 124900
    },
    {
      "epoch": 8.016809957654305,
      "grad_norm": 0.014243464916944504,
      "learning_rate": 9.916271012447068e-05,
      "loss": 0.0,
      "step": 124950
    },
    {
      "epoch": 8.02001796484024,
      "grad_norm": 0.010807509534060955,
      "learning_rate": 9.900230976517388e-05,
      "loss": 0.0,
      "step": 125000
    },
    {
      "epoch": 8.023225972026177,
      "grad_norm": 0.01534375362098217,
      "learning_rate": 9.884190940587707e-05,
      "loss": 0.0,
      "step": 125050
    },
    {
      "epoch": 8.026433979212113,
      "grad_norm": 0.0018513925606384873,
      "learning_rate": 9.868150904658026e-05,
      "loss": 0.0,
      "step": 125100
    },
    {
      "epoch": 8.02964198639805,
      "grad_norm": 0.0073201763443648815,
      "learning_rate": 9.852110868728346e-05,
      "loss": 0.0,
      "step": 125150
    },
    {
      "epoch": 8.032849993583985,
      "grad_norm": 0.00867330003529787,
      "learning_rate": 9.836070832798666e-05,
      "loss": 0.0,
      "step": 125200
    },
    {
      "epoch": 8.036058000769922,
      "grad_norm": 0.013291440904140472,
      "learning_rate": 9.820030796868986e-05,
      "loss": 0.0,
      "step": 125250
    },
    {
      "epoch": 8.039266007955858,
      "grad_norm": 0.005519127938896418,
      "learning_rate": 9.803990760939305e-05,
      "loss": 0.0,
      "step": 125300
    },
    {
      "epoch": 8.042474015141794,
      "grad_norm": 0.006203654687851667,
      "learning_rate": 9.787950725009625e-05,
      "loss": 0.0,
      "step": 125350
    },
    {
      "epoch": 8.04568202232773,
      "grad_norm": 0.00769837386906147,
      "learning_rate": 9.771910689079944e-05,
      "loss": 0.0,
      "step": 125400
    },
    {
      "epoch": 8.048890029513666,
      "grad_norm": 0.0045163314789533615,
      "learning_rate": 9.755870653150263e-05,
      "loss": 0.0,
      "step": 125450
    },
    {
      "epoch": 8.052098036699602,
      "grad_norm": 0.009237254969775677,
      "learning_rate": 9.739830617220583e-05,
      "loss": 0.0,
      "step": 125500
    },
    {
      "epoch": 8.055306043885539,
      "grad_norm": 0.002039267448708415,
      "learning_rate": 9.723790581290902e-05,
      "loss": 0.0,
      "step": 125550
    },
    {
      "epoch": 8.058514051071475,
      "grad_norm": 0.012547830119729042,
      "learning_rate": 9.707750545361221e-05,
      "loss": 0.0,
      "step": 125600
    },
    {
      "epoch": 8.061722058257411,
      "grad_norm": 0.01675141043961048,
      "learning_rate": 9.69171050943154e-05,
      "loss": 0.0,
      "step": 125650
    },
    {
      "epoch": 8.064930065443347,
      "grad_norm": 0.004193486180156469,
      "learning_rate": 9.67567047350186e-05,
      "loss": 0.0,
      "step": 125700
    },
    {
      "epoch": 8.068138072629283,
      "grad_norm": 0.0067757051438093185,
      "learning_rate": 9.659630437572179e-05,
      "loss": 0.0,
      "step": 125750
    },
    {
      "epoch": 8.07134607981522,
      "grad_norm": 0.004922047723084688,
      "learning_rate": 9.6435904016425e-05,
      "loss": 0.0,
      "step": 125800
    },
    {
      "epoch": 8.074554087001156,
      "grad_norm": 0.009378673508763313,
      "learning_rate": 9.62755036571282e-05,
      "loss": 0.0,
      "step": 125850
    },
    {
      "epoch": 8.077762094187092,
      "grad_norm": 0.004135529976338148,
      "learning_rate": 9.61151032978314e-05,
      "loss": 0.0,
      "step": 125900
    },
    {
      "epoch": 8.080970101373026,
      "grad_norm": 0.010479230433702469,
      "learning_rate": 9.595470293853459e-05,
      "loss": 0.0,
      "step": 125950
    },
    {
      "epoch": 8.084178108558962,
      "grad_norm": 0.015090622939169407,
      "learning_rate": 9.579430257923779e-05,
      "loss": 0.0,
      "step": 126000
    },
    {
      "epoch": 8.087386115744899,
      "grad_norm": 0.006269415840506554,
      "learning_rate": 9.563390221994098e-05,
      "loss": 0.0,
      "step": 126050
    },
    {
      "epoch": 8.090594122930835,
      "grad_norm": 0.00796839315444231,
      "learning_rate": 9.547350186064417e-05,
      "loss": 0.0,
      "step": 126100
    },
    {
      "epoch": 8.09380213011677,
      "grad_norm": 0.012231234461069107,
      "learning_rate": 9.531310150134737e-05,
      "loss": 0.0,
      "step": 126150
    },
    {
      "epoch": 8.097010137302707,
      "grad_norm": 0.009061186574399471,
      "learning_rate": 9.515270114205056e-05,
      "loss": 0.0,
      "step": 126200
    },
    {
      "epoch": 8.100218144488643,
      "grad_norm": 0.010527634993195534,
      "learning_rate": 9.499230078275375e-05,
      "loss": 0.0,
      "step": 126250
    },
    {
      "epoch": 8.10342615167458,
      "grad_norm": 0.0023758106399327517,
      "learning_rate": 9.483190042345695e-05,
      "loss": 0.0,
      "step": 126300
    },
    {
      "epoch": 8.106634158860516,
      "grad_norm": 0.0021204124204814434,
      "learning_rate": 9.467150006416014e-05,
      "loss": 0.0,
      "step": 126350
    },
    {
      "epoch": 8.109842166046452,
      "grad_norm": 0.002277497434988618,
      "learning_rate": 9.451109970486333e-05,
      "loss": 0.0,
      "step": 126400
    },
    {
      "epoch": 8.113050173232388,
      "grad_norm": 0.00373480306006968,
      "learning_rate": 9.435069934556653e-05,
      "loss": 0.0,
      "step": 126450
    },
    {
      "epoch": 8.116258180418324,
      "grad_norm": 0.009624538943171501,
      "learning_rate": 9.419029898626972e-05,
      "loss": 0.0,
      "step": 126500
    },
    {
      "epoch": 8.11946618760426,
      "grad_norm": 0.0064725750125944614,
      "learning_rate": 9.402989862697293e-05,
      "loss": 0.0,
      "step": 126550
    },
    {
      "epoch": 8.122674194790196,
      "grad_norm": 0.011129061691462994,
      "learning_rate": 9.386949826767612e-05,
      "loss": 0.0,
      "step": 126600
    },
    {
      "epoch": 8.125882201976133,
      "grad_norm": 0.0031808223575353622,
      "learning_rate": 9.370909790837933e-05,
      "loss": 0.0,
      "step": 126650
    },
    {
      "epoch": 8.129090209162069,
      "grad_norm": 0.003082866547629237,
      "learning_rate": 9.354869754908252e-05,
      "loss": 0.0,
      "step": 126700
    },
    {
      "epoch": 8.132298216348005,
      "grad_norm": 0.008124628104269505,
      "learning_rate": 9.338829718978571e-05,
      "loss": 0.0,
      "step": 126750
    },
    {
      "epoch": 8.135506223533941,
      "grad_norm": 0.01603950932621956,
      "learning_rate": 9.322789683048891e-05,
      "loss": 0.0,
      "step": 126800
    },
    {
      "epoch": 8.138714230719877,
      "grad_norm": 0.005127147305756807,
      "learning_rate": 9.30674964711921e-05,
      "loss": 0.0,
      "step": 126850
    },
    {
      "epoch": 8.141922237905813,
      "grad_norm": 0.009812499396502972,
      "learning_rate": 9.29070961118953e-05,
      "loss": 0.0,
      "step": 126900
    },
    {
      "epoch": 8.14513024509175,
      "grad_norm": 0.0005092652863822877,
      "learning_rate": 9.274669575259849e-05,
      "loss": 0.0,
      "step": 126950
    },
    {
      "epoch": 8.148338252277686,
      "grad_norm": 0.003915973007678986,
      "learning_rate": 9.258629539330168e-05,
      "loss": 0.0,
      "step": 127000
    },
    {
      "epoch": 8.151546259463622,
      "grad_norm": 0.009087590500712395,
      "learning_rate": 9.242589503400487e-05,
      "loss": 0.0,
      "step": 127050
    },
    {
      "epoch": 8.154754266649558,
      "grad_norm": 0.008553696796298027,
      "learning_rate": 9.226549467470807e-05,
      "loss": 0.0,
      "step": 127100
    },
    {
      "epoch": 8.157962273835494,
      "grad_norm": 0.006237217225134373,
      "learning_rate": 9.210509431541126e-05,
      "loss": 0.0,
      "step": 127150
    },
    {
      "epoch": 8.16117028102143,
      "grad_norm": 0.007037527859210968,
      "learning_rate": 9.194469395611445e-05,
      "loss": 0.0,
      "step": 127200
    },
    {
      "epoch": 8.164378288207365,
      "grad_norm": 0.009051279164850712,
      "learning_rate": 9.178429359681766e-05,
      "loss": 0.0,
      "step": 127250
    },
    {
      "epoch": 8.167586295393301,
      "grad_norm": 0.0018059719586744905,
      "learning_rate": 9.162389323752086e-05,
      "loss": 0.0,
      "step": 127300
    },
    {
      "epoch": 8.170794302579237,
      "grad_norm": 0.006396302953362465,
      "learning_rate": 9.146349287822405e-05,
      "loss": 0.0,
      "step": 127350
    },
    {
      "epoch": 8.174002309765173,
      "grad_norm": 0.012340057641267776,
      "learning_rate": 9.130309251892724e-05,
      "loss": 0.0,
      "step": 127400
    },
    {
      "epoch": 8.17721031695111,
      "grad_norm": 0.0037136885803192854,
      "learning_rate": 9.114269215963044e-05,
      "loss": 0.0,
      "step": 127450
    },
    {
      "epoch": 8.180418324137046,
      "grad_norm": 0.010792973451316357,
      "learning_rate": 9.098229180033364e-05,
      "loss": 0.0,
      "step": 127500
    },
    {
      "epoch": 8.183626331322982,
      "grad_norm": 0.0033311909064650536,
      "learning_rate": 9.082189144103684e-05,
      "loss": 0.0,
      "step": 127550
    },
    {
      "epoch": 8.186834338508918,
      "grad_norm": 0.0012154884170740843,
      "learning_rate": 9.066149108174003e-05,
      "loss": 0.0,
      "step": 127600
    },
    {
      "epoch": 8.190042345694854,
      "grad_norm": 0.006157407537102699,
      "learning_rate": 9.050109072244322e-05,
      "loss": 0.0,
      "step": 127650
    },
    {
      "epoch": 8.19325035288079,
      "grad_norm": 0.008341265842318535,
      "learning_rate": 9.034069036314642e-05,
      "loss": 0.0,
      "step": 127700
    },
    {
      "epoch": 8.196458360066726,
      "grad_norm": 0.00698840944096446,
      "learning_rate": 9.018029000384961e-05,
      "loss": 0.0,
      "step": 127750
    },
    {
      "epoch": 8.199666367252663,
      "grad_norm": 0.0064593106508255005,
      "learning_rate": 9.00198896445528e-05,
      "loss": 0.0,
      "step": 127800
    },
    {
      "epoch": 8.202874374438599,
      "grad_norm": 0.008425088599324226,
      "learning_rate": 8.9859489285256e-05,
      "loss": 0.0,
      "step": 127850
    },
    {
      "epoch": 8.206082381624535,
      "grad_norm": 0.0060037788935005665,
      "learning_rate": 8.969908892595919e-05,
      "loss": 0.0,
      "step": 127900
    },
    {
      "epoch": 8.209290388810471,
      "grad_norm": 0.0056325821205973625,
      "learning_rate": 8.95386885666624e-05,
      "loss": 0.0,
      "step": 127950
    },
    {
      "epoch": 8.212498395996407,
      "grad_norm": 0.01277738157659769,
      "learning_rate": 8.937828820736559e-05,
      "loss": 0.0,
      "step": 128000
    },
    {
      "epoch": 8.215706403182343,
      "grad_norm": 0.009829452261328697,
      "learning_rate": 8.921788784806878e-05,
      "loss": 0.0,
      "step": 128050
    },
    {
      "epoch": 8.21891441036828,
      "grad_norm": 0.011519829742610455,
      "learning_rate": 8.905748748877198e-05,
      "loss": 0.0,
      "step": 128100
    },
    {
      "epoch": 8.222122417554216,
      "grad_norm": 0.004162532743066549,
      "learning_rate": 8.889708712947517e-05,
      "loss": 0.0,
      "step": 128150
    },
    {
      "epoch": 8.225330424740152,
      "grad_norm": 0.0015025107422843575,
      "learning_rate": 8.873668677017836e-05,
      "loss": 0.0,
      "step": 128200
    },
    {
      "epoch": 8.228538431926088,
      "grad_norm": 0.01173360738903284,
      "learning_rate": 8.857628641088156e-05,
      "loss": 0.0,
      "step": 128250
    },
    {
      "epoch": 8.231746439112024,
      "grad_norm": 0.0020828852429986,
      "learning_rate": 8.841588605158475e-05,
      "loss": 0.0,
      "step": 128300
    },
    {
      "epoch": 8.23495444629796,
      "grad_norm": 0.00966288335621357,
      "learning_rate": 8.825548569228794e-05,
      "loss": 0.0,
      "step": 128350
    },
    {
      "epoch": 8.238162453483897,
      "grad_norm": 0.007054212968796492,
      "learning_rate": 8.809508533299115e-05,
      "loss": 0.0,
      "step": 128400
    },
    {
      "epoch": 8.241370460669831,
      "grad_norm": 0.0125083914026618,
      "learning_rate": 8.793468497369434e-05,
      "loss": 0.0,
      "step": 128450
    },
    {
      "epoch": 8.244578467855767,
      "grad_norm": 0.001990229357033968,
      "learning_rate": 8.777428461439754e-05,
      "loss": 0.0,
      "step": 128500
    },
    {
      "epoch": 8.247786475041703,
      "grad_norm": 0.00489080511033535,
      "learning_rate": 8.761388425510073e-05,
      "loss": 0.0,
      "step": 128550
    },
    {
      "epoch": 8.25099448222764,
      "grad_norm": 0.005406618118286133,
      "learning_rate": 8.745348389580394e-05,
      "loss": 0.0,
      "step": 128600
    },
    {
      "epoch": 8.254202489413576,
      "grad_norm": 0.00837595947086811,
      "learning_rate": 8.729308353650713e-05,
      "loss": 0.0,
      "step": 128650
    },
    {
      "epoch": 8.257410496599512,
      "grad_norm": 0.011592582799494267,
      "learning_rate": 8.713268317721032e-05,
      "loss": 0.0,
      "step": 128700
    },
    {
      "epoch": 8.260618503785448,
      "grad_norm": 0.005705907009541988,
      "learning_rate": 8.697228281791352e-05,
      "loss": 0.0,
      "step": 128750
    },
    {
      "epoch": 8.263826510971384,
      "grad_norm": 0.00765657564625144,
      "learning_rate": 8.681188245861671e-05,
      "loss": 0.0,
      "step": 128800
    },
    {
      "epoch": 8.26703451815732,
      "grad_norm": 0.00526795070618391,
      "learning_rate": 8.66514820993199e-05,
      "loss": 0.0,
      "step": 128850
    },
    {
      "epoch": 8.270242525343257,
      "grad_norm": 0.006759408861398697,
      "learning_rate": 8.64910817400231e-05,
      "loss": 0.0,
      "step": 128900
    },
    {
      "epoch": 8.273450532529193,
      "grad_norm": 0.0074004437774419785,
      "learning_rate": 8.633068138072629e-05,
      "loss": 0.0,
      "step": 128950
    },
    {
      "epoch": 8.276658539715129,
      "grad_norm": 0.003998894244432449,
      "learning_rate": 8.617028102142948e-05,
      "loss": 0.0,
      "step": 129000
    },
    {
      "epoch": 8.279866546901065,
      "grad_norm": 0.01654091849923134,
      "learning_rate": 8.600988066213268e-05,
      "loss": 0.0,
      "step": 129050
    },
    {
      "epoch": 8.283074554087001,
      "grad_norm": 0.01022404059767723,
      "learning_rate": 8.584948030283587e-05,
      "loss": 0.0,
      "step": 129100
    },
    {
      "epoch": 8.286282561272937,
      "grad_norm": 0.009674928151071072,
      "learning_rate": 8.568907994353907e-05,
      "loss": 0.0,
      "step": 129150
    },
    {
      "epoch": 8.289490568458874,
      "grad_norm": 0.0047592888586223125,
      "learning_rate": 8.552867958424226e-05,
      "loss": 0.0,
      "step": 129200
    },
    {
      "epoch": 8.29269857564481,
      "grad_norm": 0.010191050358116627,
      "learning_rate": 8.536827922494547e-05,
      "loss": 0.0,
      "step": 129250
    },
    {
      "epoch": 8.295906582830746,
      "grad_norm": 0.001287607243284583,
      "learning_rate": 8.520787886564867e-05,
      "loss": 0.0,
      "step": 129300
    },
    {
      "epoch": 8.299114590016682,
      "grad_norm": 0.012177513912320137,
      "learning_rate": 8.504747850635187e-05,
      "loss": 0.0,
      "step": 129350
    },
    {
      "epoch": 8.302322597202618,
      "grad_norm": 0.010360604152083397,
      "learning_rate": 8.488707814705506e-05,
      "loss": 0.0,
      "step": 129400
    },
    {
      "epoch": 8.305530604388554,
      "grad_norm": 0.006286147516220808,
      "learning_rate": 8.472667778775825e-05,
      "loss": 0.0,
      "step": 129450
    },
    {
      "epoch": 8.30873861157449,
      "grad_norm": 0.001427134615369141,
      "learning_rate": 8.456627742846145e-05,
      "loss": 0.0,
      "step": 129500
    },
    {
      "epoch": 8.311946618760427,
      "grad_norm": 0.006959535181522369,
      "learning_rate": 8.440587706916464e-05,
      "loss": 0.0,
      "step": 129550
    },
    {
      "epoch": 8.315154625946363,
      "grad_norm": 0.003698197426274419,
      "learning_rate": 8.424547670986783e-05,
      "loss": 0.0,
      "step": 129600
    },
    {
      "epoch": 8.318362633132299,
      "grad_norm": 0.014047102071344852,
      "learning_rate": 8.408507635057103e-05,
      "loss": 0.0,
      "step": 129650
    },
    {
      "epoch": 8.321570640318233,
      "grad_norm": 0.011682679876685143,
      "learning_rate": 8.392467599127422e-05,
      "loss": 0.0,
      "step": 129700
    },
    {
      "epoch": 8.32477864750417,
      "grad_norm": 0.0021637280005961657,
      "learning_rate": 8.376427563197741e-05,
      "loss": 0.0,
      "step": 129750
    },
    {
      "epoch": 8.327986654690106,
      "grad_norm": 0.007500918116420507,
      "learning_rate": 8.36038752726806e-05,
      "loss": 0.0,
      "step": 129800
    },
    {
      "epoch": 8.331194661876042,
      "grad_norm": 0.0048416536301374435,
      "learning_rate": 8.34434749133838e-05,
      "loss": 0.0,
      "step": 129850
    },
    {
      "epoch": 8.334402669061978,
      "grad_norm": 0.0072677419520914555,
      "learning_rate": 8.328307455408699e-05,
      "loss": 0.0,
      "step": 129900
    },
    {
      "epoch": 8.337610676247914,
      "grad_norm": 0.005039341747760773,
      "learning_rate": 8.312267419479019e-05,
      "loss": 0.0,
      "step": 129950
    },
    {
      "epoch": 8.34081868343385,
      "grad_norm": 0.0027277376502752304,
      "learning_rate": 8.29622738354934e-05,
      "loss": 0.0,
      "step": 130000
    },
    {
      "epoch": 8.344026690619787,
      "grad_norm": 0.0022342901211231947,
      "learning_rate": 8.280187347619659e-05,
      "loss": 0.0,
      "step": 130050
    },
    {
      "epoch": 8.347234697805723,
      "grad_norm": 0.00264081172645092,
      "learning_rate": 8.26414731168998e-05,
      "loss": 0.0,
      "step": 130100
    },
    {
      "epoch": 8.350442704991659,
      "grad_norm": 0.0020851416047662497,
      "learning_rate": 8.248107275760299e-05,
      "loss": 0.0,
      "step": 130150
    },
    {
      "epoch": 8.353650712177595,
      "grad_norm": 0.007196044083684683,
      "learning_rate": 8.232067239830618e-05,
      "loss": 0.0,
      "step": 130200
    },
    {
      "epoch": 8.356858719363531,
      "grad_norm": 0.002872777869924903,
      "learning_rate": 8.216027203900937e-05,
      "loss": 0.0,
      "step": 130250
    },
    {
      "epoch": 8.360066726549467,
      "grad_norm": 0.007399209309369326,
      "learning_rate": 8.199987167971257e-05,
      "loss": 0.0,
      "step": 130300
    },
    {
      "epoch": 8.363274733735404,
      "grad_norm": 0.008499113842844963,
      "learning_rate": 8.183947132041576e-05,
      "loss": 0.0,
      "step": 130350
    },
    {
      "epoch": 8.36648274092134,
      "grad_norm": 0.0075665987096726894,
      "learning_rate": 8.167907096111895e-05,
      "loss": 0.0,
      "step": 130400
    },
    {
      "epoch": 8.369690748107276,
      "grad_norm": 0.006085650529712439,
      "learning_rate": 8.151867060182215e-05,
      "loss": 0.0,
      "step": 130450
    },
    {
      "epoch": 8.372898755293212,
      "grad_norm": 0.010219253599643707,
      "learning_rate": 8.135827024252534e-05,
      "loss": 0.0,
      "step": 130500
    },
    {
      "epoch": 8.376106762479148,
      "grad_norm": 0.006228539161384106,
      "learning_rate": 8.119786988322853e-05,
      "loss": 0.0,
      "step": 130550
    },
    {
      "epoch": 8.379314769665084,
      "grad_norm": 0.006135397590696812,
      "learning_rate": 8.103746952393173e-05,
      "loss": 0.0,
      "step": 130600
    },
    {
      "epoch": 8.38252277685102,
      "grad_norm": 0.008860258385539055,
      "learning_rate": 8.087706916463493e-05,
      "loss": 0.0,
      "step": 130650
    },
    {
      "epoch": 8.385730784036957,
      "grad_norm": 0.003274590242654085,
      "learning_rate": 8.071666880533813e-05,
      "loss": 0.0,
      "step": 130700
    },
    {
      "epoch": 8.388938791222893,
      "grad_norm": 0.013670016080141068,
      "learning_rate": 8.055626844604132e-05,
      "loss": 0.0,
      "step": 130750
    },
    {
      "epoch": 8.39214679840883,
      "grad_norm": 0.005750072188675404,
      "learning_rate": 8.039586808674451e-05,
      "loss": 0.0,
      "step": 130800
    },
    {
      "epoch": 8.395354805594765,
      "grad_norm": 0.0008659425075165927,
      "learning_rate": 8.023546772744771e-05,
      "loss": 0.0,
      "step": 130850
    },
    {
      "epoch": 8.3985628127807,
      "grad_norm": 0.008312077261507511,
      "learning_rate": 8.00750673681509e-05,
      "loss": 0.0,
      "step": 130900
    },
    {
      "epoch": 8.401770819966636,
      "grad_norm": 0.002084073144942522,
      "learning_rate": 7.991466700885411e-05,
      "loss": 0.0,
      "step": 130950
    },
    {
      "epoch": 8.404978827152572,
      "grad_norm": 0.0033103497698903084,
      "learning_rate": 7.97542666495573e-05,
      "loss": 0.0,
      "step": 131000
    },
    {
      "epoch": 8.408186834338508,
      "grad_norm": 0.001402700087055564,
      "learning_rate": 7.95938662902605e-05,
      "loss": 0.0,
      "step": 131050
    },
    {
      "epoch": 8.411394841524444,
      "grad_norm": 0.005213816650211811,
      "learning_rate": 7.943346593096369e-05,
      "loss": 0.0,
      "step": 131100
    },
    {
      "epoch": 8.41460284871038,
      "grad_norm": 0.004955482669174671,
      "learning_rate": 7.927306557166688e-05,
      "loss": 0.0,
      "step": 131150
    },
    {
      "epoch": 8.417810855896317,
      "grad_norm": 0.007916542701423168,
      "learning_rate": 7.911266521237008e-05,
      "loss": 0.0,
      "step": 131200
    },
    {
      "epoch": 8.421018863082253,
      "grad_norm": 0.01238224096596241,
      "learning_rate": 7.895226485307327e-05,
      "loss": 0.0,
      "step": 131250
    },
    {
      "epoch": 8.424226870268189,
      "grad_norm": 0.004842428956180811,
      "learning_rate": 7.879186449377646e-05,
      "loss": 0.0,
      "step": 131300
    },
    {
      "epoch": 8.427434877454125,
      "grad_norm": 0.009102310985326767,
      "learning_rate": 7.863146413447967e-05,
      "loss": 0.0,
      "step": 131350
    },
    {
      "epoch": 8.430642884640061,
      "grad_norm": 0.0029614800587296486,
      "learning_rate": 7.847106377518286e-05,
      "loss": 0.0,
      "step": 131400
    },
    {
      "epoch": 8.433850891825998,
      "grad_norm": 0.010443340986967087,
      "learning_rate": 7.831066341588606e-05,
      "loss": 0.0,
      "step": 131450
    },
    {
      "epoch": 8.437058899011934,
      "grad_norm": 0.0036714982707053423,
      "learning_rate": 7.815026305658925e-05,
      "loss": 0.0,
      "step": 131500
    },
    {
      "epoch": 8.44026690619787,
      "grad_norm": 0.0021820291876792908,
      "learning_rate": 7.798986269729244e-05,
      "loss": 0.0,
      "step": 131550
    },
    {
      "epoch": 8.443474913383806,
      "grad_norm": 0.0076613035053014755,
      "learning_rate": 7.782946233799564e-05,
      "loss": 0.0,
      "step": 131600
    },
    {
      "epoch": 8.446682920569742,
      "grad_norm": 0.017507992684841156,
      "learning_rate": 7.766906197869883e-05,
      "loss": 0.0,
      "step": 131650
    },
    {
      "epoch": 8.449890927755678,
      "grad_norm": 0.001128862495534122,
      "learning_rate": 7.750866161940202e-05,
      "loss": 0.0,
      "step": 131700
    },
    {
      "epoch": 8.453098934941615,
      "grad_norm": 0.004700425546616316,
      "learning_rate": 7.734826126010522e-05,
      "loss": 0.0,
      "step": 131750
    },
    {
      "epoch": 8.45630694212755,
      "grad_norm": 0.00954331737011671,
      "learning_rate": 7.718786090080841e-05,
      "loss": 0.0,
      "step": 131800
    },
    {
      "epoch": 8.459514949313487,
      "grad_norm": 0.005124768707901239,
      "learning_rate": 7.702746054151162e-05,
      "loss": 0.0,
      "step": 131850
    },
    {
      "epoch": 8.462722956499423,
      "grad_norm": 0.006643048487603664,
      "learning_rate": 7.686706018221481e-05,
      "loss": 0.0,
      "step": 131900
    },
    {
      "epoch": 8.46593096368536,
      "grad_norm": 0.010020163841545582,
      "learning_rate": 7.6706659822918e-05,
      "loss": 0.0,
      "step": 131950
    },
    {
      "epoch": 8.469138970871295,
      "grad_norm": 0.007072631735354662,
      "learning_rate": 7.654625946362121e-05,
      "loss": 0.0,
      "step": 132000
    },
    {
      "epoch": 8.472346978057232,
      "grad_norm": 0.005380159243941307,
      "learning_rate": 7.63858591043244e-05,
      "loss": 0.0,
      "step": 132050
    },
    {
      "epoch": 8.475554985243168,
      "grad_norm": 0.003006292274221778,
      "learning_rate": 7.62254587450276e-05,
      "loss": 0.0,
      "step": 132100
    },
    {
      "epoch": 8.478762992429104,
      "grad_norm": 0.007929550483822823,
      "learning_rate": 7.606505838573079e-05,
      "loss": 0.0,
      "step": 132150
    },
    {
      "epoch": 8.481970999615038,
      "grad_norm": 0.004355449695140123,
      "learning_rate": 7.590465802643398e-05,
      "loss": 0.0,
      "step": 132200
    },
    {
      "epoch": 8.485179006800974,
      "grad_norm": 0.008863399736583233,
      "learning_rate": 7.574425766713718e-05,
      "loss": 0.0,
      "step": 132250
    },
    {
      "epoch": 8.48838701398691,
      "grad_norm": 0.004054153338074684,
      "learning_rate": 7.558385730784037e-05,
      "loss": 0.0,
      "step": 132300
    },
    {
      "epoch": 8.491595021172847,
      "grad_norm": 0.00991472415626049,
      "learning_rate": 7.542345694854356e-05,
      "loss": 0.0,
      "step": 132350
    },
    {
      "epoch": 8.494803028358783,
      "grad_norm": 0.007585498038679361,
      "learning_rate": 7.526305658924676e-05,
      "loss": 0.0,
      "step": 132400
    },
    {
      "epoch": 8.49801103554472,
      "grad_norm": 0.004244809038937092,
      "learning_rate": 7.510265622994995e-05,
      "loss": 0.0,
      "step": 132450
    },
    {
      "epoch": 8.501219042730655,
      "grad_norm": 0.007937747985124588,
      "learning_rate": 7.494225587065314e-05,
      "loss": 0.0,
      "step": 132500
    },
    {
      "epoch": 8.504427049916591,
      "grad_norm": 0.008814328350126743,
      "learning_rate": 7.478185551135634e-05,
      "loss": 0.0,
      "step": 132550
    },
    {
      "epoch": 8.507635057102528,
      "grad_norm": 0.006104394793510437,
      "learning_rate": 7.462145515205953e-05,
      "loss": 0.0,
      "step": 132600
    },
    {
      "epoch": 8.510843064288464,
      "grad_norm": 0.007933109998703003,
      "learning_rate": 7.446105479276272e-05,
      "loss": 0.0,
      "step": 132650
    },
    {
      "epoch": 8.5140510714744,
      "grad_norm": 0.012646217830479145,
      "learning_rate": 7.430065443346595e-05,
      "loss": 0.0,
      "step": 132700
    },
    {
      "epoch": 8.517259078660336,
      "grad_norm": 0.011005917564034462,
      "learning_rate": 7.414025407416914e-05,
      "loss": 0.0,
      "step": 132750
    },
    {
      "epoch": 8.520467085846272,
      "grad_norm": 0.004371188580989838,
      "learning_rate": 7.397985371487233e-05,
      "loss": 0.0,
      "step": 132800
    },
    {
      "epoch": 8.523675093032208,
      "grad_norm": 0.0057043349370360374,
      "learning_rate": 7.381945335557553e-05,
      "loss": 0.0,
      "step": 132850
    },
    {
      "epoch": 8.526883100218145,
      "grad_norm": 0.012187556363642216,
      "learning_rate": 7.365905299627872e-05,
      "loss": 0.0,
      "step": 132900
    },
    {
      "epoch": 8.53009110740408,
      "grad_norm": 0.004332556389272213,
      "learning_rate": 7.349865263698191e-05,
      "loss": 0.0,
      "step": 132950
    },
    {
      "epoch": 8.533299114590017,
      "grad_norm": 0.003534469287842512,
      "learning_rate": 7.33382522776851e-05,
      "loss": 0.0,
      "step": 133000
    },
    {
      "epoch": 8.536507121775953,
      "grad_norm": 0.00448374031111598,
      "learning_rate": 7.31778519183883e-05,
      "loss": 0.0,
      "step": 133050
    },
    {
      "epoch": 8.53971512896189,
      "grad_norm": 0.007100854534655809,
      "learning_rate": 7.301745155909149e-05,
      "loss": 0.0,
      "step": 133100
    },
    {
      "epoch": 8.542923136147826,
      "grad_norm": 0.007663855794817209,
      "learning_rate": 7.285705119979469e-05,
      "loss": 0.0,
      "step": 133150
    },
    {
      "epoch": 8.546131143333762,
      "grad_norm": 0.0011585911270231009,
      "learning_rate": 7.269665084049788e-05,
      "loss": 0.0,
      "step": 133200
    },
    {
      "epoch": 8.549339150519698,
      "grad_norm": 0.020861390978097916,
      "learning_rate": 7.253625048120107e-05,
      "loss": 0.0,
      "step": 133250
    },
    {
      "epoch": 8.552547157705634,
      "grad_norm": 0.0037556763272732496,
      "learning_rate": 7.237585012190427e-05,
      "loss": 0.0,
      "step": 133300
    },
    {
      "epoch": 8.55575516489157,
      "grad_norm": 0.004186837002635002,
      "learning_rate": 7.221544976260746e-05,
      "loss": 0.0,
      "step": 133350
    },
    {
      "epoch": 8.558963172077505,
      "grad_norm": 0.003980901557952166,
      "learning_rate": 7.205504940331067e-05,
      "loss": 0.0,
      "step": 133400
    },
    {
      "epoch": 8.56217117926344,
      "grad_norm": 0.0031424404587596655,
      "learning_rate": 7.189464904401386e-05,
      "loss": 0.0,
      "step": 133450
    },
    {
      "epoch": 8.565379186449377,
      "grad_norm": 0.004252604674547911,
      "learning_rate": 7.173424868471705e-05,
      "loss": 0.0,
      "step": 133500
    },
    {
      "epoch": 8.568587193635313,
      "grad_norm": 0.01129587460309267,
      "learning_rate": 7.157384832542026e-05,
      "loss": 0.0,
      "step": 133550
    },
    {
      "epoch": 8.57179520082125,
      "grad_norm": 0.006483563221991062,
      "learning_rate": 7.141344796612345e-05,
      "loss": 0.0,
      "step": 133600
    },
    {
      "epoch": 8.575003208007185,
      "grad_norm": 0.0020006392151117325,
      "learning_rate": 7.125304760682665e-05,
      "loss": 0.0,
      "step": 133650
    },
    {
      "epoch": 8.578211215193122,
      "grad_norm": 0.008781444281339645,
      "learning_rate": 7.109264724752984e-05,
      "loss": 0.0,
      "step": 133700
    },
    {
      "epoch": 8.581419222379058,
      "grad_norm": 0.008274075575172901,
      "learning_rate": 7.093224688823303e-05,
      "loss": 0.0,
      "step": 133750
    },
    {
      "epoch": 8.584627229564994,
      "grad_norm": 0.0071003371849656105,
      "learning_rate": 7.077184652893623e-05,
      "loss": 0.0,
      "step": 133800
    },
    {
      "epoch": 8.58783523675093,
      "grad_norm": 0.0038324252236634493,
      "learning_rate": 7.061144616963942e-05,
      "loss": 0.0,
      "step": 133850
    },
    {
      "epoch": 8.591043243936866,
      "grad_norm": 0.0011681141331791878,
      "learning_rate": 7.045104581034261e-05,
      "loss": 0.0,
      "step": 133900
    },
    {
      "epoch": 8.594251251122802,
      "grad_norm": 0.005739912856370211,
      "learning_rate": 7.029064545104581e-05,
      "loss": 0.0,
      "step": 133950
    },
    {
      "epoch": 8.597459258308739,
      "grad_norm": 0.02314426191151142,
      "learning_rate": 7.0130245091749e-05,
      "loss": 0.0,
      "step": 134000
    },
    {
      "epoch": 8.600667265494675,
      "grad_norm": 0.005653351079672575,
      "learning_rate": 6.99698447324522e-05,
      "loss": 0.0,
      "step": 134050
    },
    {
      "epoch": 8.603875272680611,
      "grad_norm": 0.008766722865402699,
      "learning_rate": 6.98094443731554e-05,
      "loss": 0.0,
      "step": 134100
    },
    {
      "epoch": 8.607083279866547,
      "grad_norm": 0.005889187101274729,
      "learning_rate": 6.96490440138586e-05,
      "loss": 0.0,
      "step": 134150
    },
    {
      "epoch": 8.610291287052483,
      "grad_norm": 0.006109984591603279,
      "learning_rate": 6.948864365456179e-05,
      "loss": 0.0,
      "step": 134200
    },
    {
      "epoch": 8.61349929423842,
      "grad_norm": 0.006945481523871422,
      "learning_rate": 6.932824329526498e-05,
      "loss": 0.0,
      "step": 134250
    },
    {
      "epoch": 8.616707301424356,
      "grad_norm": 0.006754762027412653,
      "learning_rate": 6.916784293596817e-05,
      "loss": 0.0,
      "step": 134300
    },
    {
      "epoch": 8.619915308610292,
      "grad_norm": 0.0031982276123017073,
      "learning_rate": 6.900744257667137e-05,
      "loss": 0.0,
      "step": 134350
    },
    {
      "epoch": 8.623123315796228,
      "grad_norm": 0.011480506509542465,
      "learning_rate": 6.884704221737456e-05,
      "loss": 0.0,
      "step": 134400
    },
    {
      "epoch": 8.626331322982164,
      "grad_norm": 0.0053853862918913364,
      "learning_rate": 6.868664185807777e-05,
      "loss": 0.0,
      "step": 134450
    },
    {
      "epoch": 8.6295393301681,
      "grad_norm": 0.006045630667358637,
      "learning_rate": 6.852624149878096e-05,
      "loss": 0.0,
      "step": 134500
    },
    {
      "epoch": 8.632747337354036,
      "grad_norm": 0.0029134023934602737,
      "learning_rate": 6.836584113948416e-05,
      "loss": 0.0,
      "step": 134550
    },
    {
      "epoch": 8.635955344539973,
      "grad_norm": 0.004500186536461115,
      "learning_rate": 6.820544078018735e-05,
      "loss": 0.0,
      "step": 134600
    },
    {
      "epoch": 8.639163351725909,
      "grad_norm": 0.008993390947580338,
      "learning_rate": 6.804504042089054e-05,
      "loss": 0.0,
      "step": 134650
    },
    {
      "epoch": 8.642371358911843,
      "grad_norm": 0.008363867178559303,
      "learning_rate": 6.788464006159374e-05,
      "loss": 0.0,
      "step": 134700
    },
    {
      "epoch": 8.64557936609778,
      "grad_norm": 0.008278369903564453,
      "learning_rate": 6.772423970229694e-05,
      "loss": 0.0,
      "step": 134750
    },
    {
      "epoch": 8.648787373283715,
      "grad_norm": 0.006275076884776354,
      "learning_rate": 6.756383934300014e-05,
      "loss": 0.0,
      "step": 134800
    },
    {
      "epoch": 8.651995380469652,
      "grad_norm": 0.002299315296113491,
      "learning_rate": 6.740343898370333e-05,
      "loss": 0.0,
      "step": 134850
    },
    {
      "epoch": 8.655203387655588,
      "grad_norm": 0.0035234629176557064,
      "learning_rate": 6.724303862440652e-05,
      "loss": 0.0,
      "step": 134900
    },
    {
      "epoch": 8.658411394841524,
      "grad_norm": 0.004801035393029451,
      "learning_rate": 6.708263826510972e-05,
      "loss": 0.0,
      "step": 134950
    },
    {
      "epoch": 8.66161940202746,
      "grad_norm": 0.0040488336235284805,
      "learning_rate": 6.692223790581291e-05,
      "loss": 0.0,
      "step": 135000
    },
    {
      "epoch": 8.664827409213396,
      "grad_norm": 0.005755864083766937,
      "learning_rate": 6.67618375465161e-05,
      "loss": 0.0,
      "step": 135050
    },
    {
      "epoch": 8.668035416399333,
      "grad_norm": 0.008470005355775356,
      "learning_rate": 6.66014371872193e-05,
      "loss": 0.0,
      "step": 135100
    },
    {
      "epoch": 8.671243423585269,
      "grad_norm": 0.00614888034760952,
      "learning_rate": 6.644103682792249e-05,
      "loss": 0.0,
      "step": 135150
    },
    {
      "epoch": 8.674451430771205,
      "grad_norm": 0.005119773559272289,
      "learning_rate": 6.628063646862568e-05,
      "loss": 0.0,
      "step": 135200
    },
    {
      "epoch": 8.677659437957141,
      "grad_norm": 0.004498374182730913,
      "learning_rate": 6.612023610932888e-05,
      "loss": 0.0,
      "step": 135250
    },
    {
      "epoch": 8.680867445143077,
      "grad_norm": 0.006272574421018362,
      "learning_rate": 6.595983575003208e-05,
      "loss": 0.0,
      "step": 135300
    },
    {
      "epoch": 8.684075452329013,
      "grad_norm": 0.004977688658982515,
      "learning_rate": 6.579943539073528e-05,
      "loss": 0.0,
      "step": 135350
    },
    {
      "epoch": 8.68728345951495,
      "grad_norm": 0.009031719528138638,
      "learning_rate": 6.563903503143847e-05,
      "loss": 0.0,
      "step": 135400
    },
    {
      "epoch": 8.690491466700886,
      "grad_norm": 0.005522989667952061,
      "learning_rate": 6.547863467214168e-05,
      "loss": 0.0,
      "step": 135450
    },
    {
      "epoch": 8.693699473886822,
      "grad_norm": 0.014308376237750053,
      "learning_rate": 6.531823431284487e-05,
      "loss": 0.0,
      "step": 135500
    },
    {
      "epoch": 8.696907481072758,
      "grad_norm": 0.005096307024359703,
      "learning_rate": 6.515783395354806e-05,
      "loss": 0.0,
      "step": 135550
    },
    {
      "epoch": 8.700115488258694,
      "grad_norm": 0.013692567124962807,
      "learning_rate": 6.499743359425126e-05,
      "loss": 0.0,
      "step": 135600
    },
    {
      "epoch": 8.70332349544463,
      "grad_norm": 0.005505424924194813,
      "learning_rate": 6.483703323495445e-05,
      "loss": 0.0,
      "step": 135650
    },
    {
      "epoch": 8.706531502630567,
      "grad_norm": 0.006169917061924934,
      "learning_rate": 6.467663287565764e-05,
      "loss": 0.0,
      "step": 135700
    },
    {
      "epoch": 8.709739509816503,
      "grad_norm": 0.009179774671792984,
      "learning_rate": 6.451623251636084e-05,
      "loss": 0.0,
      "step": 135750
    },
    {
      "epoch": 8.712947517002439,
      "grad_norm": 0.0063867694698274136,
      "learning_rate": 6.435583215706403e-05,
      "loss": 0.0,
      "step": 135800
    },
    {
      "epoch": 8.716155524188373,
      "grad_norm": 0.0038675295654684305,
      "learning_rate": 6.419543179776722e-05,
      "loss": 0.0,
      "step": 135850
    },
    {
      "epoch": 8.71936353137431,
      "grad_norm": 0.007865958847105503,
      "learning_rate": 6.403503143847042e-05,
      "loss": 0.0,
      "step": 135900
    },
    {
      "epoch": 8.722571538560246,
      "grad_norm": 0.003772419411689043,
      "learning_rate": 6.387463107917361e-05,
      "loss": 0.0,
      "step": 135950
    },
    {
      "epoch": 8.725779545746182,
      "grad_norm": 0.01073173526674509,
      "learning_rate": 6.37142307198768e-05,
      "loss": 0.0,
      "step": 136000
    },
    {
      "epoch": 8.728987552932118,
      "grad_norm": 0.005212046671658754,
      "learning_rate": 6.355383036058e-05,
      "loss": 0.0,
      "step": 136050
    },
    {
      "epoch": 8.732195560118054,
      "grad_norm": 0.011924396269023418,
      "learning_rate": 6.339343000128319e-05,
      "loss": 0.0,
      "step": 136100
    },
    {
      "epoch": 8.73540356730399,
      "grad_norm": 0.007077516056597233,
      "learning_rate": 6.323302964198641e-05,
      "loss": 0.0,
      "step": 136150
    },
    {
      "epoch": 8.738611574489926,
      "grad_norm": 0.01247313991189003,
      "learning_rate": 6.30726292826896e-05,
      "loss": 0.0,
      "step": 136200
    },
    {
      "epoch": 8.741819581675863,
      "grad_norm": 0.006402222439646721,
      "learning_rate": 6.29122289233928e-05,
      "loss": 0.0,
      "step": 136250
    },
    {
      "epoch": 8.745027588861799,
      "grad_norm": 0.015753954648971558,
      "learning_rate": 6.275182856409599e-05,
      "loss": 0.0,
      "step": 136300
    },
    {
      "epoch": 8.748235596047735,
      "grad_norm": 0.010370907373726368,
      "learning_rate": 6.259142820479919e-05,
      "loss": 0.0,
      "step": 136350
    },
    {
      "epoch": 8.751443603233671,
      "grad_norm": 0.004969515837728977,
      "learning_rate": 6.243102784550238e-05,
      "loss": 0.0,
      "step": 136400
    },
    {
      "epoch": 8.754651610419607,
      "grad_norm": 0.0019024808425456285,
      "learning_rate": 6.227062748620557e-05,
      "loss": 0.0,
      "step": 136450
    },
    {
      "epoch": 8.757859617605543,
      "grad_norm": 0.004522230010479689,
      "learning_rate": 6.211022712690877e-05,
      "loss": 0.0,
      "step": 136500
    },
    {
      "epoch": 8.76106762479148,
      "grad_norm": 0.002497598761692643,
      "learning_rate": 6.194982676761196e-05,
      "loss": 0.0,
      "step": 136550
    },
    {
      "epoch": 8.764275631977416,
      "grad_norm": 0.005367487668991089,
      "learning_rate": 6.178942640831515e-05,
      "loss": 0.0,
      "step": 136600
    },
    {
      "epoch": 8.767483639163352,
      "grad_norm": 0.004867807030677795,
      "learning_rate": 6.162902604901835e-05,
      "loss": 0.0,
      "step": 136650
    },
    {
      "epoch": 8.770691646349288,
      "grad_norm": 0.0019672573544085026,
      "learning_rate": 6.146862568972154e-05,
      "loss": 0.0,
      "step": 136700
    },
    {
      "epoch": 8.773899653535224,
      "grad_norm": 0.006595931947231293,
      "learning_rate": 6.130822533042473e-05,
      "loss": 0.0,
      "step": 136750
    },
    {
      "epoch": 8.77710766072116,
      "grad_norm": 0.007446611300110817,
      "learning_rate": 6.114782497112794e-05,
      "loss": 0.0,
      "step": 136800
    },
    {
      "epoch": 8.780315667907097,
      "grad_norm": 0.007531184237450361,
      "learning_rate": 6.098742461183113e-05,
      "loss": 0.0,
      "step": 136850
    },
    {
      "epoch": 8.783523675093033,
      "grad_norm": 0.0011025926796719432,
      "learning_rate": 6.0827024252534326e-05,
      "loss": 0.0,
      "step": 136900
    },
    {
      "epoch": 8.786731682278969,
      "grad_norm": 0.004455225542187691,
      "learning_rate": 6.066662389323752e-05,
      "loss": 0.0,
      "step": 136950
    },
    {
      "epoch": 8.789939689464905,
      "grad_norm": 0.002732406137511134,
      "learning_rate": 6.050622353394072e-05,
      "loss": 0.0,
      "step": 137000
    },
    {
      "epoch": 8.793147696650841,
      "grad_norm": 0.006201616488397121,
      "learning_rate": 6.034582317464391e-05,
      "loss": 0.0,
      "step": 137050
    },
    {
      "epoch": 8.796355703836777,
      "grad_norm": 0.006093478295952082,
      "learning_rate": 6.0185422815347107e-05,
      "loss": 0.0,
      "step": 137100
    },
    {
      "epoch": 8.799563711022714,
      "grad_norm": 0.003770332084968686,
      "learning_rate": 6.00250224560503e-05,
      "loss": 0.0,
      "step": 137150
    },
    {
      "epoch": 8.802771718208648,
      "grad_norm": 0.0021175292786210775,
      "learning_rate": 5.986462209675349e-05,
      "loss": 0.0,
      "step": 137200
    },
    {
      "epoch": 8.805979725394584,
      "grad_norm": 0.000683748337905854,
      "learning_rate": 5.9704221737456694e-05,
      "loss": 0.0,
      "step": 137250
    },
    {
      "epoch": 8.80918773258052,
      "grad_norm": 0.0027544056065380573,
      "learning_rate": 5.9543821378159894e-05,
      "loss": 0.0,
      "step": 137300
    },
    {
      "epoch": 8.812395739766457,
      "grad_norm": 0.0017166248289868236,
      "learning_rate": 5.938342101886309e-05,
      "loss": 0.0,
      "step": 137350
    },
    {
      "epoch": 8.815603746952393,
      "grad_norm": 0.006437315605580807,
      "learning_rate": 5.922302065956628e-05,
      "loss": 0.0,
      "step": 137400
    },
    {
      "epoch": 8.818811754138329,
      "grad_norm": 0.0020164891611784697,
      "learning_rate": 5.9062620300269474e-05,
      "loss": 0.0,
      "step": 137450
    },
    {
      "epoch": 8.822019761324265,
      "grad_norm": 0.0021266036201268435,
      "learning_rate": 5.890221994097267e-05,
      "loss": 0.0,
      "step": 137500
    },
    {
      "epoch": 8.825227768510201,
      "grad_norm": 0.005421580746769905,
      "learning_rate": 5.874181958167586e-05,
      "loss": 0.0,
      "step": 137550
    },
    {
      "epoch": 8.828435775696137,
      "grad_norm": 0.003690562676638365,
      "learning_rate": 5.8581419222379054e-05,
      "loss": 0.0,
      "step": 137600
    },
    {
      "epoch": 8.831643782882074,
      "grad_norm": 0.006726567633450031,
      "learning_rate": 5.842101886308226e-05,
      "loss": 0.0,
      "step": 137650
    },
    {
      "epoch": 8.83485179006801,
      "grad_norm": 0.0038847760297358036,
      "learning_rate": 5.8260618503785454e-05,
      "loss": 0.0,
      "step": 137700
    },
    {
      "epoch": 8.838059797253946,
      "grad_norm": 0.010745164938271046,
      "learning_rate": 5.810021814448865e-05,
      "loss": 0.0,
      "step": 137750
    },
    {
      "epoch": 8.841267804439882,
      "grad_norm": 0.007150418125092983,
      "learning_rate": 5.793981778519184e-05,
      "loss": 0.0,
      "step": 137800
    },
    {
      "epoch": 8.844475811625818,
      "grad_norm": 0.0054525877349078655,
      "learning_rate": 5.7779417425895035e-05,
      "loss": 0.0,
      "step": 137850
    },
    {
      "epoch": 8.847683818811754,
      "grad_norm": 0.005477811209857464,
      "learning_rate": 5.761901706659823e-05,
      "loss": 0.0,
      "step": 137900
    },
    {
      "epoch": 8.85089182599769,
      "grad_norm": 0.010450372472405434,
      "learning_rate": 5.745861670730142e-05,
      "loss": 0.0,
      "step": 137950
    },
    {
      "epoch": 8.854099833183627,
      "grad_norm": 0.006656292825937271,
      "learning_rate": 5.729821634800462e-05,
      "loss": 0.0,
      "step": 138000
    },
    {
      "epoch": 8.857307840369563,
      "grad_norm": 0.0032864443492144346,
      "learning_rate": 5.7137815988707815e-05,
      "loss": 0.0,
      "step": 138050
    },
    {
      "epoch": 8.860515847555499,
      "grad_norm": 0.006053573451936245,
      "learning_rate": 5.6977415629411015e-05,
      "loss": 0.0,
      "step": 138100
    },
    {
      "epoch": 8.863723854741435,
      "grad_norm": 0.007357531692832708,
      "learning_rate": 5.681701527011421e-05,
      "loss": 0.0,
      "step": 138150
    },
    {
      "epoch": 8.866931861927371,
      "grad_norm": 0.006572667043656111,
      "learning_rate": 5.66566149108174e-05,
      "loss": 0.0,
      "step": 138200
    },
    {
      "epoch": 8.870139869113308,
      "grad_norm": 0.004486417397856712,
      "learning_rate": 5.6496214551520595e-05,
      "loss": 0.0,
      "step": 138250
    },
    {
      "epoch": 8.873347876299244,
      "grad_norm": 0.013706515543162823,
      "learning_rate": 5.633581419222379e-05,
      "loss": 0.0,
      "step": 138300
    },
    {
      "epoch": 8.876555883485178,
      "grad_norm": 0.0019751142244786024,
      "learning_rate": 5.617541383292699e-05,
      "loss": 0.0,
      "step": 138350
    },
    {
      "epoch": 8.879763890671114,
      "grad_norm": 0.003204879118129611,
      "learning_rate": 5.601501347363018e-05,
      "loss": 0.0,
      "step": 138400
    },
    {
      "epoch": 8.88297189785705,
      "grad_norm": 0.0030491931829601526,
      "learning_rate": 5.5854613114333376e-05,
      "loss": 0.0,
      "step": 138450
    },
    {
      "epoch": 8.886179905042987,
      "grad_norm": 0.003421634202823043,
      "learning_rate": 5.569421275503657e-05,
      "loss": 0.0,
      "step": 138500
    },
    {
      "epoch": 8.889387912228923,
      "grad_norm": 0.0025421485770493746,
      "learning_rate": 5.553381239573977e-05,
      "loss": 0.0,
      "step": 138550
    },
    {
      "epoch": 8.892595919414859,
      "grad_norm": 0.004269592929631472,
      "learning_rate": 5.537341203644296e-05,
      "loss": 0.0,
      "step": 138600
    },
    {
      "epoch": 8.895803926600795,
      "grad_norm": 0.0018407154129818082,
      "learning_rate": 5.5213011677146156e-05,
      "loss": 0.0,
      "step": 138650
    },
    {
      "epoch": 8.899011933786731,
      "grad_norm": 0.004721301607787609,
      "learning_rate": 5.5052611317849356e-05,
      "loss": 0.0,
      "step": 138700
    },
    {
      "epoch": 8.902219940972667,
      "grad_norm": 0.01160445623099804,
      "learning_rate": 5.489221095855255e-05,
      "loss": 0.0,
      "step": 138750
    },
    {
      "epoch": 8.905427948158604,
      "grad_norm": 0.0048903487622737885,
      "learning_rate": 5.473181059925574e-05,
      "loss": 0.0,
      "step": 138800
    },
    {
      "epoch": 8.90863595534454,
      "grad_norm": 0.006792926695197821,
      "learning_rate": 5.4571410239958936e-05,
      "loss": 0.0,
      "step": 138850
    },
    {
      "epoch": 8.911843962530476,
      "grad_norm": 0.005422927904874086,
      "learning_rate": 5.441100988066213e-05,
      "loss": 0.0,
      "step": 138900
    },
    {
      "epoch": 8.915051969716412,
      "grad_norm": 0.0032895817421376705,
      "learning_rate": 5.425060952136533e-05,
      "loss": 0.0,
      "step": 138950
    },
    {
      "epoch": 8.918259976902348,
      "grad_norm": 0.009372273460030556,
      "learning_rate": 5.409020916206852e-05,
      "loss": 0.0,
      "step": 139000
    },
    {
      "epoch": 8.921467984088284,
      "grad_norm": 0.006871446035802364,
      "learning_rate": 5.3929808802771724e-05,
      "loss": 0.0,
      "step": 139050
    },
    {
      "epoch": 8.92467599127422,
      "grad_norm": 0.00676874490454793,
      "learning_rate": 5.376940844347492e-05,
      "loss": 0.0,
      "step": 139100
    },
    {
      "epoch": 8.927883998460157,
      "grad_norm": 0.0052856323309242725,
      "learning_rate": 5.360900808417811e-05,
      "loss": 0.0,
      "step": 139150
    },
    {
      "epoch": 8.931092005646093,
      "grad_norm": 0.007379163987934589,
      "learning_rate": 5.3448607724881304e-05,
      "loss": 0.0,
      "step": 139200
    },
    {
      "epoch": 8.93430001283203,
      "grad_norm": 0.0057146064937114716,
      "learning_rate": 5.32882073655845e-05,
      "loss": 0.0,
      "step": 139250
    },
    {
      "epoch": 8.937508020017965,
      "grad_norm": 0.00608123280107975,
      "learning_rate": 5.312780700628769e-05,
      "loss": 0.0,
      "step": 139300
    },
    {
      "epoch": 8.940716027203901,
      "grad_norm": 0.005571662448346615,
      "learning_rate": 5.2967406646990884e-05,
      "loss": 0.0,
      "step": 139350
    },
    {
      "epoch": 8.943924034389838,
      "grad_norm": 0.00467162299901247,
      "learning_rate": 5.280700628769409e-05,
      "loss": 0.0,
      "step": 139400
    },
    {
      "epoch": 8.947132041575774,
      "grad_norm": 0.011455556377768517,
      "learning_rate": 5.2646605928397284e-05,
      "loss": 0.0,
      "step": 139450
    },
    {
      "epoch": 8.95034004876171,
      "grad_norm": 0.0036269028205424547,
      "learning_rate": 5.248620556910048e-05,
      "loss": 0.0,
      "step": 139500
    },
    {
      "epoch": 8.953548055947646,
      "grad_norm": 0.007066833321005106,
      "learning_rate": 5.232580520980367e-05,
      "loss": 0.0,
      "step": 139550
    },
    {
      "epoch": 8.956756063133582,
      "grad_norm": 0.010198208503425121,
      "learning_rate": 5.2165404850506864e-05,
      "loss": 0.0,
      "step": 139600
    },
    {
      "epoch": 8.959964070319517,
      "grad_norm": 0.004631510004401207,
      "learning_rate": 5.200500449121006e-05,
      "loss": 0.0,
      "step": 139650
    },
    {
      "epoch": 8.963172077505453,
      "grad_norm": 0.007888222113251686,
      "learning_rate": 5.184460413191326e-05,
      "loss": 0.0,
      "step": 139700
    },
    {
      "epoch": 8.966380084691389,
      "grad_norm": 0.002498133573681116,
      "learning_rate": 5.168420377261645e-05,
      "loss": 0.0,
      "step": 139750
    },
    {
      "epoch": 8.969588091877325,
      "grad_norm": 0.007441743742674589,
      "learning_rate": 5.152380341331965e-05,
      "loss": 0.0,
      "step": 139800
    },
    {
      "epoch": 8.972796099063261,
      "grad_norm": 0.006095647346228361,
      "learning_rate": 5.1363403054022845e-05,
      "loss": 0.0,
      "step": 139850
    },
    {
      "epoch": 8.976004106249198,
      "grad_norm": 0.002770295599475503,
      "learning_rate": 5.120300269472604e-05,
      "loss": 0.0,
      "step": 139900
    },
    {
      "epoch": 8.979212113435134,
      "grad_norm": 0.004001435823738575,
      "learning_rate": 5.104260233542923e-05,
      "loss": 0.0,
      "step": 139950
    },
    {
      "epoch": 8.98242012062107,
      "grad_norm": 0.009471546858549118,
      "learning_rate": 5.0882201976132425e-05,
      "loss": 0.0,
      "step": 140000
    },
    {
      "epoch": 8.985628127807006,
      "grad_norm": 0.0069816140457987785,
      "learning_rate": 5.0721801616835625e-05,
      "loss": 0.0,
      "step": 140050
    },
    {
      "epoch": 8.988836134992942,
      "grad_norm": 0.006944557186216116,
      "learning_rate": 5.056140125753882e-05,
      "loss": 0.0,
      "step": 140100
    },
    {
      "epoch": 8.992044142178878,
      "grad_norm": 0.0032248790375888348,
      "learning_rate": 5.040100089824201e-05,
      "loss": 0.0,
      "step": 140150
    },
    {
      "epoch": 8.995252149364815,
      "grad_norm": 0.002140307566151023,
      "learning_rate": 5.0240600538945206e-05,
      "loss": 0.0,
      "step": 140200
    },
    {
      "epoch": 8.99846015655075,
      "grad_norm": 0.002439258387312293,
      "learning_rate": 5.0080200179648406e-05,
      "loss": 0.0,
      "step": 140250
    },
    {
      "epoch": 9.001668163736687,
      "grad_norm": 0.0029565670993179083,
      "learning_rate": 4.99197998203516e-05,
      "loss": 0.0,
      "step": 140300
    },
    {
      "epoch": 9.004876170922623,
      "grad_norm": 0.005414252169430256,
      "learning_rate": 4.975939946105479e-05,
      "loss": 0.0,
      "step": 140350
    },
    {
      "epoch": 9.00808417810856,
      "grad_norm": 0.0025295079685747623,
      "learning_rate": 4.959899910175799e-05,
      "loss": 0.0,
      "step": 140400
    },
    {
      "epoch": 9.011292185294495,
      "grad_norm": 0.008205843158066273,
      "learning_rate": 4.9438598742461186e-05,
      "loss": 0.0,
      "step": 140450
    },
    {
      "epoch": 9.014500192480432,
      "grad_norm": 0.006139851175248623,
      "learning_rate": 4.927819838316438e-05,
      "loss": 0.0,
      "step": 140500
    },
    {
      "epoch": 9.017708199666368,
      "grad_norm": 0.0019135866314172745,
      "learning_rate": 4.911779802386757e-05,
      "loss": 0.0,
      "step": 140550
    },
    {
      "epoch": 9.020916206852304,
      "grad_norm": 0.007471866440027952,
      "learning_rate": 4.8957397664570766e-05,
      "loss": 0.0,
      "step": 140600
    },
    {
      "epoch": 9.02412421403824,
      "grad_norm": 0.006492004729807377,
      "learning_rate": 4.879699730527396e-05,
      "loss": 0.0,
      "step": 140650
    },
    {
      "epoch": 9.027332221224176,
      "grad_norm": 0.005601928569376469,
      "learning_rate": 4.863659694597716e-05,
      "loss": 0.0,
      "step": 140700
    },
    {
      "epoch": 9.030540228410112,
      "grad_norm": 0.007349187973886728,
      "learning_rate": 4.847619658668036e-05,
      "loss": 0.0,
      "step": 140750
    },
    {
      "epoch": 9.033748235596049,
      "grad_norm": 0.007688429672271013,
      "learning_rate": 4.831579622738355e-05,
      "loss": 0.0,
      "step": 140800
    },
    {
      "epoch": 9.036956242781983,
      "grad_norm": 0.0018764697015285492,
      "learning_rate": 4.815539586808675e-05,
      "loss": 0.0,
      "step": 140850
    },
    {
      "epoch": 9.04016424996792,
      "grad_norm": 0.004248021636158228,
      "learning_rate": 4.799499550878994e-05,
      "loss": 0.0,
      "step": 140900
    },
    {
      "epoch": 9.043372257153855,
      "grad_norm": 0.005622915457934141,
      "learning_rate": 4.7834595149493134e-05,
      "loss": 0.0,
      "step": 140950
    },
    {
      "epoch": 9.046580264339791,
      "grad_norm": 0.001804234809242189,
      "learning_rate": 4.767419479019633e-05,
      "loss": 0.0,
      "step": 141000
    },
    {
      "epoch": 9.049788271525728,
      "grad_norm": 0.0038152572233229876,
      "learning_rate": 4.751379443089952e-05,
      "loss": 0.0,
      "step": 141050
    },
    {
      "epoch": 9.052996278711664,
      "grad_norm": 0.00658006826415658,
      "learning_rate": 4.735339407160273e-05,
      "loss": 0.0,
      "step": 141100
    },
    {
      "epoch": 9.0562042858976,
      "grad_norm": 0.006495876237750053,
      "learning_rate": 4.719299371230592e-05,
      "loss": 0.0,
      "step": 141150
    },
    {
      "epoch": 9.059412293083536,
      "grad_norm": 0.003755799261853099,
      "learning_rate": 4.7032593353009114e-05,
      "loss": 0.0,
      "step": 141200
    },
    {
      "epoch": 9.062620300269472,
      "grad_norm": 0.007237092591822147,
      "learning_rate": 4.687219299371231e-05,
      "loss": 0.0,
      "step": 141250
    },
    {
      "epoch": 9.065828307455408,
      "grad_norm": 0.00875684805214405,
      "learning_rate": 4.67117926344155e-05,
      "loss": 0.0,
      "step": 141300
    },
    {
      "epoch": 9.069036314641345,
      "grad_norm": 0.005071978084743023,
      "learning_rate": 4.6551392275118694e-05,
      "loss": 0.0,
      "step": 141350
    },
    {
      "epoch": 9.07224432182728,
      "grad_norm": 0.0032451599836349487,
      "learning_rate": 4.639099191582189e-05,
      "loss": 0.0,
      "step": 141400
    },
    {
      "epoch": 9.075452329013217,
      "grad_norm": 0.0036238026805222034,
      "learning_rate": 4.623059155652509e-05,
      "loss": 0.0,
      "step": 141450
    },
    {
      "epoch": 9.078660336199153,
      "grad_norm": 0.003889586543664336,
      "learning_rate": 4.607019119722828e-05,
      "loss": 0.0,
      "step": 141500
    },
    {
      "epoch": 9.08186834338509,
      "grad_norm": 0.004124439787119627,
      "learning_rate": 4.590979083793148e-05,
      "loss": 0.0,
      "step": 141550
    },
    {
      "epoch": 9.085076350571025,
      "grad_norm": 0.0034564482048153877,
      "learning_rate": 4.5749390478634675e-05,
      "loss": 0.0,
      "step": 141600
    },
    {
      "epoch": 9.088284357756962,
      "grad_norm": 0.01126242708414793,
      "learning_rate": 4.558899011933787e-05,
      "loss": 0.0,
      "step": 141650
    },
    {
      "epoch": 9.091492364942898,
      "grad_norm": 0.0017529213801026344,
      "learning_rate": 4.542858976004106e-05,
      "loss": 0.0,
      "step": 141700
    },
    {
      "epoch": 9.094700372128834,
      "grad_norm": 0.002890723990276456,
      "learning_rate": 4.526818940074426e-05,
      "loss": 0.0,
      "step": 141750
    },
    {
      "epoch": 9.09790837931477,
      "grad_norm": 0.0031521220225840807,
      "learning_rate": 4.5107789041447455e-05,
      "loss": 0.0,
      "step": 141800
    },
    {
      "epoch": 9.101116386500706,
      "grad_norm": 0.007640532683581114,
      "learning_rate": 4.494738868215065e-05,
      "loss": 0.0,
      "step": 141850
    },
    {
      "epoch": 9.104324393686642,
      "grad_norm": 0.0018175600562244654,
      "learning_rate": 4.478698832285384e-05,
      "loss": 0.0,
      "step": 141900
    },
    {
      "epoch": 9.107532400872579,
      "grad_norm": 0.007169421296566725,
      "learning_rate": 4.4626587963557035e-05,
      "loss": 0.0,
      "step": 141950
    },
    {
      "epoch": 9.110740408058515,
      "grad_norm": 0.006122696679085493,
      "learning_rate": 4.4466187604260236e-05,
      "loss": 0.0,
      "step": 142000
    },
    {
      "epoch": 9.113948415244451,
      "grad_norm": 0.003667764365673065,
      "learning_rate": 4.430578724496343e-05,
      "loss": 0.0,
      "step": 142050
    },
    {
      "epoch": 9.117156422430385,
      "grad_norm": 0.009003976359963417,
      "learning_rate": 4.414538688566663e-05,
      "loss": 0.0,
      "step": 142100
    },
    {
      "epoch": 9.120364429616322,
      "grad_norm": 0.004309698008000851,
      "learning_rate": 4.398498652636982e-05,
      "loss": 0.0,
      "step": 142150
    },
    {
      "epoch": 9.123572436802258,
      "grad_norm": 0.006509813945740461,
      "learning_rate": 4.3824586167073016e-05,
      "loss": 0.0,
      "step": 142200
    },
    {
      "epoch": 9.126780443988194,
      "grad_norm": 0.0027597113512456417,
      "learning_rate": 4.366418580777621e-05,
      "loss": 0.0,
      "step": 142250
    },
    {
      "epoch": 9.12998845117413,
      "grad_norm": 0.005938804242759943,
      "learning_rate": 4.35037854484794e-05,
      "loss": 0.0,
      "step": 142300
    },
    {
      "epoch": 9.133196458360066,
      "grad_norm": 0.010059644468128681,
      "learning_rate": 4.3343385089182596e-05,
      "loss": 0.0,
      "step": 142350
    },
    {
      "epoch": 9.136404465546002,
      "grad_norm": 0.01022026501595974,
      "learning_rate": 4.3182984729885796e-05,
      "loss": 0.0,
      "step": 142400
    },
    {
      "epoch": 9.139612472731939,
      "grad_norm": 0.003279773984104395,
      "learning_rate": 4.3022584370588996e-05,
      "loss": 0.0,
      "step": 142450
    },
    {
      "epoch": 9.142820479917875,
      "grad_norm": 0.01017890963703394,
      "learning_rate": 4.286218401129219e-05,
      "loss": 0.0,
      "step": 142500
    },
    {
      "epoch": 9.146028487103811,
      "grad_norm": 0.003086164826527238,
      "learning_rate": 4.270178365199538e-05,
      "loss": 0.0,
      "step": 142550
    },
    {
      "epoch": 9.149236494289747,
      "grad_norm": 0.0014185253530740738,
      "learning_rate": 4.254138329269858e-05,
      "loss": 0.0,
      "step": 142600
    },
    {
      "epoch": 9.152444501475683,
      "grad_norm": 0.0033625205978751183,
      "learning_rate": 4.238098293340177e-05,
      "loss": 0.0,
      "step": 142650
    },
    {
      "epoch": 9.15565250866162,
      "grad_norm": 0.011532079428434372,
      "learning_rate": 4.2220582574104963e-05,
      "loss": 0.0,
      "step": 142700
    },
    {
      "epoch": 9.158860515847556,
      "grad_norm": 0.005391816608607769,
      "learning_rate": 4.206018221480816e-05,
      "loss": 0.0,
      "step": 142750
    },
    {
      "epoch": 9.162068523033492,
      "grad_norm": 0.0055411579087376595,
      "learning_rate": 4.189978185551136e-05,
      "loss": 0.0,
      "step": 142800
    },
    {
      "epoch": 9.165276530219428,
      "grad_norm": 0.006437290459871292,
      "learning_rate": 4.173938149621456e-05,
      "loss": 0.0,
      "step": 142850
    },
    {
      "epoch": 9.168484537405364,
      "grad_norm": 0.005963520612567663,
      "learning_rate": 4.157898113691775e-05,
      "loss": 0.0,
      "step": 142900
    },
    {
      "epoch": 9.1716925445913,
      "grad_norm": 0.006348635070025921,
      "learning_rate": 4.1418580777620944e-05,
      "loss": 0.0,
      "step": 142950
    },
    {
      "epoch": 9.174900551777236,
      "grad_norm": 0.008033585734665394,
      "learning_rate": 4.125818041832414e-05,
      "loss": 0.0,
      "step": 143000
    },
    {
      "epoch": 9.178108558963173,
      "grad_norm": 0.00342956674285233,
      "learning_rate": 4.109778005902733e-05,
      "loss": 0.0,
      "step": 143050
    },
    {
      "epoch": 9.181316566149109,
      "grad_norm": 0.008668738417327404,
      "learning_rate": 4.0937379699730524e-05,
      "loss": 0.0,
      "step": 143100
    },
    {
      "epoch": 9.184524573335045,
      "grad_norm": 0.003722704481333494,
      "learning_rate": 4.0776979340433724e-05,
      "loss": 0.0,
      "step": 143150
    },
    {
      "epoch": 9.187732580520981,
      "grad_norm": 0.005406038369983435,
      "learning_rate": 4.061657898113692e-05,
      "loss": 0.0,
      "step": 143200
    },
    {
      "epoch": 9.190940587706917,
      "grad_norm": 0.004476272035390139,
      "learning_rate": 4.045617862184011e-05,
      "loss": 0.0,
      "step": 143250
    },
    {
      "epoch": 9.194148594892853,
      "grad_norm": 0.008009047247469425,
      "learning_rate": 4.029577826254331e-05,
      "loss": 0.0,
      "step": 143300
    },
    {
      "epoch": 9.197356602078788,
      "grad_norm": 0.014717641286551952,
      "learning_rate": 4.0135377903246505e-05,
      "loss": 0.0,
      "step": 143350
    },
    {
      "epoch": 9.200564609264724,
      "grad_norm": 0.014682579785585403,
      "learning_rate": 3.99749775439497e-05,
      "loss": 0.0,
      "step": 143400
    },
    {
      "epoch": 9.20377261645066,
      "grad_norm": 0.01093656849116087,
      "learning_rate": 3.981457718465289e-05,
      "loss": 0.0,
      "step": 143450
    },
    {
      "epoch": 9.206980623636596,
      "grad_norm": 0.000978076714091003,
      "learning_rate": 3.965417682535609e-05,
      "loss": 0.0,
      "step": 143500
    },
    {
      "epoch": 9.210188630822532,
      "grad_norm": 0.0032575204968452454,
      "learning_rate": 3.9493776466059285e-05,
      "loss": 0.0,
      "step": 143550
    },
    {
      "epoch": 9.213396638008469,
      "grad_norm": 0.001819500233978033,
      "learning_rate": 3.933337610676248e-05,
      "loss": 0.0,
      "step": 143600
    },
    {
      "epoch": 9.216604645194405,
      "grad_norm": 0.008682003244757652,
      "learning_rate": 3.917297574746567e-05,
      "loss": 0.0,
      "step": 143650
    },
    {
      "epoch": 9.219812652380341,
      "grad_norm": 0.005115003325045109,
      "learning_rate": 3.901257538816887e-05,
      "loss": 0.0,
      "step": 143700
    },
    {
      "epoch": 9.223020659566277,
      "grad_norm": 0.003304069396108389,
      "learning_rate": 3.8852175028872065e-05,
      "loss": 0.0,
      "step": 143750
    },
    {
      "epoch": 9.226228666752213,
      "grad_norm": 0.004318371880799532,
      "learning_rate": 3.8691774669575266e-05,
      "loss": 0.0,
      "step": 143800
    },
    {
      "epoch": 9.22943667393815,
      "grad_norm": 0.0035049256402999163,
      "learning_rate": 3.853137431027846e-05,
      "loss": 0.0,
      "step": 143850
    },
    {
      "epoch": 9.232644681124086,
      "grad_norm": 0.00864371657371521,
      "learning_rate": 3.837097395098165e-05,
      "loss": 0.0,
      "step": 143900
    },
    {
      "epoch": 9.235852688310022,
      "grad_norm": 0.002795764012262225,
      "learning_rate": 3.8210573591684846e-05,
      "loss": 0.0,
      "step": 143950
    },
    {
      "epoch": 9.239060695495958,
      "grad_norm": 0.002248232252895832,
      "learning_rate": 3.805017323238804e-05,
      "loss": 0.0,
      "step": 144000
    },
    {
      "epoch": 9.242268702681894,
      "grad_norm": 0.010138792917132378,
      "learning_rate": 3.788977287309123e-05,
      "loss": 0.0,
      "step": 144050
    },
    {
      "epoch": 9.24547670986783,
      "grad_norm": 0.00423379335552454,
      "learning_rate": 3.7729372513794426e-05,
      "loss": 0.0,
      "step": 144100
    },
    {
      "epoch": 9.248684717053766,
      "grad_norm": 0.007442333269864321,
      "learning_rate": 3.756897215449763e-05,
      "loss": 0.0,
      "step": 144150
    },
    {
      "epoch": 9.251892724239703,
      "grad_norm": 0.007970744743943214,
      "learning_rate": 3.7408571795200826e-05,
      "loss": 0.0,
      "step": 144200
    },
    {
      "epoch": 9.255100731425639,
      "grad_norm": 0.0046999165788292885,
      "learning_rate": 3.724817143590402e-05,
      "loss": 0.0,
      "step": 144250
    },
    {
      "epoch": 9.258308738611575,
      "grad_norm": 0.004885038826614618,
      "learning_rate": 3.708777107660721e-05,
      "loss": 0.0,
      "step": 144300
    },
    {
      "epoch": 9.261516745797511,
      "grad_norm": 0.002891657641157508,
      "learning_rate": 3.6927370717310406e-05,
      "loss": 0.0,
      "step": 144350
    },
    {
      "epoch": 9.264724752983447,
      "grad_norm": 0.0007755238329991698,
      "learning_rate": 3.67669703580136e-05,
      "loss": 0.0,
      "step": 144400
    },
    {
      "epoch": 9.267932760169383,
      "grad_norm": 0.0041585867293179035,
      "learning_rate": 3.660656999871679e-05,
      "loss": 0.0,
      "step": 144450
    },
    {
      "epoch": 9.27114076735532,
      "grad_norm": 0.004380361642688513,
      "learning_rate": 3.6446169639419993e-05,
      "loss": 0.0,
      "step": 144500
    },
    {
      "epoch": 9.274348774541256,
      "grad_norm": 0.009349779225885868,
      "learning_rate": 3.628576928012319e-05,
      "loss": 0.0,
      "step": 144550
    },
    {
      "epoch": 9.27755678172719,
      "grad_norm": 0.004403689410537481,
      "learning_rate": 3.612536892082639e-05,
      "loss": 0.0,
      "step": 144600
    },
    {
      "epoch": 9.280764788913126,
      "grad_norm": 0.00380571186542511,
      "learning_rate": 3.596496856152958e-05,
      "loss": 0.0,
      "step": 144650
    },
    {
      "epoch": 9.283972796099063,
      "grad_norm": 0.0018330231541767716,
      "learning_rate": 3.5804568202232774e-05,
      "loss": 0.0,
      "step": 144700
    },
    {
      "epoch": 9.287180803284999,
      "grad_norm": 0.0032304516062140465,
      "learning_rate": 3.564416784293597e-05,
      "loss": 0.0,
      "step": 144750
    },
    {
      "epoch": 9.290388810470935,
      "grad_norm": 0.007527722977101803,
      "learning_rate": 3.548376748363916e-05,
      "loss": 0.0,
      "step": 144800
    },
    {
      "epoch": 9.293596817656871,
      "grad_norm": 0.008815576322376728,
      "learning_rate": 3.532336712434236e-05,
      "loss": 0.0,
      "step": 144850
    },
    {
      "epoch": 9.296804824842807,
      "grad_norm": 0.006927126087248325,
      "learning_rate": 3.5162966765045554e-05,
      "loss": 0.0,
      "step": 144900
    },
    {
      "epoch": 9.300012832028743,
      "grad_norm": 0.004148520994931459,
      "learning_rate": 3.500256640574875e-05,
      "loss": 0.0,
      "step": 144950
    },
    {
      "epoch": 9.30322083921468,
      "grad_norm": 0.0009876659605652094,
      "learning_rate": 3.484216604645195e-05,
      "loss": 0.0,
      "step": 145000
    },
    {
      "epoch": 9.306428846400616,
      "grad_norm": 0.007993053644895554,
      "learning_rate": 3.468176568715514e-05,
      "loss": 0.0,
      "step": 145050
    },
    {
      "epoch": 9.309636853586552,
      "grad_norm": 0.004019586369395256,
      "learning_rate": 3.4521365327858335e-05,
      "loss": 0.0,
      "step": 145100
    },
    {
      "epoch": 9.312844860772488,
      "grad_norm": 0.0028937323950231075,
      "learning_rate": 3.436096496856153e-05,
      "loss": 0.0,
      "step": 145150
    },
    {
      "epoch": 9.316052867958424,
      "grad_norm": 0.0054989224299788475,
      "learning_rate": 3.420056460926473e-05,
      "loss": 0.0,
      "step": 145200
    },
    {
      "epoch": 9.31926087514436,
      "grad_norm": 0.004672104027122259,
      "learning_rate": 3.404016424996792e-05,
      "loss": 0.0,
      "step": 145250
    },
    {
      "epoch": 9.322468882330297,
      "grad_norm": 0.006334870122373104,
      "learning_rate": 3.3879763890671115e-05,
      "loss": 0.0,
      "step": 145300
    },
    {
      "epoch": 9.325676889516233,
      "grad_norm": 0.012771852314472198,
      "learning_rate": 3.371936353137431e-05,
      "loss": 0.0,
      "step": 145350
    },
    {
      "epoch": 9.328884896702169,
      "grad_norm": 0.0028591479640454054,
      "learning_rate": 3.35589631720775e-05,
      "loss": 0.0,
      "step": 145400
    },
    {
      "epoch": 9.332092903888105,
      "grad_norm": 0.013072418980300426,
      "learning_rate": 3.33985628127807e-05,
      "loss": 0.0,
      "step": 145450
    },
    {
      "epoch": 9.335300911074041,
      "grad_norm": 0.0057634287513792515,
      "learning_rate": 3.3238162453483895e-05,
      "loss": 0.0,
      "step": 145500
    },
    {
      "epoch": 9.338508918259977,
      "grad_norm": 0.0009386106394231319,
      "learning_rate": 3.3077762094187095e-05,
      "loss": 0.0,
      "step": 145550
    },
    {
      "epoch": 9.341716925445914,
      "grad_norm": 0.00480604125186801,
      "learning_rate": 3.291736173489029e-05,
      "loss": 0.0,
      "step": 145600
    },
    {
      "epoch": 9.34492493263185,
      "grad_norm": 0.0012371264165267348,
      "learning_rate": 3.275696137559348e-05,
      "loss": 0.0,
      "step": 145650
    },
    {
      "epoch": 9.348132939817786,
      "grad_norm": 0.002195921028032899,
      "learning_rate": 3.2596561016296676e-05,
      "loss": 0.0,
      "step": 145700
    },
    {
      "epoch": 9.351340947003722,
      "grad_norm": 0.00827513262629509,
      "learning_rate": 3.243616065699987e-05,
      "loss": 0.0,
      "step": 145750
    },
    {
      "epoch": 9.354548954189656,
      "grad_norm": 0.0036708612460643053,
      "learning_rate": 3.227576029770306e-05,
      "loss": 0.0,
      "step": 145800
    },
    {
      "epoch": 9.357756961375593,
      "grad_norm": 0.0014166313922032714,
      "learning_rate": 3.211535993840627e-05,
      "loss": 0.0,
      "step": 145850
    },
    {
      "epoch": 9.360964968561529,
      "grad_norm": 0.006631351076066494,
      "learning_rate": 3.195495957910946e-05,
      "loss": 0.0,
      "step": 145900
    },
    {
      "epoch": 9.364172975747465,
      "grad_norm": 0.005713469348847866,
      "learning_rate": 3.1794559219812656e-05,
      "loss": 0.0,
      "step": 145950
    },
    {
      "epoch": 9.367380982933401,
      "grad_norm": 0.012908034957945347,
      "learning_rate": 3.163415886051585e-05,
      "loss": 0.0,
      "step": 146000
    },
    {
      "epoch": 9.370588990119337,
      "grad_norm": 0.004227156285196543,
      "learning_rate": 3.147375850121904e-05,
      "loss": 0.0,
      "step": 146050
    },
    {
      "epoch": 9.373796997305273,
      "grad_norm": 0.004478768445551395,
      "learning_rate": 3.1313358141922236e-05,
      "loss": 0.0,
      "step": 146100
    },
    {
      "epoch": 9.37700500449121,
      "grad_norm": 0.004563700873404741,
      "learning_rate": 3.115295778262543e-05,
      "loss": 0.0,
      "step": 146150
    },
    {
      "epoch": 9.380213011677146,
      "grad_norm": 0.007490737363696098,
      "learning_rate": 3.099255742332863e-05,
      "loss": 0.0,
      "step": 146200
    },
    {
      "epoch": 9.383421018863082,
      "grad_norm": 0.008804120123386383,
      "learning_rate": 3.083215706403182e-05,
      "loss": 0.0,
      "step": 146250
    },
    {
      "epoch": 9.386629026049018,
      "grad_norm": 0.006615867838263512,
      "learning_rate": 3.067175670473502e-05,
      "loss": 0.0,
      "step": 146300
    },
    {
      "epoch": 9.389837033234954,
      "grad_norm": 0.004326715599745512,
      "learning_rate": 3.0511356345438213e-05,
      "loss": 0.0,
      "step": 146350
    },
    {
      "epoch": 9.39304504042089,
      "grad_norm": 0.005120156332850456,
      "learning_rate": 3.035095598614141e-05,
      "loss": 0.0,
      "step": 146400
    },
    {
      "epoch": 9.396253047606827,
      "grad_norm": 0.007787839509546757,
      "learning_rate": 3.0190555626844607e-05,
      "loss": 0.0,
      "step": 146450
    },
    {
      "epoch": 9.399461054792763,
      "grad_norm": 0.0024789234157651663,
      "learning_rate": 3.00301552675478e-05,
      "loss": 0.0,
      "step": 146500
    },
    {
      "epoch": 9.402669061978699,
      "grad_norm": 0.0035961295943707228,
      "learning_rate": 2.9869754908250994e-05,
      "loss": 0.0,
      "step": 146550
    },
    {
      "epoch": 9.405877069164635,
      "grad_norm": 0.009268435649573803,
      "learning_rate": 2.9709354548954187e-05,
      "loss": 0.0,
      "step": 146600
    },
    {
      "epoch": 9.409085076350571,
      "grad_norm": 0.0052148159593343735,
      "learning_rate": 2.9548954189657387e-05,
      "loss": 0.0,
      "step": 146650
    },
    {
      "epoch": 9.412293083536508,
      "grad_norm": 0.0013626335421577096,
      "learning_rate": 2.938855383036058e-05,
      "loss": 0.0,
      "step": 146700
    },
    {
      "epoch": 9.415501090722444,
      "grad_norm": 0.007356718648225069,
      "learning_rate": 2.9228153471063774e-05,
      "loss": 0.0,
      "step": 146750
    },
    {
      "epoch": 9.41870909790838,
      "grad_norm": 0.00548042356967926,
      "learning_rate": 2.906775311176697e-05,
      "loss": 0.0,
      "step": 146800
    },
    {
      "epoch": 9.421917105094316,
      "grad_norm": 0.0043328506872057915,
      "learning_rate": 2.8907352752470168e-05,
      "loss": 0.0,
      "step": 146850
    },
    {
      "epoch": 9.425125112280252,
      "grad_norm": 0.0037663006223738194,
      "learning_rate": 2.874695239317336e-05,
      "loss": 0.0,
      "step": 146900
    },
    {
      "epoch": 9.428333119466188,
      "grad_norm": 0.001943409675732255,
      "learning_rate": 2.8586552033876555e-05,
      "loss": 0.0,
      "step": 146950
    },
    {
      "epoch": 9.431541126652125,
      "grad_norm": 0.002479101764038205,
      "learning_rate": 2.842615167457975e-05,
      "loss": 0.0,
      "step": 147000
    },
    {
      "epoch": 9.43474913383806,
      "grad_norm": 0.00906313769519329,
      "learning_rate": 2.8265751315282948e-05,
      "loss": 0.0,
      "step": 147050
    },
    {
      "epoch": 9.437957141023995,
      "grad_norm": 0.0035439094062894583,
      "learning_rate": 2.810535095598614e-05,
      "loss": 0.0,
      "step": 147100
    },
    {
      "epoch": 9.441165148209931,
      "grad_norm": 0.0021958444267511368,
      "learning_rate": 2.794495059668934e-05,
      "loss": 0.0,
      "step": 147150
    },
    {
      "epoch": 9.444373155395867,
      "grad_norm": 0.005972015205770731,
      "learning_rate": 2.7784550237392532e-05,
      "loss": 0.0,
      "step": 147200
    },
    {
      "epoch": 9.447581162581804,
      "grad_norm": 0.006455311551690102,
      "learning_rate": 2.7624149878095725e-05,
      "loss": 0.0,
      "step": 147250
    },
    {
      "epoch": 9.45078916976774,
      "grad_norm": 0.003539060475304723,
      "learning_rate": 2.7463749518798925e-05,
      "loss": 0.0,
      "step": 147300
    },
    {
      "epoch": 9.453997176953676,
      "grad_norm": 0.00827774964272976,
      "learning_rate": 2.730334915950212e-05,
      "loss": 0.0,
      "step": 147350
    },
    {
      "epoch": 9.457205184139612,
      "grad_norm": 0.005949812475591898,
      "learning_rate": 2.7142948800205312e-05,
      "loss": 0.0,
      "step": 147400
    },
    {
      "epoch": 9.460413191325548,
      "grad_norm": 0.0043286411091685295,
      "learning_rate": 2.6982548440908505e-05,
      "loss": 0.0,
      "step": 147450
    },
    {
      "epoch": 9.463621198511484,
      "grad_norm": 0.006127120926976204,
      "learning_rate": 2.6822148081611706e-05,
      "loss": 0.0,
      "step": 147500
    },
    {
      "epoch": 9.46682920569742,
      "grad_norm": 0.005476245656609535,
      "learning_rate": 2.66617477223149e-05,
      "loss": 0.0,
      "step": 147550
    },
    {
      "epoch": 9.470037212883357,
      "grad_norm": 0.0061652641743421555,
      "learning_rate": 2.6501347363018092e-05,
      "loss": 0.0,
      "step": 147600
    },
    {
      "epoch": 9.473245220069293,
      "grad_norm": 0.002495050663128495,
      "learning_rate": 2.634094700372129e-05,
      "loss": 0.0,
      "step": 147650
    },
    {
      "epoch": 9.476453227255229,
      "grad_norm": 0.0023273557890206575,
      "learning_rate": 2.6180546644424486e-05,
      "loss": 0.0,
      "step": 147700
    },
    {
      "epoch": 9.479661234441165,
      "grad_norm": 0.002232216065749526,
      "learning_rate": 2.602014628512768e-05,
      "loss": 0.0,
      "step": 147750
    },
    {
      "epoch": 9.482869241627101,
      "grad_norm": 0.00787664670497179,
      "learning_rate": 2.5859745925830873e-05,
      "loss": 0.0,
      "step": 147800
    },
    {
      "epoch": 9.486077248813038,
      "grad_norm": 0.0023925951682031155,
      "learning_rate": 2.569934556653407e-05,
      "loss": 0.0,
      "step": 147850
    },
    {
      "epoch": 9.489285255998974,
      "grad_norm": 0.0010137805948033929,
      "learning_rate": 2.5538945207237266e-05,
      "loss": 0.0,
      "step": 147900
    },
    {
      "epoch": 9.49249326318491,
      "grad_norm": 0.0012533528497442603,
      "learning_rate": 2.537854484794046e-05,
      "loss": 0.0,
      "step": 147950
    },
    {
      "epoch": 9.495701270370846,
      "grad_norm": 0.007388807833194733,
      "learning_rate": 2.5218144488643657e-05,
      "loss": 0.0,
      "step": 148000
    },
    {
      "epoch": 9.498909277556782,
      "grad_norm": 0.003103692550212145,
      "learning_rate": 2.505774412934685e-05,
      "loss": 0.0,
      "step": 148050
    },
    {
      "epoch": 9.502117284742718,
      "grad_norm": 0.009862869046628475,
      "learning_rate": 2.4897343770050043e-05,
      "loss": 0.0,
      "step": 148100
    },
    {
      "epoch": 9.505325291928655,
      "grad_norm": 0.0031817008275538683,
      "learning_rate": 2.473694341075324e-05,
      "loss": 0.0,
      "step": 148150
    },
    {
      "epoch": 9.50853329911459,
      "grad_norm": 0.00599679397419095,
      "learning_rate": 2.4576543051456437e-05,
      "loss": 0.0,
      "step": 148200
    },
    {
      "epoch": 9.511741306300527,
      "grad_norm": 0.0053764935582876205,
      "learning_rate": 2.441614269215963e-05,
      "loss": 0.0,
      "step": 148250
    },
    {
      "epoch": 9.514949313486461,
      "grad_norm": 0.004223999101668596,
      "learning_rate": 2.4255742332862824e-05,
      "loss": 0.0,
      "step": 148300
    },
    {
      "epoch": 9.518157320672398,
      "grad_norm": 0.003310732776299119,
      "learning_rate": 2.4095341973566024e-05,
      "loss": 0.0,
      "step": 148350
    },
    {
      "epoch": 9.521365327858334,
      "grad_norm": 0.005905747879296541,
      "learning_rate": 2.3934941614269217e-05,
      "loss": 0.0,
      "step": 148400
    },
    {
      "epoch": 9.52457333504427,
      "grad_norm": 0.005678359419107437,
      "learning_rate": 2.377454125497241e-05,
      "loss": 0.0,
      "step": 148450
    },
    {
      "epoch": 9.527781342230206,
      "grad_norm": 0.003706645220518112,
      "learning_rate": 2.3614140895675607e-05,
      "loss": 0.0,
      "step": 148500
    },
    {
      "epoch": 9.530989349416142,
      "grad_norm": 0.007004246581345797,
      "learning_rate": 2.3453740536378804e-05,
      "loss": 0.0,
      "step": 148550
    },
    {
      "epoch": 9.534197356602078,
      "grad_norm": 0.0035905467811971903,
      "learning_rate": 2.3293340177081998e-05,
      "loss": 0.0,
      "step": 148600
    },
    {
      "epoch": 9.537405363788015,
      "grad_norm": 0.0028638436924666166,
      "learning_rate": 2.313293981778519e-05,
      "loss": 0.0,
      "step": 148650
    },
    {
      "epoch": 9.54061337097395,
      "grad_norm": 0.0034179987851530313,
      "learning_rate": 2.2972539458488388e-05,
      "loss": 0.0,
      "step": 148700
    },
    {
      "epoch": 9.543821378159887,
      "grad_norm": 0.0031349854543805122,
      "learning_rate": 2.281213909919158e-05,
      "loss": 0.0,
      "step": 148750
    },
    {
      "epoch": 9.547029385345823,
      "grad_norm": 0.004987640772014856,
      "learning_rate": 2.2651738739894778e-05,
      "loss": 0.0,
      "step": 148800
    },
    {
      "epoch": 9.55023739253176,
      "grad_norm": 0.00515969330444932,
      "learning_rate": 2.2491338380597975e-05,
      "loss": 0.0,
      "step": 148850
    },
    {
      "epoch": 9.553445399717695,
      "grad_norm": 0.006744665559381247,
      "learning_rate": 2.2330938021301168e-05,
      "loss": 0.0,
      "step": 148900
    },
    {
      "epoch": 9.556653406903632,
      "grad_norm": 0.0031370967626571655,
      "learning_rate": 2.217053766200436e-05,
      "loss": 0.0,
      "step": 148950
    },
    {
      "epoch": 9.559861414089568,
      "grad_norm": 0.00592456990852952,
      "learning_rate": 2.201013730270756e-05,
      "loss": 0.0,
      "step": 149000
    },
    {
      "epoch": 9.563069421275504,
      "grad_norm": 0.0018024983583018184,
      "learning_rate": 2.1849736943410755e-05,
      "loss": 0.0,
      "step": 149050
    },
    {
      "epoch": 9.56627742846144,
      "grad_norm": 0.0022983828093856573,
      "learning_rate": 2.168933658411395e-05,
      "loss": 0.0,
      "step": 149100
    },
    {
      "epoch": 9.569485435647376,
      "grad_norm": 0.003924514167010784,
      "learning_rate": 2.1528936224817142e-05,
      "loss": 0.0,
      "step": 149150
    },
    {
      "epoch": 9.572693442833312,
      "grad_norm": 0.003423751099035144,
      "learning_rate": 2.1368535865520342e-05,
      "loss": 0.0,
      "step": 149200
    },
    {
      "epoch": 9.575901450019249,
      "grad_norm": 0.00201171962544322,
      "learning_rate": 2.1208135506223536e-05,
      "loss": 0.0,
      "step": 149250
    },
    {
      "epoch": 9.579109457205185,
      "grad_norm": 0.005066437181085348,
      "learning_rate": 2.104773514692673e-05,
      "loss": 0.0,
      "step": 149300
    },
    {
      "epoch": 9.58231746439112,
      "grad_norm": 0.0029921610839664936,
      "learning_rate": 2.0887334787629922e-05,
      "loss": 0.0,
      "step": 149350
    },
    {
      "epoch": 9.585525471577057,
      "grad_norm": 0.003307356731966138,
      "learning_rate": 2.072693442833312e-05,
      "loss": 0.0,
      "step": 149400
    },
    {
      "epoch": 9.588733478762993,
      "grad_norm": 0.0056906407698988914,
      "learning_rate": 2.0566534069036316e-05,
      "loss": 0.0,
      "step": 149450
    },
    {
      "epoch": 9.59194148594893,
      "grad_norm": 0.0029805090744048357,
      "learning_rate": 2.040613370973951e-05,
      "loss": 0.0,
      "step": 149500
    },
    {
      "epoch": 9.595149493134866,
      "grad_norm": 0.0037236297503113747,
      "learning_rate": 2.0245733350442706e-05,
      "loss": 0.0,
      "step": 149550
    },
    {
      "epoch": 9.5983575003208,
      "grad_norm": 0.005688222590833902,
      "learning_rate": 2.00853329911459e-05,
      "loss": 0.0,
      "step": 149600
    },
    {
      "epoch": 9.601565507506736,
      "grad_norm": 0.004468817263841629,
      "learning_rate": 1.9924932631849096e-05,
      "loss": 0.0,
      "step": 149650
    },
    {
      "epoch": 9.604773514692672,
      "grad_norm": 0.008176736533641815,
      "learning_rate": 1.9764532272552293e-05,
      "loss": 0.0,
      "step": 149700
    },
    {
      "epoch": 9.607981521878608,
      "grad_norm": 0.006134625058621168,
      "learning_rate": 1.9604131913255486e-05,
      "loss": 0.0,
      "step": 149750
    },
    {
      "epoch": 9.611189529064545,
      "grad_norm": 0.0022569713182747364,
      "learning_rate": 1.944373155395868e-05,
      "loss": 0.0,
      "step": 149800
    },
    {
      "epoch": 9.61439753625048,
      "grad_norm": 0.0035410316195338964,
      "learning_rate": 1.9283331194661877e-05,
      "loss": 0.0,
      "step": 149850
    },
    {
      "epoch": 9.617605543436417,
      "grad_norm": 0.007421317044645548,
      "learning_rate": 1.9122930835365073e-05,
      "loss": 0.0,
      "step": 149900
    },
    {
      "epoch": 9.620813550622353,
      "grad_norm": 0.004635235294699669,
      "learning_rate": 1.8962530476068267e-05,
      "loss": 0.0,
      "step": 149950
    },
    {
      "epoch": 9.62402155780829,
      "grad_norm": 0.004125402774661779,
      "learning_rate": 1.880213011677146e-05,
      "loss": 0.0,
      "step": 150000
    },
    {
      "epoch": 9.627229564994225,
      "grad_norm": 0.0006948456284590065,
      "learning_rate": 1.8641729757474657e-05,
      "loss": 0.0,
      "step": 150050
    },
    {
      "epoch": 9.630437572180162,
      "grad_norm": 0.003053635824471712,
      "learning_rate": 1.8481329398177854e-05,
      "loss": 0.0,
      "step": 150100
    },
    {
      "epoch": 9.633645579366098,
      "grad_norm": 0.004519457928836346,
      "learning_rate": 1.8320929038881047e-05,
      "loss": 0.0,
      "step": 150150
    },
    {
      "epoch": 9.636853586552034,
      "grad_norm": 0.003794265678152442,
      "learning_rate": 1.816052867958424e-05,
      "loss": 0.0,
      "step": 150200
    },
    {
      "epoch": 9.64006159373797,
      "grad_norm": 0.0020931612234562635,
      "learning_rate": 1.8000128320287437e-05,
      "loss": 0.0,
      "step": 150250
    },
    {
      "epoch": 9.643269600923906,
      "grad_norm": 0.0013776139821857214,
      "learning_rate": 1.7839727960990634e-05,
      "loss": 0.0,
      "step": 150300
    },
    {
      "epoch": 9.646477608109842,
      "grad_norm": 0.004384193103760481,
      "learning_rate": 1.7679327601693827e-05,
      "loss": 0.0,
      "step": 150350
    },
    {
      "epoch": 9.649685615295779,
      "grad_norm": 0.0022420932073146105,
      "learning_rate": 1.7518927242397024e-05,
      "loss": 0.0,
      "step": 150400
    },
    {
      "epoch": 9.652893622481715,
      "grad_norm": 0.0036610551178455353,
      "learning_rate": 1.7358526883100218e-05,
      "loss": 0.0,
      "step": 150450
    },
    {
      "epoch": 9.656101629667651,
      "grad_norm": 0.005966009106487036,
      "learning_rate": 1.7198126523803414e-05,
      "loss": 0.0,
      "step": 150500
    },
    {
      "epoch": 9.659309636853587,
      "grad_norm": 0.0035570901818573475,
      "learning_rate": 1.703772616450661e-05,
      "loss": 0.0,
      "step": 150550
    },
    {
      "epoch": 9.662517644039523,
      "grad_norm": 0.004367686342447996,
      "learning_rate": 1.6877325805209805e-05,
      "loss": 0.0,
      "step": 150600
    },
    {
      "epoch": 9.66572565122546,
      "grad_norm": 0.01125253364443779,
      "learning_rate": 1.6716925445912998e-05,
      "loss": 0.0,
      "step": 150650
    },
    {
      "epoch": 9.668933658411396,
      "grad_norm": 0.0014782187063246965,
      "learning_rate": 1.655652508661619e-05,
      "loss": 0.0,
      "step": 150700
    },
    {
      "epoch": 9.67214166559733,
      "grad_norm": 0.0061255330219864845,
      "learning_rate": 1.639612472731939e-05,
      "loss": 0.0,
      "step": 150750
    },
    {
      "epoch": 9.675349672783266,
      "grad_norm": 0.0058402144350111485,
      "learning_rate": 1.6235724368022585e-05,
      "loss": 0.0,
      "step": 150800
    },
    {
      "epoch": 9.678557679969202,
      "grad_norm": 0.0032099641393870115,
      "learning_rate": 1.607532400872578e-05,
      "loss": 0.0,
      "step": 150850
    },
    {
      "epoch": 9.681765687155139,
      "grad_norm": 0.006216126959770918,
      "learning_rate": 1.5914923649428975e-05,
      "loss": 0.0,
      "step": 150900
    },
    {
      "epoch": 9.684973694341075,
      "grad_norm": 0.004663299303501844,
      "learning_rate": 1.5754523290132172e-05,
      "loss": 0.0,
      "step": 150950
    },
    {
      "epoch": 9.68818170152701,
      "grad_norm": 0.0038167552556842566,
      "learning_rate": 1.5594122930835365e-05,
      "loss": 0.0,
      "step": 151000
    },
    {
      "epoch": 9.691389708712947,
      "grad_norm": 0.002016832586377859,
      "learning_rate": 1.543372257153856e-05,
      "loss": 0.0,
      "step": 151050
    },
    {
      "epoch": 9.694597715898883,
      "grad_norm": 0.004345369059592485,
      "learning_rate": 1.5273322212241756e-05,
      "loss": 0.0,
      "step": 151100
    },
    {
      "epoch": 9.69780572308482,
      "grad_norm": 0.00545247457921505,
      "learning_rate": 1.511292185294495e-05,
      "loss": 0.0,
      "step": 151150
    },
    {
      "epoch": 9.701013730270756,
      "grad_norm": 0.0051566497422754765,
      "learning_rate": 1.4952521493648147e-05,
      "loss": 0.0,
      "step": 151200
    },
    {
      "epoch": 9.704221737456692,
      "grad_norm": 0.0037622787058353424,
      "learning_rate": 1.479212113435134e-05,
      "loss": 0.0,
      "step": 151250
    },
    {
      "epoch": 9.707429744642628,
      "grad_norm": 0.004069138318300247,
      "learning_rate": 1.4631720775054536e-05,
      "loss": 0.0,
      "step": 151300
    },
    {
      "epoch": 9.710637751828564,
      "grad_norm": 0.004569368436932564,
      "learning_rate": 1.4471320415757731e-05,
      "loss": 0.0,
      "step": 151350
    },
    {
      "epoch": 9.7138457590145,
      "grad_norm": 0.006739427801221609,
      "learning_rate": 1.4310920056460926e-05,
      "loss": 0.0,
      "step": 151400
    },
    {
      "epoch": 9.717053766200436,
      "grad_norm": 0.002694010967388749,
      "learning_rate": 1.4150519697164123e-05,
      "loss": 0.0,
      "step": 151450
    },
    {
      "epoch": 9.720261773386373,
      "grad_norm": 0.0015504026087000966,
      "learning_rate": 1.3990119337867316e-05,
      "loss": 0.0,
      "step": 151500
    },
    {
      "epoch": 9.723469780572309,
      "grad_norm": 0.007400341797620058,
      "learning_rate": 1.3829718978570513e-05,
      "loss": 0.0,
      "step": 151550
    },
    {
      "epoch": 9.726677787758245,
      "grad_norm": 0.0009308310109190643,
      "learning_rate": 1.3669318619273706e-05,
      "loss": 0.0,
      "step": 151600
    },
    {
      "epoch": 9.729885794944181,
      "grad_norm": 0.0026524055283516645,
      "learning_rate": 1.3508918259976903e-05,
      "loss": 0.0,
      "step": 151650
    },
    {
      "epoch": 9.733093802130117,
      "grad_norm": 0.003836130490526557,
      "learning_rate": 1.3348517900680098e-05,
      "loss": 0.0,
      "step": 151700
    },
    {
      "epoch": 9.736301809316053,
      "grad_norm": 0.0015806646551936865,
      "learning_rate": 1.3188117541383293e-05,
      "loss": 0.0,
      "step": 151750
    },
    {
      "epoch": 9.73950981650199,
      "grad_norm": 0.0032702209427952766,
      "learning_rate": 1.3027717182086488e-05,
      "loss": 0.0,
      "step": 151800
    },
    {
      "epoch": 9.742717823687926,
      "grad_norm": 0.009344605728983879,
      "learning_rate": 1.2867316822789684e-05,
      "loss": 0.0,
      "step": 151850
    },
    {
      "epoch": 9.745925830873862,
      "grad_norm": 0.003615956986322999,
      "learning_rate": 1.2706916463492879e-05,
      "loss": 0.0,
      "step": 151900
    },
    {
      "epoch": 9.749133838059798,
      "grad_norm": 0.0026516488287597895,
      "learning_rate": 1.2546516104196074e-05,
      "loss": 0.0,
      "step": 151950
    },
    {
      "epoch": 9.752341845245734,
      "grad_norm": 0.0007438577013090253,
      "learning_rate": 1.2386115744899269e-05,
      "loss": 0.0,
      "step": 152000
    },
    {
      "epoch": 9.75554985243167,
      "grad_norm": 0.008453400805592537,
      "learning_rate": 1.2225715385602464e-05,
      "loss": 0.0,
      "step": 152050
    },
    {
      "epoch": 9.758757859617605,
      "grad_norm": 0.003363407216966152,
      "learning_rate": 1.2065315026305659e-05,
      "loss": 0.0,
      "step": 152100
    },
    {
      "epoch": 9.761965866803541,
      "grad_norm": 0.00667907390743494,
      "learning_rate": 1.1904914667008854e-05,
      "loss": 0.0,
      "step": 152150
    },
    {
      "epoch": 9.765173873989477,
      "grad_norm": 0.001986835617572069,
      "learning_rate": 1.174451430771205e-05,
      "loss": 0.0,
      "step": 152200
    },
    {
      "epoch": 9.768381881175413,
      "grad_norm": 0.0006849127821624279,
      "learning_rate": 1.1584113948415244e-05,
      "loss": 0.0,
      "step": 152250
    },
    {
      "epoch": 9.77158988836135,
      "grad_norm": 0.004047578666359186,
      "learning_rate": 1.1423713589118441e-05,
      "loss": 0.0,
      "step": 152300
    },
    {
      "epoch": 9.774797895547286,
      "grad_norm": 0.0020715254358947277,
      "learning_rate": 1.1263313229821634e-05,
      "loss": 0.0,
      "step": 152350
    },
    {
      "epoch": 9.778005902733222,
      "grad_norm": 0.001516138669103384,
      "learning_rate": 1.1102912870524831e-05,
      "loss": 0.0,
      "step": 152400
    },
    {
      "epoch": 9.781213909919158,
      "grad_norm": 0.006060726474970579,
      "learning_rate": 1.0942512511228025e-05,
      "loss": 0.0,
      "step": 152450
    },
    {
      "epoch": 9.784421917105094,
      "grad_norm": 0.008352640084922314,
      "learning_rate": 1.0782112151931221e-05,
      "loss": 0.0,
      "step": 152500
    },
    {
      "epoch": 9.78762992429103,
      "grad_norm": 0.002164336619898677,
      "learning_rate": 1.0621711792634415e-05,
      "loss": 0.0,
      "step": 152550
    },
    {
      "epoch": 9.790837931476966,
      "grad_norm": 0.0016174395568668842,
      "learning_rate": 1.0461311433337612e-05,
      "loss": 0.0,
      "step": 152600
    },
    {
      "epoch": 9.794045938662903,
      "grad_norm": 0.003128107637166977,
      "learning_rate": 1.0300911074040807e-05,
      "loss": 0.0,
      "step": 152650
    },
    {
      "epoch": 9.797253945848839,
      "grad_norm": 0.003814465133473277,
      "learning_rate": 1.0140510714744e-05,
      "loss": 0.0,
      "step": 152700
    },
    {
      "epoch": 9.800461953034775,
      "grad_norm": 0.0031039223540574312,
      "learning_rate": 9.980110355447197e-06,
      "loss": 0.0,
      "step": 152750
    },
    {
      "epoch": 9.803669960220711,
      "grad_norm": 0.0038003467489033937,
      "learning_rate": 9.81970999615039e-06,
      "loss": 0.0,
      "step": 152800
    },
    {
      "epoch": 9.806877967406647,
      "grad_norm": 0.0034373984672129154,
      "learning_rate": 9.659309636853587e-06,
      "loss": 0.0,
      "step": 152850
    },
    {
      "epoch": 9.810085974592583,
      "grad_norm": 0.007107817567884922,
      "learning_rate": 9.498909277556782e-06,
      "loss": 0.0,
      "step": 152900
    },
    {
      "epoch": 9.81329398177852,
      "grad_norm": 0.0010765069164335728,
      "learning_rate": 9.338508918259977e-06,
      "loss": 0.0,
      "step": 152950
    },
    {
      "epoch": 9.816501988964456,
      "grad_norm": 0.005738299340009689,
      "learning_rate": 9.178108558963172e-06,
      "loss": 0.0,
      "step": 153000
    },
    {
      "epoch": 9.819709996150392,
      "grad_norm": 0.004045792855322361,
      "learning_rate": 9.017708199666367e-06,
      "loss": 0.0,
      "step": 153050
    },
    {
      "epoch": 9.822918003336328,
      "grad_norm": 0.004447369370609522,
      "learning_rate": 8.857307840369563e-06,
      "loss": 0.0,
      "step": 153100
    },
    {
      "epoch": 9.826126010522264,
      "grad_norm": 0.00811356958001852,
      "learning_rate": 8.696907481072758e-06,
      "loss": 0.0,
      "step": 153150
    },
    {
      "epoch": 9.8293340177082,
      "grad_norm": 0.0061824447475373745,
      "learning_rate": 8.536507121775953e-06,
      "loss": 0.0,
      "step": 153200
    },
    {
      "epoch": 9.832542024894135,
      "grad_norm": 0.002339431084692478,
      "learning_rate": 8.37610676247915e-06,
      "loss": 0.0,
      "step": 153250
    },
    {
      "epoch": 9.835750032080071,
      "grad_norm": 0.002148424042388797,
      "learning_rate": 8.215706403182343e-06,
      "loss": 0.0,
      "step": 153300
    },
    {
      "epoch": 9.838958039266007,
      "grad_norm": 0.005611301865428686,
      "learning_rate": 8.055306043885538e-06,
      "loss": 0.0,
      "step": 153350
    },
    {
      "epoch": 9.842166046451943,
      "grad_norm": 0.003751615760847926,
      "learning_rate": 7.894905684588733e-06,
      "loss": 0.0,
      "step": 153400
    },
    {
      "epoch": 9.84537405363788,
      "grad_norm": 0.0024806393776088953,
      "learning_rate": 7.734505325291928e-06,
      "loss": 0.0,
      "step": 153450
    },
    {
      "epoch": 9.848582060823816,
      "grad_norm": 0.0010211481712758541,
      "learning_rate": 7.574104965995124e-06,
      "loss": 0.0,
      "step": 153500
    },
    {
      "epoch": 9.851790068009752,
      "grad_norm": 0.007435924373567104,
      "learning_rate": 7.413704606698319e-06,
      "loss": 0.0,
      "step": 153550
    },
    {
      "epoch": 9.854998075195688,
      "grad_norm": 0.0025844431947916746,
      "learning_rate": 7.253304247401514e-06,
      "loss": 0.0,
      "step": 153600
    },
    {
      "epoch": 9.858206082381624,
      "grad_norm": 0.0007801452884450555,
      "learning_rate": 7.092903888104709e-06,
      "loss": 0.0,
      "step": 153650
    },
    {
      "epoch": 9.86141408956756,
      "grad_norm": 0.0018942103488370776,
      "learning_rate": 6.9325035288079045e-06,
      "loss": 0.0,
      "step": 153700
    },
    {
      "epoch": 9.864622096753497,
      "grad_norm": 0.006712656002491713,
      "learning_rate": 6.7721031695110996e-06,
      "loss": 0.0,
      "step": 153750
    },
    {
      "epoch": 9.867830103939433,
      "grad_norm": 0.0031078679021447897,
      "learning_rate": 6.611702810214295e-06,
      "loss": 0.0,
      "step": 153800
    },
    {
      "epoch": 9.871038111125369,
      "grad_norm": 0.006633069831877947,
      "learning_rate": 6.45130245091749e-06,
      "loss": 0.0,
      "step": 153850
    },
    {
      "epoch": 9.874246118311305,
      "grad_norm": 0.006337794475257397,
      "learning_rate": 6.290902091620685e-06,
      "loss": 0.0,
      "step": 153900
    },
    {
      "epoch": 9.877454125497241,
      "grad_norm": 0.0066010430455207825,
      "learning_rate": 6.130501732323881e-06,
      "loss": 0.0,
      "step": 153950
    },
    {
      "epoch": 9.880662132683177,
      "grad_norm": 0.0021691080182790756,
      "learning_rate": 5.970101373027076e-06,
      "loss": 0.0,
      "step": 154000
    },
    {
      "epoch": 9.883870139869114,
      "grad_norm": 0.004016765858978033,
      "learning_rate": 5.809701013730271e-06,
      "loss": 0.0,
      "step": 154050
    },
    {
      "epoch": 9.88707814705505,
      "grad_norm": 0.0029199630953371525,
      "learning_rate": 5.649300654433466e-06,
      "loss": 0.0,
      "step": 154100
    },
    {
      "epoch": 9.890286154240986,
      "grad_norm": 0.003789475653320551,
      "learning_rate": 5.488900295136661e-06,
      "loss": 0.0,
      "step": 154150
    },
    {
      "epoch": 9.893494161426922,
      "grad_norm": 0.0037638526409864426,
      "learning_rate": 5.328499935839857e-06,
      "loss": 0.0,
      "step": 154200
    },
    {
      "epoch": 9.896702168612858,
      "grad_norm": 0.008714472874999046,
      "learning_rate": 5.168099576543052e-06,
      "loss": 0.0,
      "step": 154250
    },
    {
      "epoch": 9.899910175798794,
      "grad_norm": 0.0013968860730528831,
      "learning_rate": 5.007699217246247e-06,
      "loss": 0.0,
      "step": 154300
    },
    {
      "epoch": 9.90311818298473,
      "grad_norm": 0.0033533782698214054,
      "learning_rate": 4.8472988579494415e-06,
      "loss": 0.0,
      "step": 154350
    },
    {
      "epoch": 9.906326190170667,
      "grad_norm": 0.001692110556177795,
      "learning_rate": 4.686898498652637e-06,
      "loss": 0.0,
      "step": 154400
    },
    {
      "epoch": 9.909534197356603,
      "grad_norm": 0.0026441318914294243,
      "learning_rate": 4.526498139355832e-06,
      "loss": 0.0,
      "step": 154450
    },
    {
      "epoch": 9.912742204542539,
      "grad_norm": 0.0052615441381931305,
      "learning_rate": 4.366097780059028e-06,
      "loss": 0.0,
      "step": 154500
    },
    {
      "epoch": 9.915950211728473,
      "grad_norm": 0.00609968975186348,
      "learning_rate": 4.205697420762223e-06,
      "loss": 0.0,
      "step": 154550
    },
    {
      "epoch": 9.91915821891441,
      "grad_norm": 0.004901425912976265,
      "learning_rate": 4.045297061465418e-06,
      "loss": 0.0,
      "step": 154600
    },
    {
      "epoch": 9.922366226100346,
      "grad_norm": 0.006134135648608208,
      "learning_rate": 3.884896702168613e-06,
      "loss": 0.0,
      "step": 154650
    },
    {
      "epoch": 9.925574233286282,
      "grad_norm": 0.0021221197675913572,
      "learning_rate": 3.724496342871808e-06,
      "loss": 0.0,
      "step": 154700
    },
    {
      "epoch": 9.928782240472218,
      "grad_norm": 0.0019306718604639173,
      "learning_rate": 3.5640959835750035e-06,
      "loss": 0.0,
      "step": 154750
    },
    {
      "epoch": 9.931990247658154,
      "grad_norm": 0.005112659651786089,
      "learning_rate": 3.4036956242781986e-06,
      "loss": 0.0,
      "step": 154800
    },
    {
      "epoch": 9.93519825484409,
      "grad_norm": 0.004626802634447813,
      "learning_rate": 3.2432952649813932e-06,
      "loss": 0.0,
      "step": 154850
    },
    {
      "epoch": 9.938406262030027,
      "grad_norm": 0.003320195944979787,
      "learning_rate": 3.0828949056845888e-06,
      "loss": 0.0,
      "step": 154900
    },
    {
      "epoch": 9.941614269215963,
      "grad_norm": 0.003216072218492627,
      "learning_rate": 2.922494546387784e-06,
      "loss": 0.0,
      "step": 154950
    },
    {
      "epoch": 9.944822276401899,
      "grad_norm": 0.0033801598474383354,
      "learning_rate": 2.762094187090979e-06,
      "loss": 0.0,
      "step": 155000
    },
    {
      "epoch": 9.948030283587835,
      "grad_norm": 0.001124209607951343,
      "learning_rate": 2.6016938277941744e-06,
      "loss": 0.0,
      "step": 155050
    },
    {
      "epoch": 9.951238290773771,
      "grad_norm": 0.0032625936437398195,
      "learning_rate": 2.4412934684973695e-06,
      "loss": 0.0,
      "step": 155100
    },
    {
      "epoch": 9.954446297959707,
      "grad_norm": 0.0062470100820064545,
      "learning_rate": 2.280893109200565e-06,
      "loss": 0.0,
      "step": 155150
    },
    {
      "epoch": 9.957654305145644,
      "grad_norm": 0.003497391240671277,
      "learning_rate": 2.1204927499037597e-06,
      "loss": 0.0,
      "step": 155200
    },
    {
      "epoch": 9.96086231233158,
      "grad_norm": 0.003038556082174182,
      "learning_rate": 1.960092390606955e-06,
      "loss": 0.0,
      "step": 155250
    },
    {
      "epoch": 9.964070319517516,
      "grad_norm": 0.0014884701231494546,
      "learning_rate": 1.7996920313101501e-06,
      "loss": 0.0,
      "step": 155300
    },
    {
      "epoch": 9.967278326703452,
      "grad_norm": 0.005048555321991444,
      "learning_rate": 1.6392916720133454e-06,
      "loss": 0.0,
      "step": 155350
    },
    {
      "epoch": 9.970486333889388,
      "grad_norm": 0.003953240811824799,
      "learning_rate": 1.4788913127165405e-06,
      "loss": 0.0,
      "step": 155400
    },
    {
      "epoch": 9.973694341075324,
      "grad_norm": 0.002761989366263151,
      "learning_rate": 1.3184909534197356e-06,
      "loss": 0.0,
      "step": 155450
    },
    {
      "epoch": 9.97690234826126,
      "grad_norm": 0.005563091486692429,
      "learning_rate": 1.158090594122931e-06,
      "loss": 0.0,
      "step": 155500
    }
  ],
  "logging_steps": 50,
  "max_steps": 155860,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
